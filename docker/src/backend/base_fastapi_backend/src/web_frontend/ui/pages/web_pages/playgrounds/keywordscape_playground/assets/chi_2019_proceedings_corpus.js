export const chi_2019_proceedings_corpus = [{"uri": "0", "title": "Moderation Practices as Emotional Labor in Sustaining Online Communities: The Case of AAPI Identity Work on Reddit", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Bryan Dosono", "Bryan Semaan"], "summary": "We examine how and why Asian American and Pacific Islander (AAPI) moderators on Reddit shape the norms of their online communities through the analytic lens of emotional labor. We conduct interviews with 21 moderators who facilitate identity work discourse in AAPI subreddits and present a thematic analysis of their moderation practices. We report on their challenges to sustaining moderation, which include burning out from volunteer work, navigating hierarchical structures, and balancing unfulfilled expectations. We then describe strategies that moderators employ to manage emotional labor, which involve distancing away from drama, building solidarity from shared struggles, and integrating an ecology of tools for self-organized moderation. We provide recommendations for improving moderation in online communities centered around identity work and discuss implications of emotional labor in the design of Reddit and similar platforms.", "keywords": ["process", "redditors", "identity", "time", "need", "reddit", "discussion", "self", "interview", "provide", "engaged", "woman", "labor", "user", "shared", "moderator", "work", "engage", "tool", "space", "participant", "people", "group", "aapis", "subreddit", "post", "team", "range", "way", "moderation", "sense", "mean", "service", "page", "experience", "subreddits", "content", "norm", "form", "deliberation", "drama", "comment", "volunteer", "member", "practice", "asianamerican", "day", "study", "role", "topic", "support", "aapi", "sphere", "research", "platform", "r", "paper", "harassment", "behavior", "value", "context", "community"], "document_vector": [-85.736907, 52.572536], "paragraphs": [{"paragraph_vector": [57.845039, -57.218429], "paragraph_keywords": ["work", "identity", "identities", "copies"]}, {"paragraph_vector": [49.83086, -49.29779], "paragraph_keywords": ["identity", "work", "engage", "aapis"]}, {"paragraph_vector": [55.270763, -50.124061], "paragraph_keywords": ["identity", "work", "group", "people"]}, {"paragraph_vector": [46.569648, -47.958126], "paragraph_keywords": ["community", "emotion", "labor", "work"]}, {"paragraph_vector": [52.520492, -49.675449], "paragraph_keywords": ["platform", "work", "passengers", "communities"]}, {"paragraph_vector": [51.806941, -48.605522], "paragraph_keywords": ["moderators", "rules", "subreddit", "reddit"]}, {"paragraph_vector": [55.147212, -52.758808], "paragraph_keywords": ["moderators", "subreddits", "aapi", "users"]}, {"paragraph_vector": [53.368827, -60.256015], "paragraph_keywords": ["moderator", "subreddits", "r", "reddit"]}, {"paragraph_vector": [55.624504, -50.004066], "paragraph_keywords": ["participants", "moderators", "aapi", "themes"]}, {"paragraph_vector": [57.007225, -50.939712], "paragraph_keywords": ["volunteer", "moderators", "burnout", "community"]}, {"paragraph_vector": [51.464599, -48.261081], "paragraph_keywords": ["moderation", "subreddits", "moderators", "r"]}, {"paragraph_vector": [47.370407, -51.72956], "paragraph_keywords": ["r", "subreddit", "asianamerican", "redditors"]}, {"paragraph_vector": [44.661651, -50.935218], "paragraph_keywords": ["moderators", "subreddit", "people", "r"]}, {"paragraph_vector": [52.506996, -48.309532], "paragraph_keywords": ["drama", "shared", "moderation", "subreddits"]}, {"paragraph_vector": [48.96331, -48.317222], "paragraph_keywords": ["labor", "redditors", "reddit", "work"]}, {"paragraph_vector": [57.437789, -46.53659], "paragraph_keywords": ["moderators", "r", "harassment", "redditors"]}, {"paragraph_vector": [52.034801, -48.965885], "paragraph_keywords": ["moderators", "need", "work", "solidarity"]}, {"paragraph_vector": [31.450664, -76.3069], "paragraph_keywords": ["post", "mods", "reddit", "remove"]}, {"paragraph_vector": [52.503868, -49.278789], "paragraph_keywords": ["moderators", "work", "reddit", "content"]}, {"paragraph_vector": [56.767551, -49.536846], "paragraph_keywords": ["moderators", "content", "moderation", "harassment"]}, {"paragraph_vector": [50.319118, -50.033187], "paragraph_keywords": ["identity", "values", "work", "reddit"]}, {"paragraph_vector": [51.331989, -50.037006], "paragraph_keywords": ["support", "crisis", "moderation", "disclosures"]}, {"paragraph_vector": [52.357936, -50.155899], "paragraph_keywords": ["labor", "material", "moderators", "communities"]}, {"paragraph_vector": [52.199409, -49.496128], "paragraph_keywords": ["experiences", "work", "study", "paper"]}], "content": {}, "doi": "10.1145/3290605.3300313"}, {"uri": "1", "title": "Personal Health Oracle: Explorations of Personalized Predictions in Diabetes Self-Management", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Pooja M. Desai", "Maria L. Hwang", "Lena Mamykina", "Elliot G. Mitchell"], "summary": "The increasing availability of health data and knowledge about computationally modeling human physiology opens new opportunities for personalized predictions in health. Yet little is known about how individuals interact and reason with personalized predictions. To explore these questions, we developed a smartphone app, GlucOracle, that uses selftracking data of individuals with type 2 diabetes to generate personalized forecasts for post-meal blood glucose levels. We pilot-tested GlucOracle with two populations: members of an online diabetes community, knowledgeable about diabetes and technologically savvy; and individuals from a low socio-economic status community, characterized by high prevalence of diabetes, low literacy, and limited experience with mobile apps. Individuals in both communities engaged with personal glucose forecasts and found them useful for adjusting immediate meal options, and planning future meals. However, the study raised new questions as to appropriate time, form, and focus of forecasts and suggested new research directions for personalized predictions in health. \u2217Asterisk ( * ) denotes equal contribution by authors Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300600", "keywords": ["time", "change", "perceived", "need", "information", "self", "app", "provide", "example", "help", "forecast", "user", "bg", "engagement", "know", "decision", "blood", "rds", "work", "management", "impact", "participant", "nutrition", "tool", "use", "glucose", "personalized", "learning", "health", "glucoracle", "experience", "found", "feedback", "tracking", "meal", "novice", "data", "technology", "study", "prediction", "diabetes", "support", "choice", "research", "eat", "individual", "eating", "adopter", "level", "community"], "document_vector": [15.017683, 53.540378], "paragraphs": [{"paragraph_vector": [36.945087, -11.912113], "paragraph_keywords": ["health", "data", "diabetes", "systems"]}, {"paragraph_vector": [33.71352, -10.86044], "paragraph_keywords": ["individuals", "impact", "bg", "users"]}, {"paragraph_vector": [33.293811, -10.240142], "paragraph_keywords": ["forecasts", "individuals", "decision", "app"]}, {"paragraph_vector": [34.159282, -9.986032], "paragraph_keywords": ["individuals", "users", "traffic", "forecasts"]}, {"paragraph_vector": [34.981983, -8.935541], "paragraph_keywords": ["users", "health", "changes", "impact"]}, {"paragraph_vector": [34.411983, -10.853583], "paragraph_keywords": ["glucoracle", "forecasts", "meal", "personalized"]}, {"paragraph_vector": [34.112403, -8.813656], "paragraph_keywords": ["users", "diabetes", "assessment", "glucoracle"]}, {"paragraph_vector": [35.391578, -8.469312], "paragraph_keywords": ["participants", "app", "individuals", "adopters"]}, {"paragraph_vector": [35.614658, -11.02263], "paragraph_keywords": ["meals", "study", "analysis", "forecasts"]}, {"paragraph_vector": [35.104907, -9.057917], "paragraph_keywords": ["participants", "meals", "nutrition", "diabetes"]}, {"paragraph_vector": [36.145946, -9.825051], "paragraph_keywords": ["meals", "impact", "nutrition", "diabetes"]}, {"paragraph_vector": [36.154628, -8.843661], "paragraph_keywords": ["individuals", "levels", "need", "forecasts"]}, {"paragraph_vector": [35.813682, -7.09675], "paragraph_keywords": ["adopters", "meals", "found", "novice"]}, {"paragraph_vector": [35.318336, -7.700833], "paragraph_keywords": ["rds", "perceived", "meals", "fat"]}, {"paragraph_vector": [35.450538, -9.333611], "paragraph_keywords": ["meals", "rds", "feedback", "know"]}, {"paragraph_vector": [34.150058, -9.226664], "paragraph_keywords": ["forecasts", "predictions", "perceived", "participants"]}, {"paragraph_vector": [33.339351, -8.812495], "paragraph_keywords": ["range", "forecasts", "adopters", "curves"]}, {"paragraph_vector": [32.37247, -8.047725], "paragraph_keywords": ["meal", "forecasts", "planned", "eat"]}, {"paragraph_vector": [33.588489, -8.877628], "paragraph_keywords": ["forecasts", "time", "meal", "impact"]}, {"paragraph_vector": [34.249332, -8.689948], "paragraph_keywords": ["impact", "forecasts", "individuals", "levels"]}, {"paragraph_vector": [33.666709, -8.890714], "paragraph_keywords": ["forecasts", "meal", "individuals", "health"]}, {"paragraph_vector": [38.011783, -11.484392], "paragraph_keywords": ["adoption", "experience", "tracking", "practices"]}, {"paragraph_vector": [36.194313, -12.87978], "paragraph_keywords": ["self", "support", "management", "tools"]}, {"paragraph_vector": [36.071281, -10.624068], "paragraph_keywords": ["decision", "learning", "engagement", "use"]}, {"paragraph_vector": [34.199165, -8.751351], "paragraph_keywords": ["forecasts", "research", "health", "diabetes"]}], "content": {}, "doi": "10.1145/3290605.3300316"}, {"uri": "2", "title": "Ethical Mediation in UX Practice", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Colin M. Gray", "Shruthi Sai Chivukula"], "summary": "HCI scholars have become increasingly interested in describing the complex nature of UX practice. In parallel, HCI and STS scholars have sought to describe the ethical and valueladen relationship between designers and design outcomes. However, little research describes the ethical engagement of UX practitioners as a form of design complexity, including the multiple mediating factors that impact ethical awareness and decision-making. In this paper, we use a practice-led approach to describe ethical complexity, presenting three varied cases of UX practitioners based on in situ observations and interviews. In each case, we describe salient factors relating to ethical mediation, including organizational practices, self-driven ethical principles, and unique characteristics of specific projects the practitioner is engaged in. Using the concept of mediation from activity theory, we provide a rich account of practitioners\u2019 ethical decision making. We propose future work on ethical awareness and design education based on the concept of ethical mediation.", "keywords": ["complexity", "process", "based", "set", "design", "focus", "john", "goal", "describe", "user", "activity", "interaction", "decision", "work", "engage", "allowing", "participant", "use", "agency", "client", "team", "mediation", "range", "factor", "experience", "including", "understand", "awareness", "identified", "case", "value", "practice", "james", "organization", "researcher", "study", "role", "designer", "ethic", "research", "consideration", "perspective", "observation", "knowledge", "project", "making"], "document_vector": [57.844329, 31.375082], "paragraphs": [{"paragraph_vector": [109.868133, -29.737466], "paragraph_keywords": ["design", "practice", "hci", "copies"]}, {"paragraph_vector": [106.686378, -21.385736], "paragraph_keywords": ["design", "ethics", "practice", "decision"]}, {"paragraph_vector": [112.490798, -14.648508], "paragraph_keywords": ["ethics", "design", "describe", "practice"]}, {"paragraph_vector": [108.270774, -24.117645], "paragraph_keywords": ["practice", "design", "values", "ethics"]}, {"paragraph_vector": [111.397476, -21.745599], "paragraph_keywords": ["work", "design", "shaped", "describe"]}, {"paragraph_vector": [110.017829, -18.77635], "paragraph_keywords": ["study", "case", "participants", "design"]}, {"paragraph_vector": [104.079307, -25.127065], "paragraph_keywords": ["participants", "work", "participant", "case"]}, {"paragraph_vector": [110.050529, -20.431415], "paragraph_keywords": ["decisions", "notes", "participants", "observations"]}, {"paragraph_vector": [114.584953, -35.465747], "paragraph_keywords": ["practices", "participant", "themes", "case"]}, {"paragraph_vector": [97.10794, -15.803575], "paragraph_keywords": ["agency", "design", "role", "projects"]}, {"paragraph_vector": [111.740623, -15.082286], "paragraph_keywords": ["john", "client", "clients", "projects"]}, {"paragraph_vector": [97.742347, -16.593666], "paragraph_keywords": ["john", "design", "clients", "user"]}, {"paragraph_vector": [93.91584, -17.540987], "paragraph_keywords": ["design", "james", "client", "solutions"]}, {"paragraph_vector": [100.652626, -25.675754], "paragraph_keywords": ["design", "knowledge", "judgments", "team"]}, {"paragraph_vector": [103.00077, -21.275751], "paragraph_keywords": ["trends", "agency", "allowing", "develop"]}, {"paragraph_vector": [88.921417, -2.367769], "paragraph_keywords": ["functionality", "users", "goal", "user"]}, {"paragraph_vector": [100.303352, -13.937655], "paragraph_keywords": ["design", "user", "work", "experience"]}, {"paragraph_vector": [102.293022, -16.696916], "paragraph_keywords": ["team", "work", "design", "features"]}, {"paragraph_vector": [105.067672, -10.865781], "paragraph_keywords": ["ui", "designers", "design", "library"]}, {"paragraph_vector": [105.465332, -20.192974], "paragraph_keywords": ["design", "practices", "knowledge", "ways"]}, {"paragraph_vector": [104.891067, -18.649137], "paragraph_keywords": ["practices", "design", "john", "ethics"]}, {"paragraph_vector": [107.802436, -20.848487], "paragraph_keywords": ["practices", "design", "complexity", "values"]}, {"paragraph_vector": [107.474945, -22.614372], "paragraph_keywords": ["practice", "practices", "expand", "complexity"]}], "content": {}, "doi": "10.1145/3290605.3300326"}, {"uri": "3", "title": "Continuous Alertness Assessments: Using EOG Glasses to Unobtrusively Monitor Fatigue Levels In-The-Wild", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Benjamin Tag", "Tilman Dingler"], "summary": "As the day progresses, cognitive functions are subject to fluctuations. While the circadian process results in diurnal peaks and drops, the homeostatic process manifests itself in a steady decline of alertness across the day. Awareness of these changes allows the design of proactive recommender and warning systems, which encourage demanding tasks during periods of high alertness and flag accident-prone activities in low alertness states. In contrast to conventional alertness assessments, which are often limited to lab conditions, bulky hardware, or interruptive self-assessments, we base our approach on eye blink frequency data known to directly relate to fatigue levels. Using electrooculography sensors integrated into regular glasses\u2019 frames, we recorded the eye movements of 16 participants over the course of two weeks in-the-wild and built a robust model of diurnal alertness changes. Our proposed method allows for unobtrusive and continuous monitoring of alertness levels throughout the day.", "keywords": ["process", "based", "time", "change", "person", "bf", "sensing", "performance", "self", "reaction", "analysis", "rate", "alertness", "sleepiness", "sensor", "user", "assessment", "rt", "hour", "eye", "work", "sleep", "result", "recording", "participant", "resulting", "peak", "detection", "eog", "factor", "page", "monitoring", "blink", "measurement", "test", "measure", "task", "glass", "device", "shown", "data", "day", "require", "study", "pattern", "system", "order", "paper", "detect", "fatigue", "level", "pvt"], "document_vector": [-25.873832, -38.885269], "paragraphs": [{"paragraph_vector": [-0.626648, 1.764676], "paragraph_keywords": ["copies", "work", "computing", "systems"]}, {"paragraph_vector": [2.322817, -6.34605], "paragraph_keywords": ["sleepiness", "shown", "fluctuations", "alertness"]}, {"paragraph_vector": [-2.530027, -0.582158], "paragraph_keywords": ["eye", "fatigue", "blink", "bf"]}, {"paragraph_vector": [-1.925724, 0.829656], "paragraph_keywords": ["alertness", "hours", "fatigue", "resulting"]}, {"paragraph_vector": [-0.134881, -1.204129], "paragraph_keywords": ["performance", "studies", "measures", "alertness"]}, {"paragraph_vector": [-2.808923, 0.794174], "paragraph_keywords": ["eye", "blinks", "levels", "blink"]}, {"paragraph_vector": [-2.140436, 0.364841], "paragraph_keywords": ["eye", "systems", "eog", "paper"]}, {"paragraph_vector": [-1.611319, -0.30912], "paragraph_keywords": ["data", "alertness", "eog", "fatigue"]}, {"paragraph_vector": [-2.33183, -0.812151], "paragraph_keywords": ["participants", "study", "number", "fatigue"]}, {"paragraph_vector": [-2.649932, -0.326715], "paragraph_keywords": ["participants", "app", "asked", "time"]}, {"paragraph_vector": [-1.882846, 3.735836], "paragraph_keywords": ["hours", "resulting", "day", "assessment"]}, {"paragraph_vector": [-4.552182, 3.821951], "paragraph_keywords": ["time", "bins", "pvt", "results"]}, {"paragraph_vector": [-3.997639, 3.18201], "paragraph_keywords": ["blink", "rt", "performance", "recordings"]}, {"paragraph_vector": [-3.728854, 0.645371], "paragraph_keywords": ["peak", "blink", "algorithm", "eog"]}, {"paragraph_vector": [-2.950742, 1.239099], "paragraph_keywords": ["data", "blink", "window", "min"]}, {"paragraph_vector": [-0.02793, 0.564898], "paragraph_keywords": ["data", "fatigue", "blink", "alertness"]}, {"paragraph_vector": [-4.189202, 3.002034], "paragraph_keywords": ["detection", "self", "blinks", "sleepiness"]}, {"paragraph_vector": [-1.295048, 1.114421], "paragraph_keywords": ["data", "fatigue", "work", "eog"]}, {"paragraph_vector": [1.987099, -1.890645], "paragraph_keywords": ["alertness", "help", "patterns", "work"]}, {"paragraph_vector": [4.790257, -0.161055], "paragraph_keywords": ["students", "signal", "glasses", "eog"]}, {"paragraph_vector": [-1.670762, 0.412694], "paragraph_keywords": ["find", "participants", "fatigue", "disconnects"]}, {"paragraph_vector": [-0.738199, 0.124698], "paragraph_keywords": ["detect", "blink", "systems", "changes"]}, {"paragraph_vector": [-1.035099, 0.663963], "paragraph_keywords": ["dfki", "kaiserslautern", "thank", "support"]}], "content": {}, "doi": "10.1145/3290605.3300707"}, {"uri": "4", "title": "Increasing the Transparency of Research Paperswith Explorable Multiverse Analyses", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Pierre Dragicevic", "Yvonne Jansen", "Fanny Chevalier"], "summary": "We present explorable multiverse analysis reports, a new approach to statistical reporting where readers of research papers can explore alternative analysis options by interacting with the paper itself. This approach draws from two recent ideas: i) multiverse analysis, a philosophy of statistical reporting where paper authors report the outcomes of many different statistical analyses in order to show how fragile or robust their findings are; and ii) explorable explanations, narratives that can be read as normal explanations but where the reader can also become active by dynamically changing some elements of the explanation. Based on five examples and a design space analysis, we show how combining those two ideas can complement existing reporting approaches and constitute a step towards more transparent research papers.", "keywords": ["time", "change", "emars", "discussion", "explanation", "author", "design", "multiplexing", "analysis", "writing", "focus", "example", "model", "result", "work", "space", "use", "multiverse", "statistic", "prior", "effect", "likert", "article", "reader", "acm", "control", "page", "content", "level", "-", "parameter", "plot", "document", "data", "transparency", "study", "researcher", "reporting", "support", "choice", "text", "research", "outcome", "r", "hci", "paper", "report", "emar", "mini", "option", "p", "figure"], "document_vector": [-111.01271, 1.655892], "paragraphs": [{"paragraph_vector": [40.711338, 58.395797], "paragraph_keywords": ["hci", "statistics", "copies", "acm"]}, {"paragraph_vector": [40.726203, 67.210479], "paragraph_keywords": ["analysis", "transparency", "flexibility", "researchers"]}, {"paragraph_vector": [38.60416, 63.745056], "paragraph_keywords": ["analysis", "multiverse", "analyses", "research"]}, {"paragraph_vector": [50.691795, 74.229652], "paragraph_keywords": ["documents", "multiverse", "paper", "content"]}, {"paragraph_vector": [66.328392, 73.803764], "paragraph_keywords": ["research", "figures", "publication", "interactivity"]}, {"paragraph_vector": [47.958927, 69.498222], "paragraph_keywords": ["work", "analysis", "parameters", "readers"]}, {"paragraph_vector": [49.467544, 68.385665], "paragraph_keywords": ["reports", "code", "papers", "focus"]}, {"paragraph_vector": [12.380875, 69.563629], "paragraph_keywords": ["cis", "analysis", "text", "example"]}, {"paragraph_vector": [41.150417, 68.015251], "paragraph_keywords": ["-", "analysis", "paper", "multiverse"]}, {"paragraph_vector": [51.422496, 59.798732], "paragraph_keywords": ["data", "figure", "analysis", "method"]}, {"paragraph_vector": [35.827236, 64.676261], "paragraph_keywords": ["analysis", "effect", "priors", "multiverse"]}, {"paragraph_vector": [38.152069, 64.441009], "paragraph_keywords": ["effect", "prior", "analysis", "centered"]}, {"paragraph_vector": [27.907444, 59.807697], "paragraph_keywords": ["datasets", "study", "plots", "bootstrap"]}, {"paragraph_vector": [61.941497, 70.958839], "paragraph_keywords": ["format", "html", "figures", "acm"]}, {"paragraph_vector": [34.754402, 64.011886], "paragraph_keywords": ["model", "models", "priors", "r"]}, {"paragraph_vector": [40.08916, 74.363075], "paragraph_keywords": ["analysis", "analyses", "offer", "parameters"]}, {"paragraph_vector": [34.609016, 63.739498], "paragraph_keywords": ["parameters", "example", "levels", "options"]}, {"paragraph_vector": [36.848487, 64.204605], "paragraph_keywords": ["options", "author", "reporting", "analysis"]}, {"paragraph_vector": [41.123649, 65.523094], "paragraph_keywords": ["analysis", "emar", "explanations", "reports"]}, {"paragraph_vector": [43.341072, 73.623718], "paragraph_keywords": ["multiverse", "explanations", "paper", "reporting"]}, {"paragraph_vector": [55.176509, 76.259284], "paragraph_keywords": ["multiplexing", "time", "space", "outcomes"]}, {"paragraph_vector": [46.69168, 69.658775], "paragraph_keywords": ["controls", "text", "control", "analysis"]}, {"paragraph_vector": [59.621639, 78.131172], "paragraph_keywords": ["multiplexing", "space", "text", "paper"]}, {"paragraph_vector": [58.204608, 72.515708], "paragraph_keywords": ["narratives", "narrative", "multiverse", "results"]}, {"paragraph_vector": [44.342517, 76.878059], "paragraph_keywords": ["analyses", "analysis", "models", "plots"]}, {"paragraph_vector": [46.153045, 69.720344], "paragraph_keywords": ["emars", "support", "writing", "need"]}, {"paragraph_vector": [42.316421, 67.2369], "paragraph_keywords": ["emars", "readers", "transparency", "article"]}, {"paragraph_vector": [41.897224, 67.264381], "paragraph_keywords": ["analysis", "paper", "research", "discussions"]}], "content": {}, "doi": "10.1145/3290605.3300692"}, {"uri": "5", "title": "Haptic Navigation Cues on the Steering Wheel", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Patrizia Di Campli", "Alexandros Mouzaki"], "summary": "Haptic feedback is used in cars to reduce visual inattention. While tactile feedback like vibration can be influenced by the car\u2019s movement, thermal and cutaneous push feedback should be independent of such interference. This paper presents two driving simulator studies investigating novel tactile feedback on the steering wheel for navigation. First, devices on one side of the steering wheel were warmed, indicating the turning direction, while those on the other side were cooled. This thermal feedback was compared to audio. The thermal navigation lead to 94.2% correct recognitions of warnings 200m before the turn and to 91.7% correct turns. Speech had perfect recognition for both. In the second experiment, only the destination side was indicated thermally, and this design was compared to cutaneous push feedback. The simplified thermal feedback design did not increase recognition, but cutaneous push feedback had high recognition rates (100% for 200 m warnings, 98% for turns). Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed", "keywords": ["steering", "navigation", "direction", "condition", "change", "time", "information", "design", "rate", "experiment", "wheel", "temperature", "path", "participant", "use", "cue", "compared", "feedback", "stimulus", "recognition", "push", "car", "hand", "device", "study", "presented", "lane", "showed", "paper", "driving", "turning", "turn", "attached"], "document_vector": [-151.438537, -82.321487], "paragraphs": [{"paragraph_vector": [-52.516105, -11.105528], "paragraph_keywords": ["feedback", "devices", "car", "navigation"]}, {"paragraph_vector": [-52.787143, -10.511049], "paragraph_keywords": ["feedback", "navigation", "steering", "participants"]}, {"paragraph_vector": [-53.365238, -11.584065], "paragraph_keywords": ["temperature", "change", "direction", "lane"]}, {"paragraph_vector": [-53.964229, -11.961003], "paragraph_keywords": ["vibration", "feedback", "wheel", "steering"]}, {"paragraph_vector": [-55.188095, -12.069576], "paragraph_keywords": ["feedback", "showed", "tactile", "navigation"]}, {"paragraph_vector": [-52.647064, -11.873741], "paragraph_keywords": ["navigation", "feedback", "participants", "steering"]}, {"paragraph_vector": [-50.475971, -9.553796], "paragraph_keywords": ["cues", "turn", "temperature", "c"]}, {"paragraph_vector": [-52.339649, -13.672998], "paragraph_keywords": ["turn", "feedback", "temperature", "speed"]}, {"paragraph_vector": [-3.739943, 7.737217], "paragraph_keywords": ["experience", "participants", "driving", "turns"]}, {"paragraph_vector": [-47.035575, -5.608812], "paragraph_keywords": ["path", "participants", "deviation", "calculated"]}, {"paragraph_vector": [-54.179588, -8.016183], "paragraph_keywords": ["condition", "tests", "differences", "turns"]}, {"paragraph_vector": [-54.285186, -11.045491], "paragraph_keywords": ["feedback", "participants", "recognition", "experiment"]}, {"paragraph_vector": [-53.393287, -9.931609], "paragraph_keywords": ["participants", "wheel", "hypothesis", "feedback"]}, {"paragraph_vector": [-53.910793, -9.272426], "paragraph_keywords": ["attached", "study", "wheel", "experiment"]}, {"paragraph_vector": [-49.998653, -9.286128], "paragraph_keywords": ["driving", "turning", "training", "pin"]}, {"paragraph_vector": [-47.033088, -7.93086], "paragraph_keywords": ["turns", "data", "participants", "path"]}, {"paragraph_vector": [-60.478809, -8.745443], "paragraph_keywords": ["feedback", "push", "tests", "questionnaire"]}, {"paragraph_vector": [-51.306343, -12.594271], "paragraph_keywords": ["whitney", "ratings", "recognition", "differences"]}, {"paragraph_vector": [-52.270465, -10.206784], "paragraph_keywords": ["feedback", "wheel", "condition", "design"]}, {"paragraph_vector": [-53.063537, -11.074587], "paragraph_keywords": ["feedback", "participants", "navigation", "push"]}, {"paragraph_vector": [-54.793354, -8.626488], "paragraph_keywords": ["feedback", "recognition", "rates", "award"]}], "content": {}, "doi": "10.1145/3290605.3300752"}, {"uri": "6", "title": "ElectroDermis: Fully Untethered, Stretchable, and Highly-Customizable Electronic Bandages", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Eric Markvicka", "Guanyun Wang", "Yi-Chin Lee", "Gierad Laput", "Carmel Majidi", "Lining Yao"], "summary": "Wearables have emerged as an increasingly promising interactive platform, imbuing the human body with alwaysavailable computational capabilities. This unlocks a wide range of applications, including discreet information access, health monitoring, fitness, and fashion. However, unlike previous platforms, wearable electronics require structural conformity, must be comfortable for the wearer, and should be soft, elastic, and aesthetically appealing. We envision a future where electronics can be temporarily attached to the body (like bandages or party masks), but in functional and aesthetically pleasing ways. Towards this vision, we introduce ElectroDermis, a fabrication approach that simplifies the creation of highly-functional and stretchable wearable electronics that are conformal and fully untethered by discretizing rigid circuit boards into individual components. These individual components are wired together using stretchable electrical wiring and assembled on a spandex blend fabric, to provide high functionality in a robust formfactor that is reusable. We describe our system in detail\u2014 including our fabrication parameters and its operational limits\u2014which we hope researchers and practitioners can leverage. We describe a series of example applications that illustrate the feasibility and utility of our system. Overall, we believe ElectroDermis offers a complementary approach to wearable electronics\u2014one that places value on the notion of impermanence (i.e., the opposite of tattoos and implants), better conforming to the dynamic nature of the human body. CCS Concepts \u2022 Human-centered computing~ Ubiquitous and mobile computing systems and tools.", "keywords": ["process", "based", "trace", "sensing", "body", "cut", "processing", "design", "component", "rate", "provide", "sensor", "power", "user", "model", "surface", "copper", "fabric", "work", "tool", "create", "desired", "material", "created", "wiring", "film", "monitor", "laser", "electronics", "functionality", "application", "motion", "module", "circuit", "device", "approach", "system", "led", "research", "bandage", "skin", "fabrication", "figure"], "document_vector": [70.498344, -34.784736], "paragraphs": [{"paragraph_vector": [-45.831901, 56.033863], "paragraph_keywords": ["copies", "applications", "computing", "skin"]}, {"paragraph_vector": [-45.104774, 54.713119], "paragraph_keywords": ["body", "skin", "components", "created"]}, {"paragraph_vector": [-49.05664, 55.391017], "paragraph_keywords": ["fabrication", "body", "design", "tools"]}, {"paragraph_vector": [-67.597244, 54.676769], "paragraph_keywords": ["body", "devices", "desired", "printing"]}, {"paragraph_vector": [-48.64458, 55.787525], "paragraph_keywords": ["electronics", "design", "sensing", "fabrication"]}, {"paragraph_vector": [-68.153602, 57.322322], "paragraph_keywords": ["design", "user", "model", "tool"]}, {"paragraph_vector": [-69.051208, 56.107357], "paragraph_keywords": ["components", "figure", "based", "design"]}, {"paragraph_vector": [-60.424121, 56.621479], "paragraph_keywords": ["generated", "surface", "bandage", "provide"]}, {"paragraph_vector": [-45.764614, 53.984638], "paragraph_keywords": ["sensor", "created", "circuit", "bandage"]}, {"paragraph_vector": [-34.189929, 54.89878], "paragraph_keywords": ["modules", "circuit", "copper", "power"]}, {"paragraph_vector": [-46.438438, 56.030158], "paragraph_keywords": ["adhesion", "materials", "laser", "provide"]}, {"paragraph_vector": [-46.677761, 55.51564], "paragraph_keywords": ["cut", "copper", "bonded", "film"]}, {"paragraph_vector": [-46.896202, 55.289043], "paragraph_keywords": ["body", "bandage", "provide", "bandages"]}, {"paragraph_vector": [-48.445701, 54.272068], "paragraph_keywords": ["figure", "skin", "led", "color"]}, {"paragraph_vector": [-52.015518, 53.511459], "paragraph_keywords": ["bandage", "motion", "body", "healing"]}, {"paragraph_vector": [-47.053649, 54.783008], "paragraph_keywords": ["strain", "device", "figure", "bandage"]}, {"paragraph_vector": [-47.988155, 54.935882], "paragraph_keywords": ["fabrication", "approach", "laser", "bandage"]}, {"paragraph_vector": [-47.808784, 55.364761], "paragraph_keywords": ["research", "strain", "program", "approach"]}], "content": {}, "doi": "10.1145/3290605.3300589"}, {"uri": "7", "title": "Breakdowns in Home-School Collaboration for Behavioral Intervention", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Gabriela Marcu", "Allison Spiller", "Jonathan Arevalo Garay", "Laura R. Pina", "Jonathan Arevalo"], "summary": "For some children, behavioral health services are critical in supporting their development and preventing adverse outcomes such as school dropout, substance use, or encounters with juvenile justice. Schools play an important role in identifying problem behavior and providing appropriate intervention, and these efforts are most effective when executed in collaboration with parents at home. However, homeschool collaboration is difficult to achieve. In this work, we investigated lack of information sharing as a barrier to collaboration, through a qualitative study including observation, contextual inquiry, and interviews. We found that policies, processes, and tools for documenting behaviors in schools are implemented without significant consideration toward exchanging information with parents. Consequently, a lack of effective two-way information sharing tended to hinder collaboration and erode trust. Combining our empirical findings with evidence-based strategies for parent involvement, we discuss design opportunities for promoting collaboration toward positive behavioral outcomes for children.", "keywords": ["process", "based", "child", "time", "need", "information", "education", "design", "sweden", "home", "analysis", "provide", "opportunity", "problem", "help", "goal", "school", "intervention", "sharing", "communication", "shared", "meeting", "work", "use", "desired", "service", "team", "way", "ieps", "challenge", "health", "iep", "page", "teacher", "practitioner", "collaboration", "providing", "incident", "classroom", "practice", "data", "parent", "student", "research", "paper", "behavior", "context"], "document_vector": [171.980819, 51.924243], "paragraphs": [{"paragraph_vector": [170.696151, -2.957351], "paragraph_keywords": ["children", "copies", "behaviors", "intervention"]}, {"paragraph_vector": [173.466217, 5.212927], "paragraph_keywords": ["school", "parents", "child", "practitioners"]}, {"paragraph_vector": [171.161758, 0.944001], "paragraph_keywords": ["school", "sweden", "collaboration", "design"]}, {"paragraph_vector": [171.660751, 2.12473], "paragraph_keywords": ["school", "home", "iep", "child"]}, {"paragraph_vector": [171.37973, 4.132534], "paragraph_keywords": ["school", "parents", "home", "skills"]}, {"paragraph_vector": [171.687835, 3.083047], "paragraph_keywords": ["information", "collaboration", "school", "home"]}, {"paragraph_vector": [170.446228, 3.041677], "paragraph_keywords": ["classrooms", "school", "ieps", "data"]}, {"paragraph_vector": [169.311141, 6.784821], "paragraph_keywords": ["parents", "english", "inquiry", "university"]}, {"paragraph_vector": [169.173995, 6.745637], "paragraph_keywords": ["school", "information", "practitioners", "parents"]}, {"paragraph_vector": [171.188125, 5.308407], "paragraph_keywords": ["school", "parents", "needs", "know"]}, {"paragraph_vector": [170.362945, 4.416246], "paragraph_keywords": ["school", "parents", "practitioners", "incidents"]}, {"paragraph_vector": [171.792587, 5.390751], "paragraph_keywords": ["information", "parents", "child", "school"]}, {"paragraph_vector": [171.818466, 4.553144], "paragraph_keywords": ["behaviors", "information", "school", "sharing"]}, {"paragraph_vector": [171.771606, 4.600327], "paragraph_keywords": ["school", "students", "information", "daughter"]}, {"paragraph_vector": [170.845031, 5.988974], "paragraph_keywords": ["school", "information", "child", "parents"]}, {"paragraph_vector": [170.894073, 4.271365], "paragraph_keywords": ["information", "paper", "school", "parent"]}, {"paragraph_vector": [169.220657, 6.290875], "paragraph_keywords": ["parents", "communication", "work", "parent"]}, {"paragraph_vector": [168.457153, 3.080452], "paragraph_keywords": ["goals", "school", "child", "collaboration"]}, {"paragraph_vector": [172.325805, 2.130235], "paragraph_keywords": ["parents", "intervention", "school", "data"]}, {"paragraph_vector": [173.392211, 3.71456], "paragraph_keywords": ["parents", "child", "school", "practitioners"]}, {"paragraph_vector": [171.909667, 5.699504], "paragraph_keywords": ["school", "practitioners", "parents", "shared"]}, {"paragraph_vector": [173.036239, 5.084588], "paragraph_keywords": ["parents", "information", "data", "intervention"]}, {"paragraph_vector": [172.665267, 6.597442], "paragraph_keywords": ["behaviors", "desired", "school", "intervention"]}, {"paragraph_vector": [171.058578, 3.153364], "paragraph_keywords": ["school", "sharing", "parents", "information"]}], "content": {}, "doi": "10.1145/3290605.3300410"}, {"uri": "8", "title": "Pinpoint: A PCB Debugging Pipeline Using Interruptible Routing and Instrumentation", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Evan Strasnick", "Sean Follmer", "Maneesh Agrawala"], "summary": "Difculties in accessing, isolating, and iterating on the components and connections of a printed circuit board (PCB) create unique challenges in PCB debugging. Manual probing methods are slow and error prone, and even dedicated PCB testing equipment remains limited by its inability to modify the circuit during testing. We present Pinpoint, a tool that facilitates in-circuit PCB debugging through techniques such as programmatically probing signals, dynamically disconnecting components and subcircuits to test in isolation, and splicing in new elements to explore potential modifcations. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proft or commercial advantage and that copies bear this notice and the full citation on the frst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specifc permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300278 Pinpoint automatically instruments a PCB design and generates designs for a physical jig board that interfaces the user\u2019s PCB to our custom testing hardware and to software tools. We evaluate Pinpoint\u2019s ability to facilitate the debugging of various PCB issues by instrumenting and testing diferent classes of boards, as well as by characterizing its technical limitations and by soliciting feedback through a guided exploration with PCB designers.", "keywords": ["pad", "connection", "pin", "hardware", "design", "component", "method", "probing", "ic", "error", "debugging", "dut", "example", "power", "user", "pcb", "added", "elle", "construction", "tool", "use", "instrumentation", "cost", "control", "test", "circuit", "signal", "jig", "element", "designer", "testing", "jumper", "routing", "software", "site", "interface", "pinpoint", "board", "figure"], "document_vector": [70.337829, -24.318077], "paragraphs": [{"paragraph_vector": [20.607912, 29.064783], "paragraph_keywords": ["circuit", "design", "components", "pcb"]}, {"paragraph_vector": [16.972888, 27.550664], "paragraph_keywords": ["test", "circuit", "designers", "enabling"]}, {"paragraph_vector": [20.096612, 28.683507], "paragraph_keywords": ["test", "testing", "tests", "probe"]}, {"paragraph_vector": [17.981565, 26.866279], "paragraph_keywords": ["breadboard", "tools", "pinpoint", "makers"]}, {"paragraph_vector": [17.994741, 29.756025], "paragraph_keywords": ["pinpoint", "board", "design", "debugging"]}, {"paragraph_vector": [13.983548, 23.680019], "paragraph_keywords": ["board", "circuit", "elle", "component"]}, {"paragraph_vector": [14.210768, 22.547792], "paragraph_keywords": ["circuit", "board", "elle", "jumper"]}, {"paragraph_vector": [19.179376, 22.34085], "paragraph_keywords": ["pads", "jumper", "connections", "net"]}, {"paragraph_vector": [13.349007, 25.645053], "paragraph_keywords": ["routing", "board", "instrumentation", "designer"]}, {"paragraph_vector": [17.057653, 28.750169], "paragraph_keywords": ["signals", "board", "dut", "control"]}, {"paragraph_vector": [14.7368, 23.072692], "paragraph_keywords": ["test", "pinpoint", "board", "continuity"]}, {"paragraph_vector": [11.340413, 25.062587], "paragraph_keywords": ["pinpoint", "board", "changes", "signals"]}, {"paragraph_vector": [15.955661, 23.798168], "paragraph_keywords": ["signals", "board", "control", "pins"]}, {"paragraph_vector": [14.761402, 24.88977], "paragraph_keywords": ["board", "fm", "test", "signal"]}, {"paragraph_vector": [13.941346, 24.201349], "paragraph_keywords": ["pinpoint", "users", "circuit", "debugging"]}, {"paragraph_vector": [17.326642, 25.253971], "paragraph_keywords": ["pinpoint", "board", "sites", "designs"]}, {"paragraph_vector": [15.488258, 26.729455], "paragraph_keywords": ["debugging", "pinpoint", "jig", "board"]}, {"paragraph_vector": [19.937862, 28.777545], "paragraph_keywords": ["debugging", "fabrication", "pinpoint", "pcb"]}], "content": {}, "doi": "10.1145/3290605.3300898"}, {"uri": "9", "title": "Making Diabetes Education Interactive: Tangible Educational Toys for Children with Type-1 Diabetes", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Charalampos Kyfonidis", "Marilyn Lennon"], "summary": "Younger children (under 9 years) with type-1 diabetes are often very passive in the management of their condition and can face difficulties in accessing and understanding basic diabetes related information. This can make transitioning to self-management in later years very challenging. Previous research has mostly focused on educational interventions for older children. To create an educational tool which can support the diabetes educational process of younger children, we conducted a multiphase and multi-stakeholder user-centred design process. The result is an interactive tool that illustrates diabetes concepts in an age-appropriate way with the use of tangible toys. The tool was evaluated inside a paediatric diabetes clinic with clinicians, children and parents and was found to be engaging, acceptable and effective. In addition to providing implications for the design and adoption of educational tools for children in a clinical setting, we discuss the challenges for conducting user-centred design in such a setting.", "keywords": ["process", "clinician", "child", "food", "toy", "information", "education", "design", "interview", "provide", "interactivity", "thought", "aspect", "interaction", "effectiveness", "work", "tool", "evaluation", "use", "management", "scenario", "group", "clinic", "material", "way", "learning", "think", "lack", "page", "experience", "existing", "year", "found", "feedback", "age", "practice", "fact", "approach", "element", "parent", "insulin", "study", "system", "session", "order", "paper", "knowledge", "diabetes", "figure"], "document_vector": [175.562377, 41.06475], "paragraphs": [{"paragraph_vector": [128.260162, 0.41451], "paragraph_keywords": ["diabetes", "copies", "children", "computing"]}, {"paragraph_vector": [173.93927, -2.077219], "paragraph_keywords": ["children", "clinicians", "tool", "food"]}, {"paragraph_vector": [128.250854, -12.269346], "paragraph_keywords": ["education", "diabetes", "children", "age"]}, {"paragraph_vector": [168.046783, 0.627312], "paragraph_keywords": ["education", "children", "promote", "games"]}, {"paragraph_vector": [174.192962, -1.07749], "paragraph_keywords": ["education", "children", "practices", "stage"]}, {"paragraph_vector": [173.472702, -5.998017], "paragraph_keywords": ["children", "parents", "nsg", "education"]}, {"paragraph_vector": [174.948181, -5.211916], "paragraph_keywords": ["children", "insulin", "session", "play"]}, {"paragraph_vector": [170.222717, -2.944715], "paragraph_keywords": ["children", "parents", "education", "clinicians"]}, {"paragraph_vector": [174.182693, -3.636996], "paragraph_keywords": ["tool", "children", "provide", "feedback"]}, {"paragraph_vector": [175.666656, -4.578935], "paragraph_keywords": ["scenario", "clinicians", "suggested", "scenarios"]}, {"paragraph_vector": [175.593307, -4.743515], "paragraph_keywords": ["session", "station", "toys", "sensors"]}, {"paragraph_vector": [177.891693, -1.182593], "paragraph_keywords": ["tool", "children", "session", "clinicians"]}, {"paragraph_vector": [174.920501, -1.71709], "paragraph_keywords": ["children", "tool", "session", "clinicians"]}, {"paragraph_vector": [-175.922195, 0.123073], "paragraph_keywords": ["parents", "children", "session", "analysed"]}, {"paragraph_vector": [178.222732, -6.242531], "paragraph_keywords": ["parents", "aspect", "children", "found"]}, {"paragraph_vector": [172.119522, -3.518096], "paragraph_keywords": ["tool", "children", "clinicians", "group"]}, {"paragraph_vector": [173.392044, -5.021224], "paragraph_keywords": ["tool", "children", "thought", "session"]}, {"paragraph_vector": [-165.930801, -6.345708], "paragraph_keywords": ["session", "children", "clinic", "results"]}, {"paragraph_vector": [-175.321792, -4.927822], "paragraph_keywords": ["tool", "children", "evaluation", "visits"]}, {"paragraph_vector": [171.800369, 2.093461], "paragraph_keywords": ["children", "clinicians", "tool", "parents"]}, {"paragraph_vector": [173.861465, -2.748142], "paragraph_keywords": ["children", "tool", "education", "clinicians"]}, {"paragraph_vector": [173.559631, 0.553116], "paragraph_keywords": ["children", "clinicians", "studies", "health"]}], "content": {}, "doi": "10.1145/3290605.3300624"}, {"uri": "10", "title": "Co-Created Personas: Engaging and Empowering Users with Diverse Needs Within the Design Process", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Timothy Neate", "Aikaterini Bourazeri", "Abi Roper", "Simone Stumpf", "Stephanie Wilson"], "summary": "Personas are powerful tools for designing technology and envisioning its usage. They are widely used to imagine archetypal users around whom to orient design work. We have been exploring co-created personas as a technique to use in co-design with users who have diverse needs. Our vision was that this would broaden the demographic and liberate co-designers of their personal relationship with a health condition. This paper reports three studies where we investigated using co-created personas with people who had Parkinson\u2019s disease, dementia or aphasia. Observational data of co-design sessions were collected and analysed. Findings revealed that the co-created personas encouraged users with diverse needs to engage with co-designing. Importantly, they also aforded additional benefts including empowering users within a more accessible design process. Refecting on the outcomes from the diferent user groups, we conclude with a discussion of the potential for co-created personas to be applied more broadly. \u2217Also with Division of Language and Communication Science, City, University of London, London, UK. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proft or commercial advantage and that copies bear this notice and the full citation on the frst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specifc permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300880 CCS CONCEPTS \u2022 Human-centered computing \u2192 Participatory design; Accessibility theory, concepts and paradigms;", "keywords": ["process", "george", "fred", "design", "feature", "app", "specifc", "writing", "persona", "co", "example", "disease", "help", "stroke", "user", "activity", "aphasia", "workshop", "creating", "work", "parkinson", "participant", "use", "create", "people", "group", "living", "health", "think", "created", "experience", "found", "-", "data", "technology", "study", "researcher", "designer", "dementia", "remember", "said", "ensure", "paper", "project", "making", "code"], "document_vector": [95.385139, 17.240335], "paragraphs": [{"paragraph_vector": [129.302581, -64.491806], "paragraph_keywords": ["design", "co", "health", "-"]}, {"paragraph_vector": [137.927062, -62.636108], "paragraph_keywords": ["design", "co", "-", "users"]}, {"paragraph_vector": [138.012207, -70.22364], "paragraph_keywords": ["design", "user", "process", "prototypes"]}, {"paragraph_vector": [135.410797, -63.728916], "paragraph_keywords": ["users", "personas", "design", "user"]}, {"paragraph_vector": [141.504608, -68.552192], "paragraph_keywords": ["personas", "design", "people", "co"]}, {"paragraph_vector": [138.584014, -66.259872], "paragraph_keywords": ["living", "co", "-", "groups"]}, {"paragraph_vector": [148.687149, -68.598297], "paragraph_keywords": ["personas", "workshop", "disease", "dementia"]}, {"paragraph_vector": [136.582015, -71.797645], "paragraph_keywords": ["personas", "workshop", "aphasia", "fred"]}, {"paragraph_vector": [139.382156, -69.922462], "paragraph_keywords": ["aphasia", "personas", "people", "writing"]}, {"paragraph_vector": [136.35231, -68.940032], "paragraph_keywords": ["personas", "co", "-", "participants"]}, {"paragraph_vector": [104.97544, 51.338977], "paragraph_keywords": ["personas", "progressed", "persona", "co"]}, {"paragraph_vector": [137.926071, -77.382247], "paragraph_keywords": ["data", "codes", "-", "code"]}, {"paragraph_vector": [135.523712, -72.391494], "paragraph_keywords": ["personas", "aphasia", "-", "found"]}, {"paragraph_vector": [140.335754, -71.661781], "paragraph_keywords": ["personas", "-", "participants", "co"]}, {"paragraph_vector": [135.556427, -71.339179], "paragraph_keywords": ["personas", "-", "co", "participants"]}, {"paragraph_vector": [136.561904, -67.385047], "paragraph_keywords": ["persona", "participants", "use", "designer"]}, {"paragraph_vector": [137.382049, -75.406211], "paragraph_keywords": ["music", "app", "persona", "code"]}, {"paragraph_vector": [137.632995, -70.518508], "paragraph_keywords": ["app", "toolkit", "-", "participants"]}, {"paragraph_vector": [89.290382, 43.396144], "paragraph_keywords": ["personas", "-", "participants", "co"]}, {"paragraph_vector": [134.997543, -68.937576], "paragraph_keywords": ["stroke", "persona", "personas", "charlotte"]}, {"paragraph_vector": [140.201095, -71.508209], "paragraph_keywords": ["personas", "participants", "example", "people"]}, {"paragraph_vector": [112.892845, -81.496086], "paragraph_keywords": ["activities", "personas", "came", "example"]}, {"paragraph_vector": [152.160064, -49.532909], "paragraph_keywords": ["process", "personas", "design", "participants"]}, {"paragraph_vector": [149.259506, -49.363658], "paragraph_keywords": ["personas", "co", "-", "participants"]}, {"paragraph_vector": [140.590881, -56.811309], "paragraph_keywords": ["users", "co", "-", "personas"]}], "content": {}, "doi": "10.1145/3290605.3300353"}, {"uri": "11", "title": "Heimdall", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Mitchell Karchemsky"], "summary": "Students and hobbyists build embedded systems that combine sensing, actuation and microcontrollers on solderless breadboards. To help students debug such circuits, experienced teachers apply visual inspection, targeted measurements, and circuit modifications to diagnose and localize the problem(s). However, experienced helpers may not always be available to review student projects in person. To enable remote debugging of circuit problems, we introduce Heimdall, a remote electronics workbench that allows experts to visually inspect a student\u2019s circuit; perform measurements; and to re-wire and inject test signals. These interactions are enabled by an actuated inspection camera; an augmented breadboard that Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses, contact the", "keywords": ["breadboard", "time", "potentiometer", "set", "design", "component", "heimdall", "problem", "debugging", "sensor", "user", "wire", "mcu", "tool", "use", "instrumentation", "analog", "inspection", "page", "electronics", "functionality", "perform", "measurement", "joyce", "circuit", "signal", "embedded", "task", "student", "system", "led", "microcontroller", "row", "view", "injection", "instructor", "software", "interface", "input", "behavior", "project", "board", "voltage", "code"], "document_vector": [71.887504, -23.083621], "paragraphs": [{"paragraph_vector": [16.620304, 31.251291], "paragraph_keywords": ["debugging", "systems", "electronics", "students"]}, {"paragraph_vector": [17.609182, 26.402769], "paragraph_keywords": ["debugging", "components", "inspection", "circuit"]}, {"paragraph_vector": [20.381994, 28.089689], "paragraph_keywords": ["circuit", "debugging", "tools", "novices"]}, {"paragraph_vector": [23.250675, 31.132991], "paragraph_keywords": ["students", "circuit", "troubleshooting", "approach"]}, {"paragraph_vector": [17.541439, 27.073602], "paragraph_keywords": ["students", "circuits", "time", "access"]}, {"paragraph_vector": [16.480884, 25.632581], "paragraph_keywords": ["circuit", "board", "voltage", "inspection"]}, {"paragraph_vector": [16.207513, 27.249479], "paragraph_keywords": ["heimdall", "circuit", "students", "debugging"]}, {"paragraph_vector": [15.257788, 26.292324], "paragraph_keywords": ["circuit", "breadboard", "joyce", "heimdall"]}, {"paragraph_vector": [13.880517, 25.751741], "paragraph_keywords": ["led", "joyce", "potentiometer", "row"]}, {"paragraph_vector": [13.71026, 26.076148], "paragraph_keywords": ["row", "breadboard", "analog", "voltage"]}, {"paragraph_vector": [5.769711, 30.290174], "paragraph_keywords": ["breadboard", "markers", "board", "system"]}, {"paragraph_vector": [14.726833, 25.786411], "paragraph_keywords": ["controlled", "resistance", "board", "row"]}, {"paragraph_vector": [15.323199, 25.696949], "paragraph_keywords": ["analog", "server", "heimdall", "pins"]}, {"paragraph_vector": [14.027398, 25.534036], "paragraph_keywords": ["heimdall", "student", "users", "system"]}, {"paragraph_vector": [16.946203, 27.256788], "paragraph_keywords": ["circuit", "sensor", "code", "system"]}, {"paragraph_vector": [15.509611, 25.669122], "paragraph_keywords": ["view", "users", "circuits", "injection"]}, {"paragraph_vector": [14.164228, 23.613262], "paragraph_keywords": ["signal", "system", "users", "injection"]}, {"paragraph_vector": [15.398287, 24.851398], "paragraph_keywords": ["test", "signal", "instrumentation", "heimdall"]}, {"paragraph_vector": [14.765937, 25.935747], "paragraph_keywords": ["heimdall", "mcus", "limitations", "based"]}, {"paragraph_vector": [16.07661, 28.588294], "paragraph_keywords": ["debugging", "students", "heimdall", "inspection"]}], "content": {}, "doi": "10.1145/3290605.3300414"}, {"uri": "12", "title": "Making Sense of Art: Access for Gallery Visitors with Vision Impairments", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Leona Holloway"], "summary": "While there is widespread recognition of the need to provide people with vision impairments (PVI) equitable access to cultural institutions such as art galleries, this is not easy. We present the results of a collaboration with a regional art gallery who wished to open their collection to PVIs in the local community. We describe a novel model that provides three different ways of accessing the gallery, depending upon visual acuity and mobility: virtual tours, self-guided tours and guided tours. As far as possible the model supports autonomous exploration by PVIs. It was informed by a value sensitive design exploration of the values and value conflicts of the primary stakeholders. We report a preliminary evaluation and examine the role IT technologies play in supporting the model and underlying stakeholder values.", "keywords": ["importance", "based", "institution", "need", "vision", "information", "conflict", "integrity", "community", "design", "provide", "visitor", "touch", "artist", "model", "painting", "tour", "accessibility", "workshop", "work", "participant", "use", "people", "material", "group", "art", "ba", "page", "experience", "laser", "bag", "inclusion", "provided", "gallery", "providing", "stakeholder", "study", "tactile", "presentation", "role", "support", "research", "graphic", "sculpture", "printed", "paper", "description", "staff", "value", "pvis", "access", "artwork"], "document_vector": [168.805603, -33.126014], "paragraphs": [{"paragraph_vector": [-139.315429, 41.176261], "paragraph_keywords": ["access", "people", "copies", "vision"]}, {"paragraph_vector": [-130.698989, 35.181427], "paragraph_keywords": ["pvis", "gallery", "bag", "value"]}, {"paragraph_vector": [-124.489471, 33.929164], "paragraph_keywords": ["research", "values", "art", "touch"]}, {"paragraph_vector": [-129.269317, 38.903144], "paragraph_keywords": ["access", "visitors", "museum", "sonification"]}, {"paragraph_vector": [-124.718666, 39.622257], "paragraph_keywords": ["tactile", "bas", "relief", "graphics"]}, {"paragraph_vector": [-132.798416, 39.214805], "paragraph_keywords": ["artworks", "sculpture", "rainbow", "access"]}, {"paragraph_vector": [-126.436271, 35.669757], "paragraph_keywords": ["vision", "printed", "tactile", "provided"]}, {"paragraph_vector": [-130.54216, 36.986892], "paragraph_keywords": ["gallery", "workshop", "values", "vision"]}, {"paragraph_vector": [-130.087097, 32.855609], "paragraph_keywords": ["pvis", "gallery", "participants", "stakeholders"]}, {"paragraph_vector": [-128.576782, 37.676128], "paragraph_keywords": ["community", "art", "gallery", "values"]}, {"paragraph_vector": [-133.453796, 29.233625], "paragraph_keywords": ["gallery", "community", "pvis", "artworks"]}, {"paragraph_vector": [-129.915618, 37.200008], "paragraph_keywords": ["gallery", "resources", "artworks", "pvis"]}, {"paragraph_vector": [-130.280029, 32.544384], "paragraph_keywords": ["artists", "gallery", "workshop", "description"]}, {"paragraph_vector": [-131.663101, 38.958812], "paragraph_keywords": ["artwork", "artists", "work", "statement"]}, {"paragraph_vector": [-102.375762, 31.915214], "paragraph_keywords": ["touch", "artwork", "integrity", "tactile"]}, {"paragraph_vector": [-127.816772, 36.564472], "paragraph_keywords": ["vision", "gallery", "access", "senses"]}, {"paragraph_vector": [-130.912597, 36.779842], "paragraph_keywords": ["gallery", "pvis", "vision", "information"]}, {"paragraph_vector": [-132.788986, 39.996059], "paragraph_keywords": ["gallery", "pvis", "artworks", "group"]}, {"paragraph_vector": [-128.416, 37.281261], "paragraph_keywords": ["gallery", "artworks", "vision", "role"]}, {"paragraph_vector": [-125.137878, 35.7378], "paragraph_keywords": ["artwork", "painting", "sheep", "girl"]}, {"paragraph_vector": [-111.725593, 35.647315], "paragraph_keywords": ["artworks", "people", "participants", "tour"]}, {"paragraph_vector": [-134.761505, 44.268333], "paragraph_keywords": ["gallery", "participants", "pages", "tour"]}, {"paragraph_vector": [-127.199707, 37.709403], "paragraph_keywords": ["research", "model", "access", "use"]}], "content": {}, "doi": "10.1145/3290605.3300578"}, {"uri": "13", "title": "Reveal: Investigating Proactive Location-Based Reminiscing with Personal Digital Photo Repositories", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["David McGookin"], "summary": "Recording experiences and memories is an important role for digital photography, with smartphone cameras leading to individuals taking increasing numbers of pictures of everyday experiences. Increasingly, these are automatically stored in personal, cloud-backed, photo repositories. However, such experiences can be forgotten quickly, with images \u2018lost\u2019 within the user\u2019s library, loosing their role in supporting reminiscing. We investigate how users might be provoked to view these images and the benefits they bring through the Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300665 development and evaluation of a proactive, location-based reminiscing tool, called Reveal. We outline how a locationbased approach allowed participants to reflect more widely on their photo practice, and the potential of such reminiscing tools to support effective management and curation of individual\u2019s increasingly large personal photo collections.", "keywords": ["based", "time", "location", "reminiscing", "reflect", "seen", "example", "photograph", "medium", "user", "changed", "taken", "work", "place", "participant", "use", "reminisce", "discussed", "people", "way", "forgotten", "experience", "page", "number", "year", "notification", "note", "found", "life", "reveal", "described", "day", "study", "approach", "remember", "image", "support", "took", "event", "picture", "viewing", "view", "individual", "paper", "photo", "value", "figure"], "document_vector": [153.992477, 1.007979], "paragraphs": [{"paragraph_vector": [-53.027851, -52.393489], "paragraph_keywords": ["events", "images", "individuals", "photo"]}, {"paragraph_vector": [-53.86285, -50.351272], "paragraph_keywords": ["work", "photo", "reminiscing", "individuals"]}, {"paragraph_vector": [-54.126586, -49.273303], "paragraph_keywords": ["images", "media", "individuals", "forgotten"]}, {"paragraph_vector": [-55.814216, -52.969913], "paragraph_keywords": ["media", "reminiscing", "images", "reminisce"]}, {"paragraph_vector": [-51.89867, -52.173629], "paragraph_keywords": ["images", "support", "uses", "data"]}, {"paragraph_vector": [-50.322479, -49.501922], "paragraph_keywords": ["work", "photo", "location", "fits"]}, {"paragraph_vector": [-49.910018, -49.638889], "paragraph_keywords": ["images", "location", "photo", "reminiscing"]}, {"paragraph_vector": [-50.943389, -48.936447], "paragraph_keywords": ["location", "notification", "user", "notifications"]}, {"paragraph_vector": [-54.143047, -50.295623], "paragraph_keywords": ["image", "user", "images", "figure"]}, {"paragraph_vector": [-56.458248, -54.468486], "paragraph_keywords": ["participants", "reminisce", "asked", "days"]}, {"paragraph_vector": [-52.158504, -54.205188], "paragraph_keywords": ["images", "participants", "photo", "codes"]}, {"paragraph_vector": [-54.581119, -51.202247], "paragraph_keywords": ["images", "notifications", "participants", "respond"]}, {"paragraph_vector": [-58.662666, -54.638591], "paragraph_keywords": ["time", "notifications", "image", "reveal"]}, {"paragraph_vector": [-56.194438, -51.668884], "paragraph_keywords": ["images", "participants", "taken", "notification"]}, {"paragraph_vector": [-52.835666, -49.009056], "paragraph_keywords": ["notes", "images", "support", "participants"]}, {"paragraph_vector": [-56.548107, -50.113132], "paragraph_keywords": ["images", "image", "found", "example"]}, {"paragraph_vector": [-56.172061, -51.945152], "paragraph_keywords": ["images", "lot", "time", "participants"]}, {"paragraph_vector": [-57.001876, -50.820995], "paragraph_keywords": ["images", "place", "image", "taken"]}, {"paragraph_vector": [-58.110836, -52.841762], "paragraph_keywords": ["reminiscing", "participants", "changes", "images"]}, {"paragraph_vector": [-58.577133, -48.095462], "paragraph_keywords": ["participants", "took", "photographs", "lot"]}, {"paragraph_vector": [-53.450405, -46.954448], "paragraph_keywords": ["time", "image", "participants", "recall"]}, {"paragraph_vector": [-57.945728, -53.324771], "paragraph_keywords": ["remember", "feelings", "participants", "images"]}, {"paragraph_vector": [-53.793918, -53.334014], "paragraph_keywords": ["discussed", "reminiscing", "participants", "images"]}, {"paragraph_vector": [-56.475814, -49.725353], "paragraph_keywords": ["pictures", "participants", "taking", "reveal"]}, {"paragraph_vector": [-54.560604, -51.495422], "paragraph_keywords": ["participants", "images", "photo", "reveal"]}, {"paragraph_vector": [-54.139297, -49.645236], "paragraph_keywords": ["reminiscing", "images", "image", "location"]}, {"paragraph_vector": [-53.858119, -50.655162], "paragraph_keywords": ["place", "image", "taken", "location"]}, {"paragraph_vector": [-54.861721, -51.112052], "paragraph_keywords": ["images", "image", "discussed", "reminiscing"]}, {"paragraph_vector": [-55.062156, -50.39587], "paragraph_keywords": ["images", "participants", "reminiscing", "day"]}, {"paragraph_vector": [-53.984016, -52.004348], "paragraph_keywords": ["location", "images", "reminiscing", "individuals"]}, {"paragraph_vector": [-56.937629, -50.240348], "paragraph_keywords": ["images", "participants", "location", "notification"]}, {"paragraph_vector": [-52.423381, -49.985851], "paragraph_keywords": ["reveal", "reminiscing", "support", "location"]}], "content": {}, "doi": "10.1145/3290605.3300485"}, {"uri": "14", "title": "A Wee Bit More Interaction: Designing and Evaluating an Overactive Bladder App", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Ana-Maria Salai", "Lynne Baillie"], "summary": "Overactive Bladder (OAB) is a widespread condition, affecting 20% of the population. Even though it is a treatable condition, people often do not seek treatment. In this paper, we describe how we co-designed and evaluated with 30 stakeholders (9 medical professionals and 21 endusers) an OAB mobile health application that aims to increase adherence to self-managed treatment. Our results support previous research that visualizing progress, setting goals, receiving reminders and feedback increases use. We discovered that games could be used successfully as a distraction technique for urge suppression. Contrary to the current research direction, automatically calculated features could be a detriment to app interaction. Regarding evaluation, we found that designers may not want to rely only on questionnaires when assessing the success of a game and its emotional impact on users.", "keywords": ["based", "time", "condition", "reminder", "like", "location", "progress", "design", "feature", "app", "interview", "technique", "void", "adherence", "user", "exercise", "ups", "interaction", "evaluated", "work", "use", "people", "treatment", "urge", "page", "emotion", "field", "number", "found", "mp", "understand", "bladder", "provided", "distraction", "suggested", "diary", "toilet", "day", "data", "game", "study", "map", "research", "pfm", "asked", "paper", "decided", "oab"], "document_vector": [10.116382, 63.919498], "paragraphs": [{"paragraph_vector": [-170.173721, -37.6842], "paragraph_keywords": ["oab", "people", "treatment", "app"]}, {"paragraph_vector": [-167.222946, -40.627693], "paragraph_keywords": ["oab", "studies", "copies", "bladder"]}, {"paragraph_vector": [-170.92926, -37.116237], "paragraph_keywords": ["app", "staff", "urge", "techniques"]}, {"paragraph_vector": [-169.286239, -33.509952], "paragraph_keywords": ["progress", "apps", "treatment", "app"]}, {"paragraph_vector": [-172.750564, -34.304737], "paragraph_keywords": ["people", "rehabilitation", "al", "adherence"]}, {"paragraph_vector": [-169.86621, -44.238101], "paragraph_keywords": ["people", "interviews", "avoid", "understand"]}, {"paragraph_vector": [-167.470504, -38.154247], "paragraph_keywords": ["ups", "mps", "use", "treatment"]}, {"paragraph_vector": [-164.426483, -36.291519], "paragraph_keywords": ["ups", "based", "interview", "version"]}, {"paragraph_vector": [-156.860351, -31.005159], "paragraph_keywords": ["ups", "progress", "fig", "number"]}, {"paragraph_vector": [-159.52922, -40.913604], "paragraph_keywords": ["ups", "reminders", "like", "people"]}, {"paragraph_vector": [-159.048294, -31.115779], "paragraph_keywords": ["decided", "distraction", "use", "games"]}, {"paragraph_vector": [-168.287094, -37.967948], "paragraph_keywords": ["oab", "mps", "condition", "images"]}, {"paragraph_vector": [-167.804809, -39.926654], "paragraph_keywords": ["app", "feature", "agreed", "ups"]}, {"paragraph_vector": [-165.520065, -36.487392], "paragraph_keywords": ["ups", "suggested", "games", "urge"]}, {"paragraph_vector": [-165.133773, -36.543422], "paragraph_keywords": ["based", "study", "days", "progress"]}, {"paragraph_vector": [-178.351272, -63.86087], "paragraph_keywords": ["app", "ups", "study", "understand"]}, {"paragraph_vector": [-174.398132, -62.356273], "paragraph_keywords": ["app", "ups", "data", "collected"]}, {"paragraph_vector": [-163.507598, -38.623867], "paragraph_keywords": ["progress", "ups", "toilet", "helped"]}, {"paragraph_vector": [-131.286087, 3.985084], "paragraph_keywords": ["games", "ups", "emotion", "playing"]}, {"paragraph_vector": [-166.854934, -35.583942], "paragraph_keywords": ["ups", "study", "map", "data"]}, {"paragraph_vector": [-165.997894, -36.617321], "paragraph_keywords": ["ups", "data", "diary", "time"]}, {"paragraph_vector": [-162.999908, -35.202644], "paragraph_keywords": ["progress", "people", "app", "users"]}, {"paragraph_vector": [-158.80278, -32.014709], "paragraph_keywords": ["ups", "study", "tlx", "users"]}, {"paragraph_vector": [-171.156814, -35.87033], "paragraph_keywords": ["app", "progress", "reminders", "people"]}, {"paragraph_vector": [-171.559097, -56.114452], "paragraph_keywords": ["app", "people", "field", "study"]}, {"paragraph_vector": [-155.750411, -31.742546], "paragraph_keywords": ["found", "app", "users", "goal"]}], "content": {}, "doi": "10.1145/3290605.3300760"}, {"uri": "15", "title": "GymSoles: Improving Squats and Dead-Lifts by Visualizing the User's Center of Pressure", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Don Samitha Elvitigala"], "summary": "The correct execution of exercises, such as squats and deadlifts, is essential to prevent various bodily injuries. Existing solutions either rely on expensive motion tracking or multiple Inertial Measurement Units (IMU) systems require an extensive set-up and individual calibration. This paper introduces a proof of concept, GymSoles, an insole prototype that provides feedback on the Centre of Pressure (CoP) at the feet to assist users with maintaining the correct body posture, while performing squats and dead-lifts. GymSoles was evaluated with 13 users in three conditions: 1) no feedback, 2) vibrotactile feedback, and 3) visual feedback. It has shown that solely providing feedback on the current CoP, results in a signifcantly improved body posture. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proft or commercial advantage and that copies bear this notice and the full citation on the frst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specifc permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300404 CCS CONCEPTS \u2022 Human-centered computing \u2192 Ubiquitous and mobile computing systems and tools;", "keywords": ["based", "imu", "posture", "body", "cop", "performance", "gym", "analysis", "technique", "vibration", "foot", "user", "exercise", "beginner", "lift", "participant", "use", "gymsoles", "vibrotactile", "sport", "execution", "page", "trainer", "feedback", "tracking", "motion", "providing", "insole", "pressure", "squat", "data", "dead", "system", "centre", "research", "paper", "figure"], "document_vector": [38.766365, -69.015121], "paragraphs": [{"paragraph_vector": [-89.904983, 11.132986], "paragraph_keywords": ["systems", "exercises", "feedback", "exercise"]}, {"paragraph_vector": [-91.608451, 11.995454], "paragraph_keywords": ["squats", "user", "insights", "tracking"]}, {"paragraph_vector": [-72.678634, 13.617926], "paragraph_keywords": ["imu", "exercise", "activity", "motion"]}, {"paragraph_vector": [-86.075607, 12.555866], "paragraph_keywords": ["pressure", "force", "applications", "insoles"]}, {"paragraph_vector": [-90.983001, 12.266347], "paragraph_keywords": ["body", "trainers", "pressure", "posture"]}, {"paragraph_vector": [-93.286743, 10.068718], "paragraph_keywords": ["squats", "technique", "learners", "injuries"]}, {"paragraph_vector": [-91.461624, 11.537067], "paragraph_keywords": ["technology", "pressure", "posture", "gym"]}, {"paragraph_vector": [-81.362045, 3.800402], "paragraph_keywords": ["motors", "vibration", "feedback", "cop"]}, {"paragraph_vector": [-87.517158, 15.099095], "paragraph_keywords": ["feedback", "cop", "participants", "data"]}, {"paragraph_vector": [-86.58451, 14.158085], "paragraph_keywords": ["squats", "cop", "feedback", "trainer"]}, {"paragraph_vector": [-90.491409, 13.188724], "paragraph_keywords": ["participants", "cop", "squats", "feedback"]}, {"paragraph_vector": [-89.229118, 16.914287], "paragraph_keywords": ["beginner", "cop", "t", "anova"]}, {"paragraph_vector": [-88.43724, 15.358015], "paragraph_keywords": ["lifts", "feedback", "showed", "vib"]}, {"paragraph_vector": [-90.845306, 14.613393], "paragraph_keywords": ["feedback", "posture", "cop", "vibrotactile"]}, {"paragraph_vector": [-93.029258, 13.879345], "paragraph_keywords": ["feedback", "vibration", "allows", "user"]}, {"paragraph_vector": [-88.652885, 13.904139], "paragraph_keywords": ["user", "cop", "feedback", "trainers"]}, {"paragraph_vector": [-87.173286, 15.376544], "paragraph_keywords": ["cop", "gymsoles", "exercises", "body"]}, {"paragraph_vector": [-119.079727, -10.742496], "paragraph_keywords": ["sports", "manager", "recreation", "study"]}], "content": {}, "doi": "10.1145/3290605.3300623"}, {"uri": "16", "title": "Pyrus: Designing A Collaborative Programming Game to Support Problem-Solving Behaviors", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Joshua Shi", "Armaan Shah", "Garrett Hedman"], "summary": "While problem solving is a crucial aspect of programming, few learning opportunities in computer science focus on teaching problem-solving skills like planning. In this paper, we present Pyrus, a collaborative game designed to encourage novices to plan in advance while programming. Through Pyrus, we explore a new approach to designing educational games we call behavior-centered game design, in which designers first identify behaviors that learners should practice to reach desired learning goals and then select game mechanics that incentivize those behaviors. Pyrus leverages game mechanics like a failure condition, distributed resources, and enforced turn-taking to encourage players to plan and collaborate. In a within-subjects user study, we found that pairs of novices spent more time planning and collaborated more equally when solving problems in Pyrus than in pair programming. These findings show that game mechanics can be used to promote desirable learning behaviors like planning in advance, and suggest that our behavior-centered approach to educational game design warrants further study.", "keywords": ["planning", "process", "time", "resource", "player", "design", "pyrus", "writing", "problem", "programmer", "partner", "help", "work", "participant", "mechanic", "use", "card", "learning", "pilot", "advance", "experience", "collaboration", "understanding", "found", "programming", "novice", "practice", "data", "solve", "game", "solution", "approach", "role", "student", "research", "pair", "solving", "encourage", "behavior", "plan", "turn", "code"], "document_vector": [-136.573333, 17.332923], "paragraphs": [{"paragraph_vector": [101.428031, 42.538818], "paragraph_keywords": ["problem", "solving", "programming", "copies"]}, {"paragraph_vector": [95.846008, 41.171726], "paragraph_keywords": ["games", "game", "problem", "solving"]}, {"paragraph_vector": [91.83052, 42.104404], "paragraph_keywords": ["problem", "solving", "programming", "pyrus"]}, {"paragraph_vector": [95.002586, 42.490993], "paragraph_keywords": ["problem", "programming", "solving", "learning"]}, {"paragraph_vector": [91.164299, 38.232189], "paragraph_keywords": ["games", "programming", "design", "game"]}, {"paragraph_vector": [96.250068, 41.172233], "paragraph_keywords": ["game", "learning", "level", "behaviors"]}, {"paragraph_vector": [90.13887, 40.671195], "paragraph_keywords": ["planning", "novices", "actions", "players"]}, {"paragraph_vector": [87.974754, 42.436161], "paragraph_keywords": ["pilot", "partners", "encourage", "players"]}, {"paragraph_vector": [92.20333, 41.617725], "paragraph_keywords": ["players", "programming", "player", "problem"]}, {"paragraph_vector": [92.054275, 46.12519], "paragraph_keywords": ["pilot", "card", "turn", "player"]}, {"paragraph_vector": [91.054985, 41.382423], "paragraph_keywords": ["jojo", "code", "game", "arby"]}, {"paragraph_vector": [100.27713, 41.019592], "paragraph_keywords": ["study", "participants", "students", "programming"]}, {"paragraph_vector": [88.345314, 40.17527], "paragraph_keywords": ["participants", "programming", "challenges", "pyrus"]}, {"paragraph_vector": [92.552207, 41.944274], "paragraph_keywords": ["programming", "problems", "participants", "experience"]}, {"paragraph_vector": [96.080879, 41.822738], "paragraph_keywords": ["problem", "solving", "data", "stages"]}, {"paragraph_vector": [91.707504, 42.857376], "paragraph_keywords": ["time", "data", "pairs", "code"]}, {"paragraph_vector": [93.638595, 45.740623], "paragraph_keywords": ["codes", "pyrus", "data", "advance"]}, {"paragraph_vector": [90.732063, 42.116821], "paragraph_keywords": ["pairs", "pyrus", "time", "planned"]}, {"paragraph_vector": [87.90802, 40.142742], "paragraph_keywords": ["pyrus", "pairs", "programming", "pair"]}, {"paragraph_vector": [91.438407, 41.206108], "paragraph_keywords": ["pyrus", "participants", "programming", "process"]}, {"paragraph_vector": [90.273551, 41.401275], "paragraph_keywords": ["states", "pilot", "roles", "participants"]}, {"paragraph_vector": [90.740364, 39.938125], "paragraph_keywords": ["pyrus", "person", "think", "programming"]}, {"paragraph_vector": [90.751426, 40.451347], "paragraph_keywords": ["pyrus", "programming", "pairs", "participants"]}, {"paragraph_vector": [92.463706, 41.126564], "paragraph_keywords": ["game", "design", "pyrus", "problem"]}, {"paragraph_vector": [102.993171, 40.167617], "paragraph_keywords": ["pyrus", "planning", "game", "design"]}, {"paragraph_vector": [72.961685, 33.098476], "paragraph_keywords": ["northwestern", "university", "paper", "page"]}], "content": {}, "doi": "10.1145/3290605.3300412"}, {"uri": "17", "title": "\u201cEveryone Has Some Personal Stuff\u201d: Designing to Support Digital Privacy with Shared Mobile Phone Use in Bangladesh", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Syed Ishtiaque Ahmed"], "summary": "People in South Asia frequently share a single device among multiple individuals, resulting in digital privacy challenges. This paper explores a design concept that aims to mitigate some of these challenges through a \u2018tiered\u2019 privacy model. Using this model, a person creates a \u2018shared\u2019 account that contains data they are willing to share and that is assigned a password that will be shared. Simultaneously, they create a separate \u2018secret\u2019 account that contains data they prefer to keep secret and that uses a password they do not share with anyone. When a friend or family member asks to check their device, the user can tell them the password for their shared account, with their private data secure in the secret account that the other person is unaware of. We explore the benefits and trade-offs of our design through a three-week deployment with 21 participants in Bangladesh, presenting findings that show how our work aids digital privacy while also highlighting the challenges that remain.", "keywords": ["person", "information", "discovered", "phone", "design", "app", "tier", "friend", "example", "woman", "medium", "user", "sharing", "shared", "conducted", "work", "stored", "participant", "use", "people", "nirapod", "challenge", "finding", "page", "number", "bangladesh", "application", "gallery", "usage", "password", "family", "described", "device", "share", "data", "technology", "study", "said", "system", "account", "prototype", "paper", "privacy", "photo", "hide", "access"], "document_vector": [-12.870257, 45.086399], "paragraphs": [{"paragraph_vector": [70.601127, -80.226005], "paragraph_keywords": ["privacy", "computing", "copies", "work"]}, {"paragraph_vector": [-64.905502, -82.110511], "paragraph_keywords": ["share", "privacy", "tiered", "people"]}, {"paragraph_vector": [26.968421, -83.674896], "paragraph_keywords": ["privacy", "participants", "bangladesh", "challenges"]}, {"paragraph_vector": [44.272712, -74.210426], "paragraph_keywords": ["privacy", "information", "use", "properties"]}, {"paragraph_vector": [64.622779, -61.59375], "paragraph_keywords": ["privacy", "values", "bangladesh", "countries"]}, {"paragraph_vector": [36.37405, -83.47966], "paragraph_keywords": ["device", "sharing", "people", "privacy"]}, {"paragraph_vector": [-141.147064, -90.000083], "paragraph_keywords": ["user", "vault", "design", "data"]}, {"paragraph_vector": [-52.700954, -75.856002], "paragraph_keywords": ["shared", "account", "data", "photos"]}, {"paragraph_vector": [-57.292575, -68.369209], "paragraph_keywords": ["gallery", "application", "password", "account"]}, {"paragraph_vector": [-47.538185, -65.25074], "paragraph_keywords": ["account", "device", "photos", "image"]}, {"paragraph_vector": [-79.525138, -77.050979], "paragraph_keywords": ["participants", "app", "phone", "conducted"]}, {"paragraph_vector": [166.313858, -74.099525], "paragraph_keywords": ["app", "participants", "data", "interview"]}, {"paragraph_vector": [159.843063, -75.835899], "paragraph_keywords": ["participants", "participant", "phone", "data"]}, {"paragraph_vector": [-53.176876, -79.87223], "paragraph_keywords": ["participants", "data", "photos", "sharing"]}, {"paragraph_vector": [-28.964931, -82.488998], "paragraph_keywords": ["participants", "device", "privacy", "sharing"]}, {"paragraph_vector": [-53.996395, -57.573448], "paragraph_keywords": ["participants", "app", "number", "account"]}, {"paragraph_vector": [-50.826091, -78.822944], "paragraph_keywords": ["photos", "family", "participants", "account"]}, {"paragraph_vector": [-50.521007, -78.929397], "paragraph_keywords": ["phone", "photos", "participants", "share"]}, {"paragraph_vector": [-51.601818, -79.176963], "paragraph_keywords": ["photos", "participants", "phone", "people"]}, {"paragraph_vector": [-70.25093, -74.326835], "paragraph_keywords": ["photos", "app", "password", "participants"]}, {"paragraph_vector": [-50.943153, -77.415618], "paragraph_keywords": ["app", "data", "participants", "photos"]}, {"paragraph_vector": [-65.2462, -86.854354], "paragraph_keywords": ["devices", "sharing", "person", "participants"]}, {"paragraph_vector": [83.736015, -88.202201], "paragraph_keywords": ["people", "data", "nirapod", "users"]}, {"paragraph_vector": [51.268093, -76.576011], "paragraph_keywords": ["privacy", "women", "gender", "data"]}, {"paragraph_vector": [-22.254022, -79.685668], "paragraph_keywords": ["password", "passwords", "participants", "remember"]}, {"paragraph_vector": [12.716499, -82.430992], "paragraph_keywords": ["participants", "privacy", "people", "data"]}, {"paragraph_vector": [-6.987389, -84.402145], "paragraph_keywords": ["people", "participants", "privacy", "study"]}], "content": {}, "doi": "10.1145/3290605.3300673"}, {"uri": "18", "title": "Chatbots, Humbots, and the Quest for Artificial General Intelligence", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jonathan Grudin"], "summary": "What began as a quest for artificial general intelligence branched into several pursuits, including intelligent assistants developed by tech companies and task-oriented chatbots that deliver more information or services in specific domains. Progress quickened with the spread of low-latency networking, then accelerated dramatically a few years ago. In 2016, task-focused chatbots became a centerpiece of machine intelligence, promising interfaces that are more engaging than robotic answering systems and that can accommodate our increasingly phone-based information needs. Hundreds of thousands were built. Creating successful non-trivial chatbots proved more difficult than anticipated. Some developers now design for human-chatbot (humbot) teams, with people handling difficult queries. This paper describes the conversational agent space, difficulties in meeting user expectations, potential new design approaches, uses of human-bot hybrids, and implications for the ultimate goal of creating software with general intelligence.", "keywords": ["facebook", "tech", "information", "person", "find", "development", "expectation", "author", "conversation", "companion", "reported", "tier", "restaurant", "focus", "appear", "example", "assistant", "goal", "user", "interaction", "meeting", "chatbots", "work", "language", "tool", "use", "messenger", "web", "people", "bot", "create", "service", "team", "range", "ai", "page", "handled", "year", "effort", "personality", "task", "query", "human", "data", "oriented", "study", "handle", "developer", "system", "customer", "focused", "intelligence", "platform", "request", "software", "chatbot", "paper", "question", "response"], "document_vector": [-74.176284, 1.608135], "paragraphs": [{"paragraph_vector": [34.356475, -88.457389], "paragraph_keywords": ["copies", "use", "intelligence", "software"]}, {"paragraph_vector": [32.040317, -86.06092], "paragraph_keywords": ["bots", "twitter", "notifications", "chatbots"]}, {"paragraph_vector": [-55.207595, -89.781578], "paragraph_keywords": ["chatbots", "chatbot", "web", "people"]}, {"paragraph_vector": [8.294204, -82.944602], "paragraph_keywords": ["information", "software", "task", "chatbots"]}, {"paragraph_vector": [-27.396816, -89.413238], "paragraph_keywords": ["exchanges", "companions", "assistants", "conversation"]}, {"paragraph_vector": [80.217842, -89.502761], "paragraph_keywords": ["chatbots", "bots", "enable", "platform"]}, {"paragraph_vector": [67.712532, -85.064849], "paragraph_keywords": ["chatbots", "chatbot", "bot", "founder"]}, {"paragraph_vector": [28.145851, -87.390678], "paragraph_keywords": ["users", "chatbot", "chatbots", "news"]}, {"paragraph_vector": [-20.271286, -88.296089], "paragraph_keywords": ["chatbot", "responses", "tasks", "humor"]}, {"paragraph_vector": [31.977846, -88.854049], "paragraph_keywords": ["chatbot", "chatbots", "task", "people"]}, {"paragraph_vector": [-20.259672, -89.500793], "paragraph_keywords": ["software", "conversation", "chatbot", "language"]}, {"paragraph_vector": [-60.186328, -85.155998], "paragraph_keywords": ["chatbot", "task", "stadium", "visitor"]}, {"paragraph_vector": [16.673938, -86.106933], "paragraph_keywords": ["chatbot", "people", "intents", "bot"]}, {"paragraph_vector": [1.942209, -89.11737], "paragraph_keywords": ["chatbots", "researchers", "requests", "humans"]}, {"paragraph_vector": [23.438564, -87.789184], "paragraph_keywords": ["tasks", "chatbots", "skip", "scheduling"]}, {"paragraph_vector": [-37.831748, -88.780914], "paragraph_keywords": ["watson", "service", "teaching", "bot"]}, {"paragraph_vector": [-29.371171, -88.361793], "paragraph_keywords": ["personality", "tasks", "model", "bot"]}, {"paragraph_vector": [-26.270101, -89.107666], "paragraph_keywords": ["options", "humbot", "chatbots", "expectations"]}, {"paragraph_vector": [42.941684, -89.157058], "paragraph_keywords": ["chatbots", "knowledge", "intelligence", "business"]}, {"paragraph_vector": [-43.245494, -89.385871], "paragraph_keywords": ["tasks", "people", "plan", "chatbots"]}, {"paragraph_vector": [48.804061, -88.193412], "paragraph_keywords": ["work", "era", "computer", "authors"]}], "content": {}, "doi": "10.1145/3290605.3300588"}, {"uri": "19", "title": "Do People Consume the News they Trust?", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Harsh Taneja", "Katie Yaeger"], "summary": "It is reasonable to expect trusted news organizations to have more engaged users. However, given the lowest levels of trust in media and the several intermediaries involved in digital news consumption, recent studies posit that trust and usage may not be related. We argue that while trust may not relate to overall news usage, given that much of it is incidental, but it could still explain intentional usage. We correlated passively metered usage from digital trace data on 35 national news outlets in the US with their trustworthiness from a nationally representative survey, for three discrete months. We find no association between trust and overall user engagement, but a positive relationship between trustworthiness and direct visits, the latter a measure of intentional usage. These relationships held for outlets despite their partisan leanings, multi-platform presence and their mainstream nature.", "keywords": ["time", "percentage", "association", "source", "analysis", "environment", "relationship", "medium", "user", "engagement", "news", "trust", "comscore", "sample", "trustworthiness", "result", "impact", "use", "people", "outlet", "exposure", "consumer", "factor", "visit", "usage", "audience", "measure", "organization", "data", "study", "variable", "choice", "research", "website", "mainstream", "ideology", "report", "month"], "document_vector": [-44.696537, 32.350391], "paragraphs": [{"paragraph_vector": [-126.144554, 11.321416], "paragraph_keywords": ["news", "media", "trust", "copies"]}, {"paragraph_vector": [-126.617897, 12.253158], "paragraph_keywords": ["news", "usage", "trust", "media"]}, {"paragraph_vector": [-125.174377, 12.926383], "paragraph_keywords": ["trust", "news", "credibility", "organizations"]}, {"paragraph_vector": [-126.737579, 10.416286], "paragraph_keywords": ["news", "trust", "exposure", "mainstream"]}, {"paragraph_vector": [-126.794677, 10.842169], "paragraph_keywords": ["news", "organizations", "studies", "assumption"]}, {"paragraph_vector": [-130.07817, 14.700061], "paragraph_keywords": ["news", "trust", "study", "studies"]}, {"paragraph_vector": [-126.584419, 13.109261], "paragraph_keywords": ["news", "usage", "people", "trust"]}, {"paragraph_vector": [-125.853981, 14.041945], "paragraph_keywords": ["news", "usage", "sources", "trust"]}, {"paragraph_vector": [-126.462303, 12.20437], "paragraph_keywords": ["usage", "news", "trust", "data"]}, {"paragraph_vector": [-127.990959, 13.835482], "paragraph_keywords": ["comscore", "usage", "sample", "report"]}, {"paragraph_vector": [-129.295394, 11.088596], "paragraph_keywords": ["news", "usage", "variables", "ideologies"]}, {"paragraph_vector": [-127.228256, 11.998044], "paragraph_keywords": ["news", "audience", "trustworthiness", "month"]}, {"paragraph_vector": [-128.404174, 12.228384], "paragraph_keywords": ["news", "variables", "trustworthiness", "trust"]}, {"paragraph_vector": [-128.047332, 13.302351], "paragraph_keywords": ["news", "usage", "relationship", "trust"]}, {"paragraph_vector": [-126.770431, 12.335906], "paragraph_keywords": ["news", "trust", "source", "usage"]}, {"paragraph_vector": [-124.883537, 15.110324], "paragraph_keywords": ["news", "sources", "visits", "mainstream"]}, {"paragraph_vector": [-126.065322, 12.737842], "paragraph_keywords": ["usage", "news", "sources", "months"]}, {"paragraph_vector": [-126.750839, 12.934866], "paragraph_keywords": ["news", "usage", "data", "people"]}, {"paragraph_vector": [-127.151748, 11.715178], "paragraph_keywords": ["visits", "trust", "news", "usage"]}, {"paragraph_vector": [-127.083099, 10.920246], "paragraph_keywords": ["news", "data", "organizations", "measure"]}, {"paragraph_vector": [-127.07962, 12.019251], "paragraph_keywords": ["news", "organizations", "trust", "role"]}], "content": {}, "doi": "10.1145/3290605.3300552"}, {"uri": "20", "title": "Saliency Deficit and Motion Outlier Detection  in Animated Scatterplots", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Rafael Veras"], "summary": "We report the results of a crowdsourced experiment that measured the accuracy of motion outlier detection in multivariate, animated scatterplots. The targets were outliers either in speed or direction of motion, and were presented with varying levels of saliency in dimensions that are irrelevant to the task of motion outlier detection (e.g., color, size, position). We found that participants had trouble finding the outlier when it lacked irrelevant salient features and that Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300771 visual channels contribute unevenly to the odds of an outlier being correctly detected. Direction of motion contributes the most to accurate detection of speed outliers, and position contributes the most to accurate detection of direction outliers. We introduce the concept of saliency deficit in which item importance in the data space is not reflected in the visualization due to a lack of saliency. We conclude that motion outlier detection is not well supported in multivariate animated scatterplots.", "keywords": ["direction", "point", "position", "time", "density", "dimension", "scene", "clutter", "animated", "feature", "speed", "experiment", "scatterplots", "accuracy", "outlier", "model", "result", "participant", "perception", "effect", "detection", "size", "visualization", "number", "moving", "found", "stimulus", "motion", "task", "search", "data", "saliency", "study", "variable", "color", "animation", "target", "paper", "value", "response"], "document_vector": [-152.849166, -34.494731], "paragraphs": [{"paragraph_vector": [-25.172323, 47.294765], "paragraph_keywords": ["motion", "studies", "scatterplots", "color"]}, {"paragraph_vector": [-19.732446, 47.589717], "paragraph_keywords": ["motion", "visualization", "saliency", "outlier"]}, {"paragraph_vector": [-17.754549, 44.00209], "paragraph_keywords": ["search", "scene", "number", "searches"]}, {"paragraph_vector": [-18.413551, 44.2868], "paragraph_keywords": ["motion", "saliency", "searching", "targets"]}, {"paragraph_vector": [-17.685184, 46.939212], "paragraph_keywords": ["scatterplots", "dimensions", "motion", "people"]}, {"paragraph_vector": [-19.718858, 46.333454], "paragraph_keywords": ["motion", "density", "feature", "saliency"]}, {"paragraph_vector": [-21.093362, 46.895172], "paragraph_keywords": ["search", "points", "saliency", "distractor"]}, {"paragraph_vector": [-20.901763, 43.933147], "paragraph_keywords": ["saliency", "dimensions", "visualization", "features"]}, {"paragraph_vector": [-19.6275, 45.66333], "paragraph_keywords": ["saliency", "stimuli", "conditions", "scene"]}, {"paragraph_vector": [-17.55034, 45.344741], "paragraph_keywords": ["sampled", "distance", "color", "point"]}, {"paragraph_vector": [-18.191707, 43.838191], "paragraph_keywords": ["direction", "values", "speed", "points"]}, {"paragraph_vector": [-17.819381, 40.12239], "paragraph_keywords": ["task", "participants", "trials", "animation"]}, {"paragraph_vector": [-20.952163, 45.63784], "paragraph_keywords": ["accuracy", "motion", "direction", "speed"]}, {"paragraph_vector": [-17.270181, 41.541664], "paragraph_keywords": ["direction", "odds", "speed", "task"]}, {"paragraph_vector": [-21.35358, 36.151874], "paragraph_keywords": ["points", "dimensions", "saliency", "speed"]}, {"paragraph_vector": [-18.196588, 39.422595], "paragraph_keywords": ["direction", "speed", "position", "saliency"]}, {"paragraph_vector": [-17.375688, 43.16415], "paragraph_keywords": ["direction", "task", "participants", "distribution"]}, {"paragraph_vector": [-18.368061, 45.307601], "paragraph_keywords": ["detection", "saliency", "direction", "feature"]}, {"paragraph_vector": [-23.485872, 45.666938], "paragraph_keywords": ["saliency", "data", "model", "points"]}, {"paragraph_vector": [-18.622747, 46.326816], "paragraph_keywords": ["effect", "experiment", "accuracy", "targets"]}, {"paragraph_vector": [-20.695646, 44.992713], "paragraph_keywords": ["saliency", "accuracy", "targets", "speed"]}], "content": {}, "doi": "10.1145/3290605.3300233"}, {"uri": "21", "title": "Feeling Fireworks: An Inclusive Tactile Firework Display", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Dorothea Reusser"], "summary": "This paper presents a novel design for a large-scale interactive tactile display. Fast dynamic tactile efects are created at high spatial resolution on a fexible screen, using directable nozzles that spray water jets onto the rear of the screen. The screen further has back-projected visual content and touch interaction. The technology is demonstrated in Feeling Fireworks, a tactile frework show. The goal is to make freworks more inclusive for the Blind and Low-Vision (BLV) community. A BLV focus group provided input during the development process, and a user study with BLV users showed that Feeling Fireworks is an enjoyable and meaningful experience. A user study with sighted users showed that users could accurately label the correspondence between the designed tactile frework efects and corresponding visual freworks. Beyond the Feeling Fireworks application, this is a novel approach for scalable tactile displays with potential for broader use.", "keywords": ["feeling", "time", "vision", "efect", "frework", "display", "diferent", "design", "provide", "nozzle", "focus", "touch", "produce", "user", "accessibility", "interaction", "surface", "work", "participant", "use", "resolution", "group", "screen", "freworks", "experience", "water", "number", "page", "content", "membrane", "fig", "scale", "device", "jet", "blv", "technology", "study", "tactile", "system", "firework", "paper", "silicone", "center", "efects"], "document_vector": [135.651931, -64.405227], "paragraphs": [{"paragraph_vector": [-90.707145, 18.781814], "paragraph_keywords": ["copies", "work", "freworks", "acm"]}, {"paragraph_vector": [-96.433868, 32.262855], "paragraph_keywords": ["tactile", "screen", "blv", "content"]}, {"paragraph_vector": [-94.28955, 28.387117], "paragraph_keywords": ["screen", "tactile", "freworks", "users"]}, {"paragraph_vector": [-105.981498, 34.211826], "paragraph_keywords": ["tactile", "work", "text", "resolution"]}, {"paragraph_vector": [-100.933692, 29.939907], "paragraph_keywords": ["content", "touchscreen", "displays", "screen"]}, {"paragraph_vector": [-89.575759, 25.97838], "paragraph_keywords": ["screen", "tactile", "frame", "jets"]}, {"paragraph_vector": [-92.301437, 29.045822], "paragraph_keywords": ["screen", "pump", "nozzle", "water"]}, {"paragraph_vector": [-92.040428, 25.009462], "paragraph_keywords": ["screen", "nozzle", "box", "kinect"]}, {"paragraph_vector": [-93.391456, 21.887189], "paragraph_keywords": ["nozzle", "membrane", "pressure", "water"]}, {"paragraph_vector": [-93.295295, 25.648441], "paragraph_keywords": ["membrane", "screen", "mm", "switching"]}, {"paragraph_vector": [-101.560913, 38.151306], "paragraph_keywords": ["blv", "session", "group", "users"]}, {"paragraph_vector": [-90.334571, 34.274047], "paragraph_keywords": ["efects", "user", "diferent", "tactile"]}, {"paragraph_vector": [-105.21215, 36.482154], "paragraph_keywords": ["users", "experience", "study", "user"]}, {"paragraph_vector": [-116.560173, 38.872341], "paragraph_keywords": ["participants", "experience", "birth", "freworks"]}, {"paragraph_vector": [-97.729461, 35.159271], "paragraph_keywords": ["participants", "study", "freworks", "users"]}, {"paragraph_vector": [-89.234153, 32.118888], "paragraph_keywords": ["screen", "tactile", "center", "efects"]}, {"paragraph_vector": [-91.376464, 35.456478], "paragraph_keywords": ["tactile", "efects", "users", "screen"]}, {"paragraph_vector": [-94.301246, 37.441524], "paragraph_keywords": ["frework", "users", "tactile", "user"]}, {"paragraph_vector": [-91.135543, 27.344268], "paragraph_keywords": ["tactile", "efects", "screen", "touch"]}, {"paragraph_vector": [-95.763748, 27.438047], "paragraph_keywords": ["tactile", "screen", "users", "device"]}, {"paragraph_vector": [95.289512, 6.882944], "paragraph_keywords": ["european", "commission", "horizon", "framework"]}], "content": {}, "doi": "10.1145/3290605.3300321"}, {"uri": "22", "title": "Making Sense of Human-Food Interaction", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Ferran Altarriba Bertran", "Danielle Wilde"], "summary": "Activity in Human-Food Interaction (HFI) research is skyrocketing across a broad range of disciplinary interests and concerns. The dynamic and heterogeneous nature of this emerging field presents a challenge to scholars wishing to critically engage with prior work, identify gaps and ensure impact. It also challenges the formation of community. We present a Systematic Mapping Study of HFI research and an online data visualisation tool developed to respond to these issues. The tool allows researchers to engage in new ways with the HFI literature, propose modifications and additions to the review, and thereby actively engage in communitymaking. Our contribution is threefold: (1) we characterize the state of HFI, reporting trends, challenges and opportunities; (2) we provide a taxonomy and tool for diffractive reading of the literature; and (3) we offer our approach for adaptation by research fields facing similar challenges, positing value of the tool and approach beyond HFI.", "keywords": ["visualisation", "point", "food", "change", "trend", "hfi", "literature", "analysis", "app", "focus", "figure", "example", "mapping", "model", "review", "work", "tool", "agency", "e", "identify", "publication", "domain", "related", "sense", "experience", "page", "field", "number", "dataset", "mail", "-", "diversity", "track", "data", "technology", "researcher", "contribution", "approach", "study", "research", "perspective", "hci", "taxonomy", "paper", "eating", "community"], "document_vector": [15.635107, 42.128158], "paragraphs": [{"paragraph_vector": [113.366645, -43.346828], "paragraph_keywords": ["work", "data", "copies", "reviews"]}, {"paragraph_vector": [75.205703, -5.01686], "paragraph_keywords": ["dataset", "research", "author", "food"]}, {"paragraph_vector": [78.514457, -5.051769], "paragraph_keywords": ["research", "community", "hfi", "food"]}, {"paragraph_vector": [59.604988, -20.073621], "paragraph_keywords": ["community", "workshops", "analysis", "communities"]}, {"paragraph_vector": [70.820663, -12.638128], "paragraph_keywords": ["food", "technology", "dataset", "user"]}, {"paragraph_vector": [71.119667, -9.503267], "paragraph_keywords": ["food", "publication", "contributions", "domains"]}, {"paragraph_vector": [74.979774, -9.840582], "paragraph_keywords": ["data", "food", "visualisation", "research"]}, {"paragraph_vector": [75.858291, -1.913103], "paragraph_keywords": ["research", "tool", "domain", "data"]}, {"paragraph_vector": [80.841148, -4.805451], "paragraph_keywords": ["data", "app", "researchers", "differences"]}, {"paragraph_vector": [75.853073, -5.501804], "paragraph_keywords": ["dataset", "researchers", "community", "comment"]}, {"paragraph_vector": [84.613983, -2.825385], "paragraph_keywords": ["dataset", "tool", "feedback", "poster"]}, {"paragraph_vector": [73.835342, -5.393354], "paragraph_keywords": ["e", "researchers", "-", "tool"]}, {"paragraph_vector": [75.57756, -6.276109], "paragraph_keywords": ["papers", "suggested", "participants", "data"]}, {"paragraph_vector": [78.100151, -7.198021], "paragraph_keywords": ["changes", "analysis", "hfi", "technology"]}, {"paragraph_vector": [72.155891, -10.294053], "paragraph_keywords": ["food", "figure", "data", "domain"]}, {"paragraph_vector": [64.384078, -12.802565], "paragraph_keywords": ["domain", "hfi", "eating", "technology"]}, {"paragraph_vector": [74.772994, -7.86126], "paragraph_keywords": ["hfi", "tools", "sense", "review"]}, {"paragraph_vector": [72.971565, -7.643131], "paragraph_keywords": ["food", "model", "hfi", "community"]}, {"paragraph_vector": [75.894058, -7.752442], "paragraph_keywords": ["technology", "hfi", "researchers", "field"]}, {"paragraph_vector": [79.971351, -2.28151], "paragraph_keywords": ["hfi", "research", "data", "perspectives"]}, {"paragraph_vector": [78.728683, -7.190713], "paragraph_keywords": ["fields", "example", "community", "researchers"]}, {"paragraph_vector": [73.292831, -7.629321], "paragraph_keywords": ["dataset", "tool", "community", "hfi"]}, {"paragraph_vector": [85.214744, 24.135643], "paragraph_keywords": ["hfi", "intend", "continue", "developing"]}], "content": {}, "doi": "10.1145/3290605.3300367"}, {"uri": "23", "title": "Tool Extension in Human\u2013Computer Interaction", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Joanna Bergstr\u00f6m"], "summary": "Tool use extends people\u2019s representations of the immediately actionable space around them. Physical tools thereby become integrated in people\u2019s body schemas.We introduce ameasure for tool extension in HCI by using a visual-tactile interference paradigm. In this paradigm, an index of tool extension is given by response time differences between crossmodally congruent and incongruent stimuli; tactile on the hand and visual on the tool. We use this measure to examine if and how findings on tool extension apply to interactionwith computerbased tools. Our first experiment shows that touchpad and mouse both provide tool extension over a baseline condition without a tool. A second experiment shows a higher degree of tool extension for a realistic avatar hand compared to an abstract pointer for interaction in virtual reality. In sum, our measure can detect tool extension with computer-based tools and differentiate interfaces by their degree of extension.", "keywords": ["vr", "based", "condition", "time", "finger", "body", "cursor", "experiment", "paradigm", "foot", "user", "extension", "interaction", "work", "tool", "space", "participant", "use", "holding", "cce", "finding", "compared", "touchpad", "stimulus", "appearance", "measure", "task", "hand", "computer", "shown", "study", "tactile", "instance", "colleague", "presented", "target", "hci", "paper", "interface", "mouse", "input", "index", "response"], "document_vector": [123.338485, -77.673919], "paragraphs": [{"paragraph_vector": [-85.511756, 3.236187], "paragraph_keywords": ["tool", "copies", "tools", "use"]}, {"paragraph_vector": [-79.4636, 1.685118], "paragraph_keywords": ["tool", "extension", "tools", "paradigm"]}, {"paragraph_vector": [-79.999359, 0.359029], "paragraph_keywords": ["tool", "stimuli", "use", "tools"]}, {"paragraph_vector": [-78.036796, 2.276558], "paragraph_keywords": ["tool", "tools", "holding", "golf"]}, {"paragraph_vector": [-82.787971, 0.701631], "paragraph_keywords": ["mouse", "tool", "extension", "response"]}, {"paragraph_vector": [-80.579811, 4.208103], "paragraph_keywords": ["tool", "hand", "extension", "participants"]}, {"paragraph_vector": [-81.766632, 2.020979], "paragraph_keywords": ["tool", "tools", "computer", "plane"]}, {"paragraph_vector": [-80.339187, 2.694389], "paragraph_keywords": ["hci", "tactile", "work", "measure"]}, {"paragraph_vector": [-77.549705, 0.829192], "paragraph_keywords": ["stimuli", "tactile", "hand", "instance"]}, {"paragraph_vector": [-78.398864, 2.368035], "paragraph_keywords": ["tool", "extension", "input", "conditions"]}, {"paragraph_vector": [-78.257606, 2.650156], "paragraph_keywords": ["input", "participants", "cursor", "tactile"]}, {"paragraph_vector": [-78.487472, 3.525712], "paragraph_keywords": ["cursor", "target", "participants", "stimulus"]}, {"paragraph_vector": [-24.789701, 32.830924], "paragraph_keywords": ["foot", "participants", "cursor", "distance"]}, {"paragraph_vector": [-78.065048, 5.723348], "paragraph_keywords": ["motors", "stimuli", "mouse", "vibration"]}, {"paragraph_vector": [-81.06472, 1.729746], "paragraph_keywords": ["tool", "extension", "hand", "condition"]}, {"paragraph_vector": [-81.597236, 5.477946], "paragraph_keywords": ["hand", "appearance", "cce", "arm"]}, {"paragraph_vector": [-77.496879, 3.772986], "paragraph_keywords": ["participants", "stimulus", "conditions", "times"]}, {"paragraph_vector": [-74.039764, 7.739212], "paragraph_keywords": ["hand", "finger", "foot", "appearance"]}, {"paragraph_vector": [-83.143913, 2.802743], "paragraph_keywords": ["tool", "extension", "measure", "interaction"]}, {"paragraph_vector": [-80.479423, 2.077178], "paragraph_keywords": ["tool", "extension", "tactile", "vr"]}, {"paragraph_vector": [-79.739341, 2.386838], "paragraph_keywords": ["tool", "cce", "extension", "measure"]}, {"paragraph_vector": [-81.228912, 3.39141], "paragraph_keywords": ["extension", "tactile", "tool", "tools"]}, {"paragraph_vector": [-83.61425, 0.034895], "paragraph_keywords": ["represents", "incorporation", "advance", "working"]}], "content": {}, "doi": "10.1145/3290605.3300342"}, {"uri": "24", "title": "Just Give Me What I Want:How People Use and Evaluate Music Search", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Christine Hosey", "Lara Vujovi\u0107"], "summary": "Music-streaming platforms offer users a large amount of content for consumption. Finding the right music can be challenging and users often need to search through extensive catalogs provided by these platforms. Prior research has focused on general-domain web search, which is designed to meet a broad range of user goals. Here, we study search in the domain of music, seeking to understand how and why people use search and how they evaluate their search experiences on a music-streaming platform. Over two studies, we conducted semi-structured interviews with 27 participants, asking about their search habits and preferences, and observing their behavior while searching for music. Analysis revealed participants evaluated their search experiences along two dimensions: success and effort. Importantly, how participants perceived success and effort differed by their mindset, or the way they assessed the results of their query. We conclude with recommendations to improve the user experience of music search.", "keywords": ["success", "based", "find", "information", "design", "wanted", "artist", "goal", "user", "type", "work", "result", "streaming", "participant", "use", "people", "code", "listening", "experience", "page", "mindset", "understanding", "music", "content", "found", "playlist", "understand", "effort", "described", "query", "search", "data", "entity", "study", "song", "serp", "catalog", "system", "research", "focused", "platform", "genre", "searching", "spotify"], "document_vector": [-1.797232, 0.315343], "paragraphs": [{"paragraph_vector": [140.92427, 33.098857], "paragraph_keywords": ["music", "storage", "copies", "work"]}, {"paragraph_vector": [139.05513, 35.352031], "paragraph_keywords": ["music", "search", "users", "goals"]}, {"paragraph_vector": [136.846038, 34.041591], "paragraph_keywords": ["search", "users", "song", "spotify"]}, {"paragraph_vector": [141.645477, 33.843364], "paragraph_keywords": ["music", "search", "mindset", "listening"]}, {"paragraph_vector": [141.58345, 34.675651], "paragraph_keywords": ["music", "people", "sharing", "supported"]}, {"paragraph_vector": [141.326049, 33.781826], "paragraph_keywords": ["music", "queries", "needs", "user"]}, {"paragraph_vector": [139.282791, 34.399738], "paragraph_keywords": ["user", "users", "music", "search"]}, {"paragraph_vector": [139.59436, 34.634082], "paragraph_keywords": ["search", "participants", "searching", "experiences"]}, {"paragraph_vector": [127.020103, -30.003641], "paragraph_keywords": ["codes", "themes", "participants", "search"]}, {"paragraph_vector": [139.082412, 34.752994], "paragraph_keywords": ["listening", "participants", "search", "goal"]}, {"paragraph_vector": [138.675369, 37.029048], "paragraph_keywords": ["search", "participants", "tracks", "artist"]}, {"paragraph_vector": [139.66072, 36.572219], "paragraph_keywords": ["content", "participants", "song", "effort"]}, {"paragraph_vector": [139.075942, 35.298252], "paragraph_keywords": ["participants", "search", "mindset", "searching"]}, {"paragraph_vector": [141.268737, 36.455928], "paragraph_keywords": ["mindset", "searches", "participants", "search"]}, {"paragraph_vector": [140.290206, 34.843647], "paragraph_keywords": ["mindset", "participants", "mindsets", "effort"]}, {"paragraph_vector": [139.550048, 33.035243], "paragraph_keywords": ["mindsets", "study", "participants", "mindset"]}, {"paragraph_vector": [139.52304, 34.65158], "paragraph_keywords": ["search", "participants", "find", "searches"]}, {"paragraph_vector": [124.566123, 27.93791], "paragraph_keywords": ["mindsets", "search", "participants", "success"]}, {"paragraph_vector": [137.785079, 35.138244], "paragraph_keywords": ["participants", "search", "mindsets", "artist"]}, {"paragraph_vector": [136.53363, 37.932914], "paragraph_keywords": ["participants", "search", "searches", "expected"]}, {"paragraph_vector": [139.18457, 33.970554], "paragraph_keywords": ["participants", "music", "reported", "content"]}, {"paragraph_vector": [140.034484, 34.772323], "paragraph_keywords": ["search", "music", "people", "streaming"]}, {"paragraph_vector": [139.826278, 34.261508], "paragraph_keywords": ["search", "mindset", "participants", "dimensions"]}, {"paragraph_vector": [141.963409, 35.268852], "paragraph_keywords": ["query", "search", "user", "artist"]}, {"paragraph_vector": [141.116455, 34.775672], "paragraph_keywords": ["participants", "playlist", "music", "artist"]}, {"paragraph_vector": [139.155349, 34.262245], "paragraph_keywords": ["users", "effort", "success", "search"]}, {"paragraph_vector": [138.488632, 34.946071], "paragraph_keywords": ["search", "metrics", "streaming", "building"]}], "content": {}, "doi": "10.1145/3290605.3300346"}, {"uri": "25", "title": "ThermalBracelet : Exploring Thermal Haptic Feedback Around the Wrist", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Roshan Lalitha Peiris", "Yuan-Ling Feng", "Liwei Chan"], "summary": "Smartwatches enable the wrist to be used as an ideal location to provide always-available haptic notifications as they are constantly worn with direct contact with the skin. With the wrist straps, the haptic feedback can be extended to the full space around the wrist to provide more spatial and enhanced feedback. With ThermalBracelet, we investigate thermal feedback as a haptic feedback modality around the wrist. We present three studies that lead to the development of a smartwatch-integratable thermal bracelet that stimulates six locations around the wrist. Our initial evaluation reports on the selection of the thermal module configurations. Secondly, with the selected six-module configuration, we explore its usability in real-world scenarios such as walking and reading. Thirdly, we investigate its capability of providing spatio temporal feedback while engaged in distracting tasks. Finally we present application scenarios that demonstrates its usability.", "keywords": ["explore", "based", "perceived", "condition", "information", "addition", "location", "author", "actuator", "provide", "temperature", "accuracy", "work", "result", "participant", "explored", "perception", "vibrotactile", "identify", "page", "feedback", "stimulus", "providing", "module", "configuration", "study", "research", "skin", "prototype", "paper", "wrist", "figure"], "document_vector": [52.984107, -58.513126], "paragraphs": [{"paragraph_vector": [-80.085899, -1.841379], "paragraph_keywords": ["wrist", "copies", "feedback", "explored"]}, {"paragraph_vector": [-81.24234, -2.644993], "paragraph_keywords": ["feedback", "wrist", "actuators", "providing"]}, {"paragraph_vector": [-76.455368, -3.185145], "paragraph_keywords": ["wrist", "based", "authors", "feedback"]}, {"paragraph_vector": [-80.077781, -1.753734], "paragraph_keywords": ["wrist", "feedback", "work", "authors"]}, {"paragraph_vector": [-79.720764, -1.354823], "paragraph_keywords": ["modules", "module", "temperature", "driver"]}, {"paragraph_vector": [-80.835197, 0.036835], "paragraph_keywords": ["modules", "wrist", "providing", "based"]}, {"paragraph_vector": [-76.45845, -7.2272], "paragraph_keywords": ["participants", "stimuli", "study", "temperature"]}, {"paragraph_vector": [-77.649131, -10.119077], "paragraph_keywords": ["stimuli", "temperature", "perceived", "results"]}, {"paragraph_vector": [-78.92292, -4.355922], "paragraph_keywords": ["stimuli", "configuration", "wrist", "feedback"]}, {"paragraph_vector": [-78.386253, -3.012027], "paragraph_keywords": ["study", "vibrotactile", "participants", "wrist"]}, {"paragraph_vector": [-77.971275, 1.600458], "paragraph_keywords": ["participant", "study", "stimuli", "perceived"]}, {"paragraph_vector": [-79.252532, -1.655994], "paragraph_keywords": ["stimuli", "location", "confusion", "accuracy"]}, {"paragraph_vector": [-79.42926, -3.541941], "paragraph_keywords": ["stimuli", "study", "participants", "location"]}, {"paragraph_vector": [-78.863464, -2.773072], "paragraph_keywords": ["stimuli", "feedback", "participants", "vibrotactile"]}, {"paragraph_vector": [-79.691902, -3.074543], "paragraph_keywords": ["feedback", "stimuli", "configuration", "results"]}, {"paragraph_vector": [-77.665954, -2.544568], "paragraph_keywords": ["stimuli", "wrist", "thermalbracelet", "feedback"]}, {"paragraph_vector": [-80.040336, -3.823495], "paragraph_keywords": ["stimuli", "feedback", "parameters", "research"]}, {"paragraph_vector": [-79.644721, -2.341916], "paragraph_keywords": ["feedback", "modules", "module", "issue"]}], "content": {}, "doi": "10.1145/3290605.3300266"}, {"uri": "26", "title": "Expression of Curiosity in Social Robots", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Nalin Chhibber"], "summary": "Curiosity\u2013the intrinsic desire for new information\u2013can enhance learning, memory, and exploration. Therefore, understanding how to elicit curiosity can inform the design of educational technologies. In this work, we investigate how a social peer robot\u2019s verbal expression of curiosity is perceived, whether it can affect the emotional feeling and behavioural expression of curiosity in students, and how it impacts learning. In a between-subjects experiment, 30 participants played the game LinkIt!, a game we designed for teaching rock classification, with a robot verbally expressing: curiosity, curiosity plus rationale, or no curiosity. Results indicate that participants could recognize the robot\u2019s curiosity and that curious robots produced both emotional and behavioural curiosity contagion effects in participants.", "keywords": ["condition", "information", "nao", "behaviour", "player", "feature", "design", "type", "contagion", "quiz", "interaction", "know", "work", "result", "participant", "learning", "think", "curiosity", "rock", "page", "found", "providing", "test", "robot", "measure", "task", "asking", "shown", "game", "study", "convey", "period", "student", "difference", "session", "order", "asked", "question", "week", "paper", "knowledge"], "document_vector": [-98.844284, 28.334442], "paragraphs": [{"paragraph_vector": [-158.760192, 22.863019], "paragraph_keywords": ["curiosity", "students", "copies", "acm"]}, {"paragraph_vector": [-154.478591, 21.1595], "paragraph_keywords": ["learning", "curiosity", "robot", "students"]}, {"paragraph_vector": [-153.656768, 23.700414], "paragraph_keywords": ["curiosity", "robot", "children", "learning"]}, {"paragraph_vector": [-157.902496, 21.754425], "paragraph_keywords": ["curiosity", "robot", "learning", "contagion"]}, {"paragraph_vector": [-159.820755, 25.569278], "paragraph_keywords": ["rocks", "card", "game", "player"]}, {"paragraph_vector": [-154.962051, 23.243482], "paragraph_keywords": ["robot", "curiosity", "rocks", "game"]}, {"paragraph_vector": [-160.380523, 25.352283], "paragraph_keywords": ["robot", "curiosity", "questions", "participants"]}, {"paragraph_vector": [-156.025451, 20.369684], "paragraph_keywords": ["robot", "participants", "nao", "session"]}, {"paragraph_vector": [-156.960922, 22.691076], "paragraph_keywords": ["robot", "participant", "game", "quizzes"]}, {"paragraph_vector": [-156.841629, 21.0913], "paragraph_keywords": ["rocks", "curiosity", "participants", "robot"]}, {"paragraph_vector": [-155.726242, 20.462862], "paragraph_keywords": ["curiosity", "participants", "robot", "interview"]}, {"paragraph_vector": [-156.99414, 22.360187], "paragraph_keywords": ["curiosity", "participants", "feature", "information"]}, {"paragraph_vector": [-158.566619, 24.344339], "paragraph_keywords": ["participants", "robot", "curiosity", "variables"]}, {"paragraph_vector": [-157.090164, 23.642986], "paragraph_keywords": ["robot", "rocks", "asking", "participants"]}, {"paragraph_vector": [-159.766342, 20.407346], "paragraph_keywords": ["participants", "curiosity", "robot", "think"]}, {"paragraph_vector": [-159.654342, 21.686697], "paragraph_keywords": ["rocks", "curiosity", "participants", "conditions"]}, {"paragraph_vector": [-155.781936, 23.750467], "paragraph_keywords": ["rocks", "participants", "condition", "robot"]}, {"paragraph_vector": [-156.633941, 23.18824], "paragraph_keywords": ["robot", "rocks", "curiosity", "participant"]}, {"paragraph_vector": [-156.104537, 22.879896], "paragraph_keywords": ["robot", "responses", "condition", "conditions"]}, {"paragraph_vector": [-155.578109, 24.43128], "paragraph_keywords": ["participants", "features", "number", "rocks"]}, {"paragraph_vector": [-156.918273, 21.943435], "paragraph_keywords": ["curiosity", "robot", "participants", "rocks"]}, {"paragraph_vector": [-158.335449, 22.915161], "paragraph_keywords": ["curiosity", "participants", "robot", "behaviour"]}, {"paragraph_vector": [-156.264404, 20.919256], "paragraph_keywords": ["curiosity", "participants", "robot", "knowledge"]}, {"paragraph_vector": [-156.211486, 19.51218], "paragraph_keywords": ["curiosity", "participants", "differences", "students"]}, {"paragraph_vector": [-158.835449, 21.568738], "paragraph_keywords": ["curiosity", "robot", "design", "work"]}], "content": {}, "doi": "10.1145/3290605.3300802"}, {"uri": "27", "title": "An Exploratory Study of the Use of Drones for Assisting Firefighters During Emergency Situations", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Md. Nafiz Hasan Khan"], "summary": "In the near future, emergency services within Canada will be supporting new technologies for 9-1-1 call centres and firefighters to learn about an emergency situation. One such technology is drones. To understand the benefits and challenges of using drones within emergency response, we conducted a study with citizens who have called 9-1-1 and firefighters who respond to a range of everyday emergencies. Our results show that drones have numerous benefits to both firefighters and 9-1-1 callers which include context awareness and social support for callers who receive feelings of assurance that help is on the way. Privacy was largely not an issue, though safety issues arose especially for complex uses of drones such as indoor flying. Our results point to opportunities for designing drone systems that help people to develop a sense of trust with emergency response drones, and mitigate privacy and safety concerns with more complex drone systems.", "keywords": ["police", "capture", "emergency", "benefit", "need", "talked", "information", "scene", "capturing", "design", "reaction", "drone", "provide", "safety", "fire", "example", "help", "camera", "thought", "responder", "work", "video", "building", "participant", "create", "people", "explored", "concern", "issue", "way", "challenge", "footage", "control", "page", "felt", "number", "call", "caller", "-", "firefighter", "study", "situation", "centre", "fly", "order", "paper", "privacy", "response"], "document_vector": [143.507339, 21.586742], "paragraphs": [{"paragraph_vector": [-61.537258, -32.076541], "paragraph_keywords": ["emergency", "provide", "responders", "technologies"]}, {"paragraph_vector": [-62.052242, -31.705102], "paragraph_keywords": ["firefighters", "use", "copies", "work"]}, {"paragraph_vector": [-60.590164, -29.838178], "paragraph_keywords": ["emergency", "callers", "takers", "drones"]}, {"paragraph_vector": [-63.137054, -33.208709], "paragraph_keywords": ["video", "information", "people", "emergency"]}, {"paragraph_vector": [-59.363075, -32.429157], "paragraph_keywords": ["drones", "explored", "firefighters", "studied"]}, {"paragraph_vector": [-61.295959, -31.380744], "paragraph_keywords": ["participants", "drone", "people", "emergency"]}, {"paragraph_vector": [-63.122817, -30.033378], "paragraph_keywords": ["police", "experience", "drones", "fire"]}, {"paragraph_vector": [-63.253589, -30.645944], "paragraph_keywords": ["participants", "video", "drone", "emergency"]}, {"paragraph_vector": [-61.745956, -31.937658], "paragraph_keywords": ["video", "footage", "videos", "camera"]}, {"paragraph_vector": [-60.330894, -31.690233], "paragraph_keywords": ["drone", "asked", "order", "scenes"]}, {"paragraph_vector": [-64.188217, -31.747362], "paragraph_keywords": ["drones", "callers", "participants", "data"]}, {"paragraph_vector": [-61.450717, -32.231861], "paragraph_keywords": ["drones", "drone", "callers", "emergency"]}, {"paragraph_vector": [-61.311794, -30.873527], "paragraph_keywords": ["fire", "drones", "firefighters", "building"]}, {"paragraph_vector": [-59.361907, -33.18328], "paragraph_keywords": ["drones", "firefighters", "scene", "help"]}, {"paragraph_vector": [-61.148319, -32.594074], "paragraph_keywords": ["drones", "help", "drone", "thought"]}, {"paragraph_vector": [-61.795597, -31.737602], "paragraph_keywords": ["drones", "drone", "truck", "help"]}, {"paragraph_vector": [-62.509029, -30.873533], "paragraph_keywords": ["drones", "drone", "need", "order"]}, {"paragraph_vector": [-62.544204, -30.372203], "paragraph_keywords": ["drones", "scene", "drone", "firehalls"]}, {"paragraph_vector": [-62.80878, -30.532201], "paragraph_keywords": ["drone", "felt", "control", "firefighters"]}, {"paragraph_vector": [-64.89627, -30.97882], "paragraph_keywords": ["way", "drone", "help", "callers"]}, {"paragraph_vector": [-63.168048, -32.696949], "paragraph_keywords": ["drone", "capturing", "emergency", "audio"]}, {"paragraph_vector": [-60.062271, -30.638254], "paragraph_keywords": ["seeing", "concerns", "information", "privacy"]}, {"paragraph_vector": [-61.932384, -30.596076], "paragraph_keywords": ["drones", "firefighters", "scene", "drone"]}, {"paragraph_vector": [-61.761241, -30.176321], "paragraph_keywords": ["drones", "people", "emergency", "situations"]}, {"paragraph_vector": [-60.874755, -31.384555], "paragraph_keywords": ["emergency", "drones", "drone", "need"]}, {"paragraph_vector": [-62.129608, -31.644935], "paragraph_keywords": ["scene", "drone", "firefighters", "work"]}, {"paragraph_vector": [-60.958099, -31.858066], "paragraph_keywords": ["drones", "issues", "emergency", "drone"]}, {"paragraph_vector": [-62.550121, -31.617465], "paragraph_keywords": ["reactions", "participants", "support", "drones"]}, {"paragraph_vector": [-62.294952, -31.782217], "paragraph_keywords": ["drones", "research", "design", "given"]}], "content": {}, "doi": "10.1145/3290605.3300240"}, {"uri": "28", "title": "Designing Theory-Driven User-Centric Explainable AI", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Danding Wang", "Qian Yang", "Ashraf Abdul", "Brian Y. Lim"], "summary": "From healthcare to criminal justice, artificial intelligence (AI) is increasingly supporting high-consequence human decisions. This has spurred the field of explainable AI (XAI). This paper seeks to strengthen empirical applicationspecific investigations of XAI by exploring theoretical underpinnings of human decision making, drawing from the fields of philosophy and psychology. In this paper, we propose a conceptual framework for building humancentered, decision-theory-driven XAI based on an extensive review across these fields. Drawing on this framework, we identify pathways along which human cognitive patterns drives needs for building XAI and how XAI can mitigate common cognitive biases. We then put this framework into practice by designing and implementing an explainable clinical diagnostic tool for intensive care phenotyping and conducting a co-design exercise with clinicians. Thereafter, we draw insights into how this framework bridges algorithm-generated explanations and human decision-making theories. Finally, we discuss implications for XAI design and development.", "keywords": ["reasoning", "based", "consider", "xai", "attribution", "object", "explanation", "feature", "design", "literature", "method", "expected", "showing", "help", "goal", "describe", "user", "model", "trust", "decision", "work", "cause", "use", "people", "identify", "probability", "hypothesis", "reason", "concept", "factor", "ai", "page", "diagnosis", "test", "case", "driven", "data", "framework", "system", "support", "facility", "mitigate", "research", "bias", "rule", "paper", "input", "making"], "document_vector": [-89.490699, 1.473116], "paragraphs": [{"paragraph_vector": [73.844451, 56.002006], "paragraph_keywords": ["users", "copies", "decision", "making"]}, {"paragraph_vector": [71.283317, 51.794059], "paragraph_keywords": ["framework", "xai", "explanation", "ai"]}, {"paragraph_vector": [68.591773, 47.789611], "paragraph_keywords": ["explanations", "explanation", "systems", "researchers"]}, {"paragraph_vector": [69.487792, 45.447605], "paragraph_keywords": ["reasoning", "framework", "xai", "explanations"]}, {"paragraph_vector": [71.567008, 53.158802], "paragraph_keywords": ["framework", "xai", "reasoning", "decision"]}, {"paragraph_vector": [64.617416, 56.425613], "paragraph_keywords": ["explanations", "decision", "users", "support"]}, {"paragraph_vector": [68.355751, 56.06834], "paragraph_keywords": ["reasoning", "explanations", "observation", "find"]}, {"paragraph_vector": [61.961044, 58.552837], "paragraph_keywords": ["explanation", "causes", "attribution", "factors"]}, {"paragraph_vector": [63.742851, 61.666381], "paragraph_keywords": ["reasoning", "probability", "methods", "explanations"]}, {"paragraph_vector": [61.321846, 58.765586], "paragraph_keywords": ["explanation", "explanations", "queries", "users"]}, {"paragraph_vector": [67.175781, 58.948143], "paragraph_keywords": ["represent", "concepts", "explanations", "data"]}, {"paragraph_vector": [29.994171, 82.225669], "paragraph_keywords": ["reasoning", "factors", "charts", "support"]}, {"paragraph_vector": [72.495353, 60.049991], "paragraph_keywords": ["reasoning", "people", "thinking", "system"]}, {"paragraph_vector": [76.111839, 56.091918], "paragraph_keywords": ["reasoning", "decision", "lead", "hypothesis"]}, {"paragraph_vector": [71.159271, 55.456043], "paragraph_keywords": ["decision", "strategies", "xai", "making"]}, {"paragraph_vector": [58.497978, 56.893375], "paragraph_keywords": ["bias", "decision", "mitigate", "showing"]}, {"paragraph_vector": [67.761558, 52.955604], "paragraph_keywords": ["system", "reasoning", "explanations", "trust"]}, {"paragraph_vector": [70.829734, 54.332038], "paragraph_keywords": ["decision", "reasoning", "xai", "explanations"]}, {"paragraph_vector": [68.413856, 54.370517], "paragraph_keywords": ["participants", "features", "explanation", "diagnosis"]}, {"paragraph_vector": [66.400962, 51.979663], "paragraph_keywords": ["users", "reasoning", "diagnosis", "attributions"]}, {"paragraph_vector": [66.371284, 54.605983], "paragraph_keywords": ["users", "values", "feature", "prototypes"]}, {"paragraph_vector": [68.095581, 54.716426], "paragraph_keywords": ["users", "data", "feature", "applications"]}, {"paragraph_vector": [65.516075, 52.849269], "paragraph_keywords": ["reasoning", "users", "xai", "explanations"]}, {"paragraph_vector": [64.96022, 55.210796], "paragraph_keywords": ["xai", "data", "interaction", "work"]}, {"paragraph_vector": [68.97496, 49.48682], "paragraph_keywords": ["explanations", "explanation", "xai", "user"]}, {"paragraph_vector": [65.761741, 42.574825], "paragraph_keywords": ["kee", "reasoning", "research", "xai"]}], "content": {}, "doi": "10.1145/3290605.3300751"}, {"uri": "29", "title": "Online Grocery Delivery Services: An Opportunity to Address Food Disparities in Transportation-scarce Areas", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Tawanna R. Dillahunt", "Sylvia Simioni", "Xuecong Xu"], "summary": "Online grocery delivery services present new opportunities to address food disparities, especially in underserved areas. However, such services have not been systematically evaluated. This study evaluates such services\u2019 potential to provide healthy-food access and infuence healthy-food purchases among individuals living in transportation-scarce and low-resource areas. We conducted a pilot experiment with 20 participants consisting of a randomly assigned group\u2019s 1-month use of an online grocery delivery service, and a control group\u2019s 1-month collection of grocery receipts, and a set of semi-structured interviews. We found that online grocery delivery services (a) serve as a feasible model to healthy-food access if they are afordable and amenable to multiple payment forms and (b) could lead to healthier selections. We contribute policy recommendations to bolster afordability of healthy-food access and design opportunities to promote healthy foods to support the adoption and use of these services among low-resource and transportation-scarce groups.", "keywords": ["based", "food", "time", "credit", "information", "community", "design", "purchase", "method", "interview", "store", "provide", "income", "noted", "produce", "purchased", "having", "shopping", "work", "result", "shop", "month", "participant", "use", "people", "ebt", "group", "market", "delivery", "service", "concern", "health", "cost", "consumer", "experience", "page", "receipt", "found", "provided", "understand", "afordability", "item", "technology", "study", "choice", "research", "grocery", "shipt", "address", "quality", "individual", "hci", "paper", "area", "transportation", "access", "supermarket"], "document_vector": [4.2474, 46.97414], "paragraphs": [{"paragraph_vector": [110.25093, -48.447589], "paragraph_keywords": ["grocery", "copies", "acm", "shopping"]}, {"paragraph_vector": [13.953373, -20.695941], "paragraph_keywords": ["food", "access", "supermarkets", "consumers"]}, {"paragraph_vector": [13.998656, -21.915119], "paragraph_keywords": ["grocery", "delivery", "individuals", "access"]}, {"paragraph_vector": [15.192352, -22.772731], "paragraph_keywords": ["consumer", "services", "research", "technology"]}, {"paragraph_vector": [14.066335, -22.80167], "paragraph_keywords": ["food", "research", "areas", "access"]}, {"paragraph_vector": [13.89692, -22.182035], "paragraph_keywords": ["transportation", "services", "access", "grocery"]}, {"paragraph_vector": [13.847408, -25.405464], "paragraph_keywords": ["participants", "group", "shipt", "numbers"]}, {"paragraph_vector": [14.866851, -21.559074], "paragraph_keywords": ["shipt", "individuals", "credit", "transportation"]}, {"paragraph_vector": [13.588671, -22.527957], "paragraph_keywords": ["participants", "shipt", "interviews", "service"]}, {"paragraph_vector": [11.951343, -21.268995], "paragraph_keywords": ["participants", "grocery", "transportation", "provide"]}, {"paragraph_vector": [15.770761, -22.627248], "paragraph_keywords": ["coding", "food", "transportation", "transcripts"]}, {"paragraph_vector": [15.144925, -18.019523], "paragraph_keywords": ["items", "food", "grams", "purchased"]}, {"paragraph_vector": [12.546315, -23.490297], "paragraph_keywords": ["participant", "research", "study", "shipt"]}, {"paragraph_vector": [12.962244, -22.001199], "paragraph_keywords": ["participants", "transportation", "purchases", "items"]}, {"paragraph_vector": [13.657433, -22.776412], "paragraph_keywords": ["service", "participants", "transportation", "services"]}, {"paragraph_vector": [12.50994, -25.166112], "paragraph_keywords": ["items", "participants", "noted", "shipt"]}, {"paragraph_vector": [17.350835, -22.670742], "paragraph_keywords": ["participants", "shipt", "service", "items"]}, {"paragraph_vector": [15.971113, -23.09543], "paragraph_keywords": ["participants", "markets", "keisha", "quality"]}, {"paragraph_vector": [15.171855, -25.178592], "paragraph_keywords": ["shipt", "participants", "ebt", "payment"]}, {"paragraph_vector": [18.069419, -28.85502], "paragraph_keywords": ["time", "service", "shopping", "participants"]}, {"paragraph_vector": [15.541805, -27.778417], "paragraph_keywords": ["experience", "technology", "shopping", "lovebug"]}, {"paragraph_vector": [16.603282, -20.536094], "paragraph_keywords": ["participants", "store", "stores", "produce"]}, {"paragraph_vector": [19.134702, -20.392066], "paragraph_keywords": ["shipt", "results", "food", "items"]}, {"paragraph_vector": [15.449814, -21.802946], "paragraph_keywords": ["participants", "service", "items", "services"]}, {"paragraph_vector": [13.872889, -20.103321], "paragraph_keywords": ["services", "transportation", "participants", "grocery"]}, {"paragraph_vector": [15.41035, -23.243837], "paragraph_keywords": ["participants", "ebt", "access", "services"]}, {"paragraph_vector": [14.36028, -21.498798], "paragraph_keywords": ["food", "grocery", "purchases", "participants"]}, {"paragraph_vector": [14.616296, -22.178388], "paragraph_keywords": ["participants", "purchases", "behaviors", "health"]}, {"paragraph_vector": [14.686485, -20.487108], "paragraph_keywords": ["items", "participants", "produce", "service"]}, {"paragraph_vector": [15.240221, -22.127107], "paragraph_keywords": ["food", "services", "access", "grocery"]}, {"paragraph_vector": [70.858688, 26.360052], "paragraph_keywords": ["work", "supported", "nsf", "award"]}], "content": {}, "doi": "10.1145/3290605.3300286"}, {"uri": "30", "title": "\u201cTricky to get your head around\u201d: Information Work of People Managing Chronic Kidney Disease in the UK", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Eleanor R. Burgess", "Madhu C. Reddy"], "summary": "People diagnosed with a chronic health condition have many information needs which healthcare providers, patient groups, and resource designers seek to support. However, as a disease progresses, knowing when, how, and for what purposes patients want to interact with and construct personal meaning from health-related information is still unclear. This paper presents findings regarding the information work of chronic kidney disease patients. We conducted semi-structured interviews with 13 patients and 6 clinicians, and observations at 9 patient group events. We used the stages of the information journey \u2013 recognizing need, seeking, interpreting, and using information \u2013 to frame our data analysis. We identified two distinct but often overlapping information work phases, \u2018Learning\u2019 and \u2018Living With\u2019 a chronic condition to show how patient information work activities shift over time. We also describe social and individual factors influencing information work, and discuss technology design opportunities including customized education and collaboration tools. CCS CONCEPTS \u2022 Human-centered Computing \u2192 Human computer interaction (HCI); HCI theory, concepts and models", "keywords": ["process", "based", "time", "condition", "need", "information", "resource", "self", "education", "nephrologist", "care", "stage", "ckd", "disease", "help", "activity", "context", "aspect", "decision", "work", "result", "management", "participant", "use", "patient", "people", "team", "treatment", "health", "learning", "related", "future", "page", "experience", "nurse", "understanding", "found", "including", "understand", "life", "member", "described", "family", "phase", "technology", "study", "researcher", "support", "provider", "sensemaking", "meaning", "question", "paper", "healthcare", "behavior", "kidney", "dialysis", "making"], "document_vector": [-149.076873, 89.20951], "paragraphs": [{"paragraph_vector": [162.627319, -13.90448], "paragraph_keywords": ["information", "work", "copies", "health"]}, {"paragraph_vector": [156.299957, -11.004585], "paragraph_keywords": ["information", "work", "patients", "care"]}, {"paragraph_vector": [157.598526, -12.706915], "paragraph_keywords": ["information", "work", "patients", "kidney"]}, {"paragraph_vector": [157.396621, -9.418245], "paragraph_keywords": ["dialysis", "patients", "kidney", "self"]}, {"paragraph_vector": [158.943511, -14.528365], "paragraph_keywords": ["information", "patients", "work", "healthcare"]}, {"paragraph_vector": [157.220489, -9.086857], "paragraph_keywords": ["information", "work", "health", "patients"]}, {"paragraph_vector": [158.690567, -12.625322], "paragraph_keywords": ["information", "treatment", "patients", "stages"]}, {"paragraph_vector": [152.879287, -25.500963], "paragraph_keywords": ["meaning", "making", "information", "understanding"]}, {"paragraph_vector": [155.565948, -13.342355], "paragraph_keywords": ["patients", "information", "work", "sites"]}, {"paragraph_vector": [147.724258, -20.452808], "paragraph_keywords": ["information", "interviews", "patient", "patients"]}, {"paragraph_vector": [154.349624, -15.161113], "paragraph_keywords": ["information", "work", "patients", "analysis"]}, {"paragraph_vector": [158.464416, -12.20898], "paragraph_keywords": ["patients", "care", "information", "questions"]}, {"paragraph_vector": [157.318832, -11.380573], "paragraph_keywords": ["information", "patients", "nurses", "members"]}, {"paragraph_vector": [157.581634, -13.882139], "paragraph_keywords": ["information", "patients", "people", "help"]}, {"paragraph_vector": [161.845245, -11.008703], "paragraph_keywords": ["patient", "patients", "nephrologist", "supporting"]}, {"paragraph_vector": [157.744201, -10.251077], "paragraph_keywords": ["treatment", "information", "patients", "patient"]}, {"paragraph_vector": [158.030242, -11.988297], "paragraph_keywords": ["information", "patients", "treatment", "decisions"]}, {"paragraph_vector": [157.745574, -11.740026], "paragraph_keywords": ["care", "information", "condition", "team"]}, {"paragraph_vector": [157.2108, -13.620665], "paragraph_keywords": ["information", "need", "patients", "routines"]}, {"paragraph_vector": [159.228454, -12.092512], "paragraph_keywords": ["results", "patients", "information", "page"]}, {"paragraph_vector": [159.373641, -13.003045], "paragraph_keywords": ["information", "described", "healthcare", "health"]}, {"paragraph_vector": [158.509002, -9.658626], "paragraph_keywords": ["mark", "information", "medication", "health"]}, {"paragraph_vector": [152.53572, -16.073402], "paragraph_keywords": ["information", "work", "patients", "learning"]}, {"paragraph_vector": [156.474609, -14.226531], "paragraph_keywords": ["information", "patients", "resources", "sensemaking"]}, {"paragraph_vector": [157.164245, -14.77641], "paragraph_keywords": ["information", "patients", "found", "groups"]}, {"paragraph_vector": [158.350616, -11.289923], "paragraph_keywords": ["patients", "information", "behaviors", "healthcare"]}, {"paragraph_vector": [157.811126, -12.237428], "paragraph_keywords": ["information", "work", "patient", "patients"]}, {"paragraph_vector": [158.449523, -12.004211], "paragraph_keywords": ["information", "education", "patients", "work"]}, {"paragraph_vector": [158.795486, -12.217722], "paragraph_keywords": ["information", "patients", "search", "time"]}, {"paragraph_vector": [158.42517, -10.803756], "paragraph_keywords": ["resources", "patients", "health", "information"]}, {"paragraph_vector": [157.422607, -12.336869], "paragraph_keywords": ["information", "patients", "work", "activities"]}], "content": {}, "doi": "10.1145/3290605.3300484"}, {"uri": "31", "title": "Beyond Dyadic Interactions: Considering Chatbots as Community Members", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Joseph Seering", "Michal Luria"], "summary": "Chatbots have grown as a space for research and development in recent years due both to the realization of their commercial potential and to advancements in language processing that have facilitated more natural conversations. However, nearly all chatbots to date have been designed for dyadic, one-on-one communication with users. In this paper we present a comprehensive review of research on chatbots supplemented by a review of commercial and independent chatbots. We argue that chatbots\u2019 social roles and conversational capabilities beyond dyadic interactions have been underexplored, and that expansion into this design space could support richer social interactions in online communities and help address the longstanding challenges of maintaining, moderating, and growing these communities. In order to identify opportunities beyond dyadic interactions, we used research-through-design methods to generate more than 400 concepts for new social chatbots, and we present seven categories that emerged from analysis of these ideas.", "keywords": ["message", "process", "based", "time", "development", "design", "literature", "conversation", "method", "feature", "category", "slack", "example", "user", "type", "review", "interaction", "present", "chatbots", "work", "engage", "space", "twitch", "use", "language", "messenger", "bot", "impact", "group", "designed", "team", "challenge", "sense", "computing", "page", "newcomer", "found", "variety", "including", "member", "discord", "oriented", "role", "ideation", "twitter", "support", "text", "research", "platform", "chatbot", "paper", "behavior", "come", "community"], "document_vector": [-77.260635, 31.153387], "paragraphs": [{"paragraph_vector": [81.243896, -86.582489], "paragraph_keywords": ["chatbots", "copies", "requests", "computing"]}, {"paragraph_vector": [30.163715, -88.593971], "paragraph_keywords": ["chatbots", "interaction", "community", "space"]}, {"paragraph_vector": [129.938568, -88.844696], "paragraph_keywords": ["chatbots", "research", "work", "literature"]}, {"paragraph_vector": [-21.289976, -89.422317], "paragraph_keywords": ["chatbots", "newcomers", "work", "bonds"]}, {"paragraph_vector": [65.441673, -88.716331], "paragraph_keywords": ["chatbots", "work", "based", "agents"]}, {"paragraph_vector": [60.050884, -82.522651], "paragraph_keywords": ["chatbots", "literature", "based", "keyword"]}, {"paragraph_vector": [62.147235, -83.745094], "paragraph_keywords": ["chatbots", "bot", "users", "based"]}, {"paragraph_vector": [60.243148, -87.732887], "paragraph_keywords": ["chatbots", "bots", "features", "users"]}, {"paragraph_vector": [4.294057, -87.351669], "paragraph_keywords": ["chatbots", "users", "multiparty", "bots"]}, {"paragraph_vector": [28.186698, -86.220085], "paragraph_keywords": ["chatbot", "chatbots", "users", "system"]}, {"paragraph_vector": [13.14911, -86.947143], "paragraph_keywords": ["chatbots", "platforms", "chatbot", "bots"]}, {"paragraph_vector": [98.486312, -89.026908], "paragraph_keywords": ["based", "chatbots", "chatbot", "bot"]}, {"paragraph_vector": [76.063217, -89.411247], "paragraph_keywords": ["bot", "based", "twitch", "slack"]}, {"paragraph_vector": [148.444183, -89.718223], "paragraph_keywords": ["chatbots", "community", "research", "ideas"]}, {"paragraph_vector": [-47.537841, -89.747512], "paragraph_keywords": ["ideation", "users", "chatbots", "based"]}, {"paragraph_vector": [-16.402933, -86.60588], "paragraph_keywords": ["categories", "community", "chatbot", "team"]}, {"paragraph_vector": [35.499134, -85.270751], "paragraph_keywords": ["community", "examples", "users", "behaviors"]}, {"paragraph_vector": [-109.292327, -88.524162], "paragraph_keywords": ["community", "bot", "process", "time"]}, {"paragraph_vector": [5.400579, -89.06443], "paragraph_keywords": ["communities", "users", "games", "members"]}, {"paragraph_vector": [-94.82241, -88.988845], "paragraph_keywords": ["community", "communities", "chatbot", "chatbots"]}, {"paragraph_vector": [108.135421, -89.001304], "paragraph_keywords": ["community", "chatbots", "legitimacy", "chatbot"]}, {"paragraph_vector": [19.842023, -89.475936], "paragraph_keywords": ["users", "community", "chatbots", "story"]}, {"paragraph_vector": [25.157161, -87.844947], "paragraph_keywords": ["community", "time", "come", "connections"]}, {"paragraph_vector": [-54.519943, -89.246269], "paragraph_keywords": ["chatbots", "design", "communities", "present"]}, {"paragraph_vector": [123.871269, -89.10942], "paragraph_keywords": ["work", "chatbots", "categories", "hope"]}], "content": {}, "doi": "10.1145/3290605.3300486"}, {"uri": "32", "title": "Only one item left? Heuristic Information Trumps Calorie Count When Supporting Healthy Snacking Under Low Self-Control", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Daniel Reinhardt"], "summary": "Pursuing the goal of a healthy diet may be challenging, especially when self-control resources are low. Yet many persuasive user interfaces fostering healthy choices are designed Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300708 for situations with ample self-control, e.g. showing nutritional information to support reflective decision making. In this paper we propose that under low self-control, persuasive user interfaces need to rely on simple heuristic decision making to be successful. We report an experiment that tested this assumption in a 2 (low vs. high self-control) x 2 (calorie vs. heuristic information) design. The results reveal a significant interaction effect. Participants with low selfcontrol resources chose the healthy snack more often when snacks were labelled with heuristic information than when they were labelled with calorie information. Both strategies were about equally successful for participants with high self-control. Exploiting situations of low self-control with heuristic information is a new and promising approach to designing persuasive technology for healthy eating. CHI 2019 Paper CHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK", "keywords": ["depletion", "process", "snacking", "based", "strategy", "food", "condition", "information", "heuristic", "ability", "self", "goal", "user", "decision", "persuasion", "participant", "use", "choose", "people", "e", "chocolate", "chosen", "health", "snack", "control", "state", "proof", "calorie", "task", "affect", "technology", "study", "situation", "choice", "influence", "pair", "eating", "paper", "behavior", "making"], "document_vector": [10.784087, 43.264785], "paragraphs": [{"paragraph_vector": [28.628215, -15.117107], "paragraph_keywords": ["control", "self", "people", "food"]}, {"paragraph_vector": [28.863885, -17.533704], "paragraph_keywords": ["information", "self", "control", "food"]}, {"paragraph_vector": [28.528692, -17.997577], "paragraph_keywords": ["information", "processes", "lead", "behavior"]}, {"paragraph_vector": [29.160995, -19.40662], "paragraph_keywords": ["tend", "strategies", "information", "resource"]}, {"paragraph_vector": [26.045104, -18.783555], "paragraph_keywords": ["depletion", "dieters", "people", "self"]}, {"paragraph_vector": [27.080106, -16.268808], "paragraph_keywords": ["participants", "proof", "students", "information"]}, {"paragraph_vector": [26.041479, -18.350849], "paragraph_keywords": ["participants", "snack", "snacks", "study"]}, {"paragraph_vector": [27.434114, -16.321769], "paragraph_keywords": ["task", "participants", "control", "self"]}, {"paragraph_vector": [27.100702, -16.187131], "paragraph_keywords": ["e", "crossing", "inhibition", "habit"]}, {"paragraph_vector": [25.468063, -18.405866], "paragraph_keywords": ["snack", "food", "pairs", "information"]}, {"paragraph_vector": [26.862369, -18.913753], "paragraph_keywords": ["snack", "participants", "pairs", "study"]}, {"paragraph_vector": [26.968839, -18.908704], "paragraph_keywords": ["affect", "snack", "bar", "chocolate"]}, {"paragraph_vector": [25.381677, -18.546548], "paragraph_keywords": ["affect", "control", "p", "choices"]}, {"paragraph_vector": [27.216201, -16.32327], "paragraph_keywords": ["information", "self", "calorie", "control"]}, {"paragraph_vector": [28.441181, -17.583538], "paragraph_keywords": ["information", "heuristics", "calorie", "self"]}, {"paragraph_vector": [29.115892, -17.139602], "paragraph_keywords": ["self", "control", "strategies", "user"]}, {"paragraph_vector": [26.967317, -17.559652], "paragraph_keywords": ["choices", "study", "heuristics", "need"]}], "content": {}, "doi": "10.1145/3290605.3300534"}, {"uri": "33", "title": "The Gendered Geography of Contributions to OpenStreetMap: Complexities in Self-Focus Bias", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Maitraye Das"], "summary": "Millions duction repositories that serve human information needs and provide vital world knowledge to prominent artifcial intelligence systems. Yet, extreme gender participation disparities exist in which men signifcantly outnumber women. A central concern has been that due to self-focus bias [46], these disparities can lead to corresponding gender content disparities, in which content of interest to men is better represented than content of interest to women. This paper investigates the relationship between participation and content disparities in OpenStreetMap. We replicate fndings that women are dramatically under-represented as OSM contributors, and observe that men and women contribute diferent types of content and do so about diferent places. However, the character of these diferences confound simple narratives about self-focus bias: we fnd that on a proportional basis, men produced a higher proportion of contributions in feminized spaces compared to women, while women produced a higher proportion of contributions in masculinized spaces compared to men. We discuss the implications of these complex results for both theory and practice. of people worldwide contribute content to peer pro-", "keywords": ["based", "peer", "information", "childcare", "disparity", "self", "evidence", "diferent", "focus", "mapping", "example", "gender", "woman", "wikipedia", "type", "user", "region", "production", "work", "result", "space", "proportion", "diferences", "bot", "way", "county", "participation", "computing", "contribute", "compared", "page", "dataset", "content", "found", "edit", "men", "edits", "data", "osm", "editing", "contribution", "study", "map", "masculinized", "research", "term", "bias", "paper", "editor", "area"], "document_vector": [-94.519012, 33.069927], "paragraphs": [{"paragraph_vector": [99.781204, -46.104854], "paragraph_keywords": ["computing", "production", "copies", "peer"]}, {"paragraph_vector": [117.331794, 22.56299], "paragraph_keywords": ["content", "peer", "women", "gender"]}, {"paragraph_vector": [117.934959, 24.119201], "paragraph_keywords": ["content", "gender", "research", "contribute"]}, {"paragraph_vector": [112.583763, 24.531383], "paragraph_keywords": ["participation", "gender", "women", "osm"]}, {"paragraph_vector": [121.705169, 21.42107], "paragraph_keywords": ["osm", "focus", "bias", "content"]}, {"paragraph_vector": [119.010917, 21.973455], "paragraph_keywords": ["gender", "evidence", "osm", "men"]}, {"paragraph_vector": [120.296241, 22.680707], "paragraph_keywords": ["types", "data", "contribute", "nodes"]}, {"paragraph_vector": [119.152671, 20.010169], "paragraph_keywords": ["edits", "users", "bots", "bot"]}, {"paragraph_vector": [122.336799, 21.961065], "paragraph_keywords": ["spaces", "amenity", "masculinized", "men"]}, {"paragraph_vector": [119.352798, 23.792753], "paragraph_keywords": ["gender", "spaces", "osm", "dataset"]}, {"paragraph_vector": [120.1781, 22.231636], "paragraph_keywords": ["editors", "osm", "gender", "coders"]}, {"paragraph_vector": [122.450233, 22.873197], "paragraph_keywords": ["counties", "gender", "county", "ses"]}, {"paragraph_vector": [119.466995, 24.417373], "paragraph_keywords": ["gender", "research", "contributions", "contribution"]}, {"paragraph_vector": [121.676322, 22.335687], "paragraph_keywords": ["edits", "counties", "regions", "editors"]}, {"paragraph_vector": [120.592353, 22.641809], "paragraph_keywords": ["edits", "counties", "pop", "produces"]}, {"paragraph_vector": [119.439407, 22.878749], "paragraph_keywords": ["bots", "osm", "women", "dataset"]}, {"paragraph_vector": [119.583328, 22.527896], "paragraph_keywords": ["diferences", "edits", "based", "focus"]}, {"paragraph_vector": [119.393302, 21.687229], "paragraph_keywords": ["spaces", "edits", "dataset", "editors"]}, {"paragraph_vector": [120.221733, 20.700511], "paragraph_keywords": ["spaces", "men", "editors", "results"]}, {"paragraph_vector": [119.603332, 21.292211], "paragraph_keywords": ["gender", "interests", "spaces", "men"]}, {"paragraph_vector": [118.60559, 21.843101], "paragraph_keywords": ["osm", "mapping", "knowledge", "peer"]}, {"paragraph_vector": [121.976531, 22.852876], "paragraph_keywords": ["osm", "editors", "gender", "mapping"]}, {"paragraph_vector": [119.631958, 22.523853], "paragraph_keywords": ["editors", "osm", "gender", "diferent"]}, {"paragraph_vector": [121.094551, 22.653852], "paragraph_keywords": ["editors", "content", "spaces", "bots"]}, {"paragraph_vector": [120.362571, 22.401906], "paragraph_keywords": ["editors", "gender", "osm", "content"]}, {"paragraph_vector": [79.981513, -7.39443], "paragraph_keywords": ["thank", "baldwin", "osm", "oliver"]}], "content": {}, "doi": "10.1145/3290605.3300519"}, {"uri": "34", "title": "Evaluating Sustainable Interaction Design of Digital Services: The Case of YouTube", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Chris Preist"], "summary": "Recent research has advocated for a broader conception of evaluation for Sustainable HCI (SHCI), using interdisciplinary insights and methods. In this paper, we put this into practice to conduct an evaluation of Sustainable Interaction Design (SID) of digital services. We explore how SID can contribute to corporate greenhouse gas (GHG) reduction strategies. We show how a Digital Service Provider (DSP) might incorporate SID into their design process and quantitatively evaluate a specific SID intervention by combining user analytics data with environmental life cycle assessment. We illustrate this by considering YouTube. Replacing user analytics data with aggregate estimates from publicly available sources, we estimate emissions associated with the deployment of YouTube to be approximately 10MtCO2e p.a. We estimate emissions reductions enabled through the use of an SID intervention from prior literature to be approximately 300KtCO2e p.a., and demonstrate that this is significant when considered alongside other emissions reduction interventions used by DSPs.", "keywords": ["process", "based", "consider", "change", "emission", "design", "technique", "user", "reduction", "ass", "intervention", "associated", "work", "product", "impact", "evaluation", "use", "analytics", "video", "delivery", "service", "estimate", "given", "energy", "sustainability", "content", "usage", "practice", "device", "data", "technology", "approach", "reporting", "reduce", "network", "ghg", "climate", "youtube", "paper", "company", "scope"], "document_vector": [92.798225, 45.405902], "paragraphs": [{"paragraph_vector": [102.723609, -37.037845], "paragraph_keywords": ["evaluation", "shci", "copies", "design"]}, {"paragraph_vector": [92.187538, -43.582424], "paragraph_keywords": ["design", "use", "sustainability", "services"]}, {"paragraph_vector": [92.46556, -47.353649], "paragraph_keywords": ["use", "services", "proposed", "streaming"]}, {"paragraph_vector": [90.953369, -42.729442], "paragraph_keywords": ["ghg", "consider", "design", "service"]}, {"paragraph_vector": [93.016204, -40.816547], "paragraph_keywords": ["emissions", "stakeholders", "design", "strategy"]}, {"paragraph_vector": [104.535202, -28.732103], "paragraph_keywords": ["emissions", "climate", "change", "companies"]}, {"paragraph_vector": [93.022598, -41.775768], "paragraph_keywords": ["emissions", "company", "reporting", "activities"]}, {"paragraph_vector": [91.200134, -42.264209], "paragraph_keywords": ["emissions", "use", "design", "product"]}, {"paragraph_vector": [90.324714, -43.274234], "paragraph_keywords": ["emissions", "services", "associated", "design"]}, {"paragraph_vector": [92.005867, -43.722358], "paragraph_keywords": ["user", "service", "design", "emissions"]}, {"paragraph_vector": [91.904632, -44.03865], "paragraph_keywords": ["youtube", "climate", "energy", "emissions"]}, {"paragraph_vector": [93.148818, -46.991378], "paragraph_keywords": ["data", "service", "associated", "based"]}, {"paragraph_vector": [93.050697, -45.561786], "paragraph_keywords": ["data", "service", "content", "youtube"]}, {"paragraph_vector": [92.140861, -47.160396], "paragraph_keywords": ["data", "network", "internet", "energy"]}, {"paragraph_vector": [90.515968, -50.773551], "paragraph_keywords": ["data", "use", "youtube", "networks"]}, {"paragraph_vector": [115.305015, -46.079116], "paragraph_keywords": ["associated", "music", "emissions", "data"]}, {"paragraph_vector": [92.028442, -44.767951], "paragraph_keywords": ["emissions", "google", "use", "energy"]}, {"paragraph_vector": [90.642295, -43.219379], "paragraph_keywords": ["use", "service", "reductions", "reduce"]}, {"paragraph_vector": [92.160263, -45.168788], "paragraph_keywords": ["design", "use", "result", "effect"]}, {"paragraph_vector": [92.213127, -40.996147], "paragraph_keywords": ["services", "emissions", "companies", "ghg"]}, {"paragraph_vector": [93.854919, -41.702808], "paragraph_keywords": ["value", "emissions", "demonstrated", "ghg"]}], "content": {}, "doi": "10.1145/3290605.3300661"}, {"uri": "35", "title": "How do People Sort by Ratings?", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jerry O. Talton", "Krishna Dusad"], "summary": "Sorting items by user rating is a fundamental interaction pattern of the modern Web, used to rank products (Amazon), posts (Reddit), businesses (Yelp), movies (YouTube), and more. To implement this pattern, designers must take in a distribution of ratings for each item and define a sensible total ordering over them. This is a challenging problem, since each distribution is drawn from a distinct sample population, rendering the most straightforward method of sorting \u2014 comparing averages \u2014 unreliable when the samples are small or of different sizes. Several statistical orderings for binary ratings have been proposed in the literature (e.g., based on the Wilson score, or Laplace smoothing), each attempting to account for the uncertainty introduced by sampling. In this paper, we study this uncertainty through the lens of human perception, and ask \u201cHow do people sort by ratings?\u201d In an online study, we collected 48,000 item-ranking pairs from 4,000 crowd workers along with 4,800 rationales, and analyzed the results to understand how users make decisions when comparing rated items. Our results shed light on the cognitive models users employ to choose between rating distributions, which sorts of comparisons are most contentious, and how the presentation of rating information affects users\u2019 preferences. ACM Reference Format: Jerry O. Talton, Krishna Dusad, Konstantinos Koiliaris, and Ranjitha S. Kumar. 2019. How do People Sort by Ratings? In CHI Conference on Human Factors in Computing Systems Proceedings (CHI 2019), May 4\u20139, 2019, Glasgow, Scotland Uk. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3290605.3300535 Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Copyright held by the authors. Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300535 A", "keywords": ["star", "time", "population", "percentage", "information", "worker", "distribution", "experiment", "category", "user", "model", "comparison", "sample", "risk", "work", "proportion", "participant", "people", "size", "average", "number", "vote", "task", "item", "data", "system", "presented", "compare", "paper", "rating", "preference", "figure", "rationale"], "document_vector": [-61.123329, 21.602043], "paragraphs": [{"paragraph_vector": [41.945648, 48.512641], "paragraph_keywords": ["ratings", "rating", "systems", "user"]}, {"paragraph_vector": [41.894374, 49.654403], "paragraph_keywords": ["ratings", "users", "sample", "rating"]}, {"paragraph_vector": [43.67694, 48.609016], "paragraph_keywords": ["sample", "rating", "population", "ratings"]}, {"paragraph_vector": [37.93703, 45.619701], "paragraph_keywords": ["average", "rating", "data", "confidence"]}, {"paragraph_vector": [41.943695, 46.068908], "paragraph_keywords": ["users", "star", "ratings", "information"]}, {"paragraph_vector": [44.606773, 50.945858], "paragraph_keywords": ["comparisons", "workers", "votes", "distribution"]}, {"paragraph_vector": [43.565395, 52.445304], "paragraph_keywords": ["comparisons", "category", "ratings", "distribution"]}, {"paragraph_vector": [42.718158, 51.021812], "paragraph_keywords": ["task", "selected", "time", "comparison"]}, {"paragraph_vector": [44.700103, 55.218364], "paragraph_keywords": ["workers", "time", "comparison", "rationales"]}, {"paragraph_vector": [46.017211, 51.52301], "paragraph_keywords": ["category", "votes", "time", "users"]}, {"paragraph_vector": [49.394397, 51.766479], "paragraph_keywords": ["votes", "proportion", "options", "hypothesis"]}, {"paragraph_vector": [42.831218, 51.587841], "paragraph_keywords": ["votes", "users", "experiment", "number"]}, {"paragraph_vector": [46.724548, 52.036533], "paragraph_keywords": ["comparisons", "proportion", "conditions", "users"]}, {"paragraph_vector": [48.394687, 55.393383], "paragraph_keywords": ["users", "votes", "information", "ratings"]}, {"paragraph_vector": [42.410987, 48.990703], "paragraph_keywords": ["users", "models", "systems", "rating"]}, {"paragraph_vector": [42.347095, 48.284595], "paragraph_keywords": ["ratings", "models", "star", "systems"]}], "content": {}, "doi": "10.1145/3290605.3300448"}, {"uri": "36", "title": "Voice-BasedQuizzes for Measuring Knowledge Retention in Under-Connected Populations", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Agha Ali Raza", "Zain Tariq", "Shan Randhawa"], "summary": "Information dissemination using automated phone calls allows reaching low-literate and tech-na\u00efve populations. Open challenges include rapid verification of expected knowledge gaps in the community, dissemination of specific information to address these gaps, and follow-up measurement of knowledge retention. We report Sawaal, a voice-based telephone service that uses audio-quizzes to address these challenges. Sawaal allows its open community of users to post and attempt multiple-choice questions and to vote and comment on them. Sawaal spreads virally as users challenge friends to quiz competitions. Administrator-posted questions allow confirming specific knowledge gaps, spreading correct information and measuring knowledge retention via rephrased, repeated questions. In 14 weeks and with no advertisement, Sawaal reached 3,433 users (120,119 calls) in Pakistan, who contributed 13,276 questions that were attempted 455,158 times by 2,027 users. Knowledge retention remained significant for up to two weeks. Surveys revealed that 71% of the mostly low-literate, young, male users were blind. CCS CONCEPTS \u2022 Human-centered computing \u2192 Sound-based input / output.", "keywords": ["gap", "based", "attempt", "oqs", "time", "population", "speech", "information", "connected", "education", "campaign", "friend", "user", "india", "fraction", "pakistan", "attempted", "hour", "allows", "work", "show", "language", "recording", "use", "people", "rephrased", "post", "service", "learning", "health", "control", "voice", "page", "number", "score", "content", "call", "feedback", "posted", "comment", "sawaal", "measure", "answer", "shown", "data", "day", "topic", "administrator", "retention", "system", "platform", "question", "paper", "spread", "knowledge", "community", "response"], "document_vector": [-59.479164, -5.32719], "paragraphs": [{"paragraph_vector": [103.306015, -2.065054], "paragraph_keywords": ["information", "copies", "computing", "based"]}, {"paragraph_vector": [100.032394, 6.108017], "paragraph_keywords": ["knowledge", "information", "retention", "measure"]}, {"paragraph_vector": [104.738929, 9.125994], "paragraph_keywords": ["knowledge", "information", "services", "questions"]}, {"paragraph_vector": [104.95568, 4.579488], "paragraph_keywords": ["community", "india", "speech", "based"]}, {"paragraph_vector": [109.180076, 3.35241], "paragraph_keywords": ["content", "knowledge", "information", "users"]}, {"paragraph_vector": [139.275756, 9.577682], "paragraph_keywords": ["users", "learning", "knowledge", "phase"]}, {"paragraph_vector": [101.689285, 8.626789], "paragraph_keywords": ["sawaal", "questions", "users", "voice"]}, {"paragraph_vector": [97.995574, 16.160972], "paragraph_keywords": ["users", "questions", "sawaal", "posted"]}, {"paragraph_vector": [99.896881, 16.552349], "paragraph_keywords": ["question", "answer", "questions", "users"]}, {"paragraph_vector": [96.185371, 17.84926], "paragraph_keywords": ["questions", "users", "answers", "posted"]}, {"paragraph_vector": [96.898284, 19.335422], "paragraph_keywords": ["users", "questions", "question", "knowledge"]}, {"paragraph_vector": [93.527366, 24.149793], "paragraph_keywords": ["users", "questions", "oqs", "released"]}, {"paragraph_vector": [99.01609, 14.497178], "paragraph_keywords": ["questions", "users", "present", "user"]}, {"paragraph_vector": [97.488052, 17.798839], "paragraph_keywords": ["users", "questions", "sawaal", "days"]}, {"paragraph_vector": [97.402404, 12.737261], "paragraph_keywords": ["users", "sawaal", "questions", "days"]}, {"paragraph_vector": [-140.777755, 47.025653], "paragraph_keywords": ["users", "sawaal", "urdu", "questions"]}, {"paragraph_vector": [96.894378, 12.771788], "paragraph_keywords": ["questions", "knowledge", "health", "use"]}, {"paragraph_vector": [148.6716, -45.325057], "paragraph_keywords": ["users", "water", "depression", "oq"]}, {"paragraph_vector": [96.170104, 20.439672], "paragraph_keywords": ["responses", "knowledge", "questions", "users"]}, {"paragraph_vector": [94.88636, 21.74047], "paragraph_keywords": ["questions", "responses", "retention", "question"]}, {"paragraph_vector": [96.171516, 18.997163], "paragraph_keywords": ["users", "thought", "think", "question"]}, {"paragraph_vector": [94.117347, 17.680063], "paragraph_keywords": ["questions", "marked", "songs", "asked"]}, {"paragraph_vector": [101.097129, 18.089464], "paragraph_keywords": ["questions", "comments", "users", "started"]}, {"paragraph_vector": [99.238655, 13.565662], "paragraph_keywords": ["information", "questions", "service", "recordings"]}, {"paragraph_vector": [97.289909, 16.334718], "paragraph_keywords": ["questions", "users", "knowledge", "rephrased"]}, {"paragraph_vector": [105.09851, 11.080905], "paragraph_keywords": ["knowledge", "measure", "users", "connected"]}, {"paragraph_vector": [70.79663, 33.580852], "paragraph_keywords": ["annotating", "data", "hours", "moderating"]}], "content": {}, "doi": "10.1145/3290605.3300478"}, {"uri": "37", "title": "QuizBot: A Dialogue-based Adaptive Learning System for Factual Knowledge", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Sherry Ruan", "Liwei Jiang", "neng Qiu", "Yeshuang Zhu", "Elizabeth L. Murnane", "Emma Brunskill"], "summary": "Advances in conversational AI have the potential to enable more engaging and effective ways to teach factual knowledge. To investigate this hypothesis, we created QuizBot, a dialogue-based agent that helps students learn factual knowledge in science, safety, and English vocabulary. We evaluated QuizBot with 76 students through two within-subject studies against a flashcard app, the traditional medium for learning factual knowledge. Though both systems used the same algorithm for sequencing materials, QuizBot led to students recognizing (and recalling) over 20% more correct answers than when students used the flashcard app. Using a conversational agent is more time consuming to practice with; but in a second study, of their own volition, students spent 2.6x more time learning with QuizBot than with flashcards and reported preferring it strongly for casual learning. Our results in this second study showed QuizBot yielded improved learning gains over flashcards on recall. These results suggest that educational chatbot systems may have beneficial use, particularly for learning outside of traditional settings.", "keywords": ["based", "time", "sentence", "memory", "recall", "conversation", "app", "user", "model", "engagement", "learner", "chatbots", "apps", "work", "language", "quizbot", "use", "result", "flashcard", "word", "participant", "designed", "effect", "learning", "given", "algorithm", "page", "number", "difficulty", "chat", "feedback", "-", "recognition", "test", "usage", "similarity", "answer", "item", "data", "study", "student", "system", "choice", "question", "chatbot", "knowledge"], "document_vector": [-117.875358, 27.426013], "paragraphs": [{"paragraph_vector": [82.441078, 27.409757], "paragraph_keywords": ["learning", "based", "testing", "knowledge"]}, {"paragraph_vector": [86.374343, 27.611221], "paragraph_keywords": ["learning", "quizbot", "knowledge", "feedback"]}, {"paragraph_vector": [87.520362, 26.6798], "paragraph_keywords": ["quizbot", "systems", "learning", "students"]}, {"paragraph_vector": [85.912239, 25.922142], "paragraph_keywords": ["learning", "based", "students", "systems"]}, {"paragraph_vector": [87.525413, 31.936552], "paragraph_keywords": ["memory", "supermemo", "system", "models"]}, {"paragraph_vector": [89.474876, 25.277658], "paragraph_keywords": ["user", "quizbot", "answer", "based"]}, {"paragraph_vector": [84.966056, 22.634986], "paragraph_keywords": ["sentence", "word", "glove", "embedding"]}, {"paragraph_vector": [91.84449, 56.644317], "paragraph_keywords": ["model", "represents", "sentences", "data"]}, {"paragraph_vector": [86.918212, 30.182939], "paragraph_keywords": ["app", "item", "flashcard", "based"]}, {"paragraph_vector": [87.435089, 27.66007], "paragraph_keywords": ["user", "question", "quizbot", "app"]}, {"paragraph_vector": [89.105049, 29.682983], "paragraph_keywords": ["study", "questions", "question", "system"]}, {"paragraph_vector": [87.67984, 28.465965], "paragraph_keywords": ["questions", "difficulty", "number", "workers"]}, {"paragraph_vector": [87.0251, 28.025335], "paragraph_keywords": ["app", "study", "questions", "use"]}, {"paragraph_vector": [88.8684, 27.802303], "paragraph_keywords": ["questions", "question", "learners", "-"]}, {"paragraph_vector": [86.275299, 26.442615], "paragraph_keywords": ["test", "-", "accuracy", "quizbot"]}, {"paragraph_vector": [85.270019, 27.664756], "paragraph_keywords": ["quizbot", "time", "engagement", "study"]}, {"paragraph_vector": [88.348426, 26.969469], "paragraph_keywords": ["questions", "quizbot", "test", "app"]}, {"paragraph_vector": [86.892318, 25.342449], "paragraph_keywords": ["quizbot", "answer", "based", "use"]}, {"paragraph_vector": [87.48191, 26.154573], "paragraph_keywords": ["quizbot", "answers", "users", "graded"]}, {"paragraph_vector": [86.048919, 26.982255], "paragraph_keywords": ["quizbot", "study", "students", "questions"]}, {"paragraph_vector": [88.524276, 23.216939], "paragraph_keywords": ["learning", "quizbot", "chatbot", "app"]}, {"paragraph_vector": [86.094963, 26.514413], "paragraph_keywords": ["time", "quizbot", "input", "system"]}, {"paragraph_vector": [88.224578, 26.724496], "paragraph_keywords": ["quizbot", "learning", "engagement", "study"]}, {"paragraph_vector": [84.582038, 23.466556], "paragraph_keywords": ["project", "wang", "develop", "anna"]}], "content": {}, "doi": "10.1145/3290605.3300757"}, {"uri": "38", "title": "B-Script: Transcript-based B-roll Video Editing with Recommendations", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Bernd Huber", "Hijung Valentina Shin", "Bryan Russell", "Oliver Wang", "Gautham J. Mysore"], "summary": "In video production, inserting B-roll is a widely used technique to enrich the story and make a video more engaging. However, determining the right content and positions of B-roll and actually inserting it within the main footage can be challenging, and novice producers often struggle to get both timing and content right. We present B-Script, a system that supports B-roll video editing via interactive transcripts. B-Script has a built-in recommendation system trained on expert-annotated data, recommending users B-roll position Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300311 and content. To evaluate the system, we conducted a withinsubject user study with 110 participants, and compared three interface variations: a timeline-based editor, a transcriptbased editor, and a transcript-based editor with recommendations. Users found it easier and were faster to insert B-roll using the transcript-based interface, and they created more engaging videos when recommendations were provided.", "keywords": ["based", "position", "time", "vlogs", "insertion", "set", "style", "analysis", "duration", "expert", "medium", "user", "roll", "video", "word", "participant", "recommendation", "number", "b", "content", "task", "query", "search", "data", "editing", "system", "transcript", "quality", "youtube", "paper", "interface", "editor", "figure"], "document_vector": [-3.552118, -9.452744], "paragraphs": [{"paragraph_vector": [51.293685, 16.716459], "paragraph_keywords": ["video", "roll", "vlogs", "b"]}, {"paragraph_vector": [49.768249, 15.694483], "paragraph_keywords": ["video", "b", "roll", "transcript"]}, {"paragraph_vector": [50.379825, 16.797649], "paragraph_keywords": ["video", "transcript", "based", "recommendations"]}, {"paragraph_vector": [51.872573, 15.651145], "paragraph_keywords": ["video", "editing", "b", "roll"]}, {"paragraph_vector": [50.234493, 16.176792], "paragraph_keywords": ["b", "roll", "video", "vlogs"]}, {"paragraph_vector": [51.807773, 15.278634], "paragraph_keywords": ["video", "b", "roll", "videos"]}, {"paragraph_vector": [52.508399, 13.749087], "paragraph_keywords": ["roll", "videos", "b", "coefficient"]}, {"paragraph_vector": [49.642002, 16.287946], "paragraph_keywords": ["roll", "b", "transcript", "word"]}, {"paragraph_vector": [49.350917, 13.653347], "paragraph_keywords": ["b", "roll", "video", "search"]}, {"paragraph_vector": [50.352634, 15.087771], "paragraph_keywords": ["roll", "b", "video", "editor"]}, {"paragraph_vector": [51.906265, 15.577462], "paragraph_keywords": ["word", "sentiment", "roll", "b"]}, {"paragraph_vector": [51.350292, 15.719113], "paragraph_keywords": ["word", "experts", "based", "video"]}, {"paragraph_vector": [49.414516, 14.292101], "paragraph_keywords": ["recommendations", "video", "based", "recommendation"]}, {"paragraph_vector": [24.928674, 49.554382], "paragraph_keywords": ["task", "video", "interface", "platform"]}, {"paragraph_vector": [48.797931, 14.595246], "paragraph_keywords": ["videos", "task", "video", "participants"]}, {"paragraph_vector": [48.790367, 17.586523], "paragraph_keywords": ["video", "user", "raters", "interface"]}, {"paragraph_vector": [50.144664, 16.602626], "paragraph_keywords": ["roll", "b", "time", "editing"]}, {"paragraph_vector": [49.296142, 16.836273], "paragraph_keywords": ["recommendations", "based", "interface", "users"]}, {"paragraph_vector": [50.548812, 15.668091], "paragraph_keywords": ["recommendations", "videos", "roll", "b"]}, {"paragraph_vector": [49.593513, 17.177742], "paragraph_keywords": ["roll", "video", "work", "videos"]}], "content": {}, "doi": "10.1145/3290605.3300813"}, {"uri": "39", "title": "Psychologically Inclusive Design Cues Impact Women\u2019s Participation in STEM Education", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Ren\u00e9 F. Kizilcec", "Andrew J. Saltarelli"], "summary": "Visual and verbal cues can reinforce barriers to access for women in science, technology, engineering, and math (STEM) disciplines. Psychologically inclusive design is an evidence-based approach to reduce psychological barriers by strategically placing content and design cues in the environment. Two largefi eld experiments provide estimates of the behavioral impact of psychologically inclusive cues on women\u2019s and men\u2019s enrollment behaviors in an online learning environment. First, a gender-inclusive photo and statement in an online advertisement for a STEM course increased the click-through rate among women but not men by 26% (N=209,000). Second, an inclusivity statement with a gender-inclusive course image to the enrollment page raised the proportion of women enrolling in a STEM course by up to 18% (N=63,000). Thesefindings contribute evidence of the behavioral impact of psychologically inclusive design to the literature and yield practical implications for the presentation of STEM opportunities.", "keywords": ["identity", "based", "facebook", "time", "ad", "information", "threat", "evidence", "design", "consequence", "environment", "gender", "woman", "interaction", "raise", "work", "people", "increase", "concern", "effect", "cue", "learning", "world", "belonging", "participation", "page", "number", "barrier", "content", "found", "men", "advertising", "study", "setting", "enrollment", "research", "course", "platform", "influence", "individual", "stem"], "document_vector": [-131.644714, 40.794193], "paragraphs": [{"paragraph_vector": [124.921836, 21.040088], "paragraph_keywords": ["learning", "stem", "copies", "students"]}, {"paragraph_vector": [133.920471, 29.700645], "paragraph_keywords": ["stem", "cues", "identity", "identities"]}, {"paragraph_vector": [131.290237, 25.078393], "paragraph_keywords": ["environments", "learning", "identity", "design"]}, {"paragraph_vector": [131.241928, 28.637895], "paragraph_keywords": ["content", "identity", "cues", "women"]}, {"paragraph_vector": [132.04721, 28.85429], "paragraph_keywords": ["gender", "design", "women", "course"]}, {"paragraph_vector": [130.791687, 26.63035], "paragraph_keywords": ["design", "gender", "women", "cues"]}, {"paragraph_vector": [131.642562, 27.983261], "paragraph_keywords": ["stem", "cues", "women", "course"]}, {"paragraph_vector": [131.698135, 28.331834], "paragraph_keywords": ["ad", "course", "women", "men"]}, {"paragraph_vector": [59.152599, 53.435054], "paragraph_keywords": ["ad", "facebook", "campaign", "number"]}, {"paragraph_vector": [131.256683, 28.499843], "paragraph_keywords": ["women", "cues", "study", "men"]}, {"paragraph_vector": [131.458892, 27.805376], "paragraph_keywords": ["course", "page", "target", "courses"]}, {"paragraph_vector": [132.359375, 28.764171], "paragraph_keywords": ["course", "enrollment", "page", "manipulation"]}, {"paragraph_vector": [131.201431, 27.052743], "paragraph_keywords": ["women", "enrollment", "course", "period"]}, {"paragraph_vector": [132.97116, 29.333892], "paragraph_keywords": ["cues", "women", "approach", "environments"]}, {"paragraph_vector": [133.23413, 28.343404], "paragraph_keywords": ["cues", "design", "women", "enrollment"]}, {"paragraph_vector": [132.608261, 27.806987], "paragraph_keywords": ["cues", "course", "enrollment", "women"]}, {"paragraph_vector": [131.351928, 30.645261], "paragraph_keywords": ["cues", "number", "people", "ad"]}, {"paragraph_vector": [131.878234, 29.604175], "paragraph_keywords": ["study", "cues", "design", "diversity"]}, {"paragraph_vector": [133.417022, 31.517873], "paragraph_keywords": ["cues", "design", "work", "research"]}, {"paragraph_vector": [131.897842, 28.703382], "paragraph_keywords": ["design", "cues", "settings", "world"]}], "content": {}, "doi": "10.1145/3290605.3300497"}, {"uri": "40", "title": "Touchstone2: An Interactive Environment for Exploring Trade-offs in HCI Experiment Design", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Alexander Eiselmayer", "Chat Wacharamanotham", "Michel Beaudouin-Lafon", "Wendy E. Mackay"], "summary": "Touchstone2 offers a direct-manipulation interface for generating and examining trade-offs in experiment designs. Based on interviews with experienced researchers, we developed an interactive environment for manipulating experiment design parameters, revealing patterns in trial tables, and estimating and comparing statistical power. We also developed TSL, a declarative language that precisely represents experiment designs. In two studies, experienced HCI researchers successfully used Touchstone2 to evaluate design trade-offs and calculate how many participants are required for particular effect sizes. We discuss Touchstone2\u2019s benefits and limitations, as well as directions for future research. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300447 CCS CONCEPTS \u2022Human-centered computing\u2192HCI design and evaluation methods; Laboratory experiments;", "keywords": ["process", "condition", "written", "design", "analysis", "experiment", "trade", "error", "example", "power", "counterbalancing", "user", "chart", "sample", "result", "work", "language", "participant", "use", "tsl", "effect", "team", "size", "created", "page", "number", "trial", "generate", "parameter", "table", "data", "variable", "researcher", "study", "research", "brick", "weigh", "session", "order", "hci", "paper", "interface", "level", "figure"], "document_vector": [24.622755, 1.690418], "paragraphs": [{"paragraph_vector": [42.089786, 55.611511], "paragraph_keywords": ["design", "experiments", "researchers", "designs"]}, {"paragraph_vector": [34.93312, 59.933277], "paragraph_keywords": ["designs", "experiment", "design", "experiments"]}, {"paragraph_vector": [28.33706, 63.078033], "paragraph_keywords": ["treatment", "tables", "design", "trial"]}, {"paragraph_vector": [43.300521, 57.077186], "paragraph_keywords": ["users", "effect", "power", "experiment"]}, {"paragraph_vector": [37.620094, 57.793704], "paragraph_keywords": ["participants", "design", "experiments", "experiment"]}, {"paragraph_vector": [26.170501, 61.158229], "paragraph_keywords": ["power", "counterbalancing", "table", "participants"]}, {"paragraph_vector": [30.864204, 61.02597], "paragraph_keywords": ["power", "effect", "figure", "size"]}, {"paragraph_vector": [28.297456, 63.179447], "paragraph_keywords": ["design", "power", "experiment", "counterbalancing"]}, {"paragraph_vector": [26.898593, 60.385734], "paragraph_keywords": ["trial", "table", "design", "participants"]}, {"paragraph_vector": [15.863355, 62.360248], "paragraph_keywords": ["power", "participants", "design", "effect"]}, {"paragraph_vector": [30.432556, 61.604896], "paragraph_keywords": ["users", "experiment", "figure", "displays"]}, {"paragraph_vector": [25.001253, 58.85749], "paragraph_keywords": ["design", "experiment", "web", "designs"]}, {"paragraph_vector": [-17.60474, 33.198307], "paragraph_keywords": ["tsl", "experiment", "designs", "training"]}, {"paragraph_vector": [29.009208, 60.081027], "paragraph_keywords": ["teams", "experiment", "participants", "designs"]}, {"paragraph_vector": [32.042411, 62.220516], "paragraph_keywords": ["experiment", "design", "participants", "teams"]}, {"paragraph_vector": [53.79261, 64.616409], "paragraph_keywords": ["power", "participants", "analysis", "size"]}, {"paragraph_vector": [30.852195, 63.404232], "paragraph_keywords": ["effect", "power", "designs", "size"]}, {"paragraph_vector": [39.039836, 60.932872], "paragraph_keywords": ["power", "analysis", "experiment", "number"]}, {"paragraph_vector": [44.802501, 57.581256], "paragraph_keywords": ["experiment", "researchers", "power", "experiments"]}, {"paragraph_vector": [54.897312, 54.90699], "paragraph_keywords": ["tsl", "designs", "experiment", "researchers"]}], "content": {}, "doi": "10.1145/3290605.3300654"}, {"uri": "41", "title": "Beyond Behavior: The Coach\u2019s Perspective on Technology in Health Coaching", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Heleen Rutjes", "Martijn C. Willemsen"], "summary": "Rapid innovations in electronic healthcare and behavior tracking systems are challenging health coaches (dietitians, personal trainers, etc.) to rethink their traditional roles and healthcare practices. At the same time, many current ecoaching systems have been developed without explicitly incorporating the healthcare professionals\u2019 perspective into the design process. In the current paper, we present three consecutive qualitative studies, starting from the health coach\u2019s perspective on successful coaching, progressively zooming in on the potential role and impact of technology as part of the coaching process. Our main finding is that coaches are concerned that introducing technology in the coaching process puts too much emphasis on behavioral information, lowering the attention for the client\u2019s lived experience, while understanding those experiences is key for successful coaching. We summarize our insights in a multi-channel communication model and draw implications for the design of supporting technology in health coaching.", "keywords": ["process", "success", "time", "change", "explains", "need", "information", "discussion", "coaching", "self", "training", "analysis", "interview", "coach", "focus", "example", "relationship", "goal", "help", "activity", "interaction", "advice", "result", "work", "use", "people", "group", "insight", "client", "e", "health", "experience", "page", "supporting", "understanding", "feedback", "tracking", "providing", "data", "day", "technology", "role", "support", "system", "term", "perspective", "paper", "report", "motivation", "behavior", "value", "context", "making"], "document_vector": [-50.30474, 88.798202], "paragraphs": [{"paragraph_vector": [171.835006, -23.927526], "paragraph_keywords": ["client", "health", "process", "coaching"]}, {"paragraph_vector": [171.813583, -22.72582], "paragraph_keywords": ["user", "self", "coaching", "technology"]}, {"paragraph_vector": [171.290328, -25.457401], "paragraph_keywords": ["data", "health", "pgd", "technology"]}, {"paragraph_vector": [171.560073, -20.176622], "paragraph_keywords": ["coaching", "health", "process", "coaches"]}, {"paragraph_vector": [170.198776, -21.048517], "paragraph_keywords": ["technology", "coaching", "coaches", "role"]}, {"paragraph_vector": [170.511291, -23.676168], "paragraph_keywords": ["information", "c", "coaching", "data"]}, {"paragraph_vector": [172.660552, -24.588436], "paragraph_keywords": ["clients", "coach", "coaches", "weight"]}, {"paragraph_vector": [169.471054, -26.742959], "paragraph_keywords": ["coach", "client", "coaches", "explains"]}, {"paragraph_vector": [171.127471, -26.467401], "paragraph_keywords": ["client", "information", "clients", "coach"]}, {"paragraph_vector": [171.785003, -23.118244], "paragraph_keywords": ["change", "coaches", "client", "clients"]}, {"paragraph_vector": [171.380218, -23.268159], "paragraph_keywords": ["clients", "coaching", "coaches", "goals"]}, {"paragraph_vector": [171.504196, -21.908355], "paragraph_keywords": ["coaches", "technology", "group", "information"]}, {"paragraph_vector": [169.095626, -25.85569], "paragraph_keywords": ["technology", "coaches", "information", "themes"]}, {"paragraph_vector": [171.569564, -22.565093], "paragraph_keywords": ["client", "example", "notes", "coach"]}, {"paragraph_vector": [170.265411, -22.049905], "paragraph_keywords": ["client", "coaches", "coach", "data"]}, {"paragraph_vector": [169.088348, -32.401618], "paragraph_keywords": ["data", "behavior", "client", "clients"]}, {"paragraph_vector": [170.544158, -24.912275], "paragraph_keywords": ["coaches", "technology", "data", "clients"]}, {"paragraph_vector": [170.407165, -21.178749], "paragraph_keywords": ["client", "data", "coaches", "sports"]}, {"paragraph_vector": [171.276351, -24.984642], "paragraph_keywords": ["coaches", "data", "client", "running"]}, {"paragraph_vector": [165.835342, -29.354068], "paragraph_keywords": ["client", "coaches", "data", "report"]}, {"paragraph_vector": [172.253555, -20.753738], "paragraph_keywords": ["training", "client", "coaches", "issues"]}, {"paragraph_vector": [170.883728, -22.860902], "paragraph_keywords": ["coaching", "data", "client", "coach"]}, {"paragraph_vector": [169.420425, -21.987634], "paragraph_keywords": ["behavior", "data", "client", "information"]}, {"paragraph_vector": [171.055328, -31.365533], "paragraph_keywords": ["data", "understanding", "client", "use"]}, {"paragraph_vector": [169.043273, -22.474464], "paragraph_keywords": ["data", "information", "context", "client"]}, {"paragraph_vector": [170.630981, -20.565969], "paragraph_keywords": ["information", "client", "behavior", "data"]}, {"paragraph_vector": [166.429183, -25.473417], "paragraph_keywords": ["data", "interpretation", "evidence", "sources"]}, {"paragraph_vector": [171.151748, -22.060232], "paragraph_keywords": ["coaching", "client", "technology", "coach"]}, {"paragraph_vector": [170.572555, -23.139225], "paragraph_keywords": ["data", "coaching", "process", "technology"]}], "content": {}, "doi": "10.1145/3290605.3300925"}, {"uri": "42", "title": "Resolving Target Ambiguity in 3D Gaze Interaction through VOR Depth Estimation", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Diako Mardanbegi", "Tobias Langlotz"], "summary": "Target disambiguation is a common problem in gaze interfaces, as eye tracking has accuracy and precision limitations. In 3D environments this is compounded by objects overlapping in the field of view, as a result of their positioning at different depth with partial occlusion. We introduce VOR depth estimation, a method based on the vestibulo-ocular reflex of the eyes in compensation of head movement, and explore its application to resolve target ambiguity. The method estimates gaze depth by comparing the rotations of the eye and the head when the users look at a target and deliberately rotate their head. We show that VOR eye movement presents an alternative to vergence for gaze depth estimation, that is feasible also with monocular tracking. In an evaluation of its use for target disambiguation, our method outperforms vergence for targets presented at greater depth. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300842 CCS CONCEPTS \u2022Human-centered computing\u2192Human computer interaction (HCI); Gestural input; \u2022 Computing methodologies\u2192 Virtual reality;", "keywords": ["based", "object", "selection", "method", "technique", "gaze", "user", "interaction", "eye", "movement", "participant", "angle", "range", "gain", "step", "proposed", "head", "obtained", "estimation", "distance", "task", "vergence", "signal", "data", "vg", "study", "ambiguity", "target", "vor", "pupil", "depth", "value", "figure"], "document_vector": [-141.912673, -56.364696], "paragraphs": [{"paragraph_vector": [-52.798919, -2.140712], "paragraph_keywords": ["gaze", "depth", "estimation", "eye"]}, {"paragraph_vector": [-56.2192, -3.053343], "paragraph_keywords": ["depth", "estimation", "gaze", "target"]}, {"paragraph_vector": [-52.952003, -5.387979], "paragraph_keywords": ["gaze", "ray", "head", "user"]}, {"paragraph_vector": [-57.752811, -5.34434], "paragraph_keywords": ["depth", "gaze", "target", "combined"]}, {"paragraph_vector": [-55.37445, -6.959074], "paragraph_keywords": ["head", "eye", "gaze", "vor"]}, {"paragraph_vector": [-57.785228, -6.702456], "paragraph_keywords": ["head", "eye", "vor", "gain"]}, {"paragraph_vector": [-56.989879, -4.122644], "paragraph_keywords": ["head", "target", "participants", "center"]}, {"paragraph_vector": [-56.688911, -4.570541], "paragraph_keywords": ["head", "target", "distance", "angle"]}, {"paragraph_vector": [-56.1137, -5.302389], "paragraph_keywords": ["signals", "signal", "velocity", "eye"]}, {"paragraph_vector": [-57.004673, -4.697535], "paragraph_keywords": ["vg", "values", "vgp", "pupil"]}, {"paragraph_vector": [-58.444278, -3.8162], "paragraph_keywords": ["target", "task", "selection", "gaze"]}, {"paragraph_vector": [-55.724811, -5.396878], "paragraph_keywords": ["depth", "condition", "target", "considered"]}, {"paragraph_vector": [-58.436992, -5.723526], "paragraph_keywords": ["depth", "participants", "estimation", "study"]}, {"paragraph_vector": [-55.609352, -3.877406], "paragraph_keywords": ["head", "selection", "target", "depth"]}, {"paragraph_vector": [-54.292343, -4.564298], "paragraph_keywords": ["depth", "target", "vgp", "samples"]}, {"paragraph_vector": [-56.460151, -5.483103], "paragraph_keywords": ["method", "methods", "gaze", "selection"]}, {"paragraph_vector": [-56.866611, -4.613598], "paragraph_keywords": ["head", "participants", "gaze", "targets"]}, {"paragraph_vector": [-58.393135, -4.437967], "paragraph_keywords": ["head", "gaze", "vergence", "method"]}, {"paragraph_vector": [-56.679206, -4.164151], "paragraph_keywords": ["depth", "method", "head", "eye"]}, {"paragraph_vector": [-56.043128, -5.199807], "paragraph_keywords": ["head", "eye", "method", "vergence"]}, {"paragraph_vector": [-55.282287, -6.091762], "paragraph_keywords": ["method", "gaze", "proposed", "work"]}], "content": {}, "doi": "10.1145/3290605.3300832"}, {"uri": "43", "title": "Multi-plie\u0301: a Linear Foldable and Flattenable Interactive Display to Support Efficiency, Safety and Collaboration Exploring and Ironing out Design Complexities with Airliner Pilots", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Sylvain Pauchet", "Jean-Luc Vinot", "Catherine Letondal", "Alexandre Lemort", "Claire Lavenir", "Timoth\u00e9e Lecomte", "St\u00e9phanie Rey", "Valentin Becquet", "Guillaume Crouzet"], "summary": "We present the design concept of an accordion-fold interactive display to address the limits of touch-based interaction in airliner cockpits. Based on an analysis of pilot activity, tangible design principles for this design concept are identified. Two resulting functional prototypes are explored during participatory workshops with pilots, using activity scenarios. This exploration validated the design concept by revealing its ability to match pilot responsibilities in terms of safety, efficiency and collaboration. It provides an efficient visual perception of the system for real-time collaborative operations and tangible interaction to strengthen the perception of action and to manage safety through anticipation and awareness. The design work and insights enabled to specify further our needs regarding flexible screens. They also helped to better characterize the design concept as based on continuity of a developed surface, predictability of aligned folds and pleat face roles, embodied interactive properties, and flexibility through affordable reconfigurations. CCS CONCEPTS \u2022 Human-centered computing \u2192 Human computer interaction (HCI); Interaction devices; HCI design and evaluation methods", "keywords": ["based", "time", "al", ".", "information", "set", "performance", "display", "design", "provide", "safety", "touch", "user", "activity", "aspect", "fold", "interaction", "surface", "et", "workshop", "allows", "work", "air", "space", "scenario", "use", "management", "perception", "explored", "screen", "way", "pilot", "size", "concept", "acm", "shape", "control", "checklist", "page", "collaboration", "series", "property", "cockpit", "form", "deformation", "task", "hand", "device", "data", "study", "aircraft", "crew", "system", "support", "usa", "research", "session", "enable", "structure", "prototype", "paper", "interface", "ny", "flight", "action", "context", "figure", "doi"], "document_vector": [23.353038, -35.697036], "paragraphs": [{"paragraph_vector": [-78.101181, 34.545154], "paragraph_keywords": ["use", "pilot", "copies", "systems"]}, {"paragraph_vector": [-80.858802, 37.421676], "paragraph_keywords": ["concept", "design", "activity", "prototypes"]}, {"paragraph_vector": [-84.681228, 36.231868], "paragraph_keywords": ["shape", "concept", "interface", "interfaces"]}, {"paragraph_vector": [-70.160751, 42.788391], "paragraph_keywords": ["screens", "space", "design", "screen"]}, {"paragraph_vector": [-83.759803, 37.738994], "paragraph_keywords": ["workshops", "pilots", "surfaces", "displays"]}, {"paragraph_vector": [-79.343078, 34.061042], "paragraph_keywords": ["pilots", "activities", "crew", "aircraft"]}, {"paragraph_vector": [-77.186782, 35.711341], "paragraph_keywords": ["touch", "cockpit", "interaction", "pilots"]}, {"paragraph_vector": [-78.769042, 36.476772], "paragraph_keywords": ["pilots", "activity", "design", "use"]}, {"paragraph_vector": [-81.569374, 37.623821], "paragraph_keywords": ["folds", "surface", "prototypes", "design"]}, {"paragraph_vector": [-81.191268, 36.882431], "paragraph_keywords": ["touch", "screens", "actuators", "display"]}, {"paragraph_vector": [-87.635124, 29.309112], "paragraph_keywords": ["surface", "touch", "figure", "angle"]}, {"paragraph_vector": [-87.231933, 46.103729], "paragraph_keywords": ["surface", "scenarios", "cockpit", "projection"]}, {"paragraph_vector": [-82.166664, 39.626094], "paragraph_keywords": ["pilots", "scenario", "properties", "data"]}, {"paragraph_vector": [-80.30532, 39.742397], "paragraph_keywords": ["information", "shape", "folds", "pilot"]}, {"paragraph_vector": [-84.683822, 36.484096], "paragraph_keywords": ["surface", "hand", "pilots", "preferred"]}, {"paragraph_vector": [-84.707069, 37.448886], "paragraph_keywords": ["pilots", "surface", "folds", "moves"]}, {"paragraph_vector": [-82.086036, 37.42942], "paragraph_keywords": ["pilots", "expressed", "concept", "fold"]}, {"paragraph_vector": [-72.217163, 37.185569], "paragraph_keywords": ["pilot", "management", "structure", "action"]}, {"paragraph_vector": [-78.435264, 37.938037], "paragraph_keywords": ["action", "time", "flight", "pilots"]}, {"paragraph_vector": [-80.473526, 38.006805], "paragraph_keywords": ["pilot", "pilots", "flight", "information"]}, {"paragraph_vector": [-82.54158, 36.489749], "paragraph_keywords": ["structure", "surface", "fold", "concept"]}, {"paragraph_vector": [-84.090301, 36.920764], "paragraph_keywords": ["fold", "face", "pilots", "folds"]}, {"paragraph_vector": [-82.18489, 36.593788], "paragraph_keywords": ["folds", "surface", "angles", "fold"]}, {"paragraph_vector": [-79.651512, 35.961532], "paragraph_keywords": ["pilots", "fold", "data", "actions"]}, {"paragraph_vector": [-81.263214, 36.873401], "paragraph_keywords": ["cockpit", "enable", "design", "surface"]}, {"paragraph_vector": [-81.106338, 35.426506], "paragraph_keywords": ["et", "cockpit", "space", "research"]}, {"paragraph_vector": [-81.714347, 34.759731], "paragraph_keywords": ["doi", "touch", "acm", "andrew"]}, {"paragraph_vector": [-76.629875, 33.337451], "paragraph_keywords": ["interaction", "doi", "interfaces", "ed"]}, {"paragraph_vector": [-77.217079, 31.572446], "paragraph_keywords": ["doi", ".", "interaction", "acm"]}, {"paragraph_vector": [-76.537185, 35.068481], "paragraph_keywords": ["usa", ".", "doi", "design"]}, {"paragraph_vector": [-76.275878, 33.438266], "paragraph_keywords": [".", "conference", "interaction", "proceedings"]}], "content": {}, "doi": "10.1145/3290605.3300331"}, {"uri": "44", "title": "Ethical Dimensions of Visualization Research", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Michael Correll"], "summary": "Visualizations have a potentially enormous influence on how data are used to make decisions across all areas of human endeavor. However, it is not clear how this power connects to ethical duties: what obligations do we have when it comes to visualizations and visual analytics systems, beyond our duties as scientists and engineers? Drawing on historical and contemporary examples, I address the moral components of the design and use of visualizations, identify some ongoing areas of visualization research with ethical dilemmas, and propose a set of additional moral obligations that we have as designers, builders, and researchers of visualizations. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300418 CCS CONCEPTS \u2022Human-centered computing\u2192Visualization theory, concepts and paradigms; \u2022 Security and privacy \u2192 Social aspects of security and privacy.", "keywords": ["process", "google", "based", "attempt", "population", "time", "information", "resource", "design", "method", "collect", "power", "goal", "model", "user", "labor", "impacted", "uncertainty", "communicating", "decision", "expertise", "work", "result", "impact", "analytics", "use", "people", "collection", "agency", "way", "world", "lack", "mean", "visualization", "page", "state", "existing", "obligation", "visualizing", "audience", "data", "transparency", "instance", "designer", "right", "system", "research", "collecting", "order", "paper", "privacy", "area", "conclusion", "value", "principle", "access", "making", "beginning"], "document_vector": [-145.463592, -3.121296], "paragraphs": [{"paragraph_vector": [-164.142166, 86.148025], "paragraph_keywords": ["visualization", "work", "character", "research"]}, {"paragraph_vector": [-170.137832, 84.097648], "paragraph_keywords": ["data", "visualization", "obligations", "world"]}, {"paragraph_vector": [88.27996, -71.018836], "paragraph_keywords": ["data", "people", "state", "reserve"]}, {"paragraph_vector": [77.203895, 79.228164], "paragraph_keywords": ["data", "information", "visualization", "census"]}, {"paragraph_vector": [-169.368026, 83.874107], "paragraph_keywords": ["data", "visualizations", "people", "world"]}, {"paragraph_vector": [179.323516, 82.515632], "paragraph_keywords": ["visualizations", "visualization", "data", "people"]}, {"paragraph_vector": [-163.016143, 81.779136], "paragraph_keywords": ["visualization", "areas", "ethics", "visualizations"]}, {"paragraph_vector": [-174.62973, 88.755332], "paragraph_keywords": ["data", "systems", "people", "insights"]}, {"paragraph_vector": [75.467605, 80.514801], "paragraph_keywords": ["data", "systems", "making", "models"]}, {"paragraph_vector": [86.542221, 61.686859], "paragraph_keywords": ["models", "ml", "explainability", "model"]}, {"paragraph_vector": [2.148405, 89.653465], "paragraph_keywords": ["systems", "visualization", "transparency", "steps"]}, {"paragraph_vector": [-159.210128, 85.716384], "paragraph_keywords": ["data", "information", "visualization", "obligations"]}, {"paragraph_vector": [-159.992416, 82.657905], "paragraph_keywords": ["principles", "labor", "visualizations", "visualization"]}, {"paragraph_vector": [106.657478, 83.432441], "paragraph_keywords": ["uncertainty", "data", "making", "impacted"]}, {"paragraph_vector": [6.179048, 89.944129], "paragraph_keywords": ["data", "visualizations", "use", "system"]}, {"paragraph_vector": [130.578475, 88.841148], "paragraph_keywords": ["data", "visualizations", "beings", "gap"]}, {"paragraph_vector": [-173.785034, 84.404556], "paragraph_keywords": ["data", "privacy", "result", "communicating"]}, {"paragraph_vector": [-177.870819, 87.628585], "paragraph_keywords": ["making", "data", "decision", "rights"]}, {"paragraph_vector": [98.060493, 84.212089], "paragraph_keywords": ["agency", "datasets", "design", "set"]}, {"paragraph_vector": [81.810295, -38.400238], "paragraph_keywords": ["work", "lapses", "organizations", "power"]}, {"paragraph_vector": [-161.418273, 82.447563], "paragraph_keywords": ["visualization", "work", "existing", "action"]}], "content": {}, "doi": "10.1145/3290605.3300773"}, {"uri": "45", "title": "Engagement with Mental Health Screening on Mobile Devices: Results from an Antenatal Feasibility Study", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Kevin Doherty", "Cecily Morrison"], "summary": "Perinatal depression (PND) affects up to 15% of women within the United Kingdom and has a lasting impact on a woman\u2019s quality of life, birth outcomes and her child\u2019s development. Suicide is the leading cause of maternal mortality. However, it is estimated that at least 50% of PND cases go undiagnosed. This paper presents the results of the first feasibility study to examine the potential of mobile devices to engage women in antenatal mental health screening. Using a mobile application, 254 women attending 14 National Health Service midwifery clinics provided 2,280 momentary and retrospective reports of their wellbeing over a 9-month period. Women spoke positively of the experience, installing and engaging with this technology regardless of age, education, wellbeing, number of children, marital or employment status, or past diagnosis of depression. 39 women reported a risk of depression, self-harm or suicide; two-thirds of whom were not identified by screening in-clinic. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. https://doi.org/10.1145/3290605.3300416 CCS CONCEPTS \u2022Human-centered computing\u2192 Empirical studies in HCI; Empirical studies in interaction design; Mobile devices.", "keywords": ["epds", "time", "arm", "self", "depression", "design", "app", "wellbeing", "care", "uk", "wallis", "woman", "\u03c7", "engagement", "user", "kruskal", "assessment", "risk", "use", "participant", "professional", "health", "experience", "number", "notification", "application", "provided", "survey", "including", "practice", "device", "data", "technology", "study", "period", "reporting", "installed", "support", "research", "screening", "potential", "paper", "pregnancy", "report", "context"], "document_vector": [-178.536376, 82.839126], "paragraphs": [{"paragraph_vector": [148.474105, -47.03186], "paragraph_keywords": ["women", "depression", "uk", "health"]}, {"paragraph_vector": [154.189468, -44.505638], "paragraph_keywords": ["report", "women", "health", "technologies"]}, {"paragraph_vector": [156.126296, -44.565631], "paragraph_keywords": ["health", "support", "data", "pregnancy"]}, {"paragraph_vector": [171.893386, -42.586643], "paragraph_keywords": ["self", "wellbeing", "report", "reporting"]}, {"paragraph_vector": [154.697296, -44.947315], "paragraph_keywords": ["challenges", "research", "data", "studies"]}, {"paragraph_vector": [155.632888, -44.065025], "paragraph_keywords": ["health", "women", "study", "depression"]}, {"paragraph_vector": [164.863052, -37.287742], "paragraph_keywords": ["participants", "days", "month", "provided"]}, {"paragraph_vector": [153.198654, -41.546638], "paragraph_keywords": ["study", "research", "women", "data"]}, {"paragraph_vector": [155.38031, -42.515098], "paragraph_keywords": ["women", "installed", "\u03c7", "data"]}, {"paragraph_vector": [155.816894, -41.819549], "paragraph_keywords": ["women", "epds", "use", "app"]}, {"paragraph_vector": [154.174667, -45.340484], "paragraph_keywords": ["notifications", "period", "reports", "app"]}, {"paragraph_vector": [158.907043, -46.75336], "paragraph_keywords": ["time", "women", "data", "spent"]}, {"paragraph_vector": [158.242309, -40.793258], "paragraph_keywords": ["women", "kruskal", "wallis", "\u03c7"]}, {"paragraph_vector": [155.311965, -41.652507], "paragraph_keywords": ["women", "reports", "kruskal", "self"]}, {"paragraph_vector": [157.09555, -41.3567], "paragraph_keywords": ["women", "app", "experience", "self"]}, {"paragraph_vector": [162.718505, -47.949901], "paragraph_keywords": ["women", "notifications", "felt", "app"]}, {"paragraph_vector": [156.808624, -42.108737], "paragraph_keywords": ["women", "reports", "kruskal", "wallis"]}, {"paragraph_vector": [155.324218, -41.932052], "paragraph_keywords": ["women", "health", "depression", "wellbeing"]}, {"paragraph_vector": [157.062255, -41.148334], "paragraph_keywords": ["women", "design", "self", "health"]}, {"paragraph_vector": [153.721679, -42.701206], "paragraph_keywords": ["risk", "support", "health", "pregnancy"]}, {"paragraph_vector": [153.938491, -43.078056], "paragraph_keywords": ["women", "health", "professionals", "care"]}], "content": {}, "doi": "10.1145/3290605.3300345"}, {"uri": "46", "title": "Signal Appropriation of Explicit HIV Status Disclosure Fields in Sex-Social Apps used by Gay and Bisexual Men", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Mark Warner", "Juan F. Maestre", "Jo Gibbs", "Chia-Fang Chung", "Ann Blandford"], "summary": "HIV status disclosure fields in online sex-social applications (\"apps\") are designed to help increase awareness, reduce stigma, and promote sexual health. Public disclosure could also help those diagnosed relate to others with similar statuses to feel less isolated. However, in our interview study (n=28) with HIV positive and negative men who have sex with men (MSM), we found some users preferred to keep their status private, especially when disclosure could stigmatise and disadvantage them, or risk revealing their status to someone they knew offline in a different context. How do users manage these tensions between health, stigma, and privacy? We analysed our interview data using signalling theory as a conceptual framework and identify participants developing \u2018signal appropriation\u2019 strategies, helping them manage the disclosure of their HIV status. Additionally, we propose a set of design considerations that explore the use of signals in the design of sensitive disclosure fields.", "keywords": ["strategy", "stigmatising", "information", "find", "disclosing", "evidence", "status", "self", "section", "design", "reported", "hiv", "analysis", "environment", "provide", "stigma", "example", "help", "user", "signalling", "know", "interaction", "work", "apps", "participant", "use", "people", "cost", "unraveling", "effect", "way", "think", "related", "page", "field", "number", "prep", "found", "profile", "age", "signal", "plh", "sex", "study", "reliability", "reduce", "support", "research", "disclose", "individual", "u", "paper", "privacy", "disclosure", "making"], "document_vector": [-32.235069, 45.445285], "paragraphs": [{"paragraph_vector": [35.296592, -55.013462], "paragraph_keywords": ["hiv", "plh", "help", "stigma"]}, {"paragraph_vector": [40.788806, -61.564689], "paragraph_keywords": ["hiv", "theory", "signalling", "users"]}, {"paragraph_vector": [38.647506, -53.296997], "paragraph_keywords": ["hiv", "individuals", "stigma", "marks"]}, {"paragraph_vector": [37.595382, -61.033969], "paragraph_keywords": ["stigma", "hiv", "status", "plh"]}, {"paragraph_vector": [40.301681, -55.801033], "paragraph_keywords": ["hiv", "sex", "stigma", "users"]}, {"paragraph_vector": [40.569431, -55.637088], "paragraph_keywords": ["information", "disclosure", "signalling", "users"]}, {"paragraph_vector": [177.12268, 0.767276], "paragraph_keywords": ["signal", "signals", "quality", "evidence"]}, {"paragraph_vector": [146.837509, -63.077392], "paragraph_keywords": ["information", "signal", "people", "signalling"]}, {"paragraph_vector": [37.239421, -55.011131], "paragraph_keywords": ["users", "signals", "help", "found"]}, {"paragraph_vector": [40.343944, -54.92115], "paragraph_keywords": ["sex", "participants", "hiv", "networks"]}, {"paragraph_vector": [43.232891, -57.319747], "paragraph_keywords": ["interviews", "hiv", "participants", "years"]}, {"paragraph_vector": [121.551353, -39.072113], "paragraph_keywords": ["hiv", "analysis", "study", "signalling"]}, {"paragraph_vector": [38.824531, -56.042297], "paragraph_keywords": ["status", "hiv", "disclosure", "stigma"]}, {"paragraph_vector": [34.877967, -55.629673], "paragraph_keywords": ["status", "hiv", "people", "test"]}, {"paragraph_vector": [58.549846, -56.126564], "paragraph_keywords": ["status", "participants", "hiv", "people"]}, {"paragraph_vector": [36.769878, -56.000274], "paragraph_keywords": ["hiv", "test", "having", "time"]}, {"paragraph_vector": [36.709102, -53.833946], "paragraph_keywords": ["prep", "hiv", "participants", "increased"]}, {"paragraph_vector": [50.534801, -54.280666], "paragraph_keywords": ["status", "think", "profile", "fear"]}, {"paragraph_vector": [37.719581, -56.052501], "paragraph_keywords": ["hiv", "status", "signals", "section"]}, {"paragraph_vector": [35.765178, -52.588459], "paragraph_keywords": ["prep", "reliability", "participants", "think"]}, {"paragraph_vector": [39.606784, -55.167282], "paragraph_keywords": ["status", "hiv", "reliability", "sex"]}, {"paragraph_vector": [38.125125, -55.626098], "paragraph_keywords": ["hiv", "status", "u", "disclosure"]}, {"paragraph_vector": [60.109653, -64.773735], "paragraph_keywords": ["information", "status", "effect", "find"]}, {"paragraph_vector": [36.20042, -56.473213], "paragraph_keywords": ["prep", "disclosure", "people", "users"]}, {"paragraph_vector": [34.771682, -57.65578], "paragraph_keywords": ["hiv", "design", "stigma", "status"]}, {"paragraph_vector": [38.485923, -53.385723], "paragraph_keywords": ["users", "hiv", "stigma", "help"]}, {"paragraph_vector": [61.581272, -57.942607], "paragraph_keywords": ["users", "support", "disclosure", "fields"]}, {"paragraph_vector": [52.881805, -60.742809], "paragraph_keywords": ["disclosure", "support", "privacy", "users"]}, {"paragraph_vector": [35.743743, -55.538379], "paragraph_keywords": ["signals", "users", "status", "prep"]}, {"paragraph_vector": [39.773124, -53.970767], "paragraph_keywords": ["status", "hiv", "privacy", "signal"]}, {"paragraph_vector": [59.76551, -64.523544], "paragraph_keywords": ["research", "london", "college", "innovation"]}], "content": {}, "doi": "10.1145/3290605.3300667"}, {"uri": "47", "title": "Gamification in Science: A Study of Requirements in the Context of Reproducible Research", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Sebastian S. Feger"], "summary": "The need for data preservation and reproducible research is widely recognized in the scientific community. Yet, researchers often struggle to find the motivation to contribute to data repositories and to use tools that foster reproducibility. In this paper, we explore possible uses of gamification to support reproducible practices in High Energy Physics. To understand how gamification can be effective in research tools, we participated in a workshop and performed interviews with data analysts. We then designed two interactive prototypes of a research preservation service that use contrasting gamification strategies. The evaluation of the prototypes showed that gamification needs to address core scientific challenges, in particular the fair reflection of quality and individual contribution. Through thematic analysis, we identified four themes which describe perceptions and requirements of gamification in research: Contribution, Metrics, Applications and Scientific practice. Based on these, we discuss design implications for gamification in science.", "keywords": ["process", "based", "point", "need", "information", "requirement", "analyst", "mechanism", "design", "analysis", "provide", "gamification", "example", "goal", "activity", "sged", "sharing", "communication", "conducted", "work", "impact", "hep", "participant", "use", "visibility", "service", "challenge", "related", "page", "collaboration", "science", "badge", "practice", "shown", "data", "game", "researcher", "element", "preservation", "study", "scientist", "contribution", "research", "target", "physicist", "studying", "paper", "motivation", "level", "context", "code"], "document_vector": [-94.773193, 25.228918], "paragraphs": [{"paragraph_vector": [84.85334, 11.075045], "paragraph_keywords": ["research", "gamification", "design", "studies"]}, {"paragraph_vector": [83.438072, 8.911129], "paragraph_keywords": ["gamification", "design", "challenges", "paper"]}, {"paragraph_vector": [-172.08081, 4.916169], "paragraph_keywords": ["gamification", "motivation", "design", "elements"]}, {"paragraph_vector": [84.379646, 11.347931], "paragraph_keywords": ["gamification", "research", "needs", "data"]}, {"paragraph_vector": [86.683761, 11.585616], "paragraph_keywords": ["research", "data", "sharing", "lhc"]}, {"paragraph_vector": [85.110961, 7.327187], "paragraph_keywords": ["design", "practices", "collaboration", "elements"]}, {"paragraph_vector": [169.886535, 35.128917], "paragraph_keywords": ["participants", "physicists", "design", "submission"]}, {"paragraph_vector": [165.664108, 30.395959], "paragraph_keywords": ["design", "code", "items", "codes"]}, {"paragraph_vector": [85.82022, 10.333928], "paragraph_keywords": ["communication", "information", "analysts", "research"]}, {"paragraph_vector": [85.986801, 5.694846], "paragraph_keywords": ["analysis", "execution", "analysts", "researchers"]}, {"paragraph_vector": [83.471786, 8.811566], "paragraph_keywords": ["analysis", "collaboration", "page", "analysts"]}, {"paragraph_vector": [83.773918, 8.680378], "paragraph_keywords": ["analysis", "collaboration", "analyses", "researchers"]}, {"paragraph_vector": [87.958076, 9.071202], "paragraph_keywords": ["collaboration", "sged", "point", "suitability"]}, {"paragraph_vector": [85.401641, 14.112426], "paragraph_keywords": ["visibility", "contributions", "service", "opportunities"]}, {"paragraph_vector": [87.213645, 14.419634], "paragraph_keywords": ["analysis", "frequency", "contributions", "design"]}, {"paragraph_vector": [89.284629, 24.779462], "paragraph_keywords": ["goals", "work", "people", "highlighted"]}, {"paragraph_vector": [90.108306, 10.526444], "paragraph_keywords": ["analysis", "collaboration", "metrics", "researchers"]}, {"paragraph_vector": [87.170532, 6.684903], "paragraph_keywords": ["based", "transparency", "analyses", "elements"]}, {"paragraph_vector": [88.155128, 20.099878], "paragraph_keywords": ["language", "analysis", "mechanisms", "game"]}, {"paragraph_vector": [86.39891, 20.41324], "paragraph_keywords": ["elements", "mechanisms", "points", "design"]}, {"paragraph_vector": [84.074539, 10.196729], "paragraph_keywords": ["work", "mechanisms", "design", "allow"]}, {"paragraph_vector": [81.675842, 11.127275], "paragraph_keywords": ["researchers", "research", "design", "conducted"]}, {"paragraph_vector": [84.38182, 1.476005], "paragraph_keywords": ["mechanisms", "badges", "visibility", "design"]}, {"paragraph_vector": [84.513778, 6.574397], "paragraph_keywords": ["elements", "researchers", "design", "mechanisms"]}, {"paragraph_vector": [84.591941, 11.435385], "paragraph_keywords": ["researchers", "study", "mechanisms", "design"]}, {"paragraph_vector": [82.67736, 13.334624], "paragraph_keywords": ["gamification", "research", "science", "design"]}, {"paragraph_vector": [73.450546, 29.92592], "paragraph_keywords": ["federal", "ministry", "programme", "education"]}], "content": {}, "doi": "10.1145/3290605.3300421"}, {"uri": "48", "title": "Shape Structuralizer: Design, Fabrication, and User-driven Iterative Refinement of 3D Mesh Models", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Subramanian Chidambaram", "Yunbo Zhang"], "summary": "Current Computer-Aided Design (CAD) tools lack proper support for guiding novice users towards designs ready for fabrication. We propose Shape Structuralizer (SS), an interactive design support system that repurposes surface models into structural constructions using rods and custom 3Dprinted joints. Shape Structuralizer embeds a recommendation system that computationally supports the user during design ideation by providing design suggestions on local refinements of the design. This strategy enables novice users to choose designs that both satisfy stress constraints as well as their personal design intent. The interactive guidance enables users to repurpose existing surface mesh models, analyze them in-situ for stress and displacement constraints, add movable joints to increase functionality, and attach a customized appearance. This also empowers novices to fabricate even complex constructs while ensuring structural soundness. We validate the Shape Structuralizer tool with a qualitative user study where we observed that even novice users were able to generate a large number of structurally safe designs for fabrication.", "keywords": ["fidelity", "based", "strategy", "time", "node", "cross", "design", "analysis", "user", "model", "wire", "performed", "allows", "work", "scaffolding", "tool", "space", "length", "use", "load", "recommendation", "material", "group", "joint", "printing", "shape", "structuralizer", "page", "vertex", "feedback", "provided", "-", "mesh", "fig", "fea", "novice", "study", "element", "stress", "system", "structure", "paper", "interface", "fabrication", "connector"], "document_vector": [85.072006, -32.6072], "paragraphs": [{"paragraph_vector": [-100.427574, 55.556091], "paragraph_keywords": ["design", "fabrication", "tools", "structures"]}, {"paragraph_vector": [-106.460319, 53.927825], "paragraph_keywords": ["design", "user", "users", "tools"]}, {"paragraph_vector": [-107.421775, 59.119499], "paragraph_keywords": ["design", "user", "recommendation", "novice"]}, {"paragraph_vector": [-103.802116, 55.536186], "paragraph_keywords": ["design", "user", "structures", "optimized"]}, {"paragraph_vector": [-94.302062, 55.57188], "paragraph_keywords": ["fabrication", "design", "printing", "structures"]}, {"paragraph_vector": [-108.363433, 56.308628], "paragraph_keywords": ["design", "analysis", "scaffolding", "fea"]}, {"paragraph_vector": [-97.511428, 54.023544], "paragraph_keywords": ["shape", "cross", "points", "structure"]}, {"paragraph_vector": [-112.541625, 57.818019], "paragraph_keywords": ["scaffolding", "vertices", "structure", "auto"]}, {"paragraph_vector": [-103.346832, 54.351203], "paragraph_keywords": ["user", "-", "tools", "vertices"]}, {"paragraph_vector": [-106.815834, 55.728294], "paragraph_keywords": ["users", "user", "analysis", "based"]}, {"paragraph_vector": [-106.633262, 54.562694], "paragraph_keywords": ["analysis", "stress", "region", "structure"]}, {"paragraph_vector": [-109.665977, 56.450748], "paragraph_keywords": ["stress", "j", "vi", "vertex"]}, {"paragraph_vector": [-108.339141, 57.371227], "paragraph_keywords": ["stress", "case", "time", "analysis"]}, {"paragraph_vector": [-95.376586, 54.262519], "paragraph_keywords": ["user", "freedom", "wire", "connector"]}, {"paragraph_vector": [-101.230773, 52.450183], "paragraph_keywords": ["user", "connectors", "structuralizer", "shape"]}, {"paragraph_vector": [-102.995437, 52.558002], "paragraph_keywords": ["users", "joints", "tool", "design"]}, {"paragraph_vector": [-105.064239, 50.613185], "paragraph_keywords": ["group", "load", "study", "given"]}, {"paragraph_vector": [-109.233985, 61.6935], "paragraph_keywords": ["user", "time", "users", "load"]}, {"paragraph_vector": [-103.605606, 57.043994], "paragraph_keywords": ["design", "adding", "wire", "fabrication"]}, {"paragraph_vector": [74.844635, 28.877046], "paragraph_keywords": ["reflect", "views", "funding", "agency"]}], "content": {}, "doi": "10.1145/3290605.3300796"}, {"uri": "49", "title": "Frame Analysis of Voice Interaction Gameplay", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Fraser Allison", "Joshua Newn"], "summary": "Voice control is an increasingly common feature of digital games, but the experience of playing with voice control is often hampered by feelings of embarrassment and dissonance. Past research has recognised these tensions, but has not offered a general model of how they arise and how players respond to them. In this study, we use Erving Goffman\u2019s frame analysis [16], as adapted to the study of games by Conway and Trevillian [9], to understand the social experience of playing games by voice. Based on 24 interviews with participants who played voice-controlled games in a social setting, we put forward a frame analytic model of gameplay as a social event, along with seven themes that describe how voice interaction enhances or disrupts the player experience. Our results demonstrate the utility of frame analysis for understanding social dissonance in voice interaction gameplay, and point to practical considerations for designers to improve engagement with voice-controlled games.", "keywords": ["based", "strategy", "time", "tension", "speech", "frame", "player", "atcv", "design", "unit", "analysis", "interview", "playing", "model", "user", "command", "engagement", "interaction", "communication", "participant", "use", "people", "screen", "way", "world", "think", "sense", "theme", "control", "voice", "experience", "felt", "howler", "vocalisation", "page", "character", "understanding", "characterworld", "provided", "gameplay", "conway", "described", "attention", "played", "game", "study", "technology", "role", "researcher", "feel", "said", "endwar", "system", "research", "controlled", "focused", "meaning", "asked", "paper", "input", "action", "level", "response"], "document_vector": [-27.746799, -1.117645], "paragraphs": [{"paragraph_vector": [-162.275939, -14.310515], "paragraph_keywords": ["voice", "games", "copies", "interaction"]}, {"paragraph_vector": [-156.260284, -13.269559], "paragraph_keywords": ["interaction", "games", "gameplay", "voice"]}, {"paragraph_vector": [-158.736022, -10.524565], "paragraph_keywords": ["voice", "interaction", "situations", "analysis"]}, {"paragraph_vector": [-151.571319, -11.806128], "paragraph_keywords": ["frame", "role", "people", "chess"]}, {"paragraph_vector": [-154.966476, -11.346689], "paragraph_keywords": ["frame", "player", "world", "players"]}, {"paragraph_vector": [-160.055557, -11.834576], "paragraph_keywords": ["voice", "games", "game", "interaction"]}, {"paragraph_vector": [-157.508605, -7.83952], "paragraph_keywords": ["player", "game", "voice", "commands"]}, {"paragraph_vector": [-157.788146, -11.375608], "paragraph_keywords": ["participants", "voice", "speech", "played"]}, {"paragraph_vector": [-158.111801, -10.559447], "paragraph_keywords": ["game", "played", "participants", "voice"]}, {"paragraph_vector": [-175.859741, -22.287206], "paragraph_keywords": ["interviews", "codes", "data", "interview"]}, {"paragraph_vector": [-155.240371, -18.051303], "paragraph_keywords": ["participants", "games", "gameplay", "results"]}, {"paragraph_vector": [-156.679443, -12.083912], "paragraph_keywords": ["voice", "participants", "control", "endwar"]}, {"paragraph_vector": [-156.034118, -10.945694], "paragraph_keywords": ["howler", "voice", "said", "strategy"]}, {"paragraph_vector": [-163.787475, -13.620665], "paragraph_keywords": ["frames", "game", "framework", "frame"]}, {"paragraph_vector": [-158.527694, -12.581595], "paragraph_keywords": ["voice", "players", "world", "controls"]}, {"paragraph_vector": [-159.708724, -9.804055], "paragraph_keywords": ["voice", "commands", "character", "felt"]}, {"paragraph_vector": [-155.764877, -9.106227], "paragraph_keywords": ["voice", "game", "control", "said"]}, {"paragraph_vector": [-155.376159, -9.890238], "paragraph_keywords": ["vocalisations", "voice", "sense", "game"]}, {"paragraph_vector": [-158.126159, -9.370494], "paragraph_keywords": ["participants", "voice", "speech", "game"]}, {"paragraph_vector": [-156.575805, -11.029316], "paragraph_keywords": ["voice", "game", "world", "participants"]}, {"paragraph_vector": [-157.391433, -7.27859], "paragraph_keywords": ["voice", "commands", "command", "participants"]}, {"paragraph_vector": [-157.218856, -9.533353], "paragraph_keywords": ["voice", "game", "input", "problem"]}, {"paragraph_vector": [-158.03865, -9.054639], "paragraph_keywords": ["voice", "commands", "participants", "think"]}, {"paragraph_vector": [-156.727554, -9.154981], "paragraph_keywords": ["voice", "commands", "controls", "units"]}, {"paragraph_vector": [-157.338851, -11.069416], "paragraph_keywords": ["frames", "game", "voice", "world"]}, {"paragraph_vector": [-158.048522, -9.539501], "paragraph_keywords": ["game", "voice", "player", "frames"]}, {"paragraph_vector": [-159.327713, -9.729305], "paragraph_keywords": ["world", "game", "tensions", "voice"]}, {"paragraph_vector": [-155.978317, -10.16294], "paragraph_keywords": ["voice", "commands", "sense", "participants"]}, {"paragraph_vector": [-156.99887, -9.653223], "paragraph_keywords": ["meaning", "speech", "command", "voice"]}, {"paragraph_vector": [-159.315917, -10.940435], "paragraph_keywords": ["voice", "interaction", "participants", "frame"]}, {"paragraph_vector": [-158.144378, -10.567555], "paragraph_keywords": ["voice", "interaction", "felt", "commands"]}], "content": {}, "doi": "10.1145/3290605.3300299"}, {"uri": "50", "title": "Managerial Visions Stories of Upgrading and Maintaining the Public Restroom with IoT", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Sarah E. Fox", "Kiley Sobel", "Daniela K. Rosner"], "summary": "This paper examines the entangled development of governance strategies and networked technologies in the pervasive but under-examined domain of public restrooms. Drawing on a mix of archival materials, participant observation, and interviews within and beyond the city of Seattle, Washington, we look at the motivations of public restroom facilities managers as they introduce (or consider introducing) networked technology in the spaces they administer. Over the course of the research, we found internet of things technologies\u2014or, connected devices imbued with computational capacity\u2014became increasingly tied up with cost-reducing efficiencies and exploitative regulatory techniques. Drawing from this case study, we develop the concept of managerial visions: ways of seeing that structure labor, enforce compliance, and define access to resources. We argue that these ways of seeing prove increasingly critical to HCI research as it attends to computer-mediated collaboration beyond white-collar settings.", "keywords": ["library", "consider", "resource", "analysis", "concern", "clark", "according", "learned", "field", "form", "condom", "organization", "company", "seattle", "staff", "city", "information", "interview", "industry", "park", "innovation", "way", "restroom", "acm", "iot", "seek", "data", "toilet", "technology", "day", "infrastructure", "facility", "maintenance", "center", "time", "department", "worker", "development", "onvation", "told", "manager", "labor", "management", "offered", "people", "market", "material", "shifting", "control", "governance", "hand", "device", "hygiene", "system", "seeking", "come", "access", "making", "condition", "vision", "set", "design", "networked", "care", "example", "work", "product", "space", "building", "use", "health", "page", "employee", "described", "soap", "role", "oversight", "jean", "quality", "machine", "hci", "paper", "dispenser", "site", "community"], "document_vector": [83.410598, 58.636154], "paragraphs": [{"paragraph_vector": [115.988052, -53.169048], "paragraph_keywords": ["hci", "restrooms", "people", "acm"]}, {"paragraph_vector": [107.654266, -60.110649], "paragraph_keywords": ["copies", "acm", "labor", "ways"]}, {"paragraph_vector": [108.293144, -62.586853], "paragraph_keywords": ["restrooms", "systems", "work", "adopt"]}, {"paragraph_vector": [109.799713, -56.738548], "paragraph_keywords": ["forms", "labor", "emerging", "sought"]}, {"paragraph_vector": [43.000316, -69.824882], "paragraph_keywords": ["data", "scholars", "community", "designers"]}, {"paragraph_vector": [105.212661, -52.142814], "paragraph_keywords": ["work", "labor", "forms", "role"]}, {"paragraph_vector": [94.521369, -49.714836], "paragraph_keywords": ["studies", "technologies", "search", "officers"]}, {"paragraph_vector": [100.492492, -64.716316], "paragraph_keywords": ["facilities", "managers", "networked", "restrooms"]}, {"paragraph_vector": [97.530715, -69.980499], "paragraph_keywords": ["interviews", "dispensers", "paper", "facilities"]}, {"paragraph_vector": [105.301971, -63.093246], "paragraph_keywords": ["ways", "restroom", "maintenance", "vignettes"]}, {"paragraph_vector": [104.565551, -67.389663], "paragraph_keywords": ["soap", "city", "restrooms", "linda"]}, {"paragraph_vector": [92.756202, -73.165657], "paragraph_keywords": ["access", "told", "frustration", "day"]}, {"paragraph_vector": [102.002731, -71.72586], "paragraph_keywords": ["library", "staff", "described", "city"]}, {"paragraph_vector": [98.876304, -70.335105], "paragraph_keywords": ["jean", "managers", "children", "groups"]}, {"paragraph_vector": [94.902442, -67.563156], "paragraph_keywords": ["condom", "jean", "teens", "installation"]}, {"paragraph_vector": [97.495315, -72.038757], "paragraph_keywords": ["jean", "dispensers", "people", "condom"]}, {"paragraph_vector": [100.666145, -68.690818], "paragraph_keywords": ["resources", "access", "facilities", "managers"]}, {"paragraph_vector": [93.885887, -68.480552], "paragraph_keywords": ["machines", "facilities", "managers", "described"]}, {"paragraph_vector": [98.203964, -67.637107], "paragraph_keywords": ["quality", "pitch", "care", "clark"]}, {"paragraph_vector": [105.663848, -62.994247], "paragraph_keywords": ["innovation", "story", "form", "hank"]}, {"paragraph_vector": [101.85395, -59.149093], "paragraph_keywords": ["hygiene", "product", "employee", "manufacturers"]}, {"paragraph_vector": [85.824829, -68.859748], "paragraph_keywords": ["restroom", "onvation", "managers", "clark"]}, {"paragraph_vector": [80.354568, -56.718421], "paragraph_keywords": ["paper", "experience", "earhart", "company"]}, {"paragraph_vector": [106.383987, -54.530113], "paragraph_keywords": ["onvation", "maintenance", "worker", "work"]}, {"paragraph_vector": [102.302879, -58.852962], "paragraph_keywords": ["restroom", "scheduling", "system", "promoting"]}, {"paragraph_vector": [106.509635, -57.061855], "paragraph_keywords": ["technology", "data", "labor", "people"]}, {"paragraph_vector": [109.411575, -53.459072], "paragraph_keywords": ["forms", "hci", "oversight", "labor"]}, {"paragraph_vector": [103.657409, -56.013622], "paragraph_keywords": ["instance", "iot", "managers", "systems"]}, {"paragraph_vector": [105.661842, -53.203002], "paragraph_keywords": ["profit", "market", "seeking", "technology"]}, {"paragraph_vector": [104.818733, -55.634895], "paragraph_keywords": ["systems", "hci", "firms", "example"]}, {"paragraph_vector": [82.075019, 34.219078], "paragraph_keywords": ["ames", "shorey", "cynthia", "samantha"]}], "content": {}, "doi": "10.1145/3290605.3300480"}, {"uri": "51", "title": "Optimising Encoding for Vibrotactile Skin Reading", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Granit Luzhnica", "Eduardo Veas"], "summary": "This paper proposes methods of optimising alphabet encoding for skin reading in order to avoid perception errors. First, a user study with 16 participants using two body locations serves to identify issues in recognition of both individual letters and words. To avoid such issues, a two-step optimisation method of the symbol encoding is proposed and validated in a second user study with eight participants using the optimised encoding with a seven vibromotor wearable layout on the back of the hand. The results show signi cant improvements in the recognition accuracy of letters (97%) and words (97%) when compared to the non-optimised encoding.", "keywords": [], "document_vector": [23.985778, -70.519203], "paragraphs": [{"paragraph_vector": [74.210205, 32.690551], "paragraph_keywords": []}], "content": {}, "doi": "10.1145/3290605.3300582"}, {"uri": "52", "title": "Typing on Split Keyboards with Peripheral Vision", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Yiqin Lu", "Chun Yu", "Shuyi Fan", "Xiaojun Bi", "Yuanchun Shi"], "summary": "Split keyboards are widely used on hand-held touchscreen devices (e.g., tablets). However, typing on a split keyboard often requires eye movement and attention switching between two halves of the keyboard, which slows users down and increases fatigue. We explore peripheral typing, a superior typing mode in which a user focuses her visual attention on the output text and keeps the split keyboard in peripheral vision. Our investigation showed that peripheral typing reduced attention switching, enhanced user experience and increased overall performance (27 WPM, 28% faster) over the typical eyes-on typing mode. This typing mode can be well supported by accounting the typing behavior in statistical decoding. Based on our study results, we have designed GlanceType, a text entry system that supported both peripheral and eyes-on typing modes for real typing scenario. Our evaluation showed that peripheral typing not only well coexisted with the existing eyes-on typing, but also substantially improved the text entry performance. Overall, peripheral typing is a promising typing mode and supporting it would signifcantly improve the text entry performance on a split keyboard.", "keywords": ["decoding", "tablet", "time", "vision", "selection", "oov", "speed", "experiment", "gaze", "touch", "keyboard", "user", "type", "model", "eye", "word", "participant", "algorithm", "gesture", "attention", "data", "feld", "study", "candidate", "thumb", "text", "typing", "glancetype", "required", "mode", "showed", "input", "wpm", "entering", "p", "figure"], "document_vector": [-69.584678, -61.278572], "paragraphs": [{"paragraph_vector": [-36.717536, -12.532472], "paragraph_keywords": ["typing", "keyboard", "copies", "computing"]}, {"paragraph_vector": [-31.47569, -18.194963], "paragraph_keywords": ["typing", "keyboard", "vision", "user"]}, {"paragraph_vector": [-27.522079, -20.351255], "paragraph_keywords": ["typing", "keyboard", "glancetype", "text"]}, {"paragraph_vector": [-32.308322, -12.660272], "paragraph_keywords": ["keyboard", "typing", "users", "thumb"]}, {"paragraph_vector": [-33.003189, -14.347679], "paragraph_keywords": ["vision", "users", "gesture", "keyboard"]}, {"paragraph_vector": [-33.603221, -15.407875], "paragraph_keywords": ["keyboard", "typing", "participants", "vision"]}, {"paragraph_vector": [-17.356225, -19.732044], "paragraph_keywords": ["keyboard", "participants", "typing", "text"]}, {"paragraph_vector": [-30.604301, -16.684206], "paragraph_keywords": ["participants", "keyboard", "type", "typing"]}, {"paragraph_vector": [-30.645057, -15.653338], "paragraph_keywords": ["participants", "typing", "modes", "centroid"]}, {"paragraph_vector": [-31.249259, -23.782951], "paragraph_keywords": ["keyboard", "touch", "participants", "tap"]}, {"paragraph_vector": [-30.516544, -15.860211], "paragraph_keywords": ["typing", "algorithm", "accuracy", "participants"]}, {"paragraph_vector": [-29.970056, -18.457878], "paragraph_keywords": ["candidate", "list", "participant", "mode"]}, {"paragraph_vector": [-24.073005, -15.277104], "paragraph_keywords": ["participants", "mode", "required", "selection"]}, {"paragraph_vector": [-28.363822, -18.499809], "paragraph_keywords": ["mode", "eyes", "selection", "time"]}, {"paragraph_vector": [-26.467809, -20.474704], "paragraph_keywords": ["mode", "typing", "gaze", "eyes"]}, {"paragraph_vector": [-30.769578, -19.78523], "paragraph_keywords": ["typing", "user", "region", "mode"]}, {"paragraph_vector": [-32.044555, -16.90467], "paragraph_keywords": ["input", "user", "study", "typing"]}, {"paragraph_vector": [-33.466114, -16.585428], "paragraph_keywords": ["keyboard", "typing", "glancetype", "technique"]}, {"paragraph_vector": [-27.788475, -16.763088], "paragraph_keywords": ["gaze", "speed", "glancetype", "keyboard"]}, {"paragraph_vector": [-27.939182, -18.930057], "paragraph_keywords": ["typing", "participants", "words", "enter"]}, {"paragraph_vector": [-29.412179, -19.502283], "paragraph_keywords": ["typing", "oov", "vision", "input"]}, {"paragraph_vector": [-29.352159, -18.422906], "paragraph_keywords": ["typing", "entering", "input", "glancetype"]}], "content": {}, "doi": "10.1145/3290605.3300352"}, {"uri": "53", "title": "MultiTrack: Multi-User Tracking and Activity Recognition Using Commodity WiFi", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Sheng Tan", "Linghan Zhang", "Zi Wang", "Jie Yang"], "summary": "This paper presents MultiTrack, a commodity WiFi based human sensing system that can track multiple users and recognize activities of multiple users performing them simultaneously. Such a system can enable easy and large-scale deployment for multi-user tracking and sensing without the need for additional sensors through the use of existing WiFi devices (e.g., desktops, laptops and smart appliances). The basic idea is to identify and extract the signal reflection corresponding to each individual user with the help of multiple WiFi links and all the availableWiFi channels at 5GHz. Given the extracted signal reflection of each user, MultiTrack examines the path of the reflected signals at multiple links to simultaneously track multiple users. It further reconstructs the signal profile of each user as if only a single user has performed activity in the environment to facilitate multi-user activity recognition. We evaluate MultiTrack in different multipath environments with up to 4 users for multi-user tracking and up to 3 users for activity recognition. Experimental results show that our system can achieve decimeter localization accuracy and over 92% activity recognition accuracy under multi-user scenarios.", "keywords": ["reflection", "based", "time", "body", "commodity", "wifi", "environment", "problem", "performing", "power", "user", "activity", "accuracy", "shift", "work", "channel", "scenario", "doppler", "proximity", "localization", "link", "page", "number", "existing", "perform", "profile", "tracking", "proposed", "recognition", "require", "signal", "distance", "device", "phase", "system", "delay", "achieve", "figure"], "document_vector": [29.337829, -48.207138], "paragraphs": [{"paragraph_vector": [-63.416019, 17.195228], "paragraph_keywords": ["activity", "copies", "recognition", "work"]}, {"paragraph_vector": [-68.006645, 13.641914], "paragraph_keywords": ["user", "device", "wifi", "based"]}, {"paragraph_vector": [-68.357917, 13.57155], "paragraph_keywords": ["wifi", "users", "signal", "user"]}, {"paragraph_vector": [-69.953544, 10.411067], "paragraph_keywords": ["profile", "signal", "user", "channel"]}, {"paragraph_vector": [-68.669799, 12.368937], "paragraph_keywords": ["users", "recognition", "activity", "user"]}, {"paragraph_vector": [-69.799308, 11.849042], "paragraph_keywords": ["system", "reflection", "wifi", "profile"]}, {"paragraph_vector": [-66.128562, 10.492751], "paragraph_keywords": ["channel", "phase", "error", "wifi"]}, {"paragraph_vector": [-69.175666, 12.631926], "paragraph_keywords": ["channels", "delay", "profile", "power"]}, {"paragraph_vector": [-70.424842, 10.206702], "paragraph_keywords": ["power", "profile", "signal", "environment"]}, {"paragraph_vector": [-70.110923, 10.786196], "paragraph_keywords": ["reflection", "profile", "transmission", "users"]}, {"paragraph_vector": [-70.157287, 10.111277], "paragraph_keywords": ["users", "user", "reflection", "signal"]}, {"paragraph_vector": [-70.006942, 12.636168], "paragraph_keywords": ["profile", "reflection", "user", "represents"]}, {"paragraph_vector": [-70.62294, 12.272603], "paragraph_keywords": ["profile", "signal", "user", "environment"]}, {"paragraph_vector": [-66.542633, 8.874178], "paragraph_keywords": ["user", "similarity", "feature", "activity"]}, {"paragraph_vector": [-67.901863, 13.560847], "paragraph_keywords": ["channels", "activity", "experiments", "channel"]}, {"paragraph_vector": [-73.117301, 14.416731], "paragraph_keywords": ["activity", "user", "activities", "performing"]}, {"paragraph_vector": [-71.271064, 14.067599], "paragraph_keywords": ["system", "localization", "users", "accuracy"]}, {"paragraph_vector": [-68.419616, 14.479549], "paragraph_keywords": ["accuracy", "recognition", "nlos", "c"]}, {"paragraph_vector": [-68.297775, 15.562203], "paragraph_keywords": ["work", "user", "system", "based"]}, {"paragraph_vector": [-65.367668, 16.275199], "paragraph_keywords": ["tracking", "proposed", "work", "achieve"]}, {"paragraph_vector": [-64.125228, 19.333051], "paragraph_keywords": ["system", "distance", "users", "user"]}, {"paragraph_vector": [-68.547737, 13.465839], "paragraph_keywords": ["user", "accuracy", "system", "users"]}], "content": {}, "doi": "10.1145/3290605.3300783"}, {"uri": "54", "title": "Trust and Recall of Information across Varying Degrees of Title-Visualization Misalignment", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Zhicheng Liu"], "summary": "Visualizations are emerging as a means of spreading digital misinformation. Prior work has shown that visualization interpretation can be manipulated through slanted titles that favor only one side of the visual story, yet people still think the visualization is impartial. In this work, we study whether such effects continue to exist when titles and visualizations exhibit greater degrees of misalignment: titles whose message differs from the visually cued message in the visualization, and titles whose message contradicts the visualization. We found that although titles with a contradictory slant triggered more people to identify bias compared to titles with a miscued slant, visualizations were persistently perceived as impartial by the majority. Further, people\u2019s recall of the visualization\u2019s message more frequently aligned with the titles than the visualization. Based on these results, we discuss the potential of leveraging textual components to detect and combat visual-based misinformation with text-based slants.", "keywords": ["message", "based", "condition", "perceived", "information", "recall", "attitude", "component", "category", "credibility", "title", "news", "trust", "budget", "work", "result", "participant", "people", "confirmation", "effect", "miscued", "visualization", "page", "content", "found", "data", "study", "topic", "text", "research", "headline", "bias", "influence", "showed", "misalignment", "question", "paper", "misinformation"], "document_vector": [-140.351898, -7.77895], "paragraphs": [{"paragraph_vector": [-175.688644, 62.826465], "paragraph_keywords": ["news", "headlines", "copies", "visualization"]}, {"paragraph_vector": [-177.156402, 59.353801], "paragraph_keywords": ["visualization", "title", "people", "message"]}, {"paragraph_vector": [-179.589279, 58.506954], "paragraph_keywords": ["title", "visualization", "perceived", "information"]}, {"paragraph_vector": [-175.889938, 59.847625], "paragraph_keywords": ["misinformation", "information", "work", "visualizations"]}, {"paragraph_vector": [-176.493881, 60.405555], "paragraph_keywords": ["titles", "visualizations", "visualization", "people"]}, {"paragraph_vector": [-178.22348, 59.584197], "paragraph_keywords": ["bias", "titles", "confirmation", "visualization"]}, {"paragraph_vector": [-178.554748, 57.899925], "paragraph_keywords": ["emphasis", "study", "participants", "title"]}, {"paragraph_vector": [-176.802169, 56.226718], "paragraph_keywords": ["title", "visualization", "condition", "study"]}, {"paragraph_vector": [-177.58496, 57.580478], "paragraph_keywords": ["study", "visualization", "title", "questions"]}, {"paragraph_vector": [-178.00885, 56.962905], "paragraph_keywords": ["questions", "visualization", "recall", "attitude"]}, {"paragraph_vector": [-176.260665, 61.223022], "paragraph_keywords": ["credibility", "people", "data", "visualization"]}, {"paragraph_vector": [-177.114852, 61.949684], "paragraph_keywords": ["title", "bias", "visualization", "credibility"]}, {"paragraph_vector": [178.54512, 58.480998], "paragraph_keywords": ["title", "categories", "percentage", "budget"]}, {"paragraph_vector": [-177.84497, 57.461647], "paragraph_keywords": ["visualization", "title", "people", "topic"]}, {"paragraph_vector": [-177.222885, 57.111244], "paragraph_keywords": ["people", "information", "visualization", "number"]}, {"paragraph_vector": [-178.500289, 58.909427], "paragraph_keywords": ["visualization", "title", "credibility", "bias"]}, {"paragraph_vector": [-178.005554, 57.275566], "paragraph_keywords": ["credibility", "title", "visualization", "perceived"]}, {"paragraph_vector": [-177.376861, 57.445472], "paragraph_keywords": ["title", "visualization", "people", "attitude"]}, {"paragraph_vector": [-178.097366, 59.145793], "paragraph_keywords": ["title", "attitude", "visualization", "shows"]}, {"paragraph_vector": [-174.928802, 59.0471], "paragraph_keywords": ["visualization", "titles", "information", "title"]}, {"paragraph_vector": [-174.604507, 59.27259], "paragraph_keywords": ["visualization", "text", "bias", "title"]}, {"paragraph_vector": [-174.815155, 61.679946], "paragraph_keywords": ["study", "visualization", "information", "time"]}, {"paragraph_vector": [-178.564682, 59.85041], "paragraph_keywords": ["visualization", "information", "title", "based"]}], "content": {}, "doi": "10.1145/3290605.3300473"}, {"uri": "55", "title": "Grasping Microgestures: Eliciting Single-hand Microgestures for Handheld Objects", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Adwait Sharma"], "summary": "Single-hand microgestures have been recognized for their potential to support direct and subtle interactions. While pioneering work has investigated sensing techniques and presented first sets of intuitive gestures, we still lack a systematic understanding of the complex relationship between microgestures and various types of grasps. This paper presents results from a user elicitation study of microgestures that are performed while the user is holding an object. We present an analysis of over 2,400 microgestures performed by 20 participants, using six different types of grasp and a total of 12 representative handheld objects of varied geometries and size. We expand the existing elicitation method by proposing statistical clustering on the elicited gestures. We contribute Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for thirdparty components of this work must be honored. For all other uses, contact the owner/author(s). CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-5970-2/19/05. https://doi.org/10.1145/3290605.3300632 detailed results on how grasps and object geometries affect single-hand microgestures, preferred locations, and fingers used. We also present consolidated gesture sets for different grasps and object size. From our findings, we derive recommendations for the design of microgestures compatible with a large variety of handheld objects.", "keywords": ["based", "agreement", "finger", "object", "set", "grasp", "location", "design", "touch", "user", "performed", "type", "interaction", "work", "result", "holding", "participant", "use", "microgestures", "size", "computing", "gesture", "perform", "referent", "proposed", "hand", "data", "study", "designer", "thumb", "elicitation", "paper", "input", "action"], "document_vector": [61.152111, -65.337974], "paragraphs": [{"paragraph_vector": [-59.18843, 18.206855], "paragraph_keywords": ["computing", "microgestures", "user", "holding"]}, {"paragraph_vector": [-60.969749, 22.415273], "paragraph_keywords": ["objects", "user", "object", "microgestures"]}, {"paragraph_vector": [-59.44239, 22.983682], "paragraph_keywords": ["gestures", "microgestures", "objects", "users"]}, {"paragraph_vector": [-59.094924, 22.671125], "paragraph_keywords": ["based", "gestures", "work", "objects"]}, {"paragraph_vector": [-57.000209, 21.741603], "paragraph_keywords": ["objects", "grasping", "study", "referents"]}, {"paragraph_vector": [-60.369567, 21.414798], "paragraph_keywords": ["objects", "object", "size", "weight"]}, {"paragraph_vector": [-60.187652, 22.123657], "paragraph_keywords": ["object", "grasp", "participants", "asked"]}, {"paragraph_vector": [-59.241718, 19.978628], "paragraph_keywords": ["agreement", "type", "object", "location"]}, {"paragraph_vector": [-59.200736, 22.337053], "paragraph_keywords": ["participants", "agreement", "referents", "action"]}, {"paragraph_vector": [-34.114284, 13.73197], "paragraph_keywords": ["participants", "proposed", "object", "actions"]}, {"paragraph_vector": [-61.185359, 22.081111], "paragraph_keywords": ["objects", "object", "gestures", "holding"]}, {"paragraph_vector": [-61.710971, 22.646993], "paragraph_keywords": ["gestures", "object", "objects", "hand"]}, {"paragraph_vector": [-60.849258, 23.479499], "paragraph_keywords": ["finger", "object", "grasp", "fingers"]}, {"paragraph_vector": [-59.170104, 21.410551], "paragraph_keywords": ["gesture", "object", "grasp", "fingers"]}, {"paragraph_vector": [-60.161212, 21.936033], "paragraph_keywords": ["object", "gesture", "gestures", "finger"]}, {"paragraph_vector": [-59.946491, 21.529827], "paragraph_keywords": ["clusters", "grasp", "object", "finger"]}, {"paragraph_vector": [-60.798107, 21.381113], "paragraph_keywords": ["gesture", "sets", "grasps", "action"]}, {"paragraph_vector": [-59.673229, 21.073932], "paragraph_keywords": ["object", "gestures", "gesture", "users"]}, {"paragraph_vector": [-58.655433, 23.011358], "paragraph_keywords": ["gestures", "objects", "gesture", "finger"]}, {"paragraph_vector": [-60.309093, 23.175125], "paragraph_keywords": ["finger", "gestures", "input", "object"]}, {"paragraph_vector": [-60.003238, 23.148534], "paragraph_keywords": ["objects", "study", "object", "gestures"]}, {"paragraph_vector": [-60.696926, 22.006725], "paragraph_keywords": ["work", "object", "input", "gestures"]}], "content": {}, "doi": "10.1145/3290605.3300528"}, {"uri": "56", "title": "I\u2019m Sensing in the Rain: Spatial Incongruity in Visual-Tactile Mid-Air Stimulation Can Elicit Ownership in VR Users", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Dario Pittera", "Elia Gatti", "Marianna Obrist"], "summary": "Major virtual reality (VR) companies are trying to enhance the sense of immersion in virtual environments by implementing haptic feedback in their systems (e.g., Oculus Touch). It is known that tactile stimulation adds realism to a virtual environment. In addition, when users are not limited bywearing any attachments (e.g., gloves), it is even possible to create more immersive experiences. Mid-air haptic technology provides contactless haptic feedback and offers the potential for creating such immersive VR experiences. However, one of the limitations of mid-air haptics resides in the need for freehand tracking systems (e.g., Leap Motion) to deliver tactile feedback to the user\u2019s hand. These tracking systems are not accurate, limiting designers capability of delivering spatially precise tactile stimulation. Here, we investigated an alternative way to convey incongruent visual-tactile stimulation that can be used to create the illusion of a congruent visual-tactile experience, while participants experience the phenomenon of the rubber hand illusion in VR.", "keywords": ["vhi", "stimulation", "vr", "condition", "time", "arm", "al", "posture", "set", "body", "questionnaire", "location", "design", "experiment", "ownership", "touch", "user", "illusion", "et", "palm", "air", "incongruent", "work", "result", "participant", "use", "drift", "effect", "cm", "control", "page", "feedback", "stimulus", "-", "tracking", "test", "ve", "hand", "device", "rhi", "technology", "study", "tactile", "feel", "system", "research", "difference", "paper", "congruent"], "document_vector": [140.916656, -52.248149], "paragraphs": [{"paragraph_vector": [-77.713768, 11.133805], "paragraph_keywords": ["systems", "vr", "copies", "stimulation"]}, {"paragraph_vector": [-92.320419, 17.555936], "paragraph_keywords": ["feedback", "user", "vr", "world"]}, {"paragraph_vector": [-80.405899, 2.799662], "paragraph_keywords": ["hand", "tactile", "stimulation", "-"]}, {"paragraph_vector": [-82.206024, 1.801832], "paragraph_keywords": ["hand", "illusion", "tactile", "stimulation"]}, {"paragraph_vector": [-93.742591, 21.299274], "paragraph_keywords": ["vr", "illusion", "stimulation", "system"]}, {"paragraph_vector": [-79.309341, 3.939868], "paragraph_keywords": ["illusion", "arm", "vr", "rhi"]}, {"paragraph_vector": [-80.19577, 6.847892], "paragraph_keywords": ["body", "illusion", "embody", "arm"]}, {"paragraph_vector": [-86.684906, 9.798058], "paragraph_keywords": ["tactile", "air", "devices", "touch"]}, {"paragraph_vector": [-84.488868, 8.832378], "paragraph_keywords": ["vhi", "hand", "tactile", "vr"]}, {"paragraph_vector": [-78.902786, 6.164524], "paragraph_keywords": ["hand", "stimulation", "air", "tactile"]}, {"paragraph_vector": [-78.492897, 3.492504], "paragraph_keywords": ["stimulation", "incongruent", "hand", "tactile"]}, {"paragraph_vector": [-75.880699, 3.090185], "paragraph_keywords": ["stimuli", "illusion", "participants", "stimulation"]}, {"paragraph_vector": [-69.923744, 7.078377], "paragraph_keywords": ["hand", "participants", "drift", "cursor"]}, {"paragraph_vector": [-69.776321, 7.308096], "paragraph_keywords": ["participants", "hand", "questionnaire", "device"]}, {"paragraph_vector": [-67.772659, 8.377057], "paragraph_keywords": ["p", "data", "conditions", "condition"]}, {"paragraph_vector": [-73.926467, 3.547863], "paragraph_keywords": ["stimuli", "illusion", "effect", "tactile"]}, {"paragraph_vector": [-74.110954, 4.41236], "paragraph_keywords": ["stimulation", "participants", "study", "condition"]}, {"paragraph_vector": [-68.99324, 6.429064], "paragraph_keywords": ["difference", "results", "palm", "test"]}, {"paragraph_vector": [-76.360847, 3.756969], "paragraph_keywords": ["experiment", "test", "posture", "stimulation"]}, {"paragraph_vector": [-74.228111, 3.745467], "paragraph_keywords": ["stimulation", "posture", "conditions", "p"]}, {"paragraph_vector": [-76.586524, 5.415477], "paragraph_keywords": ["stimulation", "hand", "illusion", "vr"]}, {"paragraph_vector": [-80.004264, 5.559566], "paragraph_keywords": ["tactile", "stimulation", "hand", "incongruent"]}, {"paragraph_vector": [-93.151199, 8.882054], "paragraph_keywords": ["users", "body", "tactile", "rain"]}, {"paragraph_vector": [-84.79499, 6.643362], "paragraph_keywords": ["tactile", "body", "air", "user"]}, {"paragraph_vector": [-83.160667, 7.359658], "paragraph_keywords": ["tactile", "time", "users", "vr"]}, {"paragraph_vector": [-98.390472, 17.738658], "paragraph_keywords": ["research", "vr", "thank", "european"]}], "content": {}, "doi": "10.1145/3290605.3300491"}, {"uri": "57", "title": "At Your Service: Designing Voice Assistant Personalities to Improve Automotive User Interfaces A Real World Driving Study", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Michael Braun", "Anja Mainz", "Ronee Chadowitz", "Bastian Pfleging"], "summary": "This paper investigates personalized voice characters for incar speech interfaces. In particular, we report on how we designed different personalities for voice assistants and compared them in a real world driving study. Voice assistants have become important for a wide range of use cases, yet Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300270 current interfaces are using the same style of auditory response in every situation, despite varying user needs and personalities. To close this gap, we designed four assistant personalities (Friend, Admirer, Aunt, and Butler) and compared them to a baseline (Default) in a between-subject study in real traffic conditions. Our results show higher likability and trust for assistants that correctly match the user\u2019s personality while we observed lower likability, trust, satisfaction, and usefulness for incorrectly matched personalities, each in comparison with the Default character. We discuss design aspects for voice assistants in different automotive use cases.", "keywords": ["aunt", "based", "perceived", "acceptance", "speech", "information", "design", "experiment", "personalization", "friend", "assistant", "user", "interaction", "suggests", "matching", "rated", "result", "participant", "use", "designed", "related", "voice", "character", "scale", "case", "personality", "task", "car", "data", "extraversion", "study", "system", "driver", "interface", "driving", "default", "figure"], "document_vector": [-94.656242, -38.51535], "paragraphs": [{"paragraph_vector": [9.337046, 16.562055], "paragraph_keywords": ["assistants", "voice", "driving", "interfaces"]}, {"paragraph_vector": [12.650151, 16.034339], "paragraph_keywords": ["voice", "interfaces", "assistants", "driving"]}, {"paragraph_vector": [4.706966, 26.956888], "paragraph_keywords": ["users", "behavior", "personality", "systems"]}, {"paragraph_vector": [8.992799, 18.28243], "paragraph_keywords": ["assistants", "driving", "voice", "d"]}, {"paragraph_vector": [12.043657, 19.25098], "paragraph_keywords": ["assistant", "characters", "participants", "scale"]}, {"paragraph_vector": [11.030049, 20.15986], "paragraph_keywords": ["character", "user", "characters", "designed"]}, {"paragraph_vector": [11.400637, 18.690568], "paragraph_keywords": ["character", "default", "user", "driving"]}, {"paragraph_vector": [9.896346, 19.544595], "paragraph_keywords": ["experiment", "car", "operator", "participants"]}, {"paragraph_vector": [3.462688, 13.256889], "paragraph_keywords": ["participants", "assistant", "ride", "answered"]}, {"paragraph_vector": [14.868583, 20.19214], "paragraph_keywords": ["participants", "character", "data", "based"]}, {"paragraph_vector": [9.505585, 19.318454], "paragraph_keywords": ["default", "characters", "scale", "character"]}, {"paragraph_vector": [9.156874, 18.108835], "paragraph_keywords": ["characters", "perceived", "default", "participants"]}, {"paragraph_vector": [11.500156, 18.973831], "paragraph_keywords": ["use", "character", "participants", "cases"]}, {"paragraph_vector": [9.487625, 17.215076], "paragraph_keywords": ["assistant", "character", "participants", "user"]}, {"paragraph_vector": [6.766198, 16.983137], "paragraph_keywords": ["character", "characters", "hand", "voice"]}, {"paragraph_vector": [9.900444, 18.539144], "paragraph_keywords": ["personality", "driver", "driving", "user"]}], "content": {}, "doi": "10.1145/3290605.3300820"}, {"uri": "58", "title": "Communication Cost of Single-user Gesturing Tool in Laparoscopic Surgical Training", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Yuanyuan Feng", "Katie Li", "Jacqueline Mun"], "summary": "Multi-user input over a shared display has been shown to support group process and improve performance. However, current gesturing systems for instructional collaborative tasks limit the input to experts and overlook the needs of novices in making references on a shared display. In this paper, we investigate the effects of a single-user gesturing tool on the communication between trainer and trainees in a laparoscopic surgical training. By comparing the communication structure and content between the trainings with and without the gesturing tool, we show that the communication becomes more imbalanced and the trainees become less active when using the single-user gesturing tool. Our findings Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300841 highlight the needs to grant all parties the same level of access to a shared display and suggest further directions in designing a shared display for instructional collaborative tasks.", "keywords": ["process", "act", "vp", "information", "training", "display", "gesturing", "ground", "co", "user", "grounding", "communication", "shared", "trainee", "work", "video", "tool", "use", "cost", "group", "team", "dialogue", "trainer", "collaboration", "content", "taking", "member", "task", "novice", "study", "contribution", "support", "instruction", "knowledge", "turn", "action", "access"], "document_vector": [-59.600639, -19.281291], "paragraphs": [{"paragraph_vector": [133.847885, 44.622859], "paragraph_keywords": ["communication", "task", "shared", "tasks"]}, {"paragraph_vector": [135.023864, 44.474304], "paragraph_keywords": ["novices", "use", "communication", "experts"]}, {"paragraph_vector": [125.808372, 45.998844], "paragraph_keywords": ["ground", "communication", "process", "work"]}, {"paragraph_vector": [118.595436, 46.731163], "paragraph_keywords": ["team", "members", "input", "task"]}, {"paragraph_vector": [137.85231, 43.048049], "paragraph_keywords": ["task", "user", "novices", "gesturing"]}, {"paragraph_vector": [135.699234, 46.144954], "paragraph_keywords": ["tool", "trainers", "trainees", "movements"]}, {"paragraph_vector": [132.838912, 51.425556], "paragraph_keywords": ["kinect", "user", "tasks", "pointer"]}, {"paragraph_vector": [139.299377, 47.478878], "paragraph_keywords": ["training", "video", "park", "tasks"]}, {"paragraph_vector": [137.868301, 46.919143], "paragraph_keywords": ["turns", "turn", "trainees", "actions"]}, {"paragraph_vector": [136.124328, 47.906627], "paragraph_keywords": ["task", "turn", "data", "cases"]}, {"paragraph_vector": [138.709457, 45.633087], "paragraph_keywords": ["vp", "trainees", "use", "turn"]}, {"paragraph_vector": [138.137695, 45.352092], "paragraph_keywords": ["trainees", "act", "p", "vp"]}, {"paragraph_vector": [137.13655, 44.917171], "paragraph_keywords": ["vp", "trainers", "trainees", "figure"]}, {"paragraph_vector": [152.704315, 41.813735], "paragraph_keywords": ["trainee", "clip", "instructions", "judgment"]}, {"paragraph_vector": [150.879455, 46.626991], "paragraph_keywords": ["trainee", "trainer", "excerpt", "instruction"]}, {"paragraph_vector": [138.570175, 45.295619], "paragraph_keywords": ["trainees", "trainers", "party", "task"]}, {"paragraph_vector": [137.074386, 44.622463], "paragraph_keywords": ["communication", "turn", "team", "taking"]}, {"paragraph_vector": [137.789276, 45.359935], "paragraph_keywords": ["trainees", "tasks", "display", "acts"]}, {"paragraph_vector": [135.464584, 44.986732], "paragraph_keywords": ["trainees", "center", "access", "communication"]}], "content": {}, "doi": "10.1145/3290605.3300812"}, {"uri": "59", "title": "From Director\u2019s Cut to User\u2019s Cut: to Watch a Brain-Controlled Film is to Edit it", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Richard Ramchurn", "Sarah Martindale"], "summary": "Introducing interactivity to films has proven a longstanding and difficult challenge due to their narrative-driven, linear and theatre-based nature. Previous research has suggested that Brain-Computer Interfaces (BCI) may be a promising approach but also revealed a tension between being immersed in the film and thinking about control. We report a performance-led and in-the-wild study of a BCI film called The MOMENT covering its design rationale and how it was experienced by the public as controllers, non-controllers and repeat viewers. Our findings suggest that BCI movies should be designed to be credibly controllable, generate personal versions, be watchable as linear films, encourage repeat viewing and fit the medium of cinema. They also reveal how viewers appreciated the sense of editing their own personal cuts, suggesting a new stance on introducing interactivity into lean-back media in which filmmakers release editorial control to users to make their own versions.", "keywords": ["cinema", "controller", "time", "watching", "moment", "viewer", "cut", "scene", "allow", "design", "interview", "interactivity", "eeg", "medium", "user", "thought", "interaction", "story", "going", "work", "people", "way", "think", "sense", "control", "experience", "page", "felt", "according", "character", "content", "form", "feedback", "movie", "-", "audience", "version", "attention", "data", "brain", "narrative", "thread", "viewing", "research", "bci", "controlled", "screening", "perspective", "paper", "controlling", "continuity", "film", "making"], "document_vector": [43.91341, -12.274133], "paragraphs": [{"paragraph_vector": [157.833267, 37.272792], "paragraph_keywords": ["copies", "film", "acm", "nature"]}, {"paragraph_vector": [158.605453, 37.177223], "paragraph_keywords": ["film", "interaction", "bci", "research"]}, {"paragraph_vector": [161.608505, 38.651809], "paragraph_keywords": ["film", "eeg", "viewers", "control"]}, {"paragraph_vector": [159.775497, 39.593528], "paragraph_keywords": ["film", "led", "research", "artist"]}, {"paragraph_vector": [156.730728, 37.342952], "paragraph_keywords": ["allow", "threads", "characters", "scene"]}, {"paragraph_vector": [157.25357, 37.135421], "paragraph_keywords": ["thread", "scene", "film", "attention"]}, {"paragraph_vector": [155.155273, 37.046752], "paragraph_keywords": ["film", "screenings", "audience", "content"]}, {"paragraph_vector": [155.161712, 37.66613], "paragraph_keywords": ["interviews", "introduce", "thread", "asked"]}, {"paragraph_vector": [135.397018, -21.839166], "paragraph_keywords": ["scene", "compared", "themes", "interviews"]}, {"paragraph_vector": [157.662353, 41.393665], "paragraph_keywords": ["control", "think", "way", "felt"]}, {"paragraph_vector": [156.517669, 37.637672], "paragraph_keywords": ["film", "controller", "experience", "felt"]}, {"paragraph_vector": [155.7397, 35.860141], "paragraph_keywords": ["film", "controller", "controlled", "influenced"]}, {"paragraph_vector": [157.965957, 37.118347], "paragraph_keywords": ["film", "controllers", "controlling", "think"]}, {"paragraph_vector": [155.869888, 35.584339], "paragraph_keywords": ["experience", "control", "lot", "want"]}, {"paragraph_vector": [156.11853, 35.917968], "paragraph_keywords": ["film", "controllers", "beginning", "know"]}, {"paragraph_vector": [157.495086, 37.579357], "paragraph_keywords": ["version", "control", "controlling", "film"]}, {"paragraph_vector": [152.878723, 32.922409], "paragraph_keywords": ["film", "characters", "viewings", "changed"]}, {"paragraph_vector": [155.351608, 36.889862], "paragraph_keywords": ["film", "story", "shot", "viewings"]}, {"paragraph_vector": [152.740539, 31.933477], "paragraph_keywords": ["films", "media", "interaction", "watching"]}, {"paragraph_vector": [153.443603, 34.348896], "paragraph_keywords": ["control", "film", "content", "bci"]}, {"paragraph_vector": [155.88208, 37.056846], "paragraph_keywords": ["control", "film", "interactions", "experience"]}, {"paragraph_vector": [158.264938, 37.636772], "paragraph_keywords": ["film", "experience", "interaction", "system"]}, {"paragraph_vector": [158.615463, 37.538402], "paragraph_keywords": ["film", "controlled", "experience", "making"]}, {"paragraph_vector": [156.485534, 35.084289], "paragraph_keywords": ["film", "controller", "viewing", "cuts"]}, {"paragraph_vector": [159.697921, 36.606575], "paragraph_keywords": ["film", "films", "viewers", "perspective"]}, {"paragraph_vector": [157.766906, 38.017677], "paragraph_keywords": ["film", "control", "bci", "people"]}, {"paragraph_vector": [155.254287, 36.701389], "paragraph_keywords": ["audiences", "content", "producers", "perspectives"]}, {"paragraph_vector": [141.460845, 13.676707], "paragraph_keywords": ["data", "generated", "film", "crew"]}], "content": {}, "doi": "10.1145/3290605.3300631"}, {"uri": "60", "title": "Security - Visible, Yet Unseen?", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Verena Distler"], "summary": "An unsolved debate in the field of usable security concerns whether security mechanisms should be visible, or blackboxed away from the user for the sake of usability. However, tying this question to pragmatic usability factors only might be simplistic. This study aims at researching the impact of displaying security mechanisms on User Experience (UX) in the context of e-voting. Two versions of an e-voting application were designed and tested using a between-group experimental protocol (N=38). Version D displayed security mechanisms, while version ND did not reveal any securityrelated information. We collected data on UX using standardised evaluation scales and semi-structured interviews. Version D performed better overall in terms of UX and need fulfilment. Qualitative analysis of the interviews gives further insights into factors impacting perceived security. Our study adds to existing research suggesting a conceptual shift from usability to UX and discusses implications for designing and evaluating secure systems. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300835 CCS CONCEPTS \u2022 Security and privacy\u2192 Usability in security and privacy; Social aspects of security and privacy.", "keywords": ["election", "process", "feeling", "perceived", "need", "information", "mechanism", "design", "app", "nd", "user", "aspect", "impact", "participant", "use", "usability", "e", "encryption", "concern", "given", "security", "factor", "experience", "application", "found", "vote", "version", "phase", "transparency", "technology", "study", "d", "system", "ux", "research", "order", "verification", "voting", "paper", "context"], "document_vector": [24.069116, 31.226224], "paragraphs": [{"paragraph_vector": [57.338489, -18.383785], "paragraph_keywords": ["security", "systems", "cost", "peter"]}, {"paragraph_vector": [59.902744, -16.441181], "paragraph_keywords": ["security", "user", "design", "privacy"]}, {"paragraph_vector": [69.977378, -22.696826], "paragraph_keywords": ["security", "users", "experience", "user"]}, {"paragraph_vector": [54.100772, -18.34921], "paragraph_keywords": ["security", "showed", "voting", "system"]}, {"paragraph_vector": [54.145755, -13.414899], "paragraph_keywords": ["voting", "security", "systems", "vote"]}, {"paragraph_vector": [53.18304, -16.420404], "paragraph_keywords": ["security", "voting", "held", "design"]}, {"paragraph_vector": [52.926937, -18.36621], "paragraph_keywords": ["participants", "phase", "lab", "order"]}, {"paragraph_vector": [67.544288, -9.430921], "paragraph_keywords": ["needs", "security", "scale", "ux"]}, {"paragraph_vector": [53.205234, -16.035863], "paragraph_keywords": ["voting", "security", "end", "order"]}, {"paragraph_vector": [56.216602, -16.691446], "paragraph_keywords": ["version", "security", "d", "needs"]}, {"paragraph_vector": [57.725204, -8.450194], "paragraph_keywords": ["security", "version", "found", "need"]}, {"paragraph_vector": [54.310222, -15.592714], "paragraph_keywords": ["security", "version", "encryption", "participants"]}, {"paragraph_vector": [54.062339, -15.018198], "paragraph_keywords": ["vote", "verification", "votes", "participants"]}, {"paragraph_vector": [52.355606, -20.074804], "paragraph_keywords": ["security", "participants", "authentication", "perceived"]}, {"paragraph_vector": [54.586776, -14.73715], "paragraph_keywords": ["voting", "use", "security", "vote"]}, {"paragraph_vector": [53.245201, -15.493403], "paragraph_keywords": ["voting", "paper", "security", "participants"]}, {"paragraph_vector": [52.824153, -16.340497], "paragraph_keywords": ["voting", "security", "participants", "study"]}, {"paragraph_vector": [57.031681, -16.39339], "paragraph_keywords": ["security", "usability", "create", "study"]}, {"paragraph_vector": [55.923423, -17.842046], "paragraph_keywords": ["security", "user", "voting", "understanding"]}, {"paragraph_vector": [58.544757, -16.942134], "paragraph_keywords": ["security", "participants", "verification", "perceived"]}, {"paragraph_vector": [53.136966, -18.450536], "paragraph_keywords": ["study", "security", "encryption", "aspects"]}, {"paragraph_vector": [61.943607, -16.82023], "paragraph_keywords": ["security", "users", "experience", "authentication"]}, {"paragraph_vector": [60.31755, -16.098476], "paragraph_keywords": ["security", "usability", "research", "study"]}], "content": {}, "doi": "10.1145/3290605.3300798"}, {"uri": "61", "title": "Concept-Driven Visual Analytics: an Exploratory Study of Model- and Hypothesis-Based Reasoning with Visualizations", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["In Kwon Choi", "Khairi Reda", "Nirmal Kumar Raveendranath", "Swati Mishra", "Kyle Harris"], "summary": "Visualization tools facilitate exploratory data analysis, but fall short at supporting hypothesis-based reasoning. We conducted an exploratory study to investigate how visualizations might support a concept-driven analysis style, where users can optionally share their hypotheses and conceptual models in natural language, and receive customized plots depicting the fit of their models to the data. We report on how participants leveraged these unique affordances for visual analysis. We found that a majority of participants articulated meaningful models and predictions, utilizing them as entry points to sensemaking. We contribute an abstract typology representing the types of models participants held and externalized as data expectations. Our findings suggest ways for rearchitecting visual analytics tools to better support hypothesisand model-based reasoning, in addition to their traditional role in exploratory analysis. We discuss the design implications and reflect on the potential benefits and challenges involved.", "keywords": ["reasoning", "process", "based", "time", "unemployment", "population", "trend", "information", "expectation", "design", "feature", "analysis", "rate", "provide", "expected", "example", "relationship", "model", "user", "type", "government", "thought", "work", "tool", "language", "participant", "analytics", "people", "insight", "hypothesis", "predicted", "attribute", "concept", "template", "visualization", "page", "dataset", "provided", "observed", "fit", "query", "driven", "data", "study", "instance", "testing", "correlation", "discovery", "sensemaking", "paper", "interface", "question", "typology", "knowledge", "city", "mediator", "figure"], "document_vector": [-140.389587, -8.516973], "paragraphs": [{"paragraph_vector": [34.848571, 88.694107], "paragraph_keywords": ["data", "copies", "driven", "computing"]}, {"paragraph_vector": [105.56681, 87.379005], "paragraph_keywords": ["data", "visualization", "model", "driven"]}, {"paragraph_vector": [-93.104515, 88.641242], "paragraph_keywords": ["data", "models", "sensemaking", "model"]}, {"paragraph_vector": [65.942596, 68.604835], "paragraph_keywords": ["frame", "data", "discovery", "model"]}, {"paragraph_vector": [78.480682, 83.089523], "paragraph_keywords": ["data", "discovery", "overview", "information"]}, {"paragraph_vector": [-86.832794, 89.789794], "paragraph_keywords": ["data", "users", "tools", "visualizations"]}, {"paragraph_vector": [29.496246, 89.923461], "paragraph_keywords": ["models", "data", "people", "participants"]}, {"paragraph_vector": [-166.008621, 89.04866], "paragraph_keywords": ["participants", "analysis", "models", "interface"]}, {"paragraph_vector": [111.517349, 73.12181], "paragraph_keywords": ["participants", "expectation", "visualization", "time"]}, {"paragraph_vector": [70.969879, 53.553859], "paragraph_keywords": ["participants", "interface", "expectation", "question"]}, {"paragraph_vector": [174.854919, 86.609855], "paragraph_keywords": ["mediator", "visualization", "time", "iran"]}, {"paragraph_vector": [78.238883, 70.197624], "paragraph_keywords": ["expectation", "mediator", "predicted", "annotations"]}, {"paragraph_vector": [88.558517, 77.312652], "paragraph_keywords": ["model", "participants", "expectation", "expectations"]}, {"paragraph_vector": [86.500999, 73.440406], "paragraph_keywords": ["data", "participants", "queries", "expectation"]}, {"paragraph_vector": [89.187377, 74.278854], "paragraph_keywords": ["expectations", "study", "information", "participants"]}, {"paragraph_vector": [81.997505, 49.388492], "paragraph_keywords": ["expectations", "templates", "coding", "typology"]}, {"paragraph_vector": [74.21215, 68.183143], "paragraph_keywords": ["template", "iran", "figure", "participants"]}, {"paragraph_vector": [72.022827, 69.155517], "paragraph_keywords": ["government", "rate", "example", "school"]}, {"paragraph_vector": [76.12902, 68.877769], "paragraph_keywords": ["correlation", "expected", "items", "set"]}, {"paragraph_vector": [94.802528, 75.964111], "paragraph_keywords": ["participants", "expected", "attribute", "unemployment"]}, {"paragraph_vector": [90.733665, 79.191406], "paragraph_keywords": ["participants", "model", "expectations", "predicted"]}, {"paragraph_vector": [104.601821, 83.364112], "paragraph_keywords": ["participants", "data", "models", "expectations"]}, {"paragraph_vector": [84.682518, 76.409439], "paragraph_keywords": ["data", "model", "models", "thought"]}, {"paragraph_vector": [74.232681, 70.065147], "paragraph_keywords": ["models", "expectations", "participant", "data"]}, {"paragraph_vector": [69.804161, 69.99884], "paragraph_keywords": ["model", "participant", "expectation", "ambiguity"]}, {"paragraph_vector": [73.949851, 68.5951], "paragraph_keywords": ["data", "participants", "participant", "factors"]}, {"paragraph_vector": [89.132743, 75.675453], "paragraph_keywords": ["models", "users", "model", "participants"]}, {"paragraph_vector": [122.027473, 88.326217], "paragraph_keywords": ["models", "participants", "data", "typology"]}, {"paragraph_vector": [71.104217, 35.468173], "paragraph_keywords": ["paper", "work", "supported", "science"]}], "content": {}, "doi": "10.1145/3290605.3300281"}, {"uri": "62", "title": "Freedom to Personalize My Digital Classroom: Understanding Teachers' Practices and Motivations", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Laton Vermette", "Joanna McGrenere", "Parmit K. Chilana"], "summary": "Although modern classrooms are increasingly moving towards digital immersion and personalized learning, we have few insights into K-12 teachers\u2019 current practices, motivations, and barriers in setting up their digital classroom ecosystems. We interviewed 20 teachers on their process of discovering and integrating a vast range of productivity software and educational platforms in their classrooms, with a particular focus on how they personalize the UI and content of these tools (e.g., with plugins, templates, or option menus). We found that teachers largely depended on their own experimentation and professional circles to find, personalize, and troubleshoot software tools to support student needs or their own preferences. Teachers were often hesitant to attempt more advanced personalizations due to concerns over student confusion and increased troubleshooting load. We derive several design implications for HCI to better support teachers in sharing their personalized setups and helping their students benefit from digital immersion.", "keywords": ["byod", "tech", "time", "change", "need", "trying", "find", "class", "design", "feature", "interview", "personalization", "customization", "help", "school", "personalize", "sharing", "district", "ui", "work", "video", "tool", "use", "participant", "customizations", "integration", "learning", "way", "challenge", "related", "range", "page", "experience", "teacher", "barrier", "content", "teaching", "classroom", "described", "device", "computer", "customize", "day", "technology", "troubleshooting", "study", "role", "student", "colleague", "support", "research", "software", "paper", "interface", "level", "access"], "document_vector": [-150.522567, 45.77256], "paragraphs": [{"paragraph_vector": [126.797492, 6.707463], "paragraph_keywords": ["tools", "classroom", "teachers", "technology"]}, {"paragraph_vector": [120.143203, 9.152652], "paragraph_keywords": ["teachers", "classroom", "software", "student"]}, {"paragraph_vector": [116.917778, 14.173672], "paragraph_keywords": ["teachers", "classroom", "software", "technology"]}, {"paragraph_vector": [119.309303, 11.296767], "paragraph_keywords": ["teachers", "technology", "school", "tools"]}, {"paragraph_vector": [119.832305, 12.481485], "paragraph_keywords": ["classroom", "software", "tools", "teachers"]}, {"paragraph_vector": [117.71508, 11.985394], "paragraph_keywords": ["customization", "software", "level", "personalization"]}, {"paragraph_vector": [126.328636, 10.618337], "paragraph_keywords": ["teachers", "participants", "technology", "tech"]}, {"paragraph_vector": [118.810523, 11.273182], "paragraph_keywords": ["teachers", "interview", "participants", "tools"]}, {"paragraph_vector": [119.852523, -4.667441], "paragraph_keywords": ["classroom", "teachers", "tools", "themes"]}, {"paragraph_vector": [115.986602, 14.029357], "paragraph_keywords": ["tools", "software", "classroom", "teachers"]}, {"paragraph_vector": [117.108924, 7.722123], "paragraph_keywords": ["tool", "students", "video", "student"]}, {"paragraph_vector": [119.445251, 11.313747], "paragraph_keywords": ["classroom", "teachers", "byod", "attempts"]}, {"paragraph_vector": [109.759773, 26.855337], "paragraph_keywords": ["teachers", "software", "needs", "tools"]}, {"paragraph_vector": [117.334266, 11.67464], "paragraph_keywords": ["teachers", "software", "district", "know"]}, {"paragraph_vector": [122.131866, 13.312596], "paragraph_keywords": ["software", "tools", "teachers", "customization"]}, {"paragraph_vector": [118.786453, 12.566425], "paragraph_keywords": ["students", "content", "teachers", "ui"]}, {"paragraph_vector": [117.858024, 11.246251], "paragraph_keywords": ["teachers", "customizations", "parts", "resources"]}, {"paragraph_vector": [118.505638, 12.747022], "paragraph_keywords": ["use", "classroom", "teachers", "tools"]}, {"paragraph_vector": [114.631004, 15.99368], "paragraph_keywords": ["students", "teachers", "troubleshooting", "class"]}, {"paragraph_vector": [119.377082, 11.163612], "paragraph_keywords": ["students", "school", "classroom", "device"]}, {"paragraph_vector": [116.312461, 12.595385], "paragraph_keywords": ["teachers", "class", "time", "help"]}, {"paragraph_vector": [118.506156, 12.351847], "paragraph_keywords": ["teachers", "software", "technology", "time"]}, {"paragraph_vector": [117.962493, 12.826382], "paragraph_keywords": ["teachers", "software", "learning", "technology"]}, {"paragraph_vector": [119.39199, 11.191131], "paragraph_keywords": ["teachers", "classroom", "support", "software"]}, {"paragraph_vector": [121.569267, 11.715697], "paragraph_keywords": ["teachers", "classroom", "tools", "customize"]}, {"paragraph_vector": [120.363014, 10.726282], "paragraph_keywords": ["teachers", "classroom", "school", "study"]}, {"paragraph_vector": [121.416435, 11.319941], "paragraph_keywords": ["teachers", "classroom", "teaching", "software"]}], "content": {}, "doi": "10.1145/3290605.3300451"}, {"uri": "63", "title": "The Impact of User Characteristics and Preferences on Performance with an Unfamiliar Voice User Interface", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Chelsea M. Myers", "Jichen Zhu"], "summary": "Voice User Interfaces are increasing in popularity. However, their invisible nature with no or limited visuals makes it difficult for users to interact with unfamiliar VUIs. We analyze the impact of user characteristics and preferences on how users interact with a VUI-based calendar, DiscoverCal. While recent VUI studies analyze user behavior through selfreported data, we extend this research by analyzing both VUI usage data and self-reported data to observe correlations between both data types. Results from our user study (n=50) led to four key findings: 1) programming experience did not have a wide-spread impact on performance metrics while 2) assimilation bias did, 3) participants with more technical confidence exhibited a trial-and-error approach, and 4) desiring more guidance from our VUI correlated with performance metrics that indicate cautious users.", "keywords": ["metric", "based", "utterance", "time", "performance", "vuis", "design", "error", "user", "interaction", "work", "impact", "participant", "menu", "voice", "experience", "vui", "found", "feedback", "programming", "task", "data", "study", "approach", "system", "event", "research", "initiative", "preference", "calendar"], "document_vector": [-35.148048, -16.269504], "paragraphs": [{"paragraph_vector": [126.913291, -50.205669], "paragraph_keywords": ["vuis", "user", "interfaces", "systems"]}, {"paragraph_vector": [68.187683, 47.147342], "paragraph_keywords": ["user", "vui", "preferences", "characteristics"]}, {"paragraph_vector": [63.591953, 45.103569], "paragraph_keywords": ["vui", "user", "vuis", "impact"]}, {"paragraph_vector": [54.495021, 50.306564], "paragraph_keywords": ["vui", "participants", "data", "feedback"]}, {"paragraph_vector": [64.391899, 44.368846], "paragraph_keywords": ["vui", "user", "initiative", "users"]}, {"paragraph_vector": [71.337791, 40.241947], "paragraph_keywords": ["vui", "calendar", "participants", "study"]}, {"paragraph_vector": [79.960754, 62.971153], "paragraph_keywords": ["participants", "tasks", "task", "vui"]}, {"paragraph_vector": [66.109687, 50.845947], "paragraph_keywords": ["participants", "vuis", "interaction", "vui"]}, {"paragraph_vector": [73.585037, 52.317306], "paragraph_keywords": ["participants", "received", "score", "wrote"]}, {"paragraph_vector": [68.800682, 46.420497], "paragraph_keywords": ["participants", "task", "metrics", "performance"]}, {"paragraph_vector": [60.596576, 44.666217], "paragraph_keywords": ["participants", "found", "metrics", "tasks"]}, {"paragraph_vector": [61.787994, 45.773269], "paragraph_keywords": ["vui", "experience", "participants", "programming"]}, {"paragraph_vector": [57.543567, 44.766197], "paragraph_keywords": ["vui", "participants", "utterances", "task"]}, {"paragraph_vector": [55.802768, 44.429168], "paragraph_keywords": ["users", "vui", "approach", "help"]}, {"paragraph_vector": [62.059993, 46.085807], "paragraph_keywords": ["vui", "user", "users", "design"]}, {"paragraph_vector": [66.314033, 44.5858], "paragraph_keywords": ["recognize", "tailor", "user", "differences"]}], "content": {}, "doi": "10.1145/3290605.3300540"}, {"uri": "64", "title": "Social Media TestDrive: Real-World Social Media Education for the Next Generation", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Dominic DiFranzo", "Yoon Hyung Choi", "Natalya N. Bazarova", "Amanda Purington"], "summary": "Social media sites are where life happens for many of today\u2019s young people, so it is important to teach them to use these sites safely and effectively. Many youth receive classroom education on digital literacy topics, but have few chances to build actual skills. Social Media TestDrive, an interactive social media simulation, fills a gap in digital literacy education by combining experiential learning in a realistic and safe social media environment with educator-facilitated classroom lessons. The tool was piloted with 12 educators and over 200 students, and formative evaluation data suggest that TestDrive achieved high levels of engagement with both groups. Students reported the modules enhanced their understanding of digital citizenship issues, and educators noted that students were engaging in meaningful classroom conversations. Finally, we discuss the importance of involving multiple stakeholder groups (e.g., researchers, youth, educators, curriculum developers) in designing educational technology.", "keywords": ["process", "reflection", "testdrive", "information", "timeline", "development", "discussion", "self", "education", "design", "citizenship", "simulation", "medium", "user", "activity", "quiz", "engagement", "school", "learner", "risk", "work", "tool", "evaluation", "use", "people", "designed", "post", "material", "team", "learning", "youth", "educator", "literacy", "concept", "experience", "page", "understanding", "content", "curriculum", "module", "classroom", "lesson", "skill", "student", "research", "cyberbullying", "platform", "include", "question", "site", "paper", "knowledge"], "document_vector": [-152.156311, 36.753124], "paragraphs": [{"paragraph_vector": [138.473342, 9.275022], "paragraph_keywords": ["media", "copies", "news", "education"]}, {"paragraph_vector": [137.609909, 10.682322], "paragraph_keywords": ["youth", "media", "engage", "risks"]}, {"paragraph_vector": [138.745941, 12.111766], "paragraph_keywords": ["media", "literacy", "use", "risks"]}, {"paragraph_vector": [135.074493, 10.863438], "paragraph_keywords": ["videos", "media", "lesson", "platform"]}, {"paragraph_vector": [-133.987991, -39.113914], "paragraph_keywords": ["game", "media", "include", "platforms"]}, {"paragraph_vector": [138.603973, 10.424565], "paragraph_keywords": ["media", "learning", "use", "learners"]}, {"paragraph_vector": [136.45816, 11.458526], "paragraph_keywords": ["media", "youth", "research", "educators"]}, {"paragraph_vector": [136.595565, 10.88925], "paragraph_keywords": ["media", "experience", "concepts", "simulation"]}, {"paragraph_vector": [137.598114, 9.069665], "paragraph_keywords": ["media", "research", "participant", "site"]}, {"paragraph_vector": [135.635238, 11.164165], "paragraph_keywords": ["media", "testdrive", "citizenship", "students"]}, {"paragraph_vector": [132.899688, 15.114327], "paragraph_keywords": ["module", "self", "lesson", "drew"]}, {"paragraph_vector": [138.091583, 10.432112], "paragraph_keywords": ["students", "questions", "post", "media"]}, {"paragraph_vector": [137.025482, 12.350713], "paragraph_keywords": ["team", "design", "materials", "research"]}, {"paragraph_vector": [135.218002, 12.665128], "paragraph_keywords": ["educators", "modules", "responses", "students"]}, {"paragraph_vector": [135.787094, 11.379754], "paragraph_keywords": ["students", "discussion", "educators", "media"]}, {"paragraph_vector": [135.8591, 11.921805], "paragraph_keywords": ["citizenship", "students", "module", "scores"]}, {"paragraph_vector": [134.536849, 11.200085], "paragraph_keywords": ["students", "modules", "educators", "quiz"]}, {"paragraph_vector": [136.877853, 11.7281], "paragraph_keywords": ["media", "citizenship", "curricula", "lessons"]}, {"paragraph_vector": [139.27568, 13.463215], "paragraph_keywords": ["educators", "design", "research", "process"]}, {"paragraph_vector": [136.672882, 9.898817], "paragraph_keywords": ["activities", "learners", "platform", "impact"]}, {"paragraph_vector": [135.12767, 11.002133], "paragraph_keywords": ["media", "development", "knowledge", "applications"]}, {"paragraph_vector": [137.109558, 11.513488], "paragraph_keywords": ["citizenship", "students", "media", "people"]}, {"paragraph_vector": [137.88861, 11.457331], "paragraph_keywords": ["worked", "lab", "youth", "institute"]}], "content": {}, "doi": "10.1145/3290605.3300700"}, {"uri": "65", "title": "Understanding the Effect of Accuracy on Trust in Machine Learning Models", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Ming Yin", "Jennifer Wortman Vaughan", "Hanna Wallach"], "summary": "We address a relatively under-explored aspect of human\u2013 computer interaction: people\u2019s abilities to understand the relationship between a machine learning model\u2019s stated performance on held-out data and its expected performance post deployment. We conduct large-scale, randomized humansubject experiments to examine whether laypeople\u2019s trust in a model, measured in terms of both the frequency with which they revise their predictions to match those of the model and their self-reported levels of trust in the model, varies depending on themodel\u2019s stated accuracy on held-out data and on its observed accuracy in practice. We find that people\u2019s trust in a model is affected by both its stated accuracy and its observed accuracy, and that the effect of stated accuracy can change depending on the observed accuracy. Our work relates to recent research on interpretable machine learning, but moves beyond the typical focus on model internals, exploring a different component of the machine learning pipeline.", "keywords": ["find", "information", "performance", "speed", "experiment", "subject", "stated", "accuracy", "model", "trust", "fraction", "user", "date", "result", "work", "people", "effect", "treatment", "algorithm", "feedback", "observed", "dating", "task", "phase", "data", "ml", "held", "prediction", "system", "machine", "level"], "document_vector": [-83.620857, 0.05124], "paragraphs": [{"paragraph_vector": [63.010135, 29.229116], "paragraph_keywords": ["ml", "copies", "machine", "learning"]}, {"paragraph_vector": [60.914802, 55.424705], "paragraph_keywords": ["ml", "model", "performance", "use"]}, {"paragraph_vector": [39.992259, 43.23331], "paragraph_keywords": ["model", "accuracy", "trust", "stated"]}, {"paragraph_vector": [36.202301, 42.968643], "paragraph_keywords": ["model", "accuracy", "trust", "subjects"]}, {"paragraph_vector": [38.02618, 44.660045], "paragraph_keywords": ["model", "accuracy", "trust", "people"]}, {"paragraph_vector": [36.072467, 35.976394], "paragraph_keywords": ["people", "trust", "predictions", "algorithm"]}, {"paragraph_vector": [37.340103, 38.664894], "paragraph_keywords": ["accuracy", "model", "system", "users"]}, {"paragraph_vector": [37.00521, 40.091819], "paragraph_keywords": ["model", "accuracy", "classifiers", "dating"]}, {"paragraph_vector": [38.958908, 45.639427], "paragraph_keywords": ["date", "participant", "dating", "information"]}, {"paragraph_vector": [39.647361, 44.41122], "paragraph_keywords": ["accuracy", "experiment", "subjects", "hit"]}, {"paragraph_vector": [38.936584, 41.801853], "paragraph_keywords": ["tasks", "trust", "phase", "accuracy"]}, {"paragraph_vector": [39.11763, 43.67823], "paragraph_keywords": ["model", "subjects", "agreement", "effect"]}, {"paragraph_vector": [34.913669, 38.813846], "paragraph_keywords": ["accuracy", "subjects", "phase", "model"]}, {"paragraph_vector": [37.286064, 41.553413], "paragraph_keywords": ["accuracy", "model", "stated", "effect"]}, {"paragraph_vector": [38.892086, 42.985172], "paragraph_keywords": ["accuracy", "experiment", "stated", "phase"]}, {"paragraph_vector": [39.277194, 42.172309], "paragraph_keywords": ["experiment", "tasks", "-", "subjects"]}, {"paragraph_vector": [37.243762, 43.787952], "paragraph_keywords": ["accuracy", "model", "subjects", "fraction"]}, {"paragraph_vector": [35.264087, 40.412261], "paragraph_keywords": ["accuracy", "stated", "trust", "effect"]}, {"paragraph_vector": [37.234127, 43.451248], "paragraph_keywords": ["accuracy", "experiment", "model", "subjects"]}, {"paragraph_vector": [36.779132, 42.222225], "paragraph_keywords": ["accuracy", "stated", "subjects", "treatments"]}, {"paragraph_vector": [37.473136, 41.873733], "paragraph_keywords": ["subjects", "trust", "phase", "accuracy"]}, {"paragraph_vector": [35.816497, 42.654766], "paragraph_keywords": ["subjects", "phase", "trust", "increase"]}, {"paragraph_vector": [36.857959, 41.907051], "paragraph_keywords": ["model", "subjects", "accuracy", "observed"]}, {"paragraph_vector": [36.339141, 43.616157], "paragraph_keywords": ["trust", "people", "model", "accuracy"]}, {"paragraph_vector": [42.165992, 47.012622], "paragraph_keywords": ["model", "performance", "data", "prediction"]}, {"paragraph_vector": [40.87194, 44.594448], "paragraph_keywords": ["model", "accuracy", "people", "trust"]}, {"paragraph_vector": [54.941944, 51.315811], "paragraph_keywords": ["work", "miro", "poursabzisangdeh", "machine"]}], "content": {}, "doi": "10.1145/3290605.3300908"}, {"uri": "66", "title": "Virtual Objects in the Physical World: Relatedness and Psychological Ownership in Augmented Reality", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Lev Poretski", "Ofer Arazy", "Joel Lanir"], "summary": "As technology advances, people increasingly interact with virtual objects in settings such as augmented reality (AR) where the virtual layer is superimposed on top of the physical world. Similarly to interactions with physical objects, users may assign virtual objects with value, experience a sense of relatedness, and develop psychological ownership over these objects. The objective of this study is to understand how AR\u2019s unique characteristics influences the emergence of meaning and ownership perceptions amongst users. We conducted a study of users\u2019 interactions with a virtual dog over a threeweek period, comparing AR and fully virtual settings. Our findings show that engagement with the application is a key determinant of the relation users develop with virtual objects. However, the effect of the background layer\u2013 whether physical or virtual\u2013dominates the development of relatedness and ownership feelings, highlighting the importance of the \u201creal\u201d physical layer in shaping users\u2019 perceptions. CCS CONCEPTS \u2022 Human-centered computing \u2022 Human computer interaction (HCI) \u2022 Empirical studies in HCI", "keywords": ["feeling", "time", "object", "development", "possession", "reported", "app", "analysis", "interview", "environment", "care", "territoriality", "enjoyment", "ownership", "example", "user", "engagement", "interaction", "play", "participant", "perception", "group", "interact", "screen", "dog", "world", "related", "relatedness", "experience", "page", "felt", "application", "understanding", "ve", "item", "data", "game", "study", "student", "responsibility", "ar", "research", "paper", "artifact"], "document_vector": [131.717437, -14.392498], "paragraphs": [{"paragraph_vector": [-126.301239, -28.997804], "paragraph_keywords": ["objects", "people", "material", "spaces"]}, {"paragraph_vector": [-126.854194, -21.816019], "paragraph_keywords": ["objects", "users", "acm", "ar"]}, {"paragraph_vector": [-119.959075, -20.169956], "paragraph_keywords": ["dog", "objects", "participants", "experience"]}, {"paragraph_vector": [-120.285911, -25.577024], "paragraph_keywords": ["ownership", "users", "objects", "enjoyment"]}, {"paragraph_vector": [-121.36798, -25.562366], "paragraph_keywords": ["ownership", "object", "users", "environments"]}, {"paragraph_vector": [-114.782875, -20.321735], "paragraph_keywords": ["ar", "dog", "object", "users"]}, {"paragraph_vector": [-124.560577, -26.703945], "paragraph_keywords": ["dog", "user", "application", "mode"]}, {"paragraph_vector": [-122.210769, -30.166828], "paragraph_keywords": ["participants", "dog", "study", "mode"]}, {"paragraph_vector": [-137.583343, -27.874975], "paragraph_keywords": ["participants", "dog", "ownership", "items"]}, {"paragraph_vector": [123.144126, -38.675304], "paragraph_keywords": ["analysis", "interviews", "participants", "themes"]}, {"paragraph_vector": [-127.627868, -28.28935], "paragraph_keywords": ["dog", "participants", "ar", "application"]}, {"paragraph_vector": [-127.336082, -26.265863], "paragraph_keywords": ["participants", "dog", "ar", "engagement"]}, {"paragraph_vector": [-126.422798, -25.061393], "paragraph_keywords": ["dog", "participants", "interactions", "study"]}, {"paragraph_vector": [-125.096786, -26.06347], "paragraph_keywords": ["participants", "group", "dog", "ar"]}, {"paragraph_vector": [-125.465301, -27.472841], "paragraph_keywords": ["dog", "participants", "ar", "fun"]}, {"paragraph_vector": [-128.94728, -28.159145], "paragraph_keywords": ["ownership", "participants", "groups", "student"]}, {"paragraph_vector": [-125.271148, -28.525251], "paragraph_keywords": ["dog", "felt", "participants", "mood"]}, {"paragraph_vector": [-127.286857, -25.457401], "paragraph_keywords": ["dog", "group", "responsibility", "study"]}, {"paragraph_vector": [-126.931442, -28.921176], "paragraph_keywords": ["dog", "possession", "participants", "student"]}, {"paragraph_vector": [-127.093666, -27.978857], "paragraph_keywords": ["dog", "participants", "ve", "participant"]}, {"paragraph_vector": [-123.491241, -23.380352], "paragraph_keywords": ["dog", "constructs", "enjoyment", "participants"]}, {"paragraph_vector": [-126.211708, -27.853836], "paragraph_keywords": ["dog", "enjoyment", "participants", "ar"]}, {"paragraph_vector": [-121.564086, -24.891559], "paragraph_keywords": ["ownership", "users", "development", "engagement"]}, {"paragraph_vector": [-122.065338, -21.039459], "paragraph_keywords": ["users", "presence", "objects", "feeling"]}, {"paragraph_vector": [-107.457069, 20.253337], "paragraph_keywords": ["ar", "participants", "research", "users"]}, {"paragraph_vector": [-123.386505, -24.203998], "paragraph_keywords": ["participants", "ar", "ownership", "dog"]}, {"paragraph_vector": [-21.723926, -83.746093], "paragraph_keywords": ["data", "development", "ownership", "design"]}], "content": {}, "doi": "10.1145/3290605.3300736"}, {"uri": "67", "title": "How Users Interpret Bugsin Trigger-Action Programming", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Will Brackenbury", "Abhimanyu Deora", "Jillian Ritchey", "Jason Vallee", "Weijia He", "Guan Wang", "Michael L. Littman", "Blase Ur"], "summary": "Trigger-action programming (TAP) is a programming model enabling users to connect services and devices by writing if-then rules. As such systems are deployed in increasingly complex scenarios, users must be able to identify programming bugs and reason about how to fix them.We first systematize the temporal paradigms through which TAP systems could express rules. We then identify ten classes of TAP programming bugs related to control flow, timing, and inaccurate user expectations. We report on a 153-participant online study where participants were assigned to a temporal paradigm and shown a series of pre-written TAP rules. Half of the rules exhibited bugs from our ten bug classes. For most of the bug classes, we found that the presence of a bug made it harder for participants to correctly predict the behavior of the rule. Our findings suggest directions for better supporting end-user programmers.", "keywords": ["fixed", "time", "tap", "correctness", "default", "section", "literature", "paradigm", "example", "user", "model", "bug", "work", "scenario", "participant", "triggering", "tested", "ruleset", "state", "trigger", "found", "light", "semantics", "programming", "device", "priority", "study", "system", "event", "end", "rule", "bias", "rulesets", "window", "action", "raining"], "document_vector": [19.373165, 3.293472], "paragraphs": [{"paragraph_vector": [73.315452, 28.089143], "paragraph_keywords": ["things", "copies", "trigger", "programming"]}, {"paragraph_vector": [53.469417, 21.960628], "paragraph_keywords": ["tap", "rules", "support", "programming"]}, {"paragraph_vector": [49.443134, 21.595546], "paragraph_keywords": ["tap", "bugs", "rules", "section"]}, {"paragraph_vector": [50.422908, 21.713054], "paragraph_keywords": ["tap", "time", "temporality", "event"]}, {"paragraph_vector": [50.013778, 20.052265], "paragraph_keywords": ["events", "triggers", "trigger", "event"]}, {"paragraph_vector": [45.964076, 20.43884], "paragraph_keywords": ["tap", "state", "bugs", "event"]}, {"paragraph_vector": [47.466079, 20.77367], "paragraph_keywords": ["bugs", "tap", "bug", "rules"]}, {"paragraph_vector": [49.503501, 21.400873], "paragraph_keywords": ["bugs", "action", "lights", "arise"]}, {"paragraph_vector": [47.422088, 20.592313], "paragraph_keywords": ["users", "rules", "state", "event"]}, {"paragraph_vector": [46.782817, 20.11905], "paragraph_keywords": ["tap", "paradigm", "scenario", "participants"]}, {"paragraph_vector": [49.017345, 21.990653], "paragraph_keywords": ["fido", "scenario", "following", "scenarios"]}, {"paragraph_vector": [47.048839, 18.144031], "paragraph_keywords": ["scenario", "bug", "participant", "fixed"]}, {"paragraph_vector": [69.799728, 44.55804], "paragraph_keywords": ["tap", "deployed", "code", "scenarios"]}, {"paragraph_vector": [51.76963, 24.519165], "paragraph_keywords": ["participants", "ruleset", "correctness", "bug"]}, {"paragraph_vector": [47.958053, 19.391874], "paragraph_keywords": ["participants", "bugs", "bug", "tap"]}, {"paragraph_vector": [48.530689, 19.699451], "paragraph_keywords": ["participants", "bug", "rule", "trigger"]}, {"paragraph_vector": [44.318119, 16.418647], "paragraph_keywords": ["rules", "rule", "trigger", "house"]}, {"paragraph_vector": [47.455894, 20.16781], "paragraph_keywords": ["rules", "participants", "assumed", "trigger"]}, {"paragraph_vector": [47.486255, 17.58278], "paragraph_keywords": ["rules", "windows", "tested", "participants"]}, {"paragraph_vector": [46.852836, 17.49407], "paragraph_keywords": ["participants", "alerts", "bug", "scenario"]}, {"paragraph_vector": [44.295406, 17.772447], "paragraph_keywords": ["rules", "scenario", "scenarios", "triggers"]}, {"paragraph_vector": [50.981884, 21.658439], "paragraph_keywords": ["tap", "bugs", "programming", "participants"]}, {"paragraph_vector": [48.278244, 21.102741], "paragraph_keywords": ["bugs", "window", "rules", "system"]}, {"paragraph_vector": [47.127372, 22.334486], "paragraph_keywords": ["user", "rules", "rule", "work"]}], "content": {}, "doi": "10.1145/3290605.3300769"}, {"uri": "68", "title": "ReType: Quick Text Editing with Keyboard and Gaze", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Shyamli Sindhwani", "Christof Lutteroth"], "summary": "When a user needs to reposition the cursor during text editing, this is often done using the mouse. For experienced typists especially, the switch between keyboard and mouse can slow down the keyboard editing workflow considerably. To address this we propose ReType, a new gaze-assisted positioning technique combining keyboard with gaze input based on a new \u2018patching\u2019 metaphor. ReType allows users to perform some common editing operations while keeping their hands on the keyboard. We present the result of two studies. A free-use study indicated that ReType enhances the user experience of text editing. ReType was liked by many participants, regardless of their typing skills. A comparative user study showed that ReType is able to match or even beat the speed of mouse-based interaction for small text edits. We conclude that the gaze-augmented user interface can make common interactions more fluent, especially for professional keyboard users.", "keywords": ["typo", "lead", "position", "point", "time", "correction", "retype", "selection", "design", "speed", "cursor", "pointing", "gaze", "error", "keyboard", "user", "type", "interaction", "eye", "work", "word", "start", "motor", "participant", "use", "operation", "m", "positioning", "page", "number", "character", "edit", "match", "task", "editing", "study", "string", "system", "text", "typing", "order", "mode", "patching", "paper", "editor", "mouse", "input", "figure"], "document_vector": [-78.450462, -55.166736], "paragraphs": [{"paragraph_vector": [-20.63655, -15.484742], "paragraph_keywords": ["gaze", "text", "acm", "copies"]}, {"paragraph_vector": [-21.073177, -16.708583], "paragraph_keywords": ["gaze", "input", "user", "use"]}, {"paragraph_vector": [-12.680102, -19.975547], "paragraph_keywords": ["keyboard", "retype", "text", "gaze"]}, {"paragraph_vector": [-13.630636, -19.269695], "paragraph_keywords": ["retype", "gaze", "mouse", "typo"]}, {"paragraph_vector": [-20.615638, -12.758763], "paragraph_keywords": ["gaze", "mouse", "targets", "input"]}, {"paragraph_vector": [-21.534866, -16.9053], "paragraph_keywords": ["text", "dwell", "gaze", "editing"]}, {"paragraph_vector": [-14.740502, -22.647006], "paragraph_keywords": ["retype", "text", "mode", "string"]}, {"paragraph_vector": [-12.235589, -19.668489], "paragraph_keywords": ["retype", "gaze", "user", "match"]}, {"paragraph_vector": [-11.527297, -16.988471], "paragraph_keywords": ["retype", "gaze", "keyboard", "matches"]}, {"paragraph_vector": [-11.949334, -18.643892], "paragraph_keywords": ["retype", "editing", "typo", "completion"]}, {"paragraph_vector": [-11.386318, -19.067453], "paragraph_keywords": ["mode", "retype", "user", "characters"]}, {"paragraph_vector": [-12.435297, -19.829231], "paragraph_keywords": ["edit", "distance", "string", "algorithm"]}, {"paragraph_vector": [-11.778939, -18.183086], "paragraph_keywords": ["retype", "text", "gaze", "match"]}, {"paragraph_vector": [-13.17117, -19.048458], "paragraph_keywords": ["text", "retype", "editing", "selection"]}, {"paragraph_vector": [-13.266201, -20.497682], "paragraph_keywords": ["retype", "participants", "study", "text"]}, {"paragraph_vector": [-12.341084, -19.430873], "paragraph_keywords": ["retype", "keyboard", "mouse", "order"]}, {"paragraph_vector": [-14.373143, -17.610107], "paragraph_keywords": ["time", "typo", "participant", "error"]}, {"paragraph_vector": [-15.063338, -15.515628], "paragraph_keywords": ["typos", "participants", "task", "retype"]}, {"paragraph_vector": [-18.384019, -15.214137], "paragraph_keywords": ["participants", "participant", "typos", "text"]}, {"paragraph_vector": [-19.745164, -3.648533], "paragraph_keywords": ["retype", "time", "motor", "mouse"]}, {"paragraph_vector": [-16.005018, -13.07061], "paragraph_keywords": ["retype", "mouse", "typing", "rt"]}, {"paragraph_vector": [-13.807046, -21.089128], "paragraph_keywords": ["m", "retype", "participants", "mouse"]}, {"paragraph_vector": [-14.674947, -19.144102], "paragraph_keywords": ["retype", "participants", "keyboard", "mouse"]}, {"paragraph_vector": [-15.42418, -21.000684], "paragraph_keywords": ["retype", "mouse", "time", "participants"]}, {"paragraph_vector": [-13.761336, -16.62434], "paragraph_keywords": ["retype", "gaze", "text", "study"]}, {"paragraph_vector": [-13.550478, -19.84324], "paragraph_keywords": ["retype", "text", "gaze", "interaction"]}], "content": {}, "doi": "10.1145/3290605.3300817"}, {"uri": "69", "title": "PledgeWork: Online Volunteering  through Crowdwork", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Keiko Katsuragawa"], "summary": "In this paper, we explore an alternative form of volunteer work, PledgeWork, where individuals, rather than working directly for a charity, make indirect donations by completing tasks provided by a third party task provider. PledgeWork poses novel research questions on issues of user acceptance of on-line volunteerism, on quality and quantity of work performed as a volunteer, and on the benefits low-barrier volunteerism might provide to charities. To evaluate these questions, we conduct a mixed methods study that compares the quality and quantity of work between volunteer workers and paid workers and user attitudes toward PledgeWork, including perceived benefits and drawbacks. We find that PledgeWork can improve the quality of simple tasks and that the vast majority of our participants expressed interest in using our PledgeWork platform to contribute to a charity. Our interview also reveals current problems with volunteering and online donations, thus highlighting additional strengths of PledgeWork.", "keywords": ["time", "information", "worker", "pledgework", "annotation", "play", "work", "result", "cause", "participant", "people", "group", "completed", "cost", "file", "given", "paid", "crowdwork", "page", "number", "found", "volunteer", "money", "task", "volunteering", "case", "data", "editing", "study", "crowdworkers", "donation", "support", "text", "charity", "quality", "platform", "deception", "minute", "crowdsourcing", "interface", "paper", "question"], "document_vector": [-50.506946, 20.637722], "paragraphs": [{"paragraph_vector": [45.873134, -0.200712], "paragraph_keywords": ["acm", "government", "volunteering", "time"]}, {"paragraph_vector": [44.4468, -0.522858], "paragraph_keywords": ["pledgework", "charity", "volunteers", "tasks"]}, {"paragraph_vector": [46.490203, 0.630611], "paragraph_keywords": ["pledgework", "workers", "crowdsourcing", "user"]}, {"paragraph_vector": [47.629623, 3.739408], "paragraph_keywords": ["quality", "work", "platform", "found"]}, {"paragraph_vector": [46.212726, -0.631711], "paragraph_keywords": ["task", "work", "paid", "pledgework"]}, {"paragraph_vector": [44.968662, -0.954294], "paragraph_keywords": ["pledgework", "workers", "work", "task"]}, {"paragraph_vector": [39.882362, 8.296863], "paragraph_keywords": ["charity", "study", "task", "participants"]}, {"paragraph_vector": [43.927417, 8.468513], "paragraph_keywords": ["participants", "task", "label", "annotation"]}, {"paragraph_vector": [44.369457, 13.581952], "paragraph_keywords": ["participants", "task", "editing", "window"]}, {"paragraph_vector": [40.473865, 7.559762], "paragraph_keywords": ["participants", "charity", "tasks", "deception"]}, {"paragraph_vector": [34.763893, 10.379957], "paragraph_keywords": ["paid", "participants", "interface", "task"]}, {"paragraph_vector": [44.790267, 14.887147], "paragraph_keywords": ["task", "participants", "questionnaire", "questions"]}, {"paragraph_vector": [42.491542, 7.259855], "paragraph_keywords": ["task", "participants", "group", "paid"]}, {"paragraph_vector": [41.347003, 11.200433], "paragraph_keywords": ["task", "time", "participants", "charity"]}, {"paragraph_vector": [41.36198, 11.728586], "paragraph_keywords": ["quality", "play", "task", "participants"]}, {"paragraph_vector": [41.585628, 8.233779], "paragraph_keywords": ["participants", "task", "charity", "tasks"]}, {"paragraph_vector": [44.715766, -1.144747], "paragraph_keywords": ["participants", "time", "volunteering", "minutes"]}, {"paragraph_vector": [45.417369, -3.403124], "paragraph_keywords": ["participants", "donation", "charity", "volunteering"]}, {"paragraph_vector": [46.444995, -4.711092], "paragraph_keywords": ["information", "charity", "time", "lack"]}, {"paragraph_vector": [44.930339, -2.262017], "paragraph_keywords": ["charity", "volunteering", "volunteers", "volunteer"]}, {"paragraph_vector": [43.904163, -2.195108], "paragraph_keywords": ["workers", "task", "tasks", "pledgework"]}, {"paragraph_vector": [44.661392, -1.312442], "paragraph_keywords": ["crowdwork", "pledgework", "charities", "study"]}, {"paragraph_vector": [45.404338, -2.523716], "paragraph_keywords": ["crowdwork", "pledgework", "participants", "data"]}, {"paragraph_vector": [84.162971, -34.785079], "paragraph_keywords": ["university", "waterloo", "ethics", "assistance"]}], "content": {}, "doi": "10.1145/3290605.3300553"}, {"uri": "70", "title": "Diagnosing and Coping with Mode Errors in Korean-English Dual-language Keyboard", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Sangyoon Lee", "Jaeyeon Lee"], "summary": "In countries where languages with non-Latin characters are prevalent, people use a keyboard with two language modes namely, the native language and English, and often experience mode errors. To diagnose the mode error problem, we conducted a field study and observed that 78% of the mode errors occurred immediately after application switching. We implemented four methods (Auto-switch, Preview, Smarttoggle, and Preview& Smart-toggle) based on three strategies to deal with themode error problem and conducted field studies to verify their effectiveness. In the studies considering Korean-English dual input, Auto-switch was ineffective. On the contrary, Preview significantly reduced the mode errors from 75.1% to 41.3%, and Smart-toggle saved typing cost for recovering frommode errors. In Preview& Smart-toggle, Preview reduced mode errors and Smart-toggle handled 86.2% of the mode errors that slipped past Preview. These results suggest that Preview & Smart-toggle is a promising method for preventing mode errors for the Korean-English dual-input environment.", "keywords": ["option", "based", "toggle", "method", "experiment", "environment", "problem", "error", "user", "english", "word", "language", "participant", "use", "m", "algorithm", "application", "switching", "character", "feedback", "keystroke", "computer", "switch", "prediction", "preview", "text", "mode", "paper", "input", "letter", "auto", "mef"], "document_vector": [-51.783821, -60.478046], "paragraphs": [{"paragraph_vector": [-33.927978, -13.268097], "paragraph_keywords": ["language", "copies", "user", "mode"]}, {"paragraph_vector": [-19.028888, -32.783073], "paragraph_keywords": ["language", "mode", "input", "user"]}, {"paragraph_vector": [-19.231674, -31.81875], "paragraph_keywords": ["language", "mode", "input", "methods"]}, {"paragraph_vector": [-32.118618, -24.285346], "paragraph_keywords": ["input", "characters", "language", "layout"]}, {"paragraph_vector": [-20.867614, -29.77547], "paragraph_keywords": ["input", "language", "mode", "switching"]}, {"paragraph_vector": [-17.60238, -33.667678], "paragraph_keywords": ["mode", "switching", "language", "user"]}, {"paragraph_vector": [-18.9713, -30.013898], "paragraph_keywords": ["mode", "feedback", "language", "errors"]}, {"paragraph_vector": [-14.879861, -23.373582], "paragraph_keywords": ["mode", "inputs", "experiment", "input"]}, {"paragraph_vector": [-16.089508, -25.679697], "paragraph_keywords": ["mode", "errors", "application", "mef"]}, {"paragraph_vector": [-17.344856, -23.195459], "paragraph_keywords": ["application", "time", "ms", "switch"]}, {"paragraph_vector": [-17.259038, -29.498041], "paragraph_keywords": ["user", "algorithm", "mode", "prediction"]}, {"paragraph_vector": [-20.344032, -32.983119], "paragraph_keywords": ["input", "prediction", "word", "algorithm"]}, {"paragraph_vector": [-18.568834, -30.375461], "paragraph_keywords": ["option", "feedback", "auto", "language"]}, {"paragraph_vector": [-24.132225, -21.758127], "paragraph_keywords": ["feedback", "text", "input", "participants"]}, {"paragraph_vector": [-19.20428, -27.600019], "paragraph_keywords": ["mode", "application", "user", "toggle"]}, {"paragraph_vector": [-20.547529, -31.641542], "paragraph_keywords": ["letters", "character", "probability", "input"]}, {"paragraph_vector": [-17.853967, -25.154085], "paragraph_keywords": ["mode", "participants", "feature", "auto"]}, {"paragraph_vector": [-18.718746, -30.75419], "paragraph_keywords": ["mode", "auto", "error", "cases"]}, {"paragraph_vector": [-19.479084, -29.776762], "paragraph_keywords": ["experiment", "participants", "auto", "error"]}, {"paragraph_vector": [-20.506425, -29.796882], "paragraph_keywords": ["feedback", "mef", "applications", "mode"]}, {"paragraph_vector": [-18.34473, -25.56805], "paragraph_keywords": ["experiment", "participants", "toggle", "adoptrate"]}, {"paragraph_vector": [-16.59205, -22.950206], "paragraph_keywords": ["toggle", "mode", "participants", "experiment"]}, {"paragraph_vector": [-17.564804, -30.599479], "paragraph_keywords": ["methods", "toggle", "mode", "results"]}, {"paragraph_vector": [-19.969154, -31.020048], "paragraph_keywords": ["input", "typo", "mode", "language"]}, {"paragraph_vector": [-19.391298, -26.192863], "paragraph_keywords": ["errors", "mode", "confusion", "problem"]}], "content": {}, "doi": "10.1145/3290605.3300691"}, {"uri": "71", "title": "The Role of Physical Props in VR Climbing Environments", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Peter Schulz", "Dmitry Alexandrovsky", "Felix Putze", "Rainer Malaka"], "summary": "Dealing with fear of falling is a challenge in sport climbing. Virtual reality (VR) research suggests that using physical and reality-based interaction increases the presence in VR. In this paper, we present a study that investigates the influence of physical props on presence, stress and anxiety in a VR climbing environment involving whole body movement. To help climbers overcoming fear of falling, we compared three different conditions: Climbing in reality at 10 m height, physical climbing in VR (with props attached to the climbing wall) and virtual climbing in VR using game controllers. From subjective reports and biosignals, our results show that climbing with props in VR increases the anxiety and sense of realism in VR for sport climbing. This suggests that VR in combination with physical props are an effective simulation setup to induce the sense of height.", "keywords": ["climber", "fear", "vr", "condition", "climbing", "al", "creal", "time", "employ", "falling", "wall", "self", "training", "environment", "subject", "experiment", "ground", "prop", "et", "result", "work", "participant", "effect", "vret", "sport", "exposure", "route", "experience", "page", "setup", "tracking", "scale", "measure", "hand", "study", "anxiety", "stress", "hr", "cprops", "height", "support", "reality", "rope", "acrophobia", "showed", "immersion", "paper", "level", "presence"], "document_vector": [80.442169, -71.284667], "paragraphs": [{"paragraph_vector": [-103.487136, 7.035941], "paragraph_keywords": ["climbing", "falling", "exposure", "reality"]}, {"paragraph_vector": [-103.375587, 7.252506], "paragraph_keywords": ["climbing", "presence", "vr", "environment"]}, {"paragraph_vector": [-107.06005, 2.763059], "paragraph_keywords": ["climbing", "anxiety", "route", "fear"]}, {"paragraph_vector": [-109.113601, 0.915157], "paragraph_keywords": ["anxiety", "studies", "climbers", "climbing"]}, {"paragraph_vector": [-105.508308, 4.042505], "paragraph_keywords": ["fear", "anxiety", "falling", "showed"]}, {"paragraph_vector": [-107.173118, 3.668053], "paragraph_keywords": ["presence", "climbing", "vr", "experience"]}, {"paragraph_vector": [-106.915252, 4.08641], "paragraph_keywords": ["climbing", "wall", "video", "training"]}, {"paragraph_vector": [-106.987571, 2.855301], "paragraph_keywords": ["climbing", "height", "study", "falling"]}, {"paragraph_vector": [-105.737403, 4.659142], "paragraph_keywords": ["presence", "anxiety", "props", "vr"]}, {"paragraph_vector": [-105.776535, 3.66776], "paragraph_keywords": ["anxiety", "participants", "level", "scale"]}, {"paragraph_vector": [-106.306327, 4.52027], "paragraph_keywords": ["climbing", "condition", "height", "ground"]}, {"paragraph_vector": [-59.717857, 32.141731], "paragraph_keywords": ["participants", "climbing", "rope", "tracking"]}, {"paragraph_vector": [-105.423995, 5.016771], "paragraph_keywords": ["participants", "anxiety", "results", "analysis"]}, {"paragraph_vector": [-9.836788, 1.842991], "paragraph_keywords": ["hr", "test", "sphericity", "effect"]}, {"paragraph_vector": [-13.279108, 11.455145], "paragraph_keywords": ["conditions", "presence", "response", "scores"]}, {"paragraph_vector": [-106.381172, 4.643289], "paragraph_keywords": ["cprops", "climbing", "vr", "realness"]}, {"paragraph_vector": [-106.98664, 3.947135], "paragraph_keywords": ["climbing", "tracking", "cprops", "immersion"]}, {"paragraph_vector": [-105.275672, 4.123703], "paragraph_keywords": ["climbing", "anxiety", "experience", "measures"]}, {"paragraph_vector": [-106.739341, 5.024428], "paragraph_keywords": ["training", "vr", "interaction", "climbing"]}], "content": {}, "doi": "10.1145/3290605.3300545"}, {"uri": "72", "title": "VirtualComponent: A Mixed-Reality Tool for Designing and Tuning Breadboarded Circuits", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Yoonji Kim", "Youngkyung Choi", "Hyein Lee", "Geehyuk Lee"], "summary": "Prototyping electronic circuits is an increasingly popular activity, supported by researchers, who develop toolkits to improve the design, debugging, and fabrication of electronics. Although past work mainly dealt with circuit topology, in this paper we propose a system for determining or tuning the values of the circuit components. Based on the results of a formative study with seventeen makers, we designed Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05...$15.00 https://doi.org/10.1145/3290605.3300407 VirtualComponent, a mixed-reality tool that allows users to digitally place electronic components on a real breadboard, tune their values in software, and see these changes applied to the physical circuit in real-time. VirtualComponent is composed of a set of plug-and-play modules containing banks of components, and a custom breadboard managing the connections and components\u2019 values. Through demonstrations and the results of an informal study with twelve makers, we show that VirtualComponent is easy to use and allows users to test components\u2019 value configurations with little effort.", "keywords": ["process", "breadboard", "tablet", "time", "connection", "hardware", "design", "component", "generator", "figure", "example", "debugging", "user", "resistance", "work", "tool", "participant", "use", "resistor", "maker", "screen", "wiring", "experience", "page", "level", "capacitor", "tuning", "module", "test", "circuit", "virtualcomponent", "system", "support", "tune", "software", "paper", "value", "board", "voltage"], "document_vector": [74.589408, -24.213027], "paragraphs": [{"paragraph_vector": [19.952114, 30.758861], "paragraph_keywords": ["circuit", "makers", "design", "circuits"]}, {"paragraph_vector": [13.313267, 24.959356], "paragraph_keywords": ["software", "breadboard", "components", "debugging"]}, {"paragraph_vector": [20.252538, 30.366561], "paragraph_keywords": ["components", "software", "blocks", "hardware"]}, {"paragraph_vector": [20.967033, 31.375108], "paragraph_keywords": ["circuits", "circuit", "makers", "design"]}, {"paragraph_vector": [23.67979, 29.450578], "paragraph_keywords": ["participants", "process", "makers", "components"]}, {"paragraph_vector": [16.351991, 24.119945], "paragraph_keywords": ["components", "value", "wiring", "experience"]}, {"paragraph_vector": [13.5886, 25.341615], "paragraph_keywords": ["components", "breadboard", "value", "parts"]}, {"paragraph_vector": [11.449139, 23.657199], "paragraph_keywords": ["components", "breadboard", "ldrs", "alice"]}, {"paragraph_vector": [15.57287, 26.347539], "paragraph_keywords": ["board", "breadboard", "voltage", "consists"]}, {"paragraph_vector": [10.257493, 27.924112], "paragraph_keywords": ["module", "components", "power", "board"]}, {"paragraph_vector": [9.794945, 25.699981], "paragraph_keywords": ["components", "capacitors", "inductors", "series"]}, {"paragraph_vector": [-7.907986, 28.731277], "paragraph_keywords": ["tablet", "components", "breadboard", "users"]}, {"paragraph_vector": [10.485821, 24.530269], "paragraph_keywords": ["component", "values", "screen", "components"]}, {"paragraph_vector": [12.017971, 23.042463], "paragraph_keywords": ["values", "resistance", "measurements", "capacitance"]}, {"paragraph_vector": [12.617321, 25.110618], "paragraph_keywords": ["resistor", "circuit", "components", "shows"]}, {"paragraph_vector": [13.254763, 24.753973], "paragraph_keywords": ["circuits", "tuning", "circuit", "tune"]}, {"paragraph_vector": [14.620148, 26.903011], "paragraph_keywords": ["virtualcomponent", "tuning", "components", "software"]}, {"paragraph_vector": [10.055101, 26.474376], "paragraph_keywords": ["values", "components", "users", "modules"]}, {"paragraph_vector": [20.67843, 38.846469], "paragraph_keywords": ["research", "supporting", "work", "connectivity"]}], "content": {}, "doi": "10.1145/3290605.3300606"}, {"uri": "73", "title": "Laughing is Scary, but Farting is Cute: A Conceptual Model of Children's Perspectives of Creepy Technologies", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jason C. Yip", "Kiley Sobel", "Xin Gao", "Allison Marie Hishikawa", "Alexis Lim", "Laura Meng", "Romaine Flor Ofana", "Justin Park", "Alexis Hiniker"], "summary": "In HCI, adult concerns about technologies for children have been studied extensively. However, less is known about what children themselves fnd concerning in everyday technologies. We examine children\u2019s technology-related fears by probing their use of the colloquial term \u201ccreepy.\u201d To understand children\u2019s perceptions of \u201ccreepy technologies,\u201d we conducted four participatory design sessions with children (ages 7 11) to design and evaluate creepy technologies, followed by interviews with the same children. We found that children\u2019s fear reactions emphasized physical harm and threats to their relationships (particularly with attachment fgures). The creepy signals from technology the children described include: deception, lack of control, mimicry, ominous physical appearance, and unpredictability. Children acknowledged trusted adults will mediate the relationship between creepy technology signals and fear responses. Our work contributes a close examination of what children mean when they say a technology is \u201ccreepy.\u201d By treating these concerns as principal design considerations, developers can build systems that are more transparent about the risks they produce and more sensitive to the fears they may unintentionally raise.", "keywords": ["fear", "child", "time", "information", "threat", "creepy", "childhood", "like", "design", "interview", "safety", "relationship", "noted", "model", "thought", "trust", "work", "scenario", "use", "people", "perception", "concern", "group", "way", "pd", "theme", "security", "control", "voice", "page", "understand", "appearance", "develop", "robot", "signal", "pepper", "response", "data", "technology", "study", "researcher", "designer", "parent", "adult", "surveillance", "session", "explained", "asked", "paper", "question", "privacy", "figure", "laughter", "creepiness"], "document_vector": [59.260547, 8.230583], "paragraphs": [{"paragraph_vector": [125.536842, -59.190532], "paragraph_keywords": ["children", "technologies", "copies", "computing"]}, {"paragraph_vector": [179.110336, -36.869682], "paragraph_keywords": ["children", "technologies", "technology", "fear"]}, {"paragraph_vector": [177.988479, -34.552192], "paragraph_keywords": ["fear", "fears", "children", "childhood"]}, {"paragraph_vector": [178.243392, -38.97636], "paragraph_keywords": ["children", "fear", "parents", "safety"]}, {"paragraph_vector": [176.524398, -37.332469], "paragraph_keywords": ["children", "fears", "ambiguity", "toys"]}, {"paragraph_vector": [107.546325, -53.753616], "paragraph_keywords": ["creepy", "privacy", "children", "people"]}, {"paragraph_vector": [173.656448, -37.046566], "paragraph_keywords": ["children", "fear", "pd", "design"]}, {"paragraph_vector": [159.352584, -37.162124], "paragraph_keywords": ["design", "children", "sessions", "child"]}, {"paragraph_vector": [179.112045, -35.8012], "paragraph_keywords": ["children", "design", "session", "camera"]}, {"paragraph_vector": [-144.060729, 10.967511], "paragraph_keywords": ["children", "line", "scenario", "scenarios"]}, {"paragraph_vector": [175.642135, -32.26369], "paragraph_keywords": ["use", "data", "groups", "children"]}, {"paragraph_vector": [177.089828, -35.400184], "paragraph_keywords": ["children", "fear", "themes", "fears"]}, {"paragraph_vector": [-171.358306, -28.513612], "paragraph_keywords": ["harm", "children", "stalking", "technology"]}, {"paragraph_vector": [-166.223968, -33.302555], "paragraph_keywords": ["technologies", "children", "coraline", "voice"]}, {"paragraph_vector": [-165.941284, -27.651506], "paragraph_keywords": ["technology", "children", "parents", "child"]}, {"paragraph_vector": [-148.535949, -14.082339], "paragraph_keywords": ["children", "technology", "questions", "figure"]}, {"paragraph_vector": [-150.344772, -12.333214], "paragraph_keywords": ["children", "figure", "technology", "doll"]}, {"paragraph_vector": [-167.314651, -75.675842], "paragraph_keywords": ["children", "technology", "control", "parents"]}, {"paragraph_vector": [120.545211, -50.567829], "paragraph_keywords": ["technology", "laughter", "laughing", "children"]}, {"paragraph_vector": [-143.191299, -9.959742], "paragraph_keywords": ["technology", "children", "listening", "diferent"]}, {"paragraph_vector": [-160.645721, -22.857063], "paragraph_keywords": ["children", "technology", "parents", "thought"]}, {"paragraph_vector": [-56.743392, -87.670471], "paragraph_keywords": ["parents", "technology", "information", "properties"]}, {"paragraph_vector": [-169.03746, -29.560989], "paragraph_keywords": ["children", "technology", "device", "signals"]}, {"paragraph_vector": [177.339599, -39.238769], "paragraph_keywords": ["children", "concerns", "fears", "designers"]}, {"paragraph_vector": [176.798233, -35.271255], "paragraph_keywords": ["children", "technology", "parents", "fear"]}, {"paragraph_vector": [178.726165, -36.498714], "paragraph_keywords": ["children", "technologies", "technology", "extent"]}, {"paragraph_vector": [178.108932, -37.20071], "paragraph_keywords": ["children", "design", "technologies", "adults"]}, {"paragraph_vector": [177.500946, -35.349262], "paragraph_keywords": ["children", "work", "fears", "technology"]}, {"paragraph_vector": [177.48413, -36.091739], "paragraph_keywords": ["children", "fears", "technology", "design"]}], "content": {}, "doi": "10.1145/3290605.3300651"}, {"uri": "74", "title": "TalkTraces: Real-Time Capture and Visualization of Verbal Content in Meetings", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Senthil Chandrasegaran", "Chris Bryan"], "summary": "Group Support Systems provide ways to review and edit shared content during meetings, but typically require participants to explicitly generate the content. Recent advances in speech-to-text conversion and language processing now make it possible to automatically record and review spoken information. We present the iterative design and evaluation of TalkTraces, a real-time visualization that helps teams identify themes in their discussions and obtain a sense of agenda items covered. We use topic modeling to identify themes within the discussions and word embeddings to compute Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300807 the discussion \u201crelatedness\u201d to items in the meeting agenda. We evaluate TalkTraces iteratively: we first conduct a comparative between-groups study between two teams using TalkTraces and two teams using traditional notes, over four sessions. We translate the findings into changes in the interface, further evaluated by one team over four sessions. Based on our findings, we discuss design implications for real-time displays of discussion content.", "keywords": ["based", "time", "speech", "information", "discussion", "processing", "display", "design", "provide", "help", "user", "meeting", "word", "participant", "use", "group", "talktraces", "identify", "team", "list", "relevance", "visualization", "note", "content", "awareness", "representation", "track", "smrs", "item", "data", "study", "topic", "system", "text", "transcript", "session", "paper", "interface", "modeling", "agenda", "iteration"], "document_vector": [-67.881187, 5.320312], "paragraphs": [{"paragraph_vector": [-179.459274, 41.040519], "paragraph_keywords": ["information", "systems", "meetings", "capture"]}, {"paragraph_vector": [177.311019, 39.853977], "paragraph_keywords": ["discussion", "talktraces", "agenda", "topics"]}, {"paragraph_vector": [179.988037, 39.957401], "paragraph_keywords": ["based", "topic", "meeting", "participants"]}, {"paragraph_vector": [-3.372556, 55.338603], "paragraph_keywords": ["smrs", "meeting", "provide", "processing"]}, {"paragraph_vector": [-179.958374, 40.469978], "paragraph_keywords": ["topics", "data", "based", "topic"]}, {"paragraph_vector": [178.59024, 39.401981], "paragraph_keywords": ["information", "group", "visualization", "meeting"]}, {"paragraph_vector": [179.310211, 40.929389], "paragraph_keywords": ["meeting", "group", "interface", "information"]}, {"paragraph_vector": [-179.57814, 39.268218], "paragraph_keywords": ["provide", "information", "topics", "user"]}, {"paragraph_vector": [-179.348648, 39.822299], "paragraph_keywords": ["topics", "topic", "time", "words"]}, {"paragraph_vector": [179.749938, 39.686035], "paragraph_keywords": ["agenda", "discussion", "word", "iteration"]}, {"paragraph_vector": [-179.36206, 40.716247], "paragraph_keywords": ["topic", "topics", "discussion", "cluster"]}, {"paragraph_vector": [-179.889083, 42.146244], "paragraph_keywords": ["agenda", "topic", "iteration", "item"]}, {"paragraph_vector": [-178.96492, 40.005962], "paragraph_keywords": ["topic", "word", "\u03bb", "discussion"]}, {"paragraph_vector": [179.025665, 43.073524], "paragraph_keywords": ["topic", "transcript", "speech", "text"]}, {"paragraph_vector": [179.111511, 40.89677], "paragraph_keywords": ["participants", "talktraces", "text", "teams"]}, {"paragraph_vector": [177.539154, 39.754844], "paragraph_keywords": ["team", "teams", "leader", "meeting"]}, {"paragraph_vector": [178.955337, 40.427822], "paragraph_keywords": ["participants", "meeting", "study", "agenda"]}, {"paragraph_vector": [178.167556, 42.004287], "paragraph_keywords": ["session", "participant", "discussion", "visualization"]}, {"paragraph_vector": [179.329116, 42.672225], "paragraph_keywords": ["visualization", "agenda", "distraction", "notes"]}, {"paragraph_vector": [179.904388, 40.782611], "paragraph_keywords": ["topic", "visualization", "iteration", "topics"]}, {"paragraph_vector": [178.928344, 40.443996], "paragraph_keywords": ["agenda", "items", "topic", "provide"]}, {"paragraph_vector": [178.408599, 39.52341], "paragraph_keywords": ["topic", "interpret", "meeting", "topics"]}, {"paragraph_vector": [177.954864, 40.326583], "paragraph_keywords": ["topic", "study", "participants", "agenda"]}, {"paragraph_vector": [178.104492, 40.463409], "paragraph_keywords": ["time", "discussion", "participants", "topic"]}], "content": {}, "doi": "10.1145/3290605.3300387"}, {"uri": "75", "title": "Underneath the Skin: An Analysis of YouTube Videos to Understand Insertable Device Interaction", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Aida Komkaite", "Mikael B. Skov"], "summary": "During the last decade, people have started to experiment with insertable technology like RFID or NFC chips and use them for e.g. identification. However, little is known about how people in fact interact with and adapt insertables. We conducted a video analysis of 122 YouTube videos to gain insight into the interaction with the insertables. Second, we implemented an online survey to complement our data from the video analysis. Our findings show that there are many opportunities for interaction with insertables both for task-oriented and creative purposes. However, there are also multiple challenges and obstacles as well as side effects and health concerns. Our findings conclude that the current infrastructure is not ready to support the use of insertables yet, and we discuss implications of this.", "keywords": ["mentioned", "talked", "information", "body", "analysis", "example", "having", "user", "interaction", "work", "video", "use", "patient", "people", "insertables", "health", "related", "respondent", "reader", "security", "magnet", "page", "finding", "chip", "survey", "hand", "device", "data", "technology", "study", "nfc", "purpose", "identification", "research", "focused", "order", "showed", "youtube", "paper", "privacy", "getting"], "document_vector": [71.893943, 9.58402], "paragraphs": [{"paragraph_vector": [-43.021316, -41.03656], "paragraph_keywords": ["devices", "copies", "implanted", "insertables"]}, {"paragraph_vector": [-44.688243, -40.86856], "paragraph_keywords": ["devices", "interaction", "body", "related"]}, {"paragraph_vector": [-42.522315, -40.273044], "paragraph_keywords": ["patients", "devices", "focused", "acceptance"]}, {"paragraph_vector": [-42.583641, -42.438152], "paragraph_keywords": ["microchips", "devices", "people", "body"]}, {"paragraph_vector": [-43.238403, -42.385131], "paragraph_keywords": ["data", "videos", "insertables", "youtube"]}, {"paragraph_vector": [-40.131576, -42.180339], "paragraph_keywords": ["videos", "video", "analysis", "results"]}, {"paragraph_vector": [-44.767608, -42.598751], "paragraph_keywords": ["users", "survey", "analysis", "videos"]}, {"paragraph_vector": [-45.877159, -39.82439], "paragraph_keywords": ["users", "survey", "insertables", "respondents"]}, {"paragraph_vector": [-45.240154, -44.088867], "paragraph_keywords": ["insertables", "access", "information", "identification"]}, {"paragraph_vector": [-46.017517, -40.545177], "paragraph_keywords": ["insertables", "car", "readers", "videos"]}, {"paragraph_vector": [-45.618694, -39.479221], "paragraph_keywords": ["magnet", "users", "insertables", "showed"]}, {"paragraph_vector": [-46.951492, -40.068656], "paragraph_keywords": ["reader", "magnet", "user", "read"]}, {"paragraph_vector": [-44.460025, -41.482891], "paragraph_keywords": ["insertables", "mri", "users", "paper"]}, {"paragraph_vector": [-44.891208, -40.03955], "paragraph_keywords": ["insertables", "user", "mentioned", "respondents"]}, {"paragraph_vector": [-44.951316, -40.93357], "paragraph_keywords": ["users", "sensations", "mentioned", "survey"]}, {"paragraph_vector": [-44.380668, -39.714118], "paragraph_keywords": ["users", "infection", "magnet", "cause"]}, {"paragraph_vector": [-45.427139, -39.324653], "paragraph_keywords": ["users", "issues", "respondents", "security"]}, {"paragraph_vector": [-44.349536, -43.263797], "paragraph_keywords": ["insertables", "devices", "security", "people"]}, {"paragraph_vector": [-43.276039, -41.254291], "paragraph_keywords": ["interaction", "insertables", "users", "need"]}, {"paragraph_vector": [-45.512664, -41.370189], "paragraph_keywords": ["insertables", "users", "devices", "user"]}, {"paragraph_vector": [-43.397083, -41.198326], "paragraph_keywords": ["technology", "insertables", "study", "need"]}, {"paragraph_vector": [-43.509933, -41.883384], "paragraph_keywords": ["insertables", "interaction", "study", "survey"]}], "content": {}, "doi": "10.1145/3290605.3300874"}, {"uri": "76", "title": "Designing Participatory Sensing with Remote Communities to Conserve Endangered Species", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Tshering Dema", "Margot Brereton"], "summary": "The increasing loss of species globally calls for effectivemonitoring tools and strategies to inform conservation action. The dominant approach to citizens engagement has been smart phone and platform-centric, tasking crowds to collect and analyze data. However, many critically endangered species inhabit remote areas, characterized by sparsely populated communities with poor internet connectivity. Approaches need to garner high engagement relative to population size, with data collection and knowledge synthesis suited to the local context. We conducted a field study in remote communities to understand how to enhance conservation of Bhutan\u2019s critically endangered White-bellied heron by exploring existing monitoring practices and trialing acoustic sensing technologies. We found that knowledge about the Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300894 species is partial, heterogeneous, situated within and across communities and rooted in cultural beliefs. Sensors, acoustic interfaces, and playful probes provided new ways for the community to \u2018see\u2019 and discuss their local environment fostering them to share and grow their knowledge together. We contribute a synthesis of key considerations for designing effective participatory sensing to conserve species in remote communities.", "keywords": ["explore", "based", "time", "population", "specie", "sensing", "design", "environment", "opportunity", "sensor", "sharing", "learn", "work", "engage", "apps", "participant", "use", "village", "people", "group", "interest", "team", "learning", "way", "participation", "conservation", "page", "field", "existing", "habitat", "call", "sound", "understand", "monitoring", "awareness", "found", "form", "stakeholder", "member", "endangered", "bird", "practice", "heron", "data", "device", "technology", "soundscape", "study", "approach", "pattern", "support", "nest", "research", "machine", "individual", "site", "paper", "interface", "knowledge", "context", "community"], "document_vector": [126.870819, 25.823717], "paragraphs": [{"paragraph_vector": [-87.481323, -35.269947], "paragraph_keywords": ["conservation", "species", "technology", "communities"]}, {"paragraph_vector": [-85.700447, -36.014842], "paragraph_keywords": ["knowledge", "communities", "species", "conservation"]}, {"paragraph_vector": [-88.449249, -35.361988], "paragraph_keywords": ["species", "conservation", "monitoring", "communities"]}, {"paragraph_vector": [-85.880561, -36.768421], "paragraph_keywords": ["apps", "conservation", "crowdsourcing", "data"]}, {"paragraph_vector": [-85.242637, -36.766098], "paragraph_keywords": ["data", "species", "technology", "air"]}, {"paragraph_vector": [-84.462501, -38.881507], "paragraph_keywords": ["design", "data", "practices", "devices"]}, {"paragraph_vector": [-87.407379, -37.075218], "paragraph_keywords": ["design", "conservation", "practices", "technology"]}, {"paragraph_vector": [-86.840187, -39.558193], "paragraph_keywords": ["probe", "bird", "community", "sound"]}, {"paragraph_vector": [-87.423194, -36.554668], "paragraph_keywords": ["community", "data", "understand", "soundscape"]}, {"paragraph_vector": [-85.89096, -34.554645], "paragraph_keywords": ["species", "nest", "communities", "support"]}, {"paragraph_vector": [-86.448684, -37.761947], "paragraph_keywords": ["species", "heron", "group", "work"]}, {"paragraph_vector": [-87.005378, -36.819637], "paragraph_keywords": ["data", "species", "community", "lsg"]}, {"paragraph_vector": [-86.633529, -37.079914], "paragraph_keywords": ["species", "monitoring", "conservation", "people"]}, {"paragraph_vector": [-86.038917, -37.198493], "paragraph_keywords": ["species", "practices", "area", "conservation"]}, {"paragraph_vector": [-86.736747, -37.4286], "paragraph_keywords": ["practices", "deployment", "capture", "site"]}, {"paragraph_vector": [-86.468452, -37.392154], "paragraph_keywords": ["species", "sensors", "ecologists", "knowledge"]}, {"paragraph_vector": [-87.705657, -35.104331], "paragraph_keywords": ["patterns", "soundscape", "knowledge", "data"]}, {"paragraph_vector": [-86.728958, -37.521873], "paragraph_keywords": ["knowledge", "species", "sensor", "confirms"]}, {"paragraph_vector": [-86.546264, -36.689495], "paragraph_keywords": ["nest", "bird", "calls", "site"]}, {"paragraph_vector": [-86.913566, -39.154903], "paragraph_keywords": ["species", "people", "r", "villager"]}, {"paragraph_vector": [-87.280906, -36.678844], "paragraph_keywords": ["participants", "conservation", "village", "species"]}, {"paragraph_vector": [-88.868019, -39.4267], "paragraph_keywords": ["bird", "village", "species", "time"]}, {"paragraph_vector": [-85.616943, -38.595367], "paragraph_keywords": ["species", "technology", "conservation", "birds"]}, {"paragraph_vector": [-85.25769, -36.192138], "paragraph_keywords": ["data", "knowledge", "people", "conservation"]}, {"paragraph_vector": [-89.142654, -37.014373], "paragraph_keywords": ["community", "communities", "awareness", "conservation"]}, {"paragraph_vector": [-83.666236, -39.872478], "paragraph_keywords": ["data", "probes", "design", "participation"]}, {"paragraph_vector": [-86.287651, -37.025756], "paragraph_keywords": ["data", "conservation", "people", "engage"]}, {"paragraph_vector": [-86.533073, -36.30709], "paragraph_keywords": ["species", "data", "conservation", "approaches"]}, {"paragraph_vector": [-85.730072, -36.25912], "paragraph_keywords": ["conservation", "species", "design", "community"]}, {"paragraph_vector": [-86.324661, -36.499427], "paragraph_keywords": ["conservation", "communities", "design", "opportunities"]}], "content": {}, "doi": "10.1145/3290605.3300782"}, {"uri": "77", "title": "Hands Holding Clues for Object Recognition in Teachable Machines", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Kyungjun Lee", "Hernisa Kacorri"], "summary": "Camera manipulation confounds the use of object recognition applications by blind people. This is exacerbated when photos from this population are also used to train models, as with teachable machines, where out-of-frame or partially included objects against cluttered backgrounds degrade performance. Leveraging prior evidence on the ability of blind people to coordinate hand movements using proprioception, we propose a deep learning system that jointly models hand segmentation and object localization for object classifcation. We investigate the utility of hands as a natural interface for including and indicating the object of interest in the camera frame. We confrm the potential of this approach by analyzing existing datasets from people with visual impairments for object recognition. With a new publicly available egocentric dataset and an extensive error analysis, we provide insights into this approach in the context of teachable recognizers.", "keywords": ["trained", "vision", "object", "frame", "training", "analysis", "provide", "co", "example", "camera", "model", "user", "datasets", "taken", "included", "work", "use", "people", "localization", "interest", "learning", "world", "given", "dataset", "b", "segmentation", "vizwiz", "fig", "recognition", "hand", "data", "approach", "testing", "image", "background", "photo", "context"], "document_vector": [-72.269355, -63.688919], "paragraphs": [{"paragraph_vector": [-68.932258, -19.277153], "paragraph_keywords": ["recognition", "help", "copies", "computing"]}, {"paragraph_vector": [-67.087966, -18.17019], "paragraph_keywords": ["object", "camera", "hand", "proprioception"]}, {"paragraph_vector": [-70.19017, -20.696434], "paragraph_keywords": ["object", "hand", "recognition", "analysis"]}, {"paragraph_vector": [-68.690673, -22.764001], "paragraph_keywords": ["vision", "prediction", "object", "input"]}, {"paragraph_vector": [-69.080894, -21.678882], "paragraph_keywords": ["users", "object", "photos", "taken"]}, {"paragraph_vector": [-68.349983, -24.182504], "paragraph_keywords": ["camera", "users", "frame", "object"]}, {"paragraph_vector": [-68.930793, -22.596635], "paragraph_keywords": ["hand", "object", "network", "model"]}, {"paragraph_vector": [-68.653297, -21.455364], "paragraph_keywords": ["object", "model", "models", "hand"]}, {"paragraph_vector": [-67.394058, -20.194721], "paragraph_keywords": ["images", "objects", "object", "people"]}, {"paragraph_vector": [-67.695762, -21.110986], "paragraph_keywords": ["object", "dataset", "hand", "images"]}, {"paragraph_vector": [-70.584625, -18.071918], "paragraph_keywords": ["object", "objects", "data", "dataset"]}, {"paragraph_vector": [-70.036933, -24.698238], "paragraph_keywords": ["object", "hand", "images", "total"]}, {"paragraph_vector": [-71.429145, -21.881841], "paragraph_keywords": ["images", "data", "object", "model"]}, {"paragraph_vector": [-69.603317, -20.559406], "paragraph_keywords": ["object", "images", "hand", "vizwiz"]}, {"paragraph_vector": [-67.676467, -17.905241], "paragraph_keywords": ["images", "object", "ho", "b"]}, {"paragraph_vector": [-69.70565, -22.437021], "paragraph_keywords": ["co", "sample", "approach", "models"]}, {"paragraph_vector": [-70.004394, -21.458076], "paragraph_keywords": ["images", "object", "model", "objects"]}, {"paragraph_vector": [-68.763587, -21.253852], "paragraph_keywords": ["images", "b", "object", "model"]}, {"paragraph_vector": [-68.681289, -20.478981], "paragraph_keywords": ["object", "people", "hand", "impairments"]}, {"paragraph_vector": [-68.783363, -23.493787], "paragraph_keywords": ["hand", "data", "object", "datasets"]}, {"paragraph_vector": [-68.932121, -21.341478], "paragraph_keywords": ["object", "analysis", "datasets", "hand"]}, {"paragraph_vector": [74.040115, 32.408462], "paragraph_keywords": ["hong", "yang", "reviewers", "june"]}], "content": {}, "doi": "10.1145/3290605.3300270"}, {"uri": "78", "title": "How to Work in the Car of the Future?", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Kathrin Pollmann", "Oliver Stefani", "Amelie Bengsch", "Matthias Peissner", "Mathias Vukeli\u0107"], "summary": "Autonomous driving provides new opportunities for the use of time during a car ride. One such important scenario is working. We conducted a neuroergonomical study to compare three configurations of a car interior (based on lighting, visual stimulation, sound) regarding their potential to support productive work. We assessed participants\u2018 concentration, performance and workload with subjective, behavioral and EEG measures while they carried out two different concentration tasks during simulated autonomous driving. Our results show that a configuration with a large-area, bright light with high blue components, and reduced visual and auditory stimuli promote performance, quality, efficiency, increased concentration and lower cognitive workload. Increased visual and auditory stimulation paired with linear, darker light with very few blue components resulted in lower performance, reduced subjective concentration, and higher cognitive workload, but did not differ from a normal car configuration. Our multi-method approach thus reveals possible car interior configurations for an ideal workspace.", "keywords": ["based", "time", "condition", "act", "set", "performance", "self", "design", "investigate", "analysis", "environment", "power", "eeg", "performed", "activity", "concentration", "work", "result", "participant", "workload", "vct", "people", "effect", "screen", "working", "state", "experience", "band", "passenger", "light", "configuration", "task", "car", "shown", "data", "item", "brain", "study", "approach", "cc", "support", "research", "rts", "driving", "index", "lighting", "level", "figure"], "document_vector": [-115.583557, -41.502815], "paragraphs": [{"paragraph_vector": [6.438426, 2.777492], "paragraph_keywords": ["car", "time", "driving", "cars"]}, {"paragraph_vector": [3.629458, 2.769036], "paragraph_keywords": ["car", "driving", "activities", "concentration"]}, {"paragraph_vector": [4.247803, 1.889389], "paragraph_keywords": ["participants", "performance", "working", "approach"]}, {"paragraph_vector": [4.990385, 2.979597], "paragraph_keywords": ["driving", "car", "work", "workload"]}, {"paragraph_vector": [5.081187, 1.925513], "paragraph_keywords": ["workload", "driving", "car", "screens"]}, {"paragraph_vector": [5.872832, 2.060027], "paragraph_keywords": ["car", "passenger", "cars", "seat"]}, {"paragraph_vector": [5.909772, 1.778965], "paragraph_keywords": ["car", "set", "lighting", "alertness"]}, {"paragraph_vector": [4.527564, 3.813933], "paragraph_keywords": ["light", "cells", "ganglion", "retina"]}, {"paragraph_vector": [4.911363, 1.545304], "paragraph_keywords": ["participants", "concentration", "configurations", "light"]}, {"paragraph_vector": [-6.694894, 11.86788], "paragraph_keywords": ["participants", "concentration", "task", "phase"]}, {"paragraph_vector": [-3.601561, 8.353253], "paragraph_keywords": ["items", "load", "concentration", "tlx"]}, {"paragraph_vector": [-4.671456, 6.113291], "paragraph_keywords": ["eeg", "brain", "band", "participants"]}, {"paragraph_vector": [-5.096712, 9.243453], "paragraph_keywords": ["participants", "concentration", "data", "rts"]}, {"paragraph_vector": [-4.119582, 5.235788], "paragraph_keywords": ["eeg", "data", "performed", "block"]}, {"paragraph_vector": [-5.402085, 5.759193], "paragraph_keywords": ["power", "eeg", "concentration", "band"]}, {"paragraph_vector": [-9.233252, 21.073863], "paragraph_keywords": ["effort", "vct", "distraction", "found"]}, {"paragraph_vector": [-8.173335, 11.174158], "paragraph_keywords": ["concentration", "cc", "p", "act"]}, {"paragraph_vector": [-4.776142, 8.532614], "paragraph_keywords": ["performance", "based", "tasks", "concentration"]}, {"paragraph_vector": [6.285195, 3.525425], "paragraph_keywords": ["light", "car", "studies", "workload"]}, {"paragraph_vector": [6.700408, 2.813862], "paragraph_keywords": ["lighting", "driving", "population", "tasks"]}, {"paragraph_vector": [6.092365, 7.11873], "paragraph_keywords": ["design", "driving", "car", "concentration"]}, {"paragraph_vector": [5.149314, 3.290856], "paragraph_keywords": ["design", "car", "workload", "configuration"]}, {"paragraph_vector": [5.118139, 3.147975], "paragraph_keywords": ["based", "workload", "research", "eeg"]}], "content": {}, "doi": "10.1145/3290605.3300425"}, {"uri": "79", "title": "A Translational Science Model for HCI", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Lucas Colusso"], "summary": "Using scientific discoveries to inform design practice is an important, but difficult, objective in HCI. In this paper, we provide an overview of Translational Science in HCI by triangulating literature related to the research-practice gap with interview data from many parties engaged (or not) in translating HCI knowledge. We propose a model for Translational Science in HCI based on the concept of a continuum to describe how knowledge progresses (or stalls) through multiple steps and translations until it can influence design practice. The model offers a conceptual framework that can be used by researchers and practitioners to visualize and describe the progression of HCI knowledge through a sequence of translations. Additionally, the model may facilitate a precise identification of translational barriers, which allows devising more effective strategies to increase the use of scientific findings in design practice.", "keywords": ["process", "gap", "translation", "mentioned", "time", "need", "progression", "resource", "academia", "design", "method", "psychology", "industry", "example", "help", "describe", "model", "facilitate", "communication", "theory", "work", "participant", "use", "people", "applied", "health", "metaphor", "tad", "finding", "step", "page", "field", "barrier", "practitioner", "understanding", "science", "described", "practice", "t", "study", "researcher", "designer", "said", "scholar", "adoption", "research", "translating", "hci", "continuum", "paper", "knowledge", "community"], "document_vector": [57.276992, 49.248744], "paragraphs": [{"paragraph_vector": [109.779022, -30.275318], "paragraph_keywords": ["work", "practice", "copies", "knowledge"]}, {"paragraph_vector": [96.022758, -18.622329], "paragraph_keywords": ["hci", "science", "research", "design"]}, {"paragraph_vector": [98.148811, -12.99368], "paragraph_keywords": ["design", "hci", "research", "participants"]}, {"paragraph_vector": [103.710815, -9.595501], "paragraph_keywords": ["design", "knowledge", "hci", "research"]}, {"paragraph_vector": [95.721466, -14.230021], "paragraph_keywords": ["research", "gap", "hci", "practice"]}, {"paragraph_vector": [94.511688, -17.227609], "paragraph_keywords": ["research", "work", "practitioners", "hci"]}, {"paragraph_vector": [94.259284, -22.836278], "paragraph_keywords": ["research", "interventions", "knowledge", "settings"]}, {"paragraph_vector": [93.414787, -15.779369], "paragraph_keywords": ["hci", "knowledge", "model", "science"]}, {"paragraph_vector": [93.916709, -16.264587], "paragraph_keywords": ["research", "gaps", "hci", "gap"]}, {"paragraph_vector": [95.25991, -9.6681], "paragraph_keywords": ["research", "industry", "design", "designers"]}, {"paragraph_vector": [94.350524, -12.544308], "paragraph_keywords": ["research", "design", "practitioners", "hci"]}, {"paragraph_vector": [94.974655, -6.35885], "paragraph_keywords": ["method", "assets", "need", "research"]}, {"paragraph_vector": [45.551788, 53.427909], "paragraph_keywords": ["applied", "life", "collaborations", "code"]}, {"paragraph_vector": [94.391883, -11.192073], "paragraph_keywords": ["hci", "research", "work", "participants"]}, {"paragraph_vector": [87.002967, -6.842448], "paragraph_keywords": ["participants", "hci", "research", "researchers"]}, {"paragraph_vector": [90.571884, -9.198831], "paragraph_keywords": ["practitioners", "knowledge", "practice", "research"]}, {"paragraph_vector": [98.253997, -13.269784], "paragraph_keywords": ["design", "research", "applied", "industry"]}, {"paragraph_vector": [96.981636, -12.09271], "paragraph_keywords": ["knowledge", "researchers", "research", "hci"]}, {"paragraph_vector": [98.551666, -9.940536], "paragraph_keywords": ["scholars", "research", "researchers", "practitioners"]}, {"paragraph_vector": [93.731925, -20.010702], "paragraph_keywords": ["hci", "model", "ts", "research"]}, {"paragraph_vector": [92.635848, -14.424935], "paragraph_keywords": ["research", "hci", "model", "stalled"]}, {"paragraph_vector": [93.92321, -16.86317], "paragraph_keywords": ["hci", "research", "knowledge", "parties"]}, {"paragraph_vector": [91.277122, -8.703041], "paragraph_keywords": ["research", "hci", "community", "training"]}, {"paragraph_vector": [95.212799, -13.910163], "paragraph_keywords": ["hci", "design", "adoption", "knowledge"]}, {"paragraph_vector": [97.694595, -15.272876], "paragraph_keywords": ["hci", "design", "research", "knowledge"]}, {"paragraph_vector": [71.01902, 30.468633], "paragraph_keywords": ["feedback", "support"]}], "content": {}, "doi": "10.1145/3290605.3300271"}, {"uri": "80", "title": "Cognitive Aids in Acute Care: Investigating How Cognitive Aids Affect and Support In-hospital Emergency Teams", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Tobias Grundgeiger"], "summary": "Cognitive aids \u2013 artefacts that support a user in the completion of a task at the time \u2013 have raised great interest to support healthcare staff during medical emergencies. However, the mechanisms of how cognitive aids support or affect staff remain understudied. We describe the iterative development of a tablet-based cognitive aid application to support in-hospital resuscitation team leaders. We report a summative evaluation of two different versions of the application. Finally, we outline the limitations of current explanations of how cognitive aids work and suggest an approach based on embodied cognition. We discuss how cognitive aids alter the task of the team leader (distributed cognition), the importance of the present team situation (socially situated), and the result of the interaction between mind and environment (sensorimotor coupling). Understanding and considering the implications of introducing cognitive aids may help to increase acceptance and effectiveness of cognitive aids and eventually improve patient safety. CCS CONCEPTS \u2022 Applied computing > Life and medical sciences > Health care information systems; Human-centered computing > Collaborative and social computing > Empirical studies in collaborative and social computing", "keywords": ["based", "tablet", "time", "emergency", "information", "performance", "memory", "design", "reported", "analysis", "leader", "care", "resuscitation", "simulation", "caapp", "user", "rhythm", "work", "result", "use", "effect", "team", "checklist", "page", "application", "artefact", "provided", "documentation", "docuapp", "task", "data", "study", "aid", "support", "system", "research", "perspective", "paper", "staff", "cpr", "hospital", "action", "context"], "document_vector": [28.204269, 18.972076], "paragraphs": [{"paragraph_vector": [166.053848, 30.468933], "paragraph_keywords": ["aids", "work", "crises", "copies"]}, {"paragraph_vector": [167.296752, 24.84073], "paragraph_keywords": ["checklist", "aid", "based", "team"]}, {"paragraph_vector": [168.110046, 27.296567], "paragraph_keywords": ["team", "application", "resuscitation", "caapp"]}, {"paragraph_vector": [168.049636, 22.115215], "paragraph_keywords": ["time", "team", "leader", "documentation"]}, {"paragraph_vector": [170.967132, 25.778993], "paragraph_keywords": ["docuapp", "resuscitation", "time", "leader"]}, {"paragraph_vector": [171.024551, 24.263441], "paragraph_keywords": ["cpr", "users", "life", "support"]}, {"paragraph_vector": [167.072509, 27.565198], "paragraph_keywords": ["emergency", "performance", "figure", "team"]}, {"paragraph_vector": [168.543395, 26.563905], "paragraph_keywords": ["caapp", "team", "performance", "application"]}, {"paragraph_vector": [169.066894, 27.662338], "paragraph_keywords": ["team", "training", "participants", "scenario"]}, {"paragraph_vector": [167.812286, 25.180667], "paragraph_keywords": ["analysis", "time", "chest", "rhythm"]}, {"paragraph_vector": [160.59909, 38.582958], "paragraph_keywords": ["team", "caapp", "application", "data"]}, {"paragraph_vector": [166.079727, 26.280658], "paragraph_keywords": ["docuapp", "caapp", "time", "association"]}, {"paragraph_vector": [170.760726, 24.86264], "paragraph_keywords": ["performance", "study", "docuapp", "aid"]}, {"paragraph_vector": [165.667922, 28.09025], "paragraph_keywords": ["aids", "performance", "application", "team"]}, {"paragraph_vector": [166.790557, 25.570646], "paragraph_keywords": ["aids", "memory", "workload", "cognition"]}, {"paragraph_vector": [166.662246, 28.359291], "paragraph_keywords": ["use", "checklist", "aids", "checklists"]}, {"paragraph_vector": [167.39067, 25.34089], "paragraph_keywords": ["system", "task", "agents", "team"]}, {"paragraph_vector": [167.996322, 26.222955], "paragraph_keywords": ["team", "aid", "perspective", "leader"]}, {"paragraph_vector": [165.949691, 28.573541], "paragraph_keywords": ["use", "plan", "actions", "result"]}, {"paragraph_vector": [167.839401, 28.007003], "paragraph_keywords": ["team", "situation", "actions", "trace"]}, {"paragraph_vector": [168.265945, 26.873641], "paragraph_keywords": ["values", "design", "concepts", "team"]}, {"paragraph_vector": [169.220169, 28.149673], "paragraph_keywords": ["aids", "provide", "support", "artefacts"]}], "content": {}, "doi": "10.1145/3290605.3300792"}, {"uri": "81", "title": "How Do Distance Learners Connect? ", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Na Sun", "Xiying Wang", "Mary Beth Rosson"], "summary": "Distance learners often experience social isolation and impoverished social interaction with their remote peers. To better understand the connections that distance learners are able to build with peers, we interviewed them about whether and how they perceive or cultivate connections with one another. Our analysis reveals how connections in an online learning environment are formed and experienced across different social contexts and technology affordances, and what strategies and practices enable and inhibit these connections. We discuss the implications of our findings for concepts of shared identity and evolving peer relationships among online learners and for design directions that might address their social needs.", "keywords": ["feeling", "identity", "based", "connection", "time", "peer", "degree", "information", "discussion", "education", "class", "interview", "example", "activity", "interaction", "learner", "communication", "shared", "sample", "work", "video", "tool", "participant", "psu", "use", "people", "group", "team", "learning", "enhance", "page", "felt", "college", "content", "found", "tie", "university", "life", "member", "distance", "feel", "study", "researcher", "teammate", "student", "said", "support", "course", "session", "program", "question", "share", "project", "community"], "document_vector": [-164.819473, 40.541366], "paragraphs": [{"paragraph_vector": [138.386856, 4.880461], "paragraph_keywords": ["learning", "distance", "education", "copies"]}, {"paragraph_vector": [139.135406, 4.82849], "paragraph_keywords": ["learning", "distance", "community", "students"]}, {"paragraph_vector": [138.709747, 5.633367], "paragraph_keywords": ["distance", "connections", "learning", "students"]}, {"paragraph_vector": [139.600387, 3.495721], "paragraph_keywords": ["learning", "class", "alumni", "classes"]}, {"paragraph_vector": [132.540115, 10.584418], "paragraph_keywords": ["learning", "learners", "technologies", "distance"]}, {"paragraph_vector": [121.08937, 13.182024], "paragraph_keywords": ["students", "classes", "time", "class"]}, {"paragraph_vector": [124.170692, 20.019882], "paragraph_keywords": ["courses", "time", "education", "institutions"]}, {"paragraph_vector": [121.727439, 5.868817], "paragraph_keywords": ["interview", "codes", "sample", "themes"]}, {"paragraph_vector": [122.138862, -14.70543], "paragraph_keywords": ["group", "class", "students", "groups"]}, {"paragraph_vector": [139.779785, 2.179207], "paragraph_keywords": ["class", "names", "students", "discussion"]}, {"paragraph_vector": [139.0867, 3.954539], "paragraph_keywords": ["students", "connections", "feelings", "psu"]}, {"paragraph_vector": [139.934036, 4.853987], "paragraph_keywords": ["feel", "said", "sessions", "learners"]}, {"paragraph_vector": [137.770172, 3.857202], "paragraph_keywords": ["class", "felt", "challenges", "challenge"]}, {"paragraph_vector": [140.332473, 2.343569], "paragraph_keywords": ["group", "team", "connect", "posts"]}, {"paragraph_vector": [140.971618, 2.87002], "paragraph_keywords": ["time", "shared", "group", "team"]}, {"paragraph_vector": [139.247787, 3.251336], "paragraph_keywords": ["meeting", "group", "meetings", "video"]}, {"paragraph_vector": [137.642852, 2.093236], "paragraph_keywords": ["feelings", "connections", "group", "google"]}, {"paragraph_vector": [138.585617, 3.157674], "paragraph_keywords": ["project", "ties", "contact", "teammates"]}, {"paragraph_vector": [138.299957, 4.879225], "paragraph_keywords": ["psu", "connections", "education", "members"]}, {"paragraph_vector": [138.121871, 2.516667], "paragraph_keywords": ["shared", "connection", "learning", "characteristics"]}, {"paragraph_vector": [138.001312, 4.071424], "paragraph_keywords": ["distance", "identity", "shared", "learners"]}, {"paragraph_vector": [141.979721, 2.295047], "paragraph_keywords": ["shared", "identity", "context", "efforts"]}, {"paragraph_vector": [138.282821, 4.365956], "paragraph_keywords": ["time", "learners", "interaction", "times"]}, {"paragraph_vector": [139.083679, 4.20197], "paragraph_keywords": ["members", "connections", "team", "based"]}, {"paragraph_vector": [138.347106, 4.926817], "paragraph_keywords": ["learning", "learners", "group", "connections"]}], "content": {}, "doi": "10.1145/3290605.3300895"}, {"uri": "82", "title": "Steering Performance with Error-accepting Delays", "timestamp": "2018", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Shota Yamanaka"], "summary": "In steering law tasks, deviating from the path is immediately considered an error operation. However, in navigating a hierarchical menu item, which is a representative application of the law, a deviation within a short duration is sometimes permitted. We tested the validity of the steering law model with various durations of such error-accepting delays and found that it showed high fits for each delay condition (R2 > 0.96) but poor fits if the delay values were not separated (R2 = 0.58). Because the average movement speed linearly increased as the delay increased, we refined the model by taking the delay into account, and the fitness was significantly improved (R2 = 0.97). Our model will help GUI designers estimate the average operational time on the basis of the menu item length, width, and error-accepting delay.", "keywords": ["steering", "msec", "time", "cursor", "error", "path", "model", "user", "tdelay", "result", "law", "work", "participant", "effect", "v", "equation", "given", "menu", "page", "ersteer", "proposed", "accepting", "task", "item", "data", "study", "mt", "system", "delay", "w", "paper", "mouse", "area", "value", "figure"], "document_vector": [-103.909156, -52.63964], "paragraphs": [{"paragraph_vector": [-19.948762, 17.555889], "paragraph_keywords": ["steering", "law", "model", "copies"]}, {"paragraph_vector": [-18.189014, 15.173305], "paragraph_keywords": ["cursor", "delay", "users", "path"]}, {"paragraph_vector": [-20.291177, 15.215537], "paragraph_keywords": ["path", "model", "delay", "steering"]}, {"paragraph_vector": [-24.812423, 23.91879], "paragraph_keywords": ["path", "v", "mt", "speed"]}, {"paragraph_vector": [-22.468725, 19.448413], "paragraph_keywords": ["path", "item", "cursor", "menu"]}, {"paragraph_vector": [-17.520925, 17.59118], "paragraph_keywords": ["mouse", "delay", "model", "lag"]}, {"paragraph_vector": [-23.299043, 13.053691], "paragraph_keywords": ["mouse", "cursor", "system", "path"]}, {"paragraph_vector": [-22.234088, 21.329189], "paragraph_keywords": ["path", "participants", "time", "end"]}, {"paragraph_vector": [-22.214593, 22.24197], "paragraph_keywords": ["participants", "tdelay", "time", "cursor"]}, {"paragraph_vector": [-15.870212, 19.563932], "paragraph_keywords": ["study", "path", "areas", "found"]}, {"paragraph_vector": [-19.734823, 22.468002], "paragraph_keywords": ["path", "tdelay", "ratioout", "error"]}, {"paragraph_vector": [-22.375616, 21.194484], "paragraph_keywords": ["tdelay", "p", "interaction", "effects"]}, {"paragraph_vector": [-20.940668, 25.192129], "paragraph_keywords": ["model", "path", "v", "equation"]}, {"paragraph_vector": [-17.302843, 15.489783], "paragraph_keywords": ["model", "tdelay", "values", "path"]}, {"paragraph_vector": [-21.295621, 14.432776], "paragraph_keywords": ["model", "tdelay", "task", "study"]}, {"paragraph_vector": [-18.15974, 14.057012], "paragraph_keywords": ["tdelay", "steering", "estimate", "law"]}], "content": {}, "doi": "10.1145/3290605.3300234"}, {"uri": "83", "title": "Comparing Apples and Oranges: Taxonomy and Design of Pairwise Comparisons within Tabular Data", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Po-Ming Law", "Subhajit Das", "Rahul C. Basole"], "summary": "Asking pairwise comparison questions is common. Yet, we often fnd ourselves comparing apples and oranges \u2014 the two entities of interest are not readily comparable. To understand how technologies can extend our capabilities to conduct pairwise comparisons during data analysis, we analyzed pairwise comparison questions collected from crowd workers and propose a taxonomy of pairwise comparisons. We demonstrate how the taxonomy can be adopted by incorporating pairwise comparison capabilities into Duo, a spreadsheet application that supports comparing two groups of records in a data table. Duo decomposes a pairwise comparison question into rules and showcases sloppy rules, a query technique for specifying pairwise comparisons. We conducted a user study comparing sloppy rules and natural language. The fndings suggest that for easier pairwise comparison tasks, the two techniques are comparable in effciency and preference and that for more difcult pairwise comparison tasks, sloppy rules allow faster specifcation and are more preferable.", "keywords": ["difculty", "comparing", "diferent", "analysis", "rate", "provide", "technique", "example", "user", "model", "command", "comparison", "region", "pairwise", "language", "runner", "participant", "use", "people", "group", "learning", "base", "attribute", "page", "college", "duo", "perform", "fig", "new", "task", "query", "data", "study", "compare", "research", "completion", "rule", "taxonomy", "question", "interface", "paper", "enter", "level"], "document_vector": [-77.721397, 19.801261], "paragraphs": [{"paragraph_vector": [-131.870559, 66.334564], "paragraph_keywords": ["copies", "comparisons", "pairwise", "computing"]}, {"paragraph_vector": [-131.792205, 66.90406], "paragraph_keywords": ["pairwise", "rules", "comparisons", "comparison"]}, {"paragraph_vector": [-132.504013, 68.36734], "paragraph_keywords": ["pairwise", "comparison", "comparisons", "process"]}, {"paragraph_vector": [-128.712081, 70.712692], "paragraph_keywords": ["pairwise", "comparisons", "comparison", "data"]}, {"paragraph_vector": [-132.56047, 69.358245], "paragraph_keywords": ["pairwise", "comparison", "questions", "commands"]}, {"paragraph_vector": [-115.270935, -6.818501], "paragraph_keywords": ["questions", "marathon", "workers", "runners"]}, {"paragraph_vector": [-136.10379, 71.725814], "paragraph_keywords": ["pairwise", "comparison", "questions", "taxonomy"]}, {"paragraph_vector": [-133.608825, 71.657493], "paragraph_keywords": ["pairwise", "b", "comparisons", "questions"]}, {"paragraph_vector": [-133.143341, 71.516876], "paragraph_keywords": ["comparison", "pairwise", "group", "diferences"]}, {"paragraph_vector": [-142.141113, 69.763305], "paragraph_keywords": ["pairwise", "cities", "groups", "dataset"]}, {"paragraph_vector": [-134.391174, 73.528617], "paragraph_keywords": ["rules", "group", "base", "colleges"]}, {"paragraph_vector": [-135.706054, 69.552482], "paragraph_keywords": ["rules", "users", "interface", "comparison"]}, {"paragraph_vector": [-24.398899, 83.99163], "paragraph_keywords": ["rule", "attribute", "duo", "users"]}, {"paragraph_vector": [-136.707092, 75.360115], "paragraph_keywords": ["group", "users", "shelf", "comparisons"]}, {"paragraph_vector": [-134.85144, 75.156044], "paragraph_keywords": ["attributes", "groups", "diferent", "users"]}, {"paragraph_vector": [-139.476852, 74.596191], "paragraph_keywords": ["users", "language", "compare", "density"]}, {"paragraph_vector": [-131.11238, 69.800765], "paragraph_keywords": ["participants", "interface", "tasks", "interfaces"]}, {"paragraph_vector": [-134.508163, 71.162101], "paragraph_keywords": ["tasks", "comparison", "pairwise", "interface"]}, {"paragraph_vector": [-135.353652, 69.489059], "paragraph_keywords": ["interface", "study", "pairwise", "questions"]}, {"paragraph_vector": [14.347229, 48.048122], "paragraph_keywords": ["interface", "tasks", "participants", "completion"]}, {"paragraph_vector": [-129.809768, 72.066833], "paragraph_keywords": ["participants", "difcult", "language", "p"]}, {"paragraph_vector": [-133.682266, 69.569808], "paragraph_keywords": ["interface", "rules", "pairwise", "query"]}, {"paragraph_vector": [-132.919525, 69.516571], "paragraph_keywords": ["language", "users", "pairwise", "rule"]}, {"paragraph_vector": [-130.067245, 71.130905], "paragraph_keywords": ["language", "interface", "commands", "interfaces"]}, {"paragraph_vector": [-132.814025, 69.262886], "paragraph_keywords": ["design", "pairwise", "study", "interface"]}], "content": {}, "doi": "10.1145/3290605.3300865"}, {"uri": "84", "title": "Recipes for Programmable Money", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Chris Elsden", "Tom Feltwell"], "summary": "This paper presents a qualitative study of the recent integration of a UK-based, digital-first mobile banking app \u2014 Monzo \u2014 with the web automation service IFTTT (If This Then That). Through analysis of 113 unique IFTTT \u2018recipes\u2019 shared by Monzo users on public community forums, we illustrate the potentially diverse functions of these recipes, and how they are achieved through different kinds of automation. Beyond achieving more convenient and efficient financial management, we note many playful and expressive applications of conditionality and automation that far extend traditional functions of banking applications and infrastructure. We use these findings to map opportunities, challenges and areas of future research in the development of \u2018programmable money\u2019 and related financial technologies. Specifically, we present design implications for the extension of native digital banking applications; novel uses of banking data; the applicability of blockchains and smart contracts; and future forms of financial autonomy.", "keywords": ["banking", "based", "consider", "balance", "time", "change", "set", "us", "purchase", "opportunity", "example", "spending", "user", "saving", "work", "apps", "use", "bank", "create", "recipe", "integration", "service", "way", "range", "mean", "automation", "control", "automated", "page", "application", "trigger", "form", "monzo", "pot", "money", "supported", "data", "technology", "infrastructure", "ifttt", "support", "system", "event", "research", "machine", "rule", "account", "transaction", "spend", "paper", "hci", "corpus", "value", "action", "code"], "document_vector": [44.948467, 51.912372], "paragraphs": [{"paragraph_vector": [25.912084, -39.295265], "paragraph_keywords": ["money", "copies", "services", "work"]}, {"paragraph_vector": [27.252107, -42.468841], "paragraph_keywords": ["services", "monzo", "data", "recipes"]}, {"paragraph_vector": [25.248306, -38.921882], "paragraph_keywords": ["money", "research", "hci", "ways"]}, {"paragraph_vector": [19.650667, -35.338077], "paragraph_keywords": ["money", "value", "support", "data"]}, {"paragraph_vector": [32.878704, -48.130226], "paragraph_keywords": ["machine", "users", "coffee", "way"]}, {"paragraph_vector": [28.3059, -37.524013], "paragraph_keywords": ["recipes", "ifttt", "users", "automation"]}, {"paragraph_vector": [23.918401, -38.13515], "paragraph_keywords": ["monzo", "account", "spending", "pots"]}, {"paragraph_vector": [27.471632, -38.616306], "paragraph_keywords": ["monzo", "ifttt", "account", "trigger"]}, {"paragraph_vector": [26.52873, -38.319725], "paragraph_keywords": ["monzo", "user", "forums", "ifttt"]}, {"paragraph_vector": [36.923004, -30.429727], "paragraph_keywords": ["codes", "recipe", "recipes", "coded"]}, {"paragraph_vector": [29.816656, -33.745677], "paragraph_keywords": ["recipes", "use", "actions", "themes"]}, {"paragraph_vector": [28.768125, -36.343967], "paragraph_keywords": ["money", "monzo", "functions", "recipes"]}, {"paragraph_vector": [29.588914, -35.744575], "paragraph_keywords": ["recipes", "money", "example", "lunch"]}, {"paragraph_vector": [32.028884, -32.094303], "paragraph_keywords": ["money", "example", "data", "recipes"]}, {"paragraph_vector": [28.735458, -38.920055], "paragraph_keywords": ["monzo", "actions", "money", "triggers"]}, {"paragraph_vector": [24.847393, -36.493301], "paragraph_keywords": ["recipes", "saving", "savings", "money"]}, {"paragraph_vector": [27.231494, -39.743457], "paragraph_keywords": ["money", "saving", "pot", "spending"]}, {"paragraph_vector": [23.761789, -36.576496], "paragraph_keywords": ["account", "pot", "example", "monzo"]}, {"paragraph_vector": [27.502191, -38.586826], "paragraph_keywords": ["recipes", "monzo", "spend", "opportunity"]}, {"paragraph_vector": [27.114133, -34.097404], "paragraph_keywords": ["behavior", "example", "recipes", "trigger"]}, {"paragraph_vector": [28.494062, -36.342105], "paragraph_keywords": ["automation", "data", "monzo", "experience"]}, {"paragraph_vector": [28.096651, -37.493328], "paragraph_keywords": ["money", "services", "data", "transactions"]}, {"paragraph_vector": [26.696432, -35.322231], "paragraph_keywords": ["money", "data", "interactions", "work"]}, {"paragraph_vector": [25.808185, -38.89841], "paragraph_keywords": ["money", "users", "recipes", "programmability"]}, {"paragraph_vector": [28.156747, -44.100296], "paragraph_keywords": ["money", "rules", "set", "use"]}, {"paragraph_vector": [28.689558, -39.32204], "paragraph_keywords": ["money", "users", "ifttt", "need"]}, {"paragraph_vector": [40.385765, -29.896726], "paragraph_keywords": ["publication", "corpus", "recipes", "acm"]}], "content": {}, "doi": "10.1145/3290605.3300320"}, {"uri": "85", "title": "Predicting Cognitive Load in Future Code Puzzles", "timestamp": "2018", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Caitlin Kelleher"], "summary": "Code puzzles are an increasingly popular way to introduce youth to programming. Yet our knowledge about how to maximize learning from puzzles is incomplete. We conducted a data collection study and trained a model that predicts cognitive load, the mental efort necessary to complete a task, on a future puzzle. Controlling cognitive load can lead to more efective learning. Our model suggests that it is possible to predict Cognitive Load on future problems; the model could correctly distinguish the more difcult puzzle within a pair 71%-79% of the time. Further, studying the model itself provides new insights into the sources of puzzle difculty, the factors that contribute to Cognitive Load, and their interrelationships. Finally, the ability to predict Cognitive Load on a future puzzle is an important step towards the creation of adaptive code puzzle systems.", "keywords": ["capture", "nested", "based", "attempt", "difculty", "information", "set", "performance", "feature", "provide", "problem", "error", "puzzle", "help", "model", "learner", "work", "participant", "use", "load", "construct", "completed", "efort", "learning", "page", "number", "feedback", "-", "programming", "data", "solution", "system", "statement", "research", "structure", "program", "paper", "behavior", "code"], "document_vector": [-138.660827, 17.587766], "paragraphs": [{"paragraph_vector": [111.998481, 39.456569], "paragraph_keywords": ["code", "puzzles", "learning", "copies"]}, {"paragraph_vector": [118.646308, 44.102851], "paragraph_keywords": ["load", "model", "learning", "code"]}, {"paragraph_vector": [115.416198, 43.495044], "paragraph_keywords": ["learning", "load", "learners", "problem"]}, {"paragraph_vector": [112.888984, 42.918098], "paragraph_keywords": ["code", "puzzles", "learning", "problems"]}, {"paragraph_vector": [115.708152, 42.375328], "paragraph_keywords": ["learning", "puzzle", "puzzles", "statements"]}, {"paragraph_vector": [116.269538, 44.173473], "paragraph_keywords": ["information", "learning", "learners", "systems"]}, {"paragraph_vector": [117.565933, 45.085918], "paragraph_keywords": ["learners", "users", "looking", "study"]}, {"paragraph_vector": [116.37445, 45.22031], "paragraph_keywords": ["puzzles", "loop", "constructs", "participants"]}, {"paragraph_vector": [111.301071, 39.583774], "paragraph_keywords": ["participants", "code", "help", "research"]}, {"paragraph_vector": [117.883293, 44.030284], "paragraph_keywords": ["puzzles", "participants", "puzzle", "features"]}, {"paragraph_vector": [116.205307, 44.978672], "paragraph_keywords": ["features", "load", "learners", "code"]}, {"paragraph_vector": [116.927734, 45.477645], "paragraph_keywords": ["problems", "features", "code", "puzzle"]}, {"paragraph_vector": [114.654991, 45.723861], "paragraph_keywords": ["learners", "statements", "load", "attempt"]}, {"paragraph_vector": [112.55577, 44.746364], "paragraph_keywords": ["learners", "code", "participants", "behavior"]}, {"paragraph_vector": [113.784088, 44.237213], "paragraph_keywords": ["self", "constructs", "number", "participants"]}, {"paragraph_vector": [114.331237, 46.150653], "paragraph_keywords": ["load", "puzzles", "learners", "code"]}, {"paragraph_vector": [115.880081, 50.730487], "paragraph_keywords": ["model", "performance", "models", "baseline"]}, {"paragraph_vector": [116.328849, 45.982658], "paragraph_keywords": ["puzzles", "model", "features", "feedback"]}, {"paragraph_vector": [113.964584, 45.926513], "paragraph_keywords": ["features", "learners", "puzzles", "fig"]}, {"paragraph_vector": [113.736289, 44.238647], "paragraph_keywords": ["load", "features", "puzzles", "capture"]}, {"paragraph_vector": [113.273742, 44.020519], "paragraph_keywords": ["puzzles", "code", "puzzle", "load"]}, {"paragraph_vector": [114.177574, 43.65879], "paragraph_keywords": ["load", "model", "learning", "research"]}, {"paragraph_vector": [116.146331, 44.339065], "paragraph_keywords": ["load", "data", "learning", "problem"]}, {"paragraph_vector": [75.915542, 32.606376], "paragraph_keywords": ["allen", "annie", "evan", "angela"]}], "content": {}, "doi": "10.1145/3290605.3300489"}, {"uri": "86", "title": "Will You Accept an Imperfect AI? Exploring Designs for Adjusting End-user Expectations of AI Systems", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Rafal Kocielnik", "Saleema Amershi"], "summary": "AI technologies have been incorporated into many end-user applications. However, expectations of the capabilities of such systems vary among people. Furthermore, bloated expectations have been identified as negatively affecting perception and acceptance of such systems. Although the intelligibility of ML algorithms has been well studied, there has been little work on methods for setting appropriate expectations before the initial use of an AI-based system. In this work, we use a Scheduling Assistant an AI system for automated meeting request detection in free-text email to study the impact of several methods of expectation setting. We explore two versions of this system with the same 50% level of accuracy of the AI component but each designed with a different focus on the types of errors to avoid (avoiding False Positives vs. False Negatives). We show that such different Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed", "keywords": ["time", "acceptance", "information", "precision", "slider", "expectation", "recall", "design", "technique", "email", "error", "assistant", "accuracy", "user", "type", "aspect", "meeting", "work", "product", "impact", "use", "participant", "m", "control", "ai", "page", "number", "understanding", "version", "task", "shown", "study", "positive", "system", "adjustment", "request", "end", "satisfaction", "paper", "scheduling", "level", "figure"], "document_vector": [-62.879001, -8.13858], "paragraphs": [{"paragraph_vector": [68.444541, 43.153221], "paragraph_keywords": ["expectations", "ai", "user", "factors"]}, {"paragraph_vector": [55.230968, 32.411876], "paragraph_keywords": ["techniques", "user", "impact", "assistant"]}, {"paragraph_vector": [57.774967, 40.504142], "paragraph_keywords": ["expectations", "product", "use", "satisfaction"]}, {"paragraph_vector": [66.488143, 38.636344], "paragraph_keywords": ["system", "user", "impact", "expectations"]}, {"paragraph_vector": [65.950103, 37.232505], "paragraph_keywords": ["user", "expectations", "system", "proposed"]}, {"paragraph_vector": [64.401237, 40.083976], "paragraph_keywords": ["system", "user", "positives", "experience"]}, {"paragraph_vector": [53.47034, 30.046691], "paragraph_keywords": ["system", "user", "email", "meeting"]}, {"paragraph_vector": [52.082279, 8.911874], "paragraph_keywords": ["meeting", "request", "web", "email"]}, {"paragraph_vector": [54.274517, 15.797353], "paragraph_keywords": ["accuracy", "meeting", "determine", "scheduling"]}, {"paragraph_vector": [56.115543, 34.241153], "paragraph_keywords": ["system", "expectations", "errors", "accuracy"]}, {"paragraph_vector": [178.528167, 77.144424], "paragraph_keywords": ["accuracy", "number", "visualization", "designs"]}, {"paragraph_vector": [52.577239, 23.845407], "paragraph_keywords": ["system", "meeting", "figure", "sentence"]}, {"paragraph_vector": [53.828975, 41.782169], "paragraph_keywords": ["slider", "user", "system", "detections"]}, {"paragraph_vector": [53.733585, 24.174409], "paragraph_keywords": ["participants", "page", "information", "study"]}, {"paragraph_vector": [50.644382, 29.666234], "paragraph_keywords": ["understanding", "questions", "scheduling", "assistant"]}, {"paragraph_vector": [51.226608, 37.00185], "paragraph_keywords": ["participants", "accuracy", "m", "control"]}, {"paragraph_vector": [53.639831, 37.949337], "paragraph_keywords": ["study", "accuracy", "questions", "control"]}, {"paragraph_vector": [55.704341, 30.274436], "paragraph_keywords": ["scheduling", "assistant", "ai", "participants"]}, {"paragraph_vector": [54.894039, 35.404762], "paragraph_keywords": ["m", "accuracy", "recall", "system"]}, {"paragraph_vector": [54.376857, 39.33245], "paragraph_keywords": ["acceptance", "techniques", "revealed", "p"]}, {"paragraph_vector": [54.090648, 37.778511], "paragraph_keywords": ["techniques", "m", "impact", "baseline"]}, {"paragraph_vector": [52.127849, 34.037574], "paragraph_keywords": ["system", "precision", "techniques", "acceptance"]}, {"paragraph_vector": [55.449047, 35.743045], "paragraph_keywords": ["users", "user", "techniques", "expectation"]}, {"paragraph_vector": [57.229206, 36.134307], "paragraph_keywords": ["user", "system", "task", "recall"]}, {"paragraph_vector": [54.055019, 29.792007], "paragraph_keywords": ["systems", "ai", "user", "errors"]}, {"paragraph_vector": [54.731498, 37.307613], "paragraph_keywords": ["thank", "way", "accuracy", "acceptance"]}], "content": {}, "doi": "10.1145/3290605.3300733"}, {"uri": "87", "title": "Explaining Decision-Making Algorithms through UI: Strategies to Help Non-Expert Stakeholders", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Hao-Fei Cheng", "Ruotong Wang", "Zheng Zhang", "Fiona O\u2019Connell", "Terrance Gray", "F. Maxwell Harper", "Haiyi Zhu"], "summary": "Increasingly, algorithms are used to make important decisions across society. However, these algorithms are usually poorly understood, which can reduce transparency and evoke negative emotions. In this research, we seek to learn design principles for explanation interfaces that communicate how decision-making algorithms work, in order to help organizations explain their decisions to stakeholders, or to support users\u2019 \u201cright to explanation\u201d. We conducted an online experiment where 199 participants used different explanation interfaces to understand an algorithm for making university admissions decisions. We measured users\u2019 objective and self-reported understanding of the algorithm. Our results show that both interactive explanations and \u201cwhitebox\u201d explanations (i.e. that show the inner workings of an algorithm) can improve users\u2019 comprehension. Although the interactive approach is more effective at improving comprehension, it comes with a trade-off of taking more time. Surprisingly, we also find that users\u2019 trust in algorithmic decisions is not affected by the explanation interface or their level of comprehension of the algorithm.", "keywords": ["based", "strategy", "time", "condition", "explanation", "design", "box", "help", "user", "model", "trust", "profiling", "decision", "work", "participant", "use", "people", "attribute", "literacy", "algorithm", "understanding", "university", "understand", "admission", "data", "approach", "student", "system", "research", "machine", "asked", "prototype", "paper", "interface", "question", "level", "making"], "document_vector": [-85.526527, 0.933223], "paragraphs": [{"paragraph_vector": [69.336532, 52.165458], "paragraph_keywords": ["systems", "data", "copies", "algorithm"]}, {"paragraph_vector": [67.613021, 51.183002], "paragraph_keywords": ["research", "understand", "models", "strategies"]}, {"paragraph_vector": [66.330467, 50.24015], "paragraph_keywords": ["algorithm", "algorithms", "decisions", "users"]}, {"paragraph_vector": [68.917488, 58.219444], "paragraph_keywords": ["help", "models", "users", "data"]}, {"paragraph_vector": [81.626434, 67.940246], "paragraph_keywords": ["box", "explaining", "classification", "understand"]}, {"paragraph_vector": [70.259147, 50.834949], "paragraph_keywords": ["users", "explanation", "explore", "experts"]}, {"paragraph_vector": [67.327476, 49.712203], "paragraph_keywords": ["admission", "dataset", "student", "design"]}, {"paragraph_vector": [68.487846, 58.272281], "paragraph_keywords": ["design", "participants", "models", "university"]}, {"paragraph_vector": [66.431434, 51.192184], "paragraph_keywords": ["attributes", "box", "decision", "interface"]}, {"paragraph_vector": [58.770618, 53.879673], "paragraph_keywords": ["algorithm", "users", "profiles", "decision"]}, {"paragraph_vector": [57.999279, 57.192989], "paragraph_keywords": ["algorithm", "understanding", "attributes", "profile"]}, {"paragraph_vector": [56.310169, 11.50661], "paragraph_keywords": ["participants", "trust", "algorithm", "questions"]}, {"paragraph_vector": [59.266757, 55.905849], "paragraph_keywords": ["participants", "algorithm", "survey", "check"]}, {"paragraph_vector": [68.882026, 49.358329], "paragraph_keywords": ["conditions", "understanding", "model", "box"]}, {"paragraph_vector": [69.831039, 51.719158], "paragraph_keywords": ["interfaces", "box", "participants", "conditions"]}, {"paragraph_vector": [67.839393, 49.198505], "paragraph_keywords": ["interfaces", "explanation", "understanding", "trust"]}, {"paragraph_vector": [67.626113, 50.513179], "paragraph_keywords": ["algorithm", "people", "think", "participants"]}, {"paragraph_vector": [66.416122, 49.651359], "paragraph_keywords": ["algorithm", "explanation", "recidivism", "attributes"]}, {"paragraph_vector": [69.304054, 52.244647], "paragraph_keywords": ["people", "help", "algorithms", "algorithm"]}, {"paragraph_vector": [73.980613, 31.028381], "paragraph_keywords": ["project"]}], "content": {}, "doi": "10.1145/3290605.3300522"}, {"uri": "88", "title": "When Do People Trust Their Social Groups?", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Xiao Ma", "Justin Cheng", "Shankar Iyer", "Mor Naaman"], "summary": "Trust facilitates cooperation and supports positive outcomes in social groups, including member satisfaction, information sharing, and task performance. Extensive prior research has examined individuals\u2019 general propensity to trust, as well as the factors that contribute to their trust in speci\uffffc groups. Here, we build on past work to present a comprehensive framework for predicting trust in groups. By surveying 6,383 Facebook Groups users about their trust attitudes and examining aggregated behavioral and demographic data for these individuals, we show that (1) an individual\u2019s propensity to trust is associated with how they trust their groups, (2) smaller, closed, older, more exclusive, or more homogeneous groups are trusted more, and (3) a group\u2019s overall friendshipnetwork structure and an individual\u2019s position within that structure can also predict trust. Last, we demonstrate how group trust predicts outcomes at both individual and group level such as the formation of new friendship ties.", "keywords": ["facebook", "based", "feature", "literature", "attitude", "analysis", "friend", "relationship", "gender", "model", "activity", "trust", "disposition", "associated", "work", "participant", "people", "group", "increase", "size", "factor", "page", "number", "found", "survey", "including", "age", "scale", "dierences", "member", "membership", "measure", "data", "support", "network", "outcome", "individual", "level", "community"], "document_vector": [-74.226089, 38.765762], "paragraphs": [{"paragraph_vector": [143.5009, -62.136825], "paragraph_keywords": ["trust", "groups", "copies", "work"]}, {"paragraph_vector": [145.616287, -61.075317], "paragraph_keywords": ["group", "trust", "facebook", "groups"]}, {"paragraph_vector": [145.544692, -60.725528], "paragraph_keywords": ["trust", "group", "groups", "associated"]}, {"paragraph_vector": [148.871612, -59.597019], "paragraph_keywords": ["trust", "people", "measure", "theory"]}, {"paragraph_vector": [145.274276, -62.346019], "paragraph_keywords": ["trust", "groups", "work", "performance"]}, {"paragraph_vector": [148.452774, -62.142223], "paragraph_keywords": ["trust", "groups", "group", "shown"]}, {"paragraph_vector": [149.592666, -63.595108], "paragraph_keywords": ["trust", "group", "survey", "groups"]}, {"paragraph_vector": [145.695388, -63.813285], "paragraph_keywords": ["group", "facebook", "groups", "section"]}, {"paragraph_vector": [148.271743, -58.333152], "paragraph_keywords": ["trust", "based", "group", "people"]}, {"paragraph_vector": [152.009658, -59.64524], "paragraph_keywords": ["group", "groups", "model", "survey"]}, {"paragraph_vector": [145.226211, -59.910293], "paragraph_keywords": ["trust", "disposition", "groups", "dimensions"]}, {"paragraph_vector": [146.494812, -64.09835], "paragraph_keywords": ["group", "features", "groups", "model"]}, {"paragraph_vector": [146.986129, -60.829471], "paragraph_keywords": ["trust", "group", "size", "groups"]}, {"paragraph_vector": [149.479019, -61.154506], "paragraph_keywords": ["groups", "trust", "group", "number"]}, {"paragraph_vector": [146.755401, -61.321628], "paragraph_keywords": ["group", "trust", "activity", "participant"]}, {"paragraph_vector": [145.067352, -60.144763], "paragraph_keywords": ["group", "trust", "participant", "network"]}, {"paragraph_vector": [145.459945, -59.786193], "paragraph_keywords": ["group", "trust", "features", "groups"]}, {"paragraph_vector": [152.897079, -59.646614], "paragraph_keywords": ["group", "trust", "groups", "features"]}, {"paragraph_vector": [147.458267, -63.399101], "paragraph_keywords": ["trust", "group", "groups", "disposition"]}, {"paragraph_vector": [147.514175, -62.441055], "paragraph_keywords": ["trust", "groups", "work", "directed"]}, {"paragraph_vector": [147.488754, -63.164577], "paragraph_keywords": ["groups", "trust", "group", "increase"]}, {"paragraph_vector": [146.812164, -62.63953], "paragraph_keywords": ["trust", "group", "groups", "based"]}], "content": {}, "doi": "10.1145/3290605.3300699"}, {"uri": "89", "title": "Alternative Avenues for IoT: Designing with Non-Stereotypical Homes", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Audrey Desjardins", "Jeremy E. Viny"], "summary": "We report on the findings of a co-speculative design inquiry that investigates alternative visions of the Internet of Things (IoT) for the home. We worked with 16 people living in non-stereotypical homes to develop situated and personal concepts attuned to their home. As a prompt for co-speculation and discussion, we created handmade booklets where we took turns overlaying sketched design concepts on top of photos taken with participants in their homes. Our findings reveal new avenues for the design of IoT systems such as: acknowledging porous boundaries of the home, exposing neighborly relations, exploring diverse timescales, revisiting agency, and embracing imaginary and potential uses. We invite human-computer interaction and design researchers to use these avenues as starting points to broaden current assumptions embedded in design and research practices for domestic technologies. We conclude by highlighting the value of examining divergent perspectives and surfacing the unseen.", "keywords": ["based", "time", "bespoke", "kitchen", "abby", "object", "us", "connected", "lindsey", "design", "dweller", "apartment", "home", "boundary", "possibility", "opportunity", "example", "designing", "june", "house", "know", "van", "booklet", "shared", "work", "building", "space", "participant", "kate", "use", "people", "agency", "living", "history", "designed", "way", "world", "concept", "control", "iot", "page", "karey", "-", "life", "value", "neighbor", "device", "want", "researcher", "study", "designer", "said", "penelope", "research", "leonard", "question", "paper", "called", "privacy", "saying", "window", "project"], "document_vector": [79.775398, 36.095294], "paragraphs": [{"paragraph_vector": [-90.857627, -55.388999], "paragraph_keywords": ["home", "copies", "work", "designing"]}, {"paragraph_vector": [-85.598518, -54.866298], "paragraph_keywords": ["home", "homes", "iot", "lack"]}, {"paragraph_vector": [-82.584014, -61.072853], "paragraph_keywords": ["home", "homes", "work", "living"]}, {"paragraph_vector": [-87.201789, -59.389286], "paragraph_keywords": ["homes", "design", "home", "iot"]}, {"paragraph_vector": [-88.818275, -53.383102], "paragraph_keywords": ["home", "products", "homes", "speculation"]}, {"paragraph_vector": [-86.099609, -78.38655], "paragraph_keywords": ["homes", "apartment", "participants", "house"]}, {"paragraph_vector": [-105.958976, -58.153854], "paragraph_keywords": ["participants", "home", "booklet", "homes"]}, {"paragraph_vector": [-88.124107, -59.500003], "paragraph_keywords": ["concepts", "home", "homes", "areas"]}, {"paragraph_vector": [-80.996673, -53.650897], "paragraph_keywords": ["leonard", "abby", "concept", "sunlight"]}, {"paragraph_vector": [-86.655899, -50.589729], "paragraph_keywords": ["wildlife", "window", "penelope", "boundaries"]}, {"paragraph_vector": [-70.400123, -64.523269], "paragraph_keywords": ["neighbors", "kitchen", "birds", "opportunities"]}, {"paragraph_vector": [-82.271392, -56.271015], "paragraph_keywords": ["june", "said", "conversations", "salon"]}, {"paragraph_vector": [-90.927803, -63.916393], "paragraph_keywords": ["building", "media", "home", "world"]}, {"paragraph_vector": [-84.69152, -59.369743], "paragraph_keywords": ["neighbors", "salmon", "roommate", "connections"]}, {"paragraph_vector": [-100.634826, -59.271286], "paragraph_keywords": ["home", "kate", "time", "privacy"]}, {"paragraph_vector": [-92.833686, -56.394428], "paragraph_keywords": ["june", "histories", "films", "kate"]}, {"paragraph_vector": [-89.078292, -57.646144], "paragraph_keywords": ["home", "floor", "past", "susan"]}, {"paragraph_vector": [-94.283905, -59.979988], "paragraph_keywords": ["home", "devices", "agency", "kate"]}, {"paragraph_vector": [-98.737998, -57.050506], "paragraph_keywords": ["microwave", "rid", "saying", "home"]}, {"paragraph_vector": [-106.159049, -53.617992], "paragraph_keywords": ["cupboard", "concept", "penelope", "cat"]}, {"paragraph_vector": [-104.752067, -56.293369], "paragraph_keywords": ["agency", "cat", "lindsey", "design"]}, {"paragraph_vector": [-136.736755, 18.068113], "paragraph_keywords": ["projects", "penelope", "love", "rod"]}, {"paragraph_vector": [-94.700637, -59.18354], "paragraph_keywords": ["home", "possibilities", "concept", "grace"]}, {"paragraph_vector": [-86.431007, -58.649833], "paragraph_keywords": ["home", "iot", "values", "design"]}, {"paragraph_vector": [-85.645111, -61.190589], "paragraph_keywords": ["homes", "home", "visions", "relationship"]}, {"paragraph_vector": [-86.447639, -60.201702], "paragraph_keywords": ["home", "homes", "designers", "avenues"]}, {"paragraph_vector": [-88.855987, -59.856304], "paragraph_keywords": ["blanket", "term", "aschenbeck", "ball"]}], "content": {}, "doi": "10.1145/3290605.3300556"}, {"uri": "90", "title": "Privacy, Anonymity, and Perceived Risk in Open Collaboration: A Study of Service Providers", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Nora McDonald", "Benjamin Mako Hill", "Rachel Greenstadt", "Andrea Forte"], "summary": "Anonymity can enable both healthy online interactions like support-seeking and toxic behaviors like hate speech. How do online service providers balance these threats and opportunities? This two-part qualitative study examines the challenges perceived by open collaboration service providers in allowing anonymous contributions to their projects. We interviewed eleven people familiar with organizational decisions related to privacy and security at fve open collaboration projects and followed up with an analysis of public discussions about anonymous contribution to Wikipedia. We contrast our fndings with prior work on threats perceived by project volunteers and explore misalignment between policies aiming to serve contributors and the privacy practices of contributors themselves.", "keywords": ["identity", "perceived", "policy", "threat", "discussion", "feature", "analysis", "interview", "anons", "example", "wikipedia", "user", "type", "decision", "work", "participant", "use", "people", "perception", "contributor", "service", "way", "related", "participation", "contribute", "experience", "page", "barrier", "collaboration", "understanding", "norm", "tor", "anonymity", "require", "member", "value", "data", "contribution", "study", "support", "system", "provider", "perspective", "discourse", "site", "paper", "privacy", "harassment", "behavior", "project", "ip", "community"], "document_vector": [-43.600177, 38.399009], "paragraphs": [{"paragraph_vector": [105.583053, -56.040439], "paragraph_keywords": ["computing", "wikipedia", "anonymity", "copies"]}, {"paragraph_vector": [75.845489, -31.959363], "paragraph_keywords": ["anonymity", "service", "threats", "projects"]}, {"paragraph_vector": [77.1137, -32.633068], "paragraph_keywords": ["threats", "anonymity", "service", "identities"]}, {"paragraph_vector": [77.392814, -31.334373], "paragraph_keywords": ["collaboration", "tools", "behavior", "data"]}, {"paragraph_vector": [76.88932, -38.512439], "paragraph_keywords": ["privacy", "threats", "anonymity", "types"]}, {"paragraph_vector": [79.07621, -35.001541], "paragraph_keywords": ["identity", "privacy", "contributors", "aspects"]}, {"paragraph_vector": [83.673088, -36.69448], "paragraph_keywords": ["identity", "privacy", "decision", "threats"]}, {"paragraph_vector": [88.91082, -40.596961], "paragraph_keywords": ["interview", "participants", "people", "privacy"]}, {"paragraph_vector": [94.746437, -43.960262], "paragraph_keywords": ["participants", "data", "interview", "sites"]}, {"paragraph_vector": [95.808242, -35.417987], "paragraph_keywords": ["contributors", "term", "themes", "discussed"]}, {"paragraph_vector": [95.36145, -34.897716], "paragraph_keywords": ["threats", "participants", "author", "data"]}, {"paragraph_vector": [74.856262, -33.689701], "paragraph_keywords": ["contributors", "people", "projects", "harassment"]}, {"paragraph_vector": [70.997634, -27.662658], "paragraph_keywords": ["community", "problem", "project", "contributors"]}, {"paragraph_vector": [74.368217, -30.411996], "paragraph_keywords": ["contributors", "sites", "contribute", "contributions"]}, {"paragraph_vector": [76.253456, -32.020656], "paragraph_keywords": ["contributors", "identity", "project", "establish"]}, {"paragraph_vector": [76.641441, -22.177814], "paragraph_keywords": ["contributions", "people", "quality", "community"]}, {"paragraph_vector": [74.602737, -30.899808], "paragraph_keywords": ["privacy", "contributions", "data", "identity"]}, {"paragraph_vector": [72.781929, -31.910419], "paragraph_keywords": ["people", "participant", "contributors", "interview"]}, {"paragraph_vector": [75.638702, -32.208679], "paragraph_keywords": ["ip", "data", "contributors", "contributor"]}, {"paragraph_vector": [76.055778, -36.180603], "paragraph_keywords": ["contributor", "privacy", "perspectives", "people"]}, {"paragraph_vector": [78.274124, -34.534152], "paragraph_keywords": ["contributors", "perspective", "participation", "identity"]}, {"paragraph_vector": [75.776657, -31.306076], "paragraph_keywords": ["anons", "contributors", "wikipedia", "creating"]}, {"paragraph_vector": [77.826683, -33.574501], "paragraph_keywords": ["wikipedia", "threats", "contributors", "proxies"]}, {"paragraph_vector": [76.889999, -34.337257], "paragraph_keywords": ["contributors", "providers", "service", "participation"]}, {"paragraph_vector": [76.256797, -32.011623], "paragraph_keywords": ["contributors", "anonymity", "collaboration", "identity"]}, {"paragraph_vector": [78.605422, -31.823654], "paragraph_keywords": ["norms", "systems", "experiences", "providers"]}, {"paragraph_vector": [61.865791, -70.88845], "paragraph_keywords": ["tool", "understanding", "privacy", "concerns"]}], "content": {}, "doi": "10.1145/3290605.3300289"}, {"uri": "91", "title": "Affinity Lens", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Hariharan Subramonyam", "Steven M. Drucker"], "summary": "Despite the availability of software to support Affinity Diagramming (AD), practitioners still largely favor physical sticky-notes. Physical notes are easy to set-up, can be moved around in space and offer flexibility when clustering unstructured data. However, when working with mixed data sources such as surveys, designers often trade off the physicality of notes for analytical power. We propose Affinity Lens, a mobile-based augmented reality (AR) application for Data-Assisted Affinity Diagramming (DAAD). Our application provides just-in-time quantitative insights overlaid on physical notes. Affinity Lens uses several different types of AR overlays (called lenses) to help users find specific notes, cluster information, and summarize insights from clusters. Through a formative study of AD users, we developed design principles for data-assisted AD and an initial collection of lenses. Based on our prototype, we find that Affinity Lens Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300628 supports easy switching between qualitative and quantitative \u2018views\u2019 of data, without surrendering the lightweight benefits of existing AD practice.", "keywords": ["process", "lens", "based", "marker", "time", "ad", "information", "set", "phone", "wall", "scene", "design", "analysis", "example", "camera", "user", "work", "selected", "analytics", "participant", "use", "people", "insight", "screen", "overlay", "attribute", "visualization", "page", "look", "generate", "daad", "note", "dataset", "number", "including", "dave", "affinity", "task", "query", "search", "data", "diagramming", "study", "designer", "support", "system", "text", "clustering", "view", "session", "end", "mode", "paper", "cluster", "figure"], "document_vector": [154.405227, -7.251085], "paragraphs": [{"paragraph_vector": [-94.438362, 34.763256], "paragraph_keywords": ["ad", "data", "notes", "affinity"]}, {"paragraph_vector": [-84.270065, 57.989635], "paragraph_keywords": ["designer", "affinity", "notes", "comments"]}, {"paragraph_vector": [-79.145072, 75.046684], "paragraph_keywords": ["affinity", "shared", "analysis", "work"]}, {"paragraph_vector": [-79.616676, 74.150161], "paragraph_keywords": ["work", "cluster", "support", "affinity"]}, {"paragraph_vector": [-81.399574, 75.249855], "paragraph_keywords": ["paper", "notes", "affinity", "work"]}, {"paragraph_vector": [-79.473083, 71.070549], "paragraph_keywords": ["participants", "affinity", "lens", "task"]}, {"paragraph_vector": [-62.301769, 71.172882], "paragraph_keywords": ["clusters", "visualizations", "dataset", "students"]}, {"paragraph_vector": [-73.872573, 74.522491], "paragraph_keywords": ["participants", "data", "assistance", "text"]}, {"paragraph_vector": [-67.776473, 69.93869], "paragraph_keywords": ["participants", "clusters", "data", "cluster"]}, {"paragraph_vector": [-76.223342, 75.520423], "paragraph_keywords": ["data", "clusters", "ad", "text"]}, {"paragraph_vector": [-71.883064, 69.350952], "paragraph_keywords": ["data", "lens", "display", "affinity"]}, {"paragraph_vector": [-80.258796, 76.368171], "paragraph_keywords": ["dave", "notes", "lens", "note"]}, {"paragraph_vector": [-67.496932, 69.433723], "paragraph_keywords": ["cluster", "lens", "dave", "clusters"]}, {"paragraph_vector": [-85.653823, 72.581947], "paragraph_keywords": ["lenses", "note", "data", "dave"]}, {"paragraph_vector": [-64.86341, 70.173568], "paragraph_keywords": ["lens", "notes", "search", "lenses"]}, {"paragraph_vector": [-65.673072, 67.697433], "paragraph_keywords": ["lens", "notes", "view", "cluster"]}, {"paragraph_vector": [-65.69242, 69.805076], "paragraph_keywords": ["notes", "view", "lens", "user"]}, {"paragraph_vector": [-60.131309, 70.409263], "paragraph_keywords": ["notes", "scene", "lenses", "markers"]}, {"paragraph_vector": [-56.056632, 66.514633], "paragraph_keywords": ["lens", "query", "module", "lenses"]}, {"paragraph_vector": [-64.641883, 68.344306], "paragraph_keywords": ["notes", "data", "clustering", "cluster"]}, {"paragraph_vector": [-64.828308, 71.997787], "paragraph_keywords": ["participants", "notes", "cluster", "clusters"]}, {"paragraph_vector": [-68.325843, 67.636016], "paragraph_keywords": ["participants", "lens", "affinity", "insights"]}, {"paragraph_vector": [-73.880851, 74.748764], "paragraph_keywords": ["data", "participants", "privacy", "notes"]}, {"paragraph_vector": [-71.371902, 73.331687], "paragraph_keywords": ["data", "participants", "affinity", "clusters"]}, {"paragraph_vector": [-81.862159, 76.036483], "paragraph_keywords": ["participants", "data", "affinity", "lens"]}, {"paragraph_vector": [-87.969955, 83.539207], "paragraph_keywords": ["data", "affinity", "lens", "daad"]}, {"paragraph_vector": [-77.633316, 73.925514], "paragraph_keywords": ["data", "notes", "user", "affinity"]}, {"paragraph_vector": [-10.556096, 49.242065], "paragraph_keywords": ["ad", "thank", "users", "system"]}], "content": {}, "doi": "10.1145/3290605.3300636"}, {"uri": "92", "title": "Our Friends Electric: Reflections on Advocacy and Design Research for the Voice Enabled Internet", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jon Rogers", "Loraine Clarke", "Martin Skelly", "Nick Taylor", "Pete Thomas", "Michelle Thorne", "Solana Larsen", "Katarzyna Odrozek", "Julia Kloiber", "Peter Bihr"], "summary": "Emerging technologies\u2014such as the voice enabled internet\u2014 present many opportunities and challenges for HCI research Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300344 and society as a whole. Advocating for better, healthier implementations of these technologies will require us to communicate abstract values, such as trust, to an audience that ranges from the general public to technologists and even policymakers. In this paper, we show how a combination of film-making and product design can help to illustrate these abstract values. Working as part of a wider international advocacy campaign, Our Friends Electric focuses on the voice enabled internet, translating abstract notions of Internet Health into comprehensible digital futures for the relationship between our voice and the internet. We conclude with a call for designers of physical things to be more involved with the development of trust, privacy and security in this powerful emerging technological landscape. CHI 2019 Paper CHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK", "keywords": ["explore", "google", "advocacy", "time", "need", "object", "consent", "ability", "development", "bellagio", "design", "friend", "wanted", "example", "assistant", "expert", "enabled", "user", "trust", "interaction", "work", "product", "language", "use", "internet", "people", "issue", "way", "health", "future", "voice", "ai", "eddi", "page", "segment", "form", "including", "audience", "device", "computer", "summit", "data", "technology", "researcher", "approach", "designer", "karma", "research", "machine", "hci", "paper", "question", "privacy", "film", "value", "making"], "document_vector": [72.023582, 29.382713], "paragraphs": [{"paragraph_vector": [120.252227, -50.411636], "paragraph_keywords": ["internet", "technology", "design", "voice"]}, {"paragraph_vector": [112.330688, -50.447933], "paragraph_keywords": ["design", "internet", "designers", "issues"]}, {"paragraph_vector": [115.115074, -52.005588], "paragraph_keywords": ["voice", "internet", "google", "alexa"]}, {"paragraph_vector": [113.541786, -45.437763], "paragraph_keywords": ["design", "internet", "hci", "advocacy"]}, {"paragraph_vector": [101.865303, -49.773612], "paragraph_keywords": ["internet", "research", "values", "design"]}, {"paragraph_vector": [115.327461, -48.750751], "paragraph_keywords": ["futures", "design", "research", "film"]}, {"paragraph_vector": [118.096221, -50.265747], "paragraph_keywords": ["internet", "voice", "consent", "way"]}, {"paragraph_vector": [108.367668, -53.916542], "paragraph_keywords": ["internet", "devices", "bodies", "ways"]}, {"paragraph_vector": [127.797103, -61.85654], "paragraph_keywords": ["script", "voice", "developed", "tone"]}, {"paragraph_vector": [116.934768, -52.456295], "paragraph_keywords": ["language", "wanted", "devices", "film"]}, {"paragraph_vector": [122.443763, -53.007484], "paragraph_keywords": ["film", "objects", "voice", "reference"]}, {"paragraph_vector": [-173.380477, -53.452518], "paragraph_keywords": ["eddi", "film", "shared", "makers"]}, {"paragraph_vector": [116.079154, -51.893268], "paragraph_keywords": ["karma", "eddi", "making", "personality"]}, {"paragraph_vector": [118.148483, -58.247344], "paragraph_keywords": ["user", "segment", "sig", "karma"]}, {"paragraph_vector": [115.731948, -51.731822], "paragraph_keywords": ["design", "film", "researcher", "advocacy"]}, {"paragraph_vector": [108.506378, -47.470169], "paragraph_keywords": ["film", "audience", "way", "approach"]}, {"paragraph_vector": [153.345748, 31.498928], "paragraph_keywords": ["design", "film", "audience", "objects"]}, {"paragraph_vector": [-159.581726, -13.512208], "paragraph_keywords": ["voice", "design", "research", "advocacy"]}, {"paragraph_vector": [115.369483, -51.670841], "paragraph_keywords": ["design", "google", "work", "duplex"]}, {"paragraph_vector": [95.270538, -35.45375], "paragraph_keywords": ["research", "product", "need", "design"]}, {"paragraph_vector": [94.457695, -45.968963], "paragraph_keywords": ["design", "products", "data", "internet"]}, {"paragraph_vector": [107.507896, -25.3861], "paragraph_keywords": ["futures", "design", "legislation", "designers"]}, {"paragraph_vector": [101.21215, -42.9808], "paragraph_keywords": ["hci", "internet", "ways", "opportunity"]}], "content": {}, "doi": "10.1145/3290605.3300354"}, {"uri": "93", "title": "Understanding Law Enforcement Strategies and Needs for Combating Human Trafficking", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Julia Deeb-Swihart", "Alex Endert"], "summary": "In working to rescue victims of human trafficking, law enforcement officers face a host of challenges. Working in complex, layered organizational structures, they face challenges of collaboration and communication. Online information is central to every phase of a human-trafficking investigation. With terabytes of available data such as sex work ads, policing is increasingly a big-data research problem. In this study, we interview sixteen law enforcement officers working to rescue victims of human trafficking to try to understand their computational needs. We highlight three major areas where future work in human-computer interaction can help. First, combating human trafficking requires advances in information visualization of large, complex, geospatial data, as victims are frequently forcibly moved across jurisdictions. Second, the need for unified information databases raises critical research issues of usable security and privacy. Finally, the archaic nature of information systems available to law enforcement raises policy issues regarding resource allocation for software development.", "keywords": ["process", "police", "time", "mentioned", "need", "information", "department", "person", "find", "phone", "evidence", "training", "interview", "help", "noted", "officer", "investigator", "know", "work", "law", "tool", "participant", "use", "investigation", "victim", "issue", "working", "state", "page", "look", "number", "collaboration", "effort", "enforcement", "database", "trafficker", "case", "crime", "track", "search", "data", "technology", "sex", "role", "support", "system", "lot", "research", "paper", "trafficking", "privacy", "access"], "document_vector": [-112.444831, 65.608581], "paragraphs": [{"paragraph_vector": [97.352142, -54.582035], "paragraph_keywords": ["trafficking", "enforcement", "law", "copies"]}, {"paragraph_vector": [59.478614, -31.773855], "paragraph_keywords": ["trafficking", "law", "enforcement", "research"]}, {"paragraph_vector": [59.962066, -35.669303], "paragraph_keywords": ["trafficking", "victims", "departments", "work"]}, {"paragraph_vector": [59.5545, -29.637302], "paragraph_keywords": ["trafficking", "law", "enforcement", "work"]}, {"paragraph_vector": [58.327129, -31.133382], "paragraph_keywords": ["data", "police", "technology", "departments"]}, {"paragraph_vector": [57.926914, -31.21462], "paragraph_keywords": ["data", "law", "enforcement", "issues"]}, {"paragraph_vector": [59.426296, -34.805118], "paragraph_keywords": ["participants", "interviews", "process", "person"]}, {"paragraph_vector": [58.141975, -32.52349], "paragraph_keywords": ["trafficking", "participants", "training", "tools"]}, {"paragraph_vector": [56.709487, -30.750787], "paragraph_keywords": ["participants", "trafficking", "process", "investigations"]}, {"paragraph_vector": [57.028686, -32.957057], "paragraph_keywords": ["trafficking", "tips", "cases", "advertisements"]}, {"paragraph_vector": [60.522174, -31.283687], "paragraph_keywords": ["tips", "cases", "trafficking", "investigating"]}, {"paragraph_vector": [58.692638, -31.947725], "paragraph_keywords": ["information", "victim", "trafficking", "try"]}, {"paragraph_vector": [58.20256, -29.962419], "paragraph_keywords": ["number", "search", "phone", "track"]}, {"paragraph_vector": [57.04103, -30.625686], "paragraph_keywords": ["interviews", "victim", "person", "victims"]}, {"paragraph_vector": [66.65802, -72.125648], "paragraph_keywords": ["times", "want", "person", "information"]}, {"paragraph_vector": [58.09206, -32.278984], "paragraph_keywords": ["trafficker", "investigators", "case", "evidence"]}, {"paragraph_vector": [58.437866, -32.820682], "paragraph_keywords": ["participants", "charges", "tools", "databases"]}, {"paragraph_vector": [54.998073, -34.259574], "paragraph_keywords": ["tools", "case", "investigators", "participants"]}, {"paragraph_vector": [57.42889, -31.469911], "paragraph_keywords": ["collaborators", "participants", "case", "collaboration"]}, {"paragraph_vector": [55.739852, -31.69024], "paragraph_keywords": ["victim", "departments", "data", "problem"]}, {"paragraph_vector": [56.994056, -31.521671], "paragraph_keywords": ["information", "access", "cases", "phone"]}, {"paragraph_vector": [56.556022, -32.981094], "paragraph_keywords": ["information", "law", "enforcement", "track"]}, {"paragraph_vector": [55.054222, -29.521905], "paragraph_keywords": ["process", "data", "information", "software"]}, {"paragraph_vector": [56.764675, -35.263744], "paragraph_keywords": ["ads", "investigators", "patterns", "state"]}, {"paragraph_vector": [56.85464, -32.681587], "paragraph_keywords": ["tools", "time", "investigators", "way"]}, {"paragraph_vector": [52.190017, -22.269968], "paragraph_keywords": ["data", "visualization", "models", "results"]}, {"paragraph_vector": [57.052913, -25.551759], "paragraph_keywords": ["policy", "data", "tools", "law"]}, {"paragraph_vector": [70.224998, -39.682788], "paragraph_keywords": ["privacy", "databases", "workers", "sex"]}, {"paragraph_vector": [59.829799, -30.57463], "paragraph_keywords": ["trafficking", "data", "ensure", "abuse"]}, {"paragraph_vector": [57.754547, -32.132781], "paragraph_keywords": ["research", "tools", "build", "efforts"]}], "content": {}, "doi": "10.1145/3290605.3300563"}, {"uri": "94", "title": "Multilayer Haptic Feedback for Pen-Based Tablet Interaction", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Ernst Kruijff"], "summary": "We present a novel, haptic multilayer interaction approach that enables state transitions between spatially abovescreen and 2D on-screen feedback layers. This approach supports the exploration of haptic features that are hard to simulate using rigid 2D screens. We accomplish this by adding a haptic layer above the screen that can be actuated and interacted with (pressed on) while the user interacts with on-screen content using pen input. The haptic layer provides variable firmness and contour feedback, while its membrane functionality affords additional tactile cues like texture feedback. Through two user studies, we look at how users can use the layer in haptic exploration tasks, showing that users can discriminate well between different firmness levels, and can perceive object contour characteristics. Demonstrated also through an art application, the results show the potential of multilayer feedback to extend onscreen content with additional widget, tool and surface properties, as well as for user guidance.", "keywords": ["simulate", "tablet", "based", "change", "tension", "performance", "display", "force", "layer", "provide", "mm", "vibration", "user", "exploration", "button", "surface", "interaction", "sliding", "work", "tool", "use", "perception", "material", "screen", "cue", "rim", "m", "art", "shape", "page", "application", "property", "feedback", "firmness", "fig", "pressing", "pressure", "study", "tactile", "servo", "approach", "flexurface", "system", "pen", "paper"], "document_vector": [121.945457, -68.66526], "paragraphs": [{"paragraph_vector": [-91.627029, 23.735105], "paragraph_keywords": ["acm", "interaction", "copies", "cues"]}, {"paragraph_vector": [-91.42826, 23.616641], "paragraph_keywords": ["layer", "perception", "screen", "interaction"]}, {"paragraph_vector": [-94.552024, 25.111764], "paragraph_keywords": ["feedback", "pen", "system", "space"]}, {"paragraph_vector": [-95.022186, 22.678405], "paragraph_keywords": ["space", "feedback", "interfaces", "materials"]}, {"paragraph_vector": [-91.709846, 25.13828], "paragraph_keywords": ["cues", "feedback", "interaction", "tactile"]}, {"paragraph_vector": [-91.311988, 24.401603], "paragraph_keywords": ["pen", "tension", "tablet", "display"]}, {"paragraph_vector": [-88.22586, 24.346647], "paragraph_keywords": ["surface", "display", "pen", "material"]}, {"paragraph_vector": [-90.578773, 24.832778], "paragraph_keywords": ["tension", "servos", "surface", "membrane"]}, {"paragraph_vector": [-90.49295, 25.805017], "paragraph_keywords": ["feedback", "pilot", "study", "audio"]}, {"paragraph_vector": [-79.582992, 18.95045], "paragraph_keywords": ["pressure", "users", "finger", "fig"]}, {"paragraph_vector": [-86.326477, 24.260013], "paragraph_keywords": ["tension", "pressure", "button", "protocol"]}, {"paragraph_vector": [-88.606376, 22.575017], "paragraph_keywords": ["pen", "sliding", "pressing", "based"]}, {"paragraph_vector": [-85.215301, 23.234794], "paragraph_keywords": ["feedback", "m", "study", "sd"]}, {"paragraph_vector": [-87.469017, 27.775064], "paragraph_keywords": ["vibration", "tension", "rim", "speed"]}, {"paragraph_vector": [-89.09317, 23.336734], "paragraph_keywords": ["tension", "change", "rim", "speed"]}, {"paragraph_vector": [-86.807266, 21.953189], "paragraph_keywords": ["cues", "system", "tactile", "rim"]}, {"paragraph_vector": [-91.1119, 25.075702], "paragraph_keywords": ["surface", "application", "pen", "paper"]}, {"paragraph_vector": [-91.960105, 25.076099], "paragraph_keywords": ["layer", "painting", "content", "layers"]}, {"paragraph_vector": [-92.983856, 24.783451], "paragraph_keywords": ["feedback", "display", "surface", "system"]}, {"paragraph_vector": [-90.67514, 24.439229], "paragraph_keywords": ["properties", "surface", "feedback", "cues"]}, {"paragraph_vector": [-89.340728, 23.915983], "paragraph_keywords": ["simulate", "material", "pen", "display"]}, {"paragraph_vector": [-90.377616, 23.199918], "paragraph_keywords": ["feedback", "pen", "properties", "exploration"]}, {"paragraph_vector": [-89.478149, 24.046897], "paragraph_keywords": ["feedback", "tension", "cues", "performance"]}, {"paragraph_vector": [-83.82566, 22.633039], "paragraph_keywords": ["system", "interaction", "finger", "use"]}], "content": {}, "doi": "10.1145/3290605.3300807"}, {"uri": "95", "title": "HawkEye \u2013 Deploying a Design Fiction Probe", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Renee Noortman", "Britta F. Schulte", "Paul Marshall", "Saskia Bakker", "Anna L. Cox"], "summary": "This paper explores how a design fiction can be designed to be used as a pragmatic user-centred design method to generate insights on future technology use. We built HawkEye, a design fiction probe that embodies a future fiction of dementia care. To learn how participants respond to the probe, we employed it with eight participants for three weeks in their own homes as well as evaluating it with six HCI experts in sessions of 1.5h. In addition to presenting the probe in detail, we share insights into the process of building it and discuss the utility of design fiction as a tool to elicit empathetic and rich discussions about potential outcomes of future technologies.", "keywords": ["resident", "based", "information", "discussion", "design", "method", "home", "care", "interview", "hawkeye", "story", "deployment", "work", "participant", "use", "helped", "people", "insight", "designed", "think", "future", "mean", "experience", "page", "felt", "fiction", "feedback", "provided", "probe", "module", "data", "day", "technology", "study", "feel", "role", "dementia", "system", "lot", "research", "session", "evaluate", "paper", "printed", "annie", "level"], "document_vector": [87.999069, 25.452825], "paragraphs": [{"paragraph_vector": [145.701919, -84.901107], "paragraph_keywords": ["technologies", "design", "probe", "fiction"]}, {"paragraph_vector": [132.349121, 7.294955], "paragraph_keywords": ["design", "work", "fiction", "copies"]}, {"paragraph_vector": [-153.453063, -84.582641], "paragraph_keywords": ["participants", "design", "deployment", "probe"]}, {"paragraph_vector": [145.445968, -86.221794], "paragraph_keywords": ["dementia", "people", "technologies", "home"]}, {"paragraph_vector": [170.684097, -84.498474], "paragraph_keywords": ["design", "fiction", "participants", "hawkeye"]}, {"paragraph_vector": [-147.177871, -84.407463], "paragraph_keywords": ["participants", "probe", "annie", "fiction"]}, {"paragraph_vector": [119.982963, -89.390983], "paragraph_keywords": ["hawkeye", "care", "annie", "company"]}, {"paragraph_vector": [6.996963, -88.768615], "paragraph_keywords": ["modules", "level", "medication", "home"]}, {"paragraph_vector": [-90.802078, -77.062263], "paragraph_keywords": ["resident", "level", "module", "based"]}, {"paragraph_vector": [165.615051, -76.977531], "paragraph_keywords": ["participants", "data", "system", "modules"]}, {"paragraph_vector": [-114.095146, -84.54663], "paragraph_keywords": ["participants", "designed", "study", "experience"]}, {"paragraph_vector": [-174.513076, -83.31295], "paragraph_keywords": ["participants", "interviews", "sessions", "design"]}, {"paragraph_vector": [-111.522987, -89.42163], "paragraph_keywords": ["sessions", "experts", "study", "design"]}, {"paragraph_vector": [132.233673, -87.55944], "paragraph_keywords": ["participants", "fiction", "technologies", "experience"]}, {"paragraph_vector": [129.024703, -83.56031], "paragraph_keywords": ["participants", "care", "role", "way"]}, {"paragraph_vector": [123.756576, -86.734054], "paragraph_keywords": ["participants", "annie", "fiction", "felt"]}, {"paragraph_vector": [-126.451744, -86.536796], "paragraph_keywords": ["dementia", "participants", "design", "probe"]}, {"paragraph_vector": [-69.049995, -84.258064], "paragraph_keywords": ["system", "participants", "technology", "use"]}, {"paragraph_vector": [104.374084, 13.244049], "paragraph_keywords": ["think", "participants", "probe", "information"]}, {"paragraph_vector": [-102.130851, -66.230697], "paragraph_keywords": ["participants", "information", "data", "story"]}, {"paragraph_vector": [-97.483848, -72.227584], "paragraph_keywords": ["thought", "experience", "participants", "scenario"]}, {"paragraph_vector": [-164.008041, -83.469146], "paragraph_keywords": ["participants", "probe", "friends", "insights"]}, {"paragraph_vector": [-170.131134, -86.124374], "paragraph_keywords": ["participants", "probes", "fiction", "technologies"]}, {"paragraph_vector": [-155.798934, -85.439788], "paragraph_keywords": ["participants", "enabled", "experience", "fiction"]}, {"paragraph_vector": [-138.336868, -86.712364], "paragraph_keywords": ["fiction", "participants", "design", "considered"]}, {"paragraph_vector": [106.609863, -24.160367], "paragraph_keywords": ["insights", "design", "probe", "participants"]}], "content": {}, "doi": "10.1145/3290605.3300931"}, {"uri": "96", "title": "ChewIt. An Intraoral Interface for Discreet Interactions", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Pablo Gallego Casc\u00f3n", "Denys J.C. Matthies", "Sachith Muthukumarana"], "summary": "Sensing interfaces relying on head or facial gestures provide efective solutions for hands-free scenarios. Most of these interfaces utilize sensors attached to the face, as well as into the mouth, being either obtrusive or limited in input bandwidth. In this paper, we propose ChewIt \u2013 a novel intraoral input interface. ChewIt resembles an edible object that allows users to perform various hands-free input operations, both simply and discreetly. Our design is informed by a series of studies investigating the implications of shape, size, locations for comfort, discreetness, maneuverability, and obstructiveness. Additionally, we evaluated potential gestures that users could utilize to interact with such an intraoral interface.", "keywords": ["based", "imu", "time", "acceptance", "bite", "speech", "object", "placed", "set", "dimension", "location", "discreetness", "mm", "comfort", "user", "chewit", "accuracy", "performed", "interaction", "surface", "work", "holding", "participant", "use", "people", "tongue", "teeth", "size", "acm", "shape", "orientation", "spectator", "gesture", "found", "including", "test", "hand", "device", "enables", "data", "pressure", "technology", "study", "acceptability", "chewing", "prototype", "asked", "interface", "input", "figure", "mouth"], "document_vector": [58.486099, -60.110267], "paragraphs": [{"paragraph_vector": [-47.452156, -22.445318], "paragraph_keywords": ["interaction", "input", "copies", "computing"]}, {"paragraph_vector": [-46.78469, -25.497241], "paragraph_keywords": ["speech", "interfaces", "user", "privacy"]}, {"paragraph_vector": [-48.272876, -27.002473], "paragraph_keywords": ["interfaces", "technologies", "instance", "mouth"]}, {"paragraph_vector": [-47.057765, -24.596742], "paragraph_keywords": ["user", "interface", "interacting", "acceptance"]}, {"paragraph_vector": [-46.971672, -25.592542], "paragraph_keywords": ["device", "mouth", "user", "interaction"]}, {"paragraph_vector": [-68.444602, 24.44666], "paragraph_keywords": ["gesture", "data", "power", "recorded"]}, {"paragraph_vector": [-62.193428, 14.501405], "paragraph_keywords": ["classifer", "data", "set", "input"]}, {"paragraph_vector": [-48.047946, -23.99591], "paragraph_keywords": ["object", "users", "gestures", "dt"]}, {"paragraph_vector": [-51.22071, -23.271081], "paragraph_keywords": ["participants", "condition", "confdence", "device"]}, {"paragraph_vector": [-48.896518, -23.485544], "paragraph_keywords": ["participants", "mouth", "object", "chewing"]}, {"paragraph_vector": [-49.101531, -22.986379], "paragraph_keywords": ["participants", "size", "mm", "dimensions"]}, {"paragraph_vector": [-49.416477, -22.13389], "paragraph_keywords": ["test", "size", "participants", "orientation"]}, {"paragraph_vector": [-50.062995, -23.317623], "paragraph_keywords": ["tissue", "surfaces", "cut", "shape"]}, {"paragraph_vector": [-50.489036, -23.535041], "paragraph_keywords": ["participants", "figure", "shape", "maneuverability"]}, {"paragraph_vector": [-49.845191, -23.536996], "paragraph_keywords": ["performed", "figure", "location", "object"]}, {"paragraph_vector": [-47.438369, -24.672447], "paragraph_keywords": ["gestures", "ratings", "parameter", "bite"]}, {"paragraph_vector": [-48.721988, -23.90435], "paragraph_keywords": ["location", "gestures", "users", "holding"]}, {"paragraph_vector": [-50.241359, -23.203613], "paragraph_keywords": ["users", "shapes", "gestures", "size"]}, {"paragraph_vector": [-47.744705, -24.639026], "paragraph_keywords": ["chewit", "users", "material", "including"]}, {"paragraph_vector": [-47.195339, -22.277597], "paragraph_keywords": ["chewit", "interface", "gestures", "controlling"]}, {"paragraph_vector": [-46.238174, -27.312078], "paragraph_keywords": ["user", "tongue", "interface", "input"]}, {"paragraph_vector": [-44.163536, -23.585245], "paragraph_keywords": ["interface", "pillcam", "hands", "speech"]}, {"paragraph_vector": [-46.019203, -27.165351], "paragraph_keywords": ["cho", "conference", "based", "yang"]}], "content": {}, "doi": "10.1145/3290605.3300761"}, {"uri": "97", "title": "How Women Wikipedians Negotiate and Navigate Safety", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Amanda Menking"], "summary": "Wikipedia is one of the most successful online communities in history, yet it struggles to attract and retain women editors\u2014a phenomenon known as the gender gap. We investigate this gap by focusing on the voices of experienced women Wikipedians. In this interview-based study (N=25), we identify a core theme among these voices: safety. We reveal how our participants perceive safety within their community, how they manage their safety both conceptually and physically, and how they act on this understanding to create safe spaces on and off Wikipedia. Our analysis shows Wikipedia functions as both a multidimensional and porous space encompassing a spectrum of safety. Navigating this space requires these women to employ sophisticated tactics related to identity management, boundary management, and emotion work. We conclude with a set of provocations to spur the design of future online environments that encourage equity, inclusivity, and safety for historically marginalized users.", "keywords": ["gap", "facebook", "based", "time", "conflict", "continue", "interview", "wikimedia", "safety", "wikipedians", "provide", "example", "gender", "wikipedia", "woman", "help", "user", "participate", "noted", "know", "production", "creating", "risk", "shared", "work", "engage", "space", "place", "use", "participant", "create", "people", "group", "way", "think", "article", "participation", "lack", "interviewee", "finding", "page", "experience", "year", "content", "norm", "edit", "men", "kind", "culture", "taking", "member", "wiki", "practice", "data", "feel", "study", "researcher", "designer", "manage", "wmf", "system", "usa", "paper", "editor", "harassment", "community", "making"], "document_vector": [-73.769409, 41.398994], "paragraphs": [{"paragraph_vector": [62.896488, -36.780647], "paragraph_keywords": ["wikipedia", "helena", "continue", "women"]}, {"paragraph_vector": [60.193054, -33.044265], "paragraph_keywords": ["wikipedia", "wikimedia", "systems", "world"]}, {"paragraph_vector": [59.937347, -38.483207], "paragraph_keywords": ["harassment", "wmf", "wikipedia", "gap"]}, {"paragraph_vector": [56.634517, -44.676601], "paragraph_keywords": ["women", "participation", "gender", "systems"]}, {"paragraph_vector": [112.103919, 15.661555], "paragraph_keywords": ["women", "wikipedia", "production", "gardner"]}, {"paragraph_vector": [112.662635, 15.413763], "paragraph_keywords": ["women", "gap", "wikipedia", "lack"]}, {"paragraph_vector": [119.186332, -41.262157], "paragraph_keywords": ["safety", "risk", "taking", "people"]}, {"paragraph_vector": [56.639148, -47.497474], "paragraph_keywords": ["spaces", "space", "harassment", "harm"]}, {"paragraph_vector": [58.880558, -44.590774], "paragraph_keywords": ["interviews", "participants", "wmf", "author"]}, {"paragraph_vector": [116.059524, -38.969051], "paragraph_keywords": ["usa", "professor", "wikipedia", "researcher"]}, {"paragraph_vector": [57.871852, -42.075653], "paragraph_keywords": ["wikipedia", "spaces", "character", "wikimedians"]}, {"paragraph_vector": [59.721046, -36.385044], "paragraph_keywords": ["wikipedia", "facebook", "women", "page"]}, {"paragraph_vector": [60.862777, -39.460678], "paragraph_keywords": ["wikipedia", "people", "women", "spaces"]}, {"paragraph_vector": [59.955253, -39.985836], "paragraph_keywords": ["wikipedia", "space", "community", "know"]}, {"paragraph_vector": [61.051208, -36.370258], "paragraph_keywords": ["wikipedia", "trolls", "interviewees", "community"]}, {"paragraph_vector": [62.313289, -39.6585], "paragraph_keywords": ["women", "spaces", "feel", "wiki"]}, {"paragraph_vector": [60.942333, -36.984004], "paragraph_keywords": ["people", "creating", "women", "interviewees"]}, {"paragraph_vector": [66.833076, -28.886466], "paragraph_keywords": ["edit", "articles", "jordan", "places"]}, {"paragraph_vector": [62.864227, -34.465316], "paragraph_keywords": ["work", "articles", "wikipedia", "edit"]}, {"paragraph_vector": [55.95272, -37.904685], "paragraph_keywords": ["wikipedia", "community", "people", "kind"]}, {"paragraph_vector": [56.800441, -38.588703], "paragraph_keywords": ["work", "emotion", "norms", "engage"]}, {"paragraph_vector": [60.920127, -37.67461], "paragraph_keywords": ["wikipedia", "community", "wikipedians", "practices"]}, {"paragraph_vector": [58.358539, -43.467109], "paragraph_keywords": ["women", "meritocracy", "community", "culture"]}, {"paragraph_vector": [60.235847, -39.500125], "paragraph_keywords": ["safety", "wikipedia", "spaces", "require"]}, {"paragraph_vector": [77.974266, -43.334606], "paragraph_keywords": ["designers", "spaces", "kinds", "people"]}, {"paragraph_vector": [60.712593, -37.86124], "paragraph_keywords": ["use", "spaces", "wikipedia", "community"]}, {"paragraph_vector": [64.782264, -37.778118], "paragraph_keywords": ["women", "design", "wikipedia", "study"]}, {"paragraph_vector": [58.960327, -48.339324], "paragraph_keywords": ["women", "environments", "harassment", "thank"]}], "content": {}, "doi": "10.1145/3290605.3300401"}, {"uri": "98", "title": "Encoding Materials and Data for Iterative Personalization ", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Troy Nachtigall", "Oscar Tomico", "Ron Wakkary", "Pauline van Dongen"], "summary": "Data is changing how we design consumer products. Shoe production is a prime example of this; foot size, footstep pressure and personal preferences can be used to design personalized shoes. Research done around metamaterials, programming materials and computational composites illustrate the possibilities of creating complex data & material relationships. These new relationships allow us to look at future products almost like software apps, becoming a kind of product service systems, where the focus is on its iterative personalized improvement over time. Can we create systems of such data driven objects that in turn allow us to design new objects that are informed by the data trail? In this paper we report on four RtD project iterations that explore this challenge and provide a set of insights on how to close this new iterative loop.", "keywords": ["process", "time", "bespoke", "object", "sensing", "needed", "precision", "design", "craft", "personalization", "technique", "encoding", "seen", "foot", "sensor", "user", "creating", "work", "use", "create", "people", "material", "learning", "challenge", "printing", "created", "experience", "generate", "allowed", "understanding", "form", "understand", "encoded", "pressure", "filament", "data", "geometry", "system", "printer", "required", "research", "composite", "machine", "shoe", "footstep", "structure", "software", "tread", "area", "behavior", "project", "making", "code"], "document_vector": [69.725143, -16.976081], "paragraphs": [{"paragraph_vector": [-82.669006, 55.318767], "paragraph_keywords": ["data", "design", "al", "things"]}, {"paragraph_vector": [-85.101432, 56.299678], "paragraph_keywords": ["shoes", "foot", "shoe", "data"]}, {"paragraph_vector": [-85.946571, 58.985382], "paragraph_keywords": ["data", "design", "materials", "shoe"]}, {"paragraph_vector": [-83.128479, 55.772949], "paragraph_keywords": ["data", "design", "object", "research"]}, {"paragraph_vector": [-84.755012, 58.702117], "paragraph_keywords": ["research", "materials", "personalization", "shoes"]}, {"paragraph_vector": [-85.301597, 56.570373], "paragraph_keywords": ["project", "data", "footstep", "projects"]}, {"paragraph_vector": [-79.493515, 58.041557], "paragraph_keywords": ["sensors", "foot", "software", "sensor"]}, {"paragraph_vector": [-80.530181, 57.087707], "paragraph_keywords": ["sensor", "foot", "pressure", "level"]}, {"paragraph_vector": [-75.807762, 53.642311], "paragraph_keywords": ["foot", "data", "shoe", "people"]}, {"paragraph_vector": [-81.556945, 57.493244], "paragraph_keywords": ["data", "shoe", "software", "tread"]}, {"paragraph_vector": [-88.568252, 53.381698], "paragraph_keywords": ["shoe", "software", "needed", "geometries"]}, {"paragraph_vector": [-84.062339, 57.055084], "paragraph_keywords": ["required", "structures", "points", "seed"]}, {"paragraph_vector": [-84.975234, 58.827331], "paragraph_keywords": ["material", "areas", "behavior", "nozzle"]}, {"paragraph_vector": [-89.163444, 57.468311], "paragraph_keywords": ["data", "design", "software", "limits"]}, {"paragraph_vector": [-82.458267, 54.244132], "paragraph_keywords": ["data", "users", "shoes", "shoe"]}, {"paragraph_vector": [-81.075439, 55.909198], "paragraph_keywords": ["shoe", "browser", "data", "user"]}, {"paragraph_vector": [-80.345603, 55.048374], "paragraph_keywords": ["shoe", "project", "data", "process"]}, {"paragraph_vector": [-82.495117, 56.447238], "paragraph_keywords": ["comfort", "design", "material", "structures"]}, {"paragraph_vector": [-82.332542, 56.515529], "paragraph_keywords": ["material", "use", "required", "project"]}, {"paragraph_vector": [-85.829872, 56.901039], "paragraph_keywords": ["material", "data", "required", "design"]}, {"paragraph_vector": [-86.181297, 57.73421], "paragraph_keywords": ["material", "sensors", "sensing", "hybrid"]}, {"paragraph_vector": [-85.315452, 56.802997], "paragraph_keywords": ["data", "understand", "way", "knitting"]}, {"paragraph_vector": [-81.987808, 55.895317], "paragraph_keywords": ["data", "system", "personalization", "encoded"]}, {"paragraph_vector": [-84.79528, 56.96326], "paragraph_keywords": ["data", "time", "shoe", "material"]}, {"paragraph_vector": [-82.906715, 55.389488], "paragraph_keywords": ["data", "design", "personalization", "materials"]}, {"paragraph_vector": [-88.05706, 53.991184], "paragraph_keywords": ["research", "data", "shoes", "members"]}], "content": {}, "doi": "10.1145/3290605.3300668"}, {"uri": "99", "title": "Designing for Reproducibility: AQualitative Study of Challenges and Opportunities in High Energy Physics", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Sebastian S. Feger"], "summary": "Reproducibility should be a cornerstone of scientific research and is a growing concern among the scientific community and the public. Understanding how to design services and tools that support documentation, preservation and sharing is required to maximize the positive impact of scientific research. We conducted a study of user attitudes towards systems that support data preservation in High Energy Physics, one of science\u2019s most data-intensive branches. We report on our interview study with 12 experimental physicists, studying requirements and opportunities in designing for research preservation and reproducibility. Our findings suggest that we need to design for motivation and benefits in order to stimulate contributions and to address the observed scalability challenge. Therefore, researchers\u2019 attitudes towards communication, uncertainty, collaboration and automation need to be reflected in design. Based on our findings, we present a systematic view of user needs and constraints that define the design space of systems supporting reproducible practices.", "keywords": ["based", "time", "need", "reproducibility", "information", "resource", "requirement", "analyst", "design", "analysis", "interview", "provide", "experiment", "describe", "uncertainty", "know", "communication", "sharing", "shared", "work", "hep", "participant", "people", "group", "service", "related", "challenge", "working", "interviewee", "finding", "page", "year", "collaboration", "-", "science", "described", "practice", "enables", "want", "data", "preservation", "study", "researcher", "technology", "colleague", "lhc", "system", "support", "research", "cern", "structure", "hci", "paper", "convener", "share", "knowledge", "access", "benefit"], "document_vector": [-89.584411, 23.165515], "paragraphs": [{"paragraph_vector": [84.018287, 1.060367], "paragraph_keywords": ["study", "research", "science", "studies"]}, {"paragraph_vector": [83.661666, 2.11275], "paragraph_keywords": ["data", "research", "reproducibility", "experiment"]}, {"paragraph_vector": [80.856422, 3.021343], "paragraph_keywords": ["reproducibility", "data", "publishing", "researchers"]}, {"paragraph_vector": [84.178344, -0.166042], "paragraph_keywords": ["research", "hci", "replication", "role"]}, {"paragraph_vector": [78.854232, 1.934932], "paragraph_keywords": ["data", "research", "study", "sharing"]}, {"paragraph_vector": [81.956932, 3.07313], "paragraph_keywords": ["lhc", "collaborations", "research", "cern"]}, {"paragraph_vector": [84.728057, 6.08138], "paragraph_keywords": ["data", "analysis", "cap", "preservation"]}, {"paragraph_vector": [83.791641, 5.837726], "paragraph_keywords": ["researchers", "interviewees", "cern", "working"]}, {"paragraph_vector": [85.095092, 7.704555], "paragraph_keywords": ["cern", "participants", "service", "analysis"]}, {"paragraph_vector": [89.810935, -1.884355], "paragraph_keywords": ["analysis", "analyses", "interviews", "transcriptions"]}, {"paragraph_vector": [89.723968, -11.050449], "paragraph_keywords": ["analysis", "paper", "groups", "communication"]}, {"paragraph_vector": [86.656311, 2.674212], "paragraph_keywords": ["preservation", "access", "analysis", "convener"]}, {"paragraph_vector": [96.727516, -7.479971], "paragraph_keywords": ["know", "colleagues", "communication", "information"]}, {"paragraph_vector": [85.813758, 4.951037], "paragraph_keywords": ["information", "documentation", "ask", "resources"]}, {"paragraph_vector": [85.888092, 8.024332], "paragraph_keywords": ["data", "analysis", "group", "resources"]}, {"paragraph_vector": [85.098114, 5.6952], "paragraph_keywords": ["analyses", "analysts", "communication", "dataset"]}, {"paragraph_vector": [82.73413, 23.419517], "paragraph_keywords": ["collaboration", "analyses", "lhc", "increase"]}, {"paragraph_vector": [84.409408, 14.489446], "paragraph_keywords": ["analysis", "course", "templates", "template"]}, {"paragraph_vector": [84.370216, 13.198088], "paragraph_keywords": ["analyses", "comparison", "want", "systematics"]}, {"paragraph_vector": [83.561622, 8.175791], "paragraph_keywords": ["analysis", "data", "analyses", "preservation"]}, {"paragraph_vector": [83.845909, 3.003052], "paragraph_keywords": ["researchers", "research", "preservation", "sharing"]}, {"paragraph_vector": [84.83139, 4.737238], "paragraph_keywords": ["preservation", "service", "data", "uncertainty"]}, {"paragraph_vector": [83.309913, 4.767749], "paragraph_keywords": ["research", "resources", "collaboration", "expertise"]}, {"paragraph_vector": [82.859161, 3.060842], "paragraph_keywords": ["preservation", "research", "policies", "workflows"]}, {"paragraph_vector": [85.551033, -0.970536], "paragraph_keywords": ["research", "create", "data", "incentive"]}, {"paragraph_vector": [82.617149, 2.347353], "paragraph_keywords": ["research", "reproducibility", "data", "study"]}, {"paragraph_vector": [84.145561, 3.412201], "paragraph_keywords": ["research", "preservation", "study", "data"]}], "content": {}, "doi": "10.1145/3290605.3300805"}, {"uri": "100", "title": "Anchored Audio Sampling", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Alexis Hiniker", "Jon E. Froehlich", "Mingrui Zhang", "Erin Beneteau"], "summary": "Many traditional HCI methods, such as surveys and interviews, are of limited value when working with preschoolers. In this paper, we present anchored audio sampling (AAS), a remote data collection technique for extracting qualitative audio samples during feld deployments with young children. AAS ofers a developmentally sensitive way of understanding how children make sense of technology and situates their use in the larger context of daily life. AAS is defned by an anchor event, around which audio is collected. A sliding window surrounding this anchor captures both antecedent and ensuing recording, providing the researcher insight into the activities that led up to the event of interest as well as those that followed. We present themes from three deployments that leverage this technique. Based on our experiences using AAS, we have also developed a reusable open-source library for embedding AAS into any Android application.", "keywords": ["library", "process", "capture", "child", "time", "moment", "method", "specifc", "app", "provide", "technique", "collect", "example", "user", "ui", "sample", "deployment", "work", "video", "recording", "participant", "aa", "use", "collection", "team", "control", "experience", "number", "antecedent", "function", "anchor", "feedback", "understand", "family", "data", "researcher", "study", "esm", "system", "support", "developer", "event", "research", "audio", "context"], "document_vector": [118.918289, 25.393142], "paragraphs": [{"paragraph_vector": [-165.690155, -53.091388], "paragraph_keywords": ["children", "data", "experiences", "engage"]}, {"paragraph_vector": [-161.976791, -54.389667], "paragraph_keywords": ["aas", "children", "data", "moments"]}, {"paragraph_vector": [102.593276, -53.130733], "paragraph_keywords": ["esm", "testing", "research", "users"]}, {"paragraph_vector": [-163.717346, -55.98524], "paragraph_keywords": ["data", "participants", "colleagues", "samples"]}, {"paragraph_vector": [-178.491622, -30.888246], "paragraph_keywords": ["children", "colleagues", "studies", "methods"]}, {"paragraph_vector": [-159.900787, -56.338775], "paragraph_keywords": ["user", "events", "anchor", "aas"]}, {"paragraph_vector": [-158.282958, -56.230415], "paragraph_keywords": ["child", "recording", "event", "data"]}, {"paragraph_vector": [-161.516677, -58.36058], "paragraph_keywords": ["participants", "feedback", "aas", "recording"]}, {"paragraph_vector": [-156.484939, -58.708763], "paragraph_keywords": ["data", "library", "anchor", "aas"]}, {"paragraph_vector": [-159.249832, -59.730255], "paragraph_keywords": ["recording", "developer", "research", "recordingmanager"]}, {"paragraph_vector": [-173.822845, -59.800884], "paragraph_keywords": ["video", "playlist", "recordings", "default"]}, {"paragraph_vector": [-157.188217, -33.968887], "paragraph_keywords": ["function", "use", "audio", "time"]}, {"paragraph_vector": [132.013595, -45.011821], "paragraph_keywords": ["study", "data", "transcripts", "studies"]}, {"paragraph_vector": [-155.78218, -17.977947], "paragraph_keywords": ["child", "children", "brush", "game"]}, {"paragraph_vector": [-170.285263, -57.134052], "paragraph_keywords": ["recording", "antecedent", "child", "echo"]}, {"paragraph_vector": [-161.467453, -56.38174], "paragraph_keywords": ["data", "participants", "aas", "hours"]}, {"paragraph_vector": [-167.420181, -58.133258], "paragraph_keywords": ["child", "participants", "aas", "study"]}, {"paragraph_vector": [-166.598876, -57.95243], "paragraph_keywords": ["data", "participants", "recording", "child"]}, {"paragraph_vector": [-162.57698, -58.217319], "paragraph_keywords": ["participants", "data", "study", "feedback"]}, {"paragraph_vector": [-164.850311, -54.652664], "paragraph_keywords": ["children", "study", "participants", "deployments"]}, {"paragraph_vector": [-162.154983, -56.245445], "paragraph_keywords": ["data", "aas", "accuracy", "event"]}, {"paragraph_vector": [-159.666091, -59.267959], "paragraph_keywords": ["data", "participants", "aas", "extent"]}, {"paragraph_vector": [-162.75859, -58.418987], "paragraph_keywords": ["participants", "study", "research", "awareness"]}, {"paragraph_vector": [-163.347198, -55.646778], "paragraph_keywords": ["researchers", "aas", "events", "interest"]}], "content": {}, "doi": "10.1145/3290605.3300366"}, {"uri": "101", "title": "An Evaluation of Touch Input at the Edge of a Table", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Nikhita Joshi"], "summary": "Tables, desks, and counters are often nearby, motivating their use as interactive surfaces. However, they are typically cluttered. As an alternative, we explore touch input along the \u2018edge\u2019 of table-like surfaces. The performance of tapping, crossing, and dragging is tested along the two ridges and front face of a table edge. Results show top ridge movement time is comparable to the top face when tapping or dragging. When crossing, both ridges are at least 11% faster than the top face. Effective width analysis is used to model performance and provide recommended target sizes. Based on observed user behaviour, variations of top and bottom ridge crossing are explored in a second study, and design recommendations with example applications are provided.", "keywords": ["ridge", "time", "finger", "posture", "tap", "tapping", "cross", "experiment", "error", "touch", "user", "surface", "interaction", "work", "participant", "use", "contact", "page", "dragging", "trial", "face", "block", "crossing", "task", "hand", "t", "table", "study", "system", "thumb", "target", "sar", "input", "index", "edge"], "document_vector": [78.535629, -71.440811], "paragraphs": [{"paragraph_vector": [-43.085937, 15.656726], "paragraph_keywords": ["surface", "interaction", "table", "copies"]}, {"paragraph_vector": [-42.004661, 16.216529], "paragraph_keywords": ["edge", "touch", "table", "dragging"]}, {"paragraph_vector": [-42.334186, 20.019172], "paragraph_keywords": ["surfaces", "user", "input", "touch"]}, {"paragraph_vector": [-45.433467, 20.060392], "paragraph_keywords": ["surfaces", "touch", "input", "ridges"]}, {"paragraph_vector": [-43.37701, 18.622848], "paragraph_keywords": ["table", "touch", "edge", "input"]}, {"paragraph_vector": [-42.74966, 17.05788], "paragraph_keywords": ["finger", "table", "projection", "projector"]}, {"paragraph_vector": [-50.2205, 16.178163], "paragraph_keywords": ["finger", "table", "crossing", "touch"]}, {"paragraph_vector": [-32.312133, 18.778528], "paragraph_keywords": ["target", "task", "errors", "finger"]}, {"paragraph_vector": [-30.125606, 13.967004], "paragraph_keywords": ["task", "d", "face", "w"]}, {"paragraph_vector": [-24.977209, 20.864286], "paragraph_keywords": ["crossing", "trials", "error", "task"]}, {"paragraph_vector": [-26.544696, 13.982358], "paragraph_keywords": ["differences", "p", "face", "difference"]}, {"paragraph_vector": [-30.414541, 14.347801], "paragraph_keywords": ["p", "ridge", "error", "task"]}, {"paragraph_vector": [-26.070539, 19.545061], "paragraph_keywords": ["crossing", "surfaces", "condorcet", "ranked"]}, {"paragraph_vector": [-26.195547, 16.146621], "paragraph_keywords": ["face", "target", "time", "task"]}, {"paragraph_vector": [-28.886329, 17.331504], "paragraph_keywords": ["ridge", "t", "learning", "participants"]}, {"paragraph_vector": [-34.780597, 17.148017], "paragraph_keywords": ["crossing", "participants", "ridge", "face"]}, {"paragraph_vector": [-34.765243, 15.949987], "paragraph_keywords": ["experiment", "face", "posture", "task"]}, {"paragraph_vector": [-25.326381, 17.57763], "paragraph_keywords": ["block", "p", "task", "error"]}, {"paragraph_vector": [-29.704204, 16.831731], "paragraph_keywords": ["ridge", "factor", "cross", "posture"]}, {"paragraph_vector": [-35.166679, 14.675356], "paragraph_keywords": ["error", "posture", "pointing", "ridge"]}, {"paragraph_vector": [-32.813137, 14.709125], "paragraph_keywords": ["hand", "posture", "ridge", "wrist"]}, {"paragraph_vector": [-36.238914, 14.201847], "paragraph_keywords": ["face", "notification", "ridge", "adjust"]}, {"paragraph_vector": [-42.144187, 13.954095], "paragraph_keywords": ["input", "edge", "touch", "finger"]}, {"paragraph_vector": [-42.703227, 17.419538], "paragraph_keywords": ["table", "surfaces", "help", "work"]}], "content": {}, "doi": "10.1145/3290605.3300429"}, {"uri": "102", "title": "Relations are more than Bytes: Re-thinking the Benefits of Smart Services with People and Things", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Claude P. R. Heath"], "summary": "Critical approaches to smart technologies have emerged in HCI that question the conditions necessary for smart technologies to benefit people. Smart services rely on a relation of trust and sense of security between people and technology requiring a more expansive definition of security. Using established design methods, we worked with two residents\u2019 groups to critically explore and rethink smart services in the home and city. From our data analysis, we derive insights about perceptions and understandings of trust, privacy and security of smart devices, and identify how technological security needs to work in concert with social and relational forms of security for smart services to be effective. We conclude with an orientation for HCI that focuses on designing services for and with smart people and things.", "keywords": ["sunderland", "requires", "vision", "civics", "design", "literature", "analysis", "reflect", "home", "socio", "example", "help", "model", "engagement", "trust", "government", "brixton", "shared", "capability", "work", "space", "participant", "use", "people", "resulting", "group", "service", "way", "given", "challenge", "sense", "security", "form", "-", "develop", "described", "citizen", "data", "technology", "study", "approach", "said", "support", "system", "research", "order", "hci", "individual", "paper", "question", "lego", "value", "city", "community", "benefit"], "document_vector": [87.216842, 48.678165], "paragraphs": [{"paragraph_vector": [80.091262, -63.658073], "paragraph_keywords": ["copies", "work", "technologies", "data"]}, {"paragraph_vector": [79.304695, -60.886054], "paragraph_keywords": ["security", "technologies", "civics", "paper"]}, {"paragraph_vector": [77.414894, -66.469238], "paragraph_keywords": ["city", "citizenship", "citizens", "data"]}, {"paragraph_vector": [79.276008, -60.294956], "paragraph_keywords": ["technologies", "technology", "hci", "capabilities"]}, {"paragraph_vector": [84.451736, -62.146762], "paragraph_keywords": ["security", "civics", "focus", "trust"]}, {"paragraph_vector": [79.652778, -61.546554], "paragraph_keywords": ["security", "trust", "hobbes", "building"]}, {"paragraph_vector": [82.213211, -59.385635], "paragraph_keywords": ["study", "security", "east", "north"]}, {"paragraph_vector": [75.571533, -50.850719], "paragraph_keywords": ["challenges", "sunderland", "pallion", "borough"]}, {"paragraph_vector": [-135.834854, -25.082635], "paragraph_keywords": ["participants", "reflect", "community", "technology"]}, {"paragraph_vector": [102.205474, -50.449951], "paragraph_keywords": ["participants", "research", "services", "use"]}, {"paragraph_vector": [104.273628, -64.397155], "paragraph_keywords": ["participants", "data", "models", "gathered"]}, {"paragraph_vector": [73.049232, -67.754226], "paragraph_keywords": ["technology", "participants", "technologies", "community"]}, {"paragraph_vector": [40.208972, -62.289562], "paragraph_keywords": ["technology", "participants", "participant", "help"]}, {"paragraph_vector": [78.034248, -63.167366], "paragraph_keywords": ["people", "community", "having", "awareness"]}, {"paragraph_vector": [-93.545005, -89.667289], "paragraph_keywords": ["technology", "sunderland", "home", "participant"]}, {"paragraph_vector": [27.094287, -51.849567], "paragraph_keywords": ["data", "model", "technology", "bank"]}, {"paragraph_vector": [106.560188, -61.432167], "paragraph_keywords": ["measures", "technologies", "monitoring", "system"]}, {"paragraph_vector": [69.883102, -86.006416], "paragraph_keywords": ["lack", "technology", "library", "example"]}, {"paragraph_vector": [-91.485466, -89.186103], "paragraph_keywords": ["benefits", "space", "shared", "technologies"]}, {"paragraph_vector": [82.643539, -58.700214], "paragraph_keywords": ["socio", "design", "participants", "technology"]}, {"paragraph_vector": [83.047485, -60.551467], "paragraph_keywords": ["capability", "analysis", "work", "people"]}, {"paragraph_vector": [86.251304, -58.694545], "paragraph_keywords": ["state", "security", "communities", "sense"]}, {"paragraph_vector": [85.158691, -62.712753], "paragraph_keywords": ["security", "services", "forms", "trade"]}, {"paragraph_vector": [78.479743, -60.689987], "paragraph_keywords": ["security", "technologies", "models", "values"]}, {"paragraph_vector": [84.530395, -64.860519], "paragraph_keywords": ["technologies", "security", "discussions", "values"]}, {"paragraph_vector": [80.918701, -62.913303], "paragraph_keywords": ["time", "security", "research", "thank"]}], "content": {}, "doi": "10.1145/3290605.3300789"}, {"uri": "103", "title": "Some Prior(s) Experience Necessary", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Chanda Phelan", "Jessica Hullman"], "summary": "Bayesian statistical analysis has gained attention in recent years, including in HCI. The Bayesian approach has several advantages over traditional statistics, including producing results with more intuitive interpretations. Despite growing interest, few papers in CHI use Bayesian analysis. Existing tools to learn Bayesian statistics require significant time investment, making it difficult to casually explore Bayesian methods. Here, we present a tool that lowers the barrier to exploration: a set of R code templates that guide Bayesian novices through their first analysis. The templates are tailored to CHI, supporting analyses found to be most common in recent CHI papers. In a user study, we found that the templates were easy to understand and use. However, we found that participants without a statistical background were not confident in their use. Together our contributions provide a concise analysis tool and empirical results for understanding and addressing barriers to using Bayesian analysis in HCI.", "keywords": ["process", "bayesian", "information", "set", "distribution", "section", "method", "analysis", "example", "user", "model", "result", "work", "participant", "use", "statistic", "people", "prior", "confidence", "effect", "learning", "way", "size", "template", "found", "complete", "understand", "chi", "parameter", "data", "study", "researcher", "testing", "setting", "said", "student", "frequentist", "research", "r", "paper", "background", "knowledge", "code"], "document_vector": [-121.037727, 0.736103], "paragraphs": [{"paragraph_vector": [37.460197, 57.685691], "paragraph_keywords": ["bayesian", "copies", "statistics", "approach"]}, {"paragraph_vector": [34.806858, 62.078884], "paragraph_keywords": ["research", "bayesian", "analysis", "knowledge"]}, {"paragraph_vector": [34.453544, 64.172752], "paragraph_keywords": ["bayesian", "user", "analysis", "templates"]}, {"paragraph_vector": [44.366771, 62.323188], "paragraph_keywords": ["priors", "data", "bayesian", "parameters"]}, {"paragraph_vector": [44.030544, 65.018836], "paragraph_keywords": ["bayesian", "analysis", "intervals", "frequentist"]}, {"paragraph_vector": [29.238071, 63.965206], "paragraph_keywords": ["bayesian", "studies", "effect", "analysis"]}, {"paragraph_vector": [40.857604, 60.811378], "paragraph_keywords": ["learning", "bayesian", "students", "example"]}, {"paragraph_vector": [39.692829, 62.972984], "paragraph_keywords": ["templates", "bayesian", "statistics", "template"]}, {"paragraph_vector": [156.173049, 65.68814], "paragraph_keywords": ["code", "analysis", "templates", "model"]}, {"paragraph_vector": [34.764167, 63.78907], "paragraph_keywords": ["model", "chi", "papers", "tests"]}, {"paragraph_vector": [34.345813, 64.831741], "paragraph_keywords": ["analyses", "code", "priors", "setting"]}, {"paragraph_vector": [31.900737, 69.589508], "paragraph_keywords": ["priors", "section", "hops", "uncertainty"]}, {"paragraph_vector": [41.87199, 64.154968], "paragraph_keywords": ["bayesian", "participants", "use", "analysis"]}, {"paragraph_vector": [45.784351, 61.952938], "paragraph_keywords": ["participants", "datasets", "template", "published"]}, {"paragraph_vector": [42.42171, 61.434196], "paragraph_keywords": ["participants", "analysis", "use", "asked"]}, {"paragraph_vector": [37.528968, 60.642837], "paragraph_keywords": ["participants", "analyses", "template", "testing"]}, {"paragraph_vector": [49.886596, 61.616851], "paragraph_keywords": ["template", "said", "users", "participants"]}, {"paragraph_vector": [39.505676, 64.457038], "paragraph_keywords": ["priors", "participants", "template", "analysis"]}, {"paragraph_vector": [37.163665, 65.942703], "paragraph_keywords": ["priors", "set", "template", "analysis"]}, {"paragraph_vector": [40.440326, 62.169166], "paragraph_keywords": ["priors", "bayesian", "information", "users"]}, {"paragraph_vector": [45.361343, 61.84991], "paragraph_keywords": ["templates", "learning", "bayesian", "analysis"]}, {"paragraph_vector": [39.321933, 58.390007], "paragraph_keywords": ["template", "user", "bayesian", "analyses"]}, {"paragraph_vector": [33.802581, 66.804107], "paragraph_keywords": ["priors", "participants", "analysis", "distribution"]}, {"paragraph_vector": [39.77214, 61.282157], "paragraph_keywords": ["bayesian", "templates", "statistics", "adoption"]}], "content": {}, "doi": "10.1145/3290605.3300639"}, {"uri": "104", "title": "AWalk on the Child Side: Investigating Parents\u2019 and Children\u2019s Experience and Perspective on Mobile Technology for Outdoor Child Independent Mobility", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Michela Ferron", "Chiara Leonardi", "Elisabetta Farella", "Paolo Massa", "Gianluca Schiavo", "Amy L. Murphy"], "summary": "Technology increasingly offers parents opportunities to monitor children, reshaping the way control and autonomy are negotiated within families. This paper investigates the views of parents and primary school children on mobile technology designed to support child independent mobility in the context of the local walking school buses. Based on a schoolyear long field study, we report findings on children\u2019s and parents\u2019 experience with proximity detection devices. The results provide insights into how the parents and children accepted and socially appropriated the technology into the walking school bus activity, shedding light on the way they understand and conceptualize a technology that collects data on children\u2019s proximity to the volunteers\u2019 smartphone. We discuss parents\u2019 needs and concerns around monitoring technologies and the related challenges in terms of trust-control balance. These insights are elaborated to inform the future design of technology for child independent mobility.", "keywords": ["based", "child", "mobility", "need", "time", "parenting", "mother", "location", "style", "app", "interview", "bus", "problem", "relationship", "example", "sensor", "activity", "trust", "school", "work", "drawing", "use", "proximity", "detection", "way", "control", "walking", "experience", "page", "smartphone", "tracking", "monitoring", "autonomy", "volunteer", "device", "data", "technology", "study", "parent", "support", "gps", "research", "adult", "surveillance", "paper", "privacy", "observation", "value"], "document_vector": [135.181427, 35.42271], "paragraphs": [{"paragraph_vector": [-169.305389, -56.795936], "paragraph_keywords": ["children", "parents", "copies", "acm"]}, {"paragraph_vector": [-171.725738, -58.2444], "paragraph_keywords": ["children", "technology", "walking", "bus"]}, {"paragraph_vector": [-170.784423, -59.113979], "paragraph_keywords": ["parents", "children", "technology", "tracking"]}, {"paragraph_vector": [-178.896942, -57.683738], "paragraph_keywords": ["children", "tracking", "trust", "parenting"]}, {"paragraph_vector": [-173.174148, -59.006259], "paragraph_keywords": ["children", "parenting", "privacy", "styles"]}, {"paragraph_vector": [-169.916015, -61.492622], "paragraph_keywords": ["children", "parents", "technology", "school"]}, {"paragraph_vector": [-169.975357, -57.874591], "paragraph_keywords": ["children", "school", "child", "bus"]}, {"paragraph_vector": [-170.635803, -58.155628], "paragraph_keywords": ["observations", "technology", "observed", "interviews"]}, {"paragraph_vector": [-176.272552, -60.31483], "paragraph_keywords": ["children", "parents", "technology", "interviews"]}, {"paragraph_vector": [159.919708, -51.395553], "paragraph_keywords": ["data", "children", "parents", "approach"]}, {"paragraph_vector": [170.415878, -57.004993], "paragraph_keywords": ["children", "devices", "device", "walking"]}, {"paragraph_vector": [-168.878021, -57.397682], "paragraph_keywords": ["children", "technology", "parents", "drawings"]}, {"paragraph_vector": [-174.550674, -60.768615], "paragraph_keywords": ["children", "technology", "app", "volunteer"]}, {"paragraph_vector": [-169.430831, -58.105472], "paragraph_keywords": ["children", "app", "smartphone", "stop"]}, {"paragraph_vector": [-172.747787, -61.213874], "paragraph_keywords": ["children", "app", "technology", "parents"]}, {"paragraph_vector": [-171.316253, -57.830921], "paragraph_keywords": ["children", "parents", "need", "autonomy"]}, {"paragraph_vector": [-170.923141, -55.982326], "paragraph_keywords": ["children", "parents", "trust", "bus"]}, {"paragraph_vector": [-170.574386, -58.284938], "paragraph_keywords": ["technology", "autonomy", "parents", "children"]}, {"paragraph_vector": [-171.696853, -58.270156], "paragraph_keywords": ["children", "autonomy", "parents", "child"]}, {"paragraph_vector": [-169.327468, -59.339984], "paragraph_keywords": ["device", "data", "parents", "children"]}, {"paragraph_vector": [-172.985763, -59.245182], "paragraph_keywords": ["parenting", "children", "technology", "trust"]}, {"paragraph_vector": [-170.250534, -58.89212], "paragraph_keywords": ["parents", "children", "bus", "technology"]}, {"paragraph_vector": [-178.608062, -58.688549], "paragraph_keywords": ["children", "technology", "need", "surveillance"]}, {"paragraph_vector": [-171.857803, -57.359527], "paragraph_keywords": ["parents", "children", "detection", "technology"]}], "content": {}, "doi": "10.1145/3290605.3300893"}, {"uri": "105", "title": "An Autonomy-Perspective on the Design of Assistive Technology: Experiences of People with Multiple Sclerosis", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Florian G\u00fcldenpfennig", "Peter Mayer", "Paul Panek"], "summary": "In HCI and Assistive Technology design, autonomy is regularly equated with independence. This is a shortcut and leaves out design opportunities by omitting a more nuanced idea of autonomy. To improve our understanding of how people with severe physical disabilities experience autonomy, particularly in the context of Assistive Technologies, we engaged in in-depth fieldwork with 15 people with Multiple Sclerosis who were used to assistive devices. We constructed a grounded theory from a series of interviews, focus groups and observations, pointing to strategies in which participants sought autonomy either in the short-term (managing their daily energy reserve) or in the long-term (making future plans). The theory shows how factors like enabling technologies, capital (human, social, psychological resources), and compatibility with daily practices facilitated a sense of being in control for our participants. Moreover, we show how over-ambitious or bad design (e.g., paternalism) can lead to opposite results and restrict autonomy.", "keywords": ["strategy", "time", "reserve", "person", "resource", "self", "section", "design", "literature", "analysis", "interview", "care", "category", "aal", "example", "help", "goal", "theory", "capital", "conducted", "work", "decision", "participant", "use", "patient", "people", "exercising", "m", "energy", "idea", "concept", "sense", "daycare", "control", "finding", "page", "according", "understanding", "life", "autonomy", "value", "described", "hand", "want", "toilet", "data", "technology", "study", "disability", "routine", "grounded", "support", "independence", "system", "research", "term", "coding", "order", "hci", "paper", "healthcare", "project", "center", "context"], "document_vector": [99.660842, 61.790378], "paragraphs": [{"paragraph_vector": [-158.223281, -35.109493], "paragraph_keywords": ["autonomy", "aal", "copies", "work"]}, {"paragraph_vector": [-160.328872, -38.30043], "paragraph_keywords": ["design", "people", "autonomy", "ms"]}, {"paragraph_vector": [-179.556686, -42.7355], "paragraph_keywords": ["autonomy", "design", "hci", "people"]}, {"paragraph_vector": [-164.576553, -38.590648], "paragraph_keywords": ["autonomy", "design", "life", "people"]}, {"paragraph_vector": [140.189727, -34.901172], "paragraph_keywords": ["autonomy", "person", "autonomia", "idea"]}, {"paragraph_vector": [159.327194, -37.024421], "paragraph_keywords": ["autonomy", "decisions", "caregivers", "collopy"]}, {"paragraph_vector": [-161.626739, -38.55009], "paragraph_keywords": ["ms", "section", "fatigue", "management"]}, {"paragraph_vector": [-159.568984, -35.211982], "paragraph_keywords": ["project", "toilet", "technology", "user"]}, {"paragraph_vector": [-163.289718, -38.690208], "paragraph_keywords": ["participants", "people", "research", "disability"]}, {"paragraph_vector": [-159.53189, -36.060997], "paragraph_keywords": ["toilet", "interviews", "daycare", "center"]}, {"paragraph_vector": [-162.057571, -36.505558], "paragraph_keywords": ["interviews", "notes", "participants", "analysis"]}, {"paragraph_vector": [-176.128799, -45.847442], "paragraph_keywords": ["data", "theory", "coding", "research"]}, {"paragraph_vector": [143.730087, -32.234199], "paragraph_keywords": ["categories", "coding", "energy", "data"]}, {"paragraph_vector": [-160.950973, -37.63058], "paragraph_keywords": ["life", "term", "people", "technologies"]}, {"paragraph_vector": [-162.379394, -37.2322], "paragraph_keywords": ["participants", "categories", "care", "taking"]}, {"paragraph_vector": [-169.556411, -32.184318], "paragraph_keywords": ["use", "interviews", "toilet", "things"]}, {"paragraph_vector": [-160.354293, -33.896354], "paragraph_keywords": ["exercising", "example", "participants", "capital"]}, {"paragraph_vector": [-159.759933, -35.183204], "paragraph_keywords": ["technology", "participants", "way", "energy"]}, {"paragraph_vector": [-161.190017, -35.674442], "paragraph_keywords": ["technology", "participants", "toilet", "people"]}, {"paragraph_vector": [-172.876052, -31.813798], "paragraph_keywords": ["fall", "feel", "participants", "routines"]}, {"paragraph_vector": [-164.537628, -40.26955], "paragraph_keywords": ["routines", "capital", "participants", "resources"]}, {"paragraph_vector": [-164.315887, -39.346195], "paragraph_keywords": ["technology", "help", "family", "pointed"]}, {"paragraph_vector": [-171.94609, -38.253955], "paragraph_keywords": ["technology", "time", "favors", "help"]}, {"paragraph_vector": [-160.874694, -37.82233], "paragraph_keywords": ["autonomy", "designers", "design", "participants"]}, {"paragraph_vector": [-162.215133, -38.436061], "paragraph_keywords": ["autonomy", "people", "supporting", "independence"]}, {"paragraph_vector": [179.647842, -37.604732], "paragraph_keywords": ["autonomy", "people", "researchers", "theory"]}, {"paragraph_vector": [-162.900466, -40.850948], "paragraph_keywords": ["autonomy", "findings", "research", "inhibitors"]}, {"paragraph_vector": [129.47322, -46.875663], "paragraph_keywords": ["autonomy", "research", "hci", "work"]}], "content": {}, "doi": "10.1145/3290605.3300402"}, {"uri": "106", "title": "App Usage Predicts Cognitive Ability in Older Adults", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Mitchell L. Gordon", "Leon Gatys", "Carlos Guestrin", "Jeffrey P. Bigham", "Andrew Trister"], "summary": "Wehave limited understanding of how older adults use smartphones, how their usage differs from younger users, and the causes for those differences. As a result, researchers and developers may miss promising opportunities to support older adults or offer solutions to unimportant problems. To characterize smartphone usage among older adults, we collected iPhone usage data from 84 healthy older adults over three months. We find that older adults use fewer apps, take longer to complete tasks, and send fewer messages. We use cognitive test results from these same older adults to then show that up to 79% of these differences can be explained by cognitive decline, and that we can predict cognitive test performance from smartphone usage with 83% ROCAUC. While older adults differ from younger adults in app usage behavior, the \u201ccognitively young\u201d older adults use smartphones much like their younger counterparts. Our study suggests that to better support all older adults, researchers and developers should consider the full spectrum of cognitive function. ACM Reference Format: Mitchell L. Gordon, Leon Gatys, Carlos Guestrin, Jeffrey P. Bigham, Andrew Trister, and Kayur Patel. 2019. App Usage Predicts Cognitive Ability in Older Adults. In CHI Conference on Human Factors in Computing Systems Proceedings (CHI 2019), May 4\u20139, 2019, Glasgow, Scotland UK. ACM, New York, NY, USA, 12 pages. https: //doi.org/10.1145/3290605.3300398", "keywords": ["time", "population", "al", "find", "ability", "phone", "memory", "feature", "app", "analysis", "duration", "experiment", "morrison", "user", "launch", "et", "apps", "work", "result", "use", "participant", "learning", "iphone", "page", "number", "dataset", "application", "function", "found", "-", "age", "usage", "task", "smartphones", "data", "day", "technology", "study", "switch", "pattern", "adult", "difference", "paper", "behavior", "level"], "document_vector": [-29.689689, -13.771183], "paragraphs": [{"paragraph_vector": [-24.766222, -59.919456], "paragraph_keywords": ["adults", "usage", "applications", "work"]}, {"paragraph_vector": [-23.454317, -57.61325], "paragraph_keywords": ["usage", "adults", "function", "differences"]}, {"paragraph_vector": [-24.222454, -57.285511], "paragraph_keywords": ["adults", "work", "apps", "usage"]}, {"paragraph_vector": [-25.903778, -78.557487], "paragraph_keywords": ["usage", "adults", "iphone", "use"]}, {"paragraph_vector": [-22.316375, -57.372505], "paragraph_keywords": ["adults", "use", "found", "usage"]}, {"paragraph_vector": [-27.296779, -56.652976], "paragraph_keywords": ["usage", "app", "patterns", "level"]}, {"paragraph_vector": [-24.111734, -57.659996], "paragraph_keywords": ["participants", "app", "launch", "paper"]}, {"paragraph_vector": [-27.413415, -68.223144], "paragraph_keywords": ["adults", "category", "apps", "usage"]}, {"paragraph_vector": [-31.549018, -66.852478], "paragraph_keywords": ["usage", "found", "apps", "app"]}, {"paragraph_vector": [-33.125926, -66.062088], "paragraph_keywords": ["app", "apps", "switches", "patterns"]}, {"paragraph_vector": [-29.023595, -69.004135], "paragraph_keywords": ["switches", "app", "apps", "users"]}, {"paragraph_vector": [-24.833904, -58.06958], "paragraph_keywords": ["task", "adults", "usage", "paper"]}, {"paragraph_vector": [-23.06147, -58.454284], "paragraph_keywords": ["group", "adults", "data", "scores"]}, {"paragraph_vector": [-22.433097, -57.556537], "paragraph_keywords": ["adults", "difference", "usage", "apps"]}, {"paragraph_vector": [-24.267597, -59.170139], "paragraph_keywords": ["found", "memory", "duration", "working"]}, {"paragraph_vector": [-21.701911, -57.0158], "paragraph_keywords": ["adults", "apps", "ability", "night"]}, {"paragraph_vector": [-20.017126, -58.084156], "paragraph_keywords": ["roc", "user", "auc", "models"]}, {"paragraph_vector": [-22.106107, -59.50938], "paragraph_keywords": ["app", "usage", "apps", "feature"]}, {"paragraph_vector": [-23.467433, -59.005264], "paragraph_keywords": ["results", "confounders", "compare", "participants"]}, {"paragraph_vector": [-22.265876, -58.908805], "paragraph_keywords": ["adults", "usage", "patterns", "smartphones"]}, {"paragraph_vector": [-22.429801, -58.667953], "paragraph_keywords": ["adults", "differences", "usage", "apps"]}], "content": {}, "doi": "10.1145/3290605.3300307"}, {"uri": "107", "title": "Unobtrusively Enhancing Reflection-in-Action of Teachers through Spatially Distributed Ambient Information", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Pengcheng An", "Saskia Bakker", "Sara Ordanovski", "Ruurd Taconis", "Chris L.E. Paffen", "Berry Eggen"], "summary": "Reflecting on their performance during classroom-teaching is an important competence for teachers. Such reflection-inaction (RiA) enables them to optimize teaching on the spot. But RiA is also challenging, demanding extra thinking in teachers\u2019 already intensive routines. Little is known on how HCI systems can facilitate teachers\u2019 RiA during classroomteaching. To fill in this gap, we evaluate ClassBeacons, a system that uses spatially distributed lamps to depict teachers\u2019 ongoing performance on how they have divided their time and attention over students in the classroom. Empirical qualitative data from eleven teachers in 22 class periods show that this ambient information facilitated teachers\u2019 RiA without burdening teaching in progress. Based on our theoretical grounding and field evaluation, we contribute empirical knowledge about how an HCI system enhanced teachers\u2019 process of RiA as well as a set of design principles for unobtrusively supporting RiA. CCS CONCEPTS \u2022 Applied computing~Computer-assisted instruction \u2022 Human-centered computing~Field studies; Displays and imagers", "keywords": ["reflection", "process", "time", "information", "performance", "distribution", "display", "design", "reflect", "example", "help", "spot", "work", "use", "proximity", "group", "distributed", "lamp", "page", "teacher", "practitioner", "feedback", "teaching", "principle", "classroom", "supported", "task", "attention", "practice", "data", "ria", "lesson", "study", "classbeacons", "student", "system", "support", "hci", "paper", "action", "context", "figure"], "document_vector": [-175.1725, 19.036046], "paragraphs": [{"paragraph_vector": [-175.623184, 21.323036], "paragraph_keywords": ["teaching", "teachers", "copies", "ria"]}, {"paragraph_vector": [-174.186569, 18.931852], "paragraph_keywords": ["teachers", "ria", "performance", "action"]}, {"paragraph_vector": [-177.500076, 14.281582], "paragraph_keywords": ["teachers", "ria", "action", "situation"]}, {"paragraph_vector": [-176.722213, 17.090951], "paragraph_keywords": ["teachers", "teaching", "reflection", "ria"]}, {"paragraph_vector": [-175.980651, 18.076009], "paragraph_keywords": ["teachers", "information", "technology", "displays"]}, {"paragraph_vector": [-172.773971, 17.872236], "paragraph_keywords": ["teachers", "information", "ria", "support"]}, {"paragraph_vector": [-175.468444, 19.513109], "paragraph_keywords": ["teacher", "lesson", "figure", "time"]}, {"paragraph_vector": [-172.55162, 21.679702], "paragraph_keywords": ["proximity", "teacher", "lamp", "teachers"]}, {"paragraph_vector": [-175.285507, 19.133623], "paragraph_keywords": ["teachers", "classbeacons", "design", "proximity"]}, {"paragraph_vector": [-175.088577, 16.561372], "paragraph_keywords": ["classbeacons", "teaching", "teachers", "existing"]}, {"paragraph_vector": [-174.268005, 14.733216], "paragraph_keywords": ["classbeacons", "data", "asked", "experiences"]}, {"paragraph_vector": [-173.346511, 18.943115], "paragraph_keywords": ["performance", "lesson", "action", "confirm"]}, {"paragraph_vector": [-175.407028, 18.660865], "paragraph_keywords": ["classbeacons", "teachers", "action", "proximity"]}, {"paragraph_vector": [-174.523071, 20.609165], "paragraph_keywords": ["classbeacons", "notice", "way", "patterns"]}, {"paragraph_vector": [-173.640655, 17.453941], "paragraph_keywords": ["students", "classbeacons", "attention", "teachers"]}, {"paragraph_vector": [-174.546676, 18.839502], "paragraph_keywords": ["classbeacons", "students", "design", "principles"]}, {"paragraph_vector": [-174.868972, 19.719087], "paragraph_keywords": ["feedback", "classbeacons", "reflect", "time"]}, {"paragraph_vector": [-173.883361, 19.688863], "paragraph_keywords": ["teachers", "action", "attention", "classbeacons"]}, {"paragraph_vector": [-175.622665, 17.346584], "paragraph_keywords": ["classbeacons", "teachers", "classroom", "midst"]}, {"paragraph_vector": [-174.848434, 19.75457], "paragraph_keywords": ["classbeacons", "teachers", "teaching", "information"]}, {"paragraph_vector": [-177.220153, 18.788433], "paragraph_keywords": ["classbeacons", "students", "teachers", "time"]}, {"paragraph_vector": [-174.496856, 18.703607], "paragraph_keywords": ["teachers", "classbeacons", "action", "ria"]}, {"paragraph_vector": [-173.31575, 20.189224], "paragraph_keywords": ["teachers", "teacher", "ria", "system"]}, {"paragraph_vector": [-172.329025, 16.101371], "paragraph_keywords": ["teachers", "information", "offloaded", "space"]}, {"paragraph_vector": [-172.76361, 17.613494], "paragraph_keywords": ["design", "teachers", "system", "studies"]}, {"paragraph_vector": [-173.481277, 17.671346], "paragraph_keywords": ["teachers", "design", "principles", "classbeacons"]}], "content": {}, "doi": "10.1145/3290605.3300488"}, {"uri": "108", "title": "ElasticVR: Providing Multilevel Continuously-Changing Resistive Force and Instant Impact Using Elasticity for VR", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Hsin-Ruey Tsai", "Jun Rekimoto", "Bing-Yu Chen"], "summary": "Resistive force (e.g., due to object elasticity) and impact (e.g., due to recoil) are common e ects in our daily life. However, resistive force continuously changes due to users\u2019 movements while impact instantly occurs when an event triggers it. These feedback are still not realistically provided by current VR haptic methods. In this paper, a wearable device, ElasticVR, which consists of an elastic band, servo motors and mechanical brakes, is proposed to provide the continuouslychanging resistive force and instantly-occurring impact upon the user\u2019s hand to enhance VR realism. By changing two physical properties, length and extension distance, of the elastic band, ElasticVR provides multilevel resistive force with no delay and impact with little delay, respectively, for realistic and versatile VR applications. A force perception study was performed to observe users\u2019 force distinguishability of the resistive force and impact, and the prototype was built based on its results. A VR experience study further proves that the resistive force and impact from ElasticVR both outperform those from current approaches in realism. Applications using ElasticVR are also demonstrated.", "keywords": ["vr", "controller", "object", "elasticvr", "force", "brake", "provide", "erent", "em", "power", "user", "wire", "extension", "impact", "motor", "movement", "participant", "e", "control", "provides", "band", "feedback", "provided", "stimulus", "pressing", "hand", "study", "rotation", "ball", "delay", "prototype", "di", "level", "figure"], "document_vector": [127.009353, -57.592456], "paragraphs": [{"paragraph_vector": [-96.023117, 16.019231], "paragraph_keywords": ["force", "objects", "copies", "impact"]}, {"paragraph_vector": [-99.441108, 14.761335], "paragraph_keywords": ["force", "impact", "motors", "band"]}, {"paragraph_vector": [-98.599708, 12.561275], "paragraph_keywords": ["force", "provide", "feedback", "vr"]}, {"paragraph_vector": [-94.303314, 13.071381], "paragraph_keywords": ["force", "motors", "control", "provide"]}, {"paragraph_vector": [-98.538993, 13.838446], "paragraph_keywords": ["impact", "force", "provide", "motors"]}, {"paragraph_vector": [-96.546798, 15.279713], "paragraph_keywords": ["force", "band", "hand", "brake"]}, {"paragraph_vector": [-93.609222, 18.08344], "paragraph_keywords": ["brake", "wire", "band", "motor"]}, {"paragraph_vector": [-98.0597, 13.832074], "paragraph_keywords": ["force", "brake", "movement", "impact"]}, {"paragraph_vector": [-95.176956, 12.133732], "paragraph_keywords": ["force", "prototype", "study", "users"]}, {"paragraph_vector": [-95.442657, 17.116954], "paragraph_keywords": ["force", "band", "extension", "cm"]}, {"paragraph_vector": [-95.826309, 12.99028], "paragraph_keywords": ["force", "stimuli", "study", "band"]}, {"paragraph_vector": [-94.687873, 11.797857], "paragraph_keywords": ["force", "results", "impact", "feedback"]}, {"paragraph_vector": [-92.417564, 14.311902], "paragraph_keywords": ["force", "balls", "feedback", "study"]}, {"paragraph_vector": [-95.9533, 12.918282], "paragraph_keywords": ["power", "pressing", "feedback", "likert"]}, {"paragraph_vector": [-91.261856, 10.162415], "paragraph_keywords": ["force", "e", "v", "signi"]}, {"paragraph_vector": [-96.48188, 13.039573], "paragraph_keywords": ["force", "impact", "e", "recoil"]}, {"paragraph_vector": [-96.40982, 10.406833], "paragraph_keywords": ["force", "users", "ball", "impact"]}, {"paragraph_vector": [-96.436416, 12.901042], "paragraph_keywords": ["elasticvr", "force", "impact", "provide"]}, {"paragraph_vector": [72.445991, 32.835597], "paragraph_keywords": ["taiwan", "national", "technology", "university"]}], "content": {}, "doi": "10.1145/3290605.3300837"}, {"uri": "109", "title": "Local Standards for Anonymization Practices in Health, Wellness, Accessibility, and Aging Research at CHI", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jacob Abbott", "Haley MacLeod", "Novia Nurain", "Gustave Ekobe", "Sameer Patil"], "summary": "When studying technologies pertaining to health, wellness, accessibility, and aging, researchers are often required to perform a balancing act between controlling and sharing sensitive data of the people in their studies and protecting the privacy of these participants. If the data can be anonymized and shared, it can boost the impact of the research by facilitating replication and extension. Despite anonymization, data reporting and sharing may lead to re-identifcation of participants, which can be particularly problematic when the research deals with sensitive topics, such as health. We analyzed 509 CHI papers in the domains of health, wellness, accessibility, and aging to examine data reporting and sharing practices. Our analysis revealed notable patterns and trends regarding the reporting of age, gender, participant types, sample sizes, methodology, ethical considerations, anonymization techniques, and data sharing. Based on our fndings, we propose several suggestions for community standards and practices that could facilitate data reporting and sharing while limiting the privacy risks for study participants.", "keywords": ["based", "condition", "al", "information", "identifcation", "quote", "author", "reported", "specifc", "method", "identifers", "accessibility", "sharing", "anonymized", "risk", "et", "work", "included", "involved", "result", "participant", "use", "people", "detail", "publication", "health", "page", "number", "found", "provided", "-", "followed", "providing", "disclosure", "chi", "case", "data", "study", "researcher", "reporting", "ethic", "identifed", "considered", "research", "hci", "paper", "privacy", "consent", "community"], "document_vector": [-6.913866, 55.548427], "paragraphs": [{"paragraph_vector": [114.384063, -55.73632], "paragraph_keywords": ["research", "hci", "copies", "computing"]}, {"paragraph_vector": [83.265937, -26.012163], "paragraph_keywords": ["reporting", "data", "practices", "desire"]}, {"paragraph_vector": [87.128631, -30.389791], "paragraph_keywords": ["support", "research", "aging", "health"]}, {"paragraph_vector": [53.217235, -57.747344], "paragraph_keywords": ["people", "self", "et", "participants"]}, {"paragraph_vector": [86.542808, -28.387144], "paragraph_keywords": ["research", "participants", "privacy", "district"]}, {"paragraph_vector": [84.371742, -29.469867], "paragraph_keywords": ["participants", "research", "researchers", "pages"]}, {"paragraph_vector": [86.075523, -29.157659], "paragraph_keywords": ["data", "-", "identifers", "health"]}, {"paragraph_vector": [86.368652, -29.697763], "paragraph_keywords": ["papers", "studies", "health", "-"]}, {"paragraph_vector": [83.785911, -27.485784], "paragraph_keywords": ["provided", "location", "information", "participants"]}, {"paragraph_vector": [82.061637, -26.828474], "paragraph_keywords": ["studies", "papers", "ethics", "year"]}, {"paragraph_vector": [84.22229, -27.113845], "paragraph_keywords": ["health", "studies", "participant", "impairment"]}, {"paragraph_vector": [86.744094, -26.249122], "paragraph_keywords": ["studies", "reported", "participants", "study"]}, {"paragraph_vector": [85.967811, -24.986888], "paragraph_keywords": ["studies", "participant", "included", "number"]}, {"paragraph_vector": [83.702758, -27.828926], "paragraph_keywords": ["data", "participant", "sharing", "privacy"]}, {"paragraph_vector": [84.28997, -26.269258], "paragraph_keywords": ["data", "papers", "researchers", "reported"]}, {"paragraph_vector": [85.093696, -26.387557], "paragraph_keywords": ["data", "researchers", "research", "purposes"]}, {"paragraph_vector": [85.761344, -29.762636], "paragraph_keywords": ["participant", "participants", "researchers", "pseudonyms"]}, {"paragraph_vector": [86.65139, -27.120225], "paragraph_keywords": ["people", "diseases", "conditions", "research"]}, {"paragraph_vector": [89.386131, -29.036928], "paragraph_keywords": ["participants", "consent", "data", "paper"]}, {"paragraph_vector": [86.473602, -30.917219], "paragraph_keywords": ["researchers", "data", "ethics", "study"]}, {"paragraph_vector": [84.603744, -28.537477], "paragraph_keywords": ["papers", "community", "research", "approval"]}, {"paragraph_vector": [87.750747, -25.390232], "paragraph_keywords": ["data", "research", "reporting", "community"]}], "content": {}, "doi": "10.1145/3290605.3300298"}, {"uri": "110", "title": "Integrated Workflows", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Emrecan Gulay"], "summary": "As design thinking shifted away from conventional methods with the rapid adoption of computer-aided design and fabrication technologies, architects have been seeking ways to initiate a comprehensive dialogue between the virtual and the material realms. Current methodologies do not offer embodied workflows that utilize the feedback obtained through a subsequent transition process between physical and digital design. Therefore, narrowing the separation between these two platforms remains as a research problem. This literature review elaborates the divide between physical and digital design, testing and manufacturing techniques in the morphological process of architectural form. We first review the digital transformation in the architectural design discourse. Then, we proceed by introducing a variety of methods that are integrating digital and physical workflows and suggesting an alternative approach. Our work unveils that there is a need for empirical research with a focus on integrated approaches to create intuitively embodied experiences for architectural designers.", "keywords": ["process", "manipulation", "based", "time", "al", "object", "information", "design", "method", "literature", "technique", "assembly", "provide", "introduced", "model", "workflow", "review", "interaction", "et", "tool", "limitation", "create", "material", "created", "page", "laser", "generate", "cad", "form", "feedback", "representation", "scanning", "scale", "hand", "computer", "data", "phase", "technology", "study", "approach", "designer", "testing", "role", "research", "built", "hci", "software", "paper", "constraint", "prototype", "fabrication"], "document_vector": [90.391906, -28.831912], "paragraphs": [{"paragraph_vector": [-108.961494, 44.661205], "paragraph_keywords": ["design", "research", "technologies", "fabrication"]}, {"paragraph_vector": [-111.081535, 47.040218], "paragraph_keywords": ["design", "research", "review", "computer"]}, {"paragraph_vector": [-112.536338, 44.4972], "paragraph_keywords": ["design", "literature", "research", "sketchpad"]}, {"paragraph_vector": [-110.2546, 47.391891], "paragraph_keywords": ["geometry", "models", "fabrication", "computer"]}, {"paragraph_vector": [-112.262039, 56.753231], "paragraph_keywords": ["design", "form", "tools", "fabrication"]}, {"paragraph_vector": [-110.092124, 46.799274], "paragraph_keywords": ["design", "processes", "form", "designers"]}, {"paragraph_vector": [-110.713859, 46.28223], "paragraph_keywords": ["design", "models", "material", "tools"]}, {"paragraph_vector": [-112.122535, 45.964324], "paragraph_keywords": ["design", "models", "fabrication", "sense"]}, {"paragraph_vector": [-108.398735, 49.113441], "paragraph_keywords": ["fabrication", "design", "models", "sculptures"]}, {"paragraph_vector": [-109.078063, 48.166568], "paragraph_keywords": ["design", "fabrication", "method", "technologies"]}, {"paragraph_vector": [-103.370483, 50.758342], "paragraph_keywords": ["process", "assembly", "fabrication", "time"]}, {"paragraph_vector": [-108.353515, 47.292522], "paragraph_keywords": ["design", "process", "technologies", "gehry"]}, {"paragraph_vector": [-108.511047, 49.954154], "paragraph_keywords": ["design", "process", "hybrid", "processes"]}, {"paragraph_vector": [-110.973625, 47.336318], "paragraph_keywords": ["design", "process", "fabrication", "phase"]}, {"paragraph_vector": [-106.327705, 44.309574], "paragraph_keywords": ["time", "representations", "fabrication", "laser"]}, {"paragraph_vector": [-110.353485, 48.081752], "paragraph_keywords": ["design", "process", "material", "fabrication"]}, {"paragraph_vector": [-110.943176, 44.702594], "paragraph_keywords": ["fabrication", "design", "approaches", "limitations"]}, {"paragraph_vector": [-94.256248, 39.150001], "paragraph_keywords": ["sensors", "manipulation", "designers", "display"]}, {"paragraph_vector": [-103.179656, 40.042572], "paragraph_keywords": ["displays", "material", "method", "hand"]}, {"paragraph_vector": [-111.608444, 46.093387], "paragraph_keywords": ["design", "form", "research", "blocks"]}, {"paragraph_vector": [-108.903732, 47.915096], "paragraph_keywords": ["manipulation", "process", "models", "scanning"]}, {"paragraph_vector": [-109.253059, 48.480552], "paragraph_keywords": ["design", "process", "workflow", "fabrication"]}, {"paragraph_vector": [-105.759979, 49.365459], "paragraph_keywords": ["model", "process", "scale", "test"]}, {"paragraph_vector": [-108.212875, 46.508964], "paragraph_keywords": ["design", "process", "laser", "scale"]}, {"paragraph_vector": [-110.186706, 49.178161], "paragraph_keywords": ["designers", "method", "design", "paper"]}], "content": {}, "doi": "10.1145/3290605.3300460"}, {"uri": "111", "title": "Assessing the Accuracy of Point & Teleport Locomotion with Orientation Indication for Virtual Reality using Curved Trajectories", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Markus Funk", "Florian M\u00fcller", "Marco Fendrich", "Megan Shene", "Moritz Kolvenbach", "Niclas Dobbertin", "Sebastian G\u00fcnther", "Max M\u00fchlh\u00e4user"], "summary": "Room-scale Virtual Reality (VR) systems have arrived in users\u2019 homes where tracked environments are set up in limited physical spaces. As most Virtual Environments (VEs) are larger than the tracked physical space, locomotion techniques are used to navigate in VEs. Currently, in recent VR games, point & teleport is the most popular locomotion technique. However, it only allows users to select the position of the teleportation and not the orientation that the user is facing after the teleport. This results in users having to manually correct their orientation after teleporting and possibly Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proft or commercial advantage and that copies bear this notice and the full citation on the frst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specifc permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300377 getting entangled by the cable of the headset. In this paper, we introduce and evaluate three diferent point & teleport techniques that enable users to specify the target orientation while teleporting. The results show that, although the three teleportation techniques with orientation indication increase the average teleportation time, they lead to a decreased need for correcting the orientation after teleportation.", "keywords": ["vr", "point", "position", "controller", "correction", "al", "method", "teleportation", "technique", "user", "walk", "et", "participant", "use", "orientation", "walking", "compared", "locomotion", "ve", "distance", "study", "system", "parabola", "target", "teleport", "indication", "paper", "angleselect"], "document_vector": [-176.142425, -31.420244], "paragraphs": [{"paragraph_vector": [-48.489292, 27.920696], "paragraph_keywords": ["locomotion", "teleport", "users", "orientation"]}, {"paragraph_vector": [-46.050849, 28.791984], "paragraph_keywords": ["techniques", "teleport", "locomotion", "point"]}, {"paragraph_vector": [-50.26649, 33.484764], "paragraph_keywords": ["walking", "space", "technique", "locomotion"]}, {"paragraph_vector": [-48.560218, 29.433475], "paragraph_keywords": ["users", "locomotion", "teleportation", "teleport"]}, {"paragraph_vector": [-44.88731, 27.793792], "paragraph_keywords": ["teleport", "orientation", "indication", "point"]}, {"paragraph_vector": [-46.665817, 29.374763], "paragraph_keywords": ["parabola", "teleport", "target", "user"]}, {"paragraph_vector": [-39.243061, 29.035181], "paragraph_keywords": ["teleport", "orientation", "target", "touchpad"]}, {"paragraph_vector": [-44.830234, 27.364528], "paragraph_keywords": ["teleport", "curve", "target", "users"]}, {"paragraph_vector": [-42.952392, 26.889842], "paragraph_keywords": ["teleport", "method", "teleportation", "user"]}, {"paragraph_vector": [-32.554565, 24.350568], "paragraph_keywords": ["targets", "participants", "user", "target"]}, {"paragraph_vector": [-44.686115, 28.798431], "paragraph_keywords": ["participants", "teleportation", "asked", "study"]}, {"paragraph_vector": [-38.238719, 28.535892], "paragraph_keywords": ["teleportation", "correction", "methods", "teleport"]}, {"paragraph_vector": [-40.275238, 27.590881], "paragraph_keywords": ["teleport", "conditions", "teleportation", "m"]}, {"paragraph_vector": [-46.56464, 27.60894], "paragraph_keywords": ["teleport", "teleportation", "techniques", "methods"]}, {"paragraph_vector": [-45.363677, 28.922618], "paragraph_keywords": ["teleport", "teleportation", "angleselect", "participants"]}, {"paragraph_vector": [-45.156688, 28.492465], "paragraph_keywords": ["orientation", "teleportation", "teleport", "angleselect"]}, {"paragraph_vector": [-45.096439, 28.875516], "paragraph_keywords": ["orientation", "teleport", "teleportation", "indication"]}, {"paragraph_vector": [-44.612277, 28.496181], "paragraph_keywords": ["teleportation", "teleport", "users", "methods"]}, {"paragraph_vector": [-45.613071, 28.160587], "paragraph_keywords": ["teleportation", "orientation", "teleport", "techniques"]}], "content": {}, "doi": "10.1145/3290605.3300605"}, {"uri": "112", "title": "\u201cIf It\u2019s Important It Will Be A Headline\u201d: Cybersecurity Information Seeking in Older Adults", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["James Nicholson", "Lynne Coventry", "Pam Briggs"], "summary": "Older adults are increasingly vulnerable to cybersecurity attacks and scams. Yet we know relatively little about their understanding of cybersecurity, their information-seeking behaviours, and their trusted sources of information and advice in this domain. We conducted 22 semi-structured interviews with community-dwelling older adults in order to explore their cybersecurity information seeking behaviours. Following a thematic analysis of these interviews, we developed a cybersecurity information access framework that highlights shortcomings in older adults\u2019 choice of information resources. Specifically, we find that older users prioritise social resources based on availability, rather than cybersecurity expertise, and that they avoid using the Internet for cybersecurity information searches despite using it for other domains. Finally, we discuss the design of cybersecurity information dissemination strategies for older users, incorporating favoured sources such as TV adverts and radio programming.", "keywords": ["time", "female", "need", "resource", "information", "got", "ability", "threat", "behaviour", "radio", "source", "organisation", "interview", "friend", "focus", "thing", "help", "medium", "user", "trust", "know", "advice", "work", "language", "use", "internet", "participant", "people", "group", "interest", "given", "think", "literacy", "security", "experience", "page", "seeking", "male", "including", "understand", "family", "device", "computer", "said", "framework", "support", "cybersecurity", "adult", "course", "paper", "coping", "knowledge", "access"], "document_vector": [-48.159198, 45.21228], "paragraphs": [{"paragraph_vector": [12.929903, -59.389579], "paragraph_keywords": ["work", "sources", "copies", "threats"]}, {"paragraph_vector": [16.419401, -61.44263], "paragraph_keywords": ["adults", "information", "cybersecurity", "trust"]}, {"paragraph_vector": [21.730182, -61.222473], "paragraph_keywords": ["adults", "threat", "response", "threats"]}, {"paragraph_vector": [17.455921, -62.2518], "paragraph_keywords": ["literacy", "threat", "cybersecurity", "ability"]}, {"paragraph_vector": [15.852129, -61.596515], "paragraph_keywords": ["sources", "information", "cybersecurity", "family"]}, {"paragraph_vector": [13.783055, -61.164615], "paragraph_keywords": ["security", "users", "information", "play"]}, {"paragraph_vector": [81.842231, -40.874679], "paragraph_keywords": ["participants", "information", "interviews", "experiences"]}, {"paragraph_vector": [84.708442, -46.762851], "paragraph_keywords": ["participants", "asked", "experiences", "information"]}, {"paragraph_vector": [90.076095, -46.626186], "paragraph_keywords": ["team", "information", "framework", "knowledge"]}, {"paragraph_vector": [16.233242, -61.451793], "paragraph_keywords": ["information", "knowledge", "location", "cybersecurity"]}, {"paragraph_vector": [12.799897, -63.616504], "paragraph_keywords": ["information", "user", "cybersecurity", "learned"]}, {"paragraph_vector": [15.741984, -60.432064], "paragraph_keywords": ["language", "cybersecurity", "confidence", "user"]}, {"paragraph_vector": [14.835808, -62.033786], "paragraph_keywords": ["experiences", "users", "update", "female"]}, {"paragraph_vector": [16.407627, -62.435176], "paragraph_keywords": ["information", "users", "resources", "cybersecurity"]}, {"paragraph_vector": [16.204603, -60.191352], "paragraph_keywords": ["son", "people", "users", "know"]}, {"paragraph_vector": [17.582895, -60.470695], "paragraph_keywords": ["got", "friend", "problem", "availability"]}, {"paragraph_vector": [15.634622, -61.95877], "paragraph_keywords": ["female", "users", "devices", "said"]}, {"paragraph_vector": [15.97155, -61.966918], "paragraph_keywords": ["courses", "users", "information", "age"]}, {"paragraph_vector": [12.392871, -25.222953], "paragraph_keywords": ["support", "users", "resources", "structures"]}, {"paragraph_vector": [16.236373, -60.993778], "paragraph_keywords": ["users", "radio", "resources", "information"]}, {"paragraph_vector": [21.304771, -60.804222], "paragraph_keywords": ["radio", "tv", "information", "media"]}, {"paragraph_vector": [13.729642, -60.713645], "paragraph_keywords": ["users", "cybersecurity", "security", "report"]}, {"paragraph_vector": [14.871143, -61.695766], "paragraph_keywords": ["users", "information", "cybersecurity", "internet"]}, {"paragraph_vector": [21.153867, -62.131389], "paragraph_keywords": ["users", "information", "resources", "cybersecurity"]}, {"paragraph_vector": [13.088069, -59.06575], "paragraph_keywords": ["information", "coping", "users", "courses"]}, {"paragraph_vector": [12.760742, -60.500408], "paragraph_keywords": ["cybersecurity", "information", "users", "radio"]}, {"paragraph_vector": [10.219312, -59.49871], "paragraph_keywords": ["cybersecurity", "information", "engineering", "ep"]}], "content": {}, "doi": "10.1145/3290605.3300611"}, {"uri": "113", "title": "Using Social Media to Automate the Authentication Ceremony in Secure Messaging", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Elham Vaziripour", "Devon Howard", "Jake Tyler", "Mark O\u2019Neill", "Justin Wu", "Kent Seamons", "Daniel Zappala"], "summary": "The privacy guaranteed by secure messaging applications relies on users completing an authentication ceremony to verify they are using the proper encryption keys. We examine the feasibility of social authentication, which partially automates the ceremony using social media accounts. We implemented social authentication in Signal and conducted a within-subject user study with 42 participants to compare this with existing methods. To generalize our results, we conducted a Mechanical Turk survey involving 421 respondents. Our results show that users found social authentication to be convenient and fast. They particularly liked verifying keys asynchronously, and viewing social media profiles naturally coincided with how participants thought of verification. However, some participants reacted negatively to integrating social media with Signal, primarily because they distrust social media services. Overall, automating the authentication ceremony and distributing trust with additional service providers is promising, but this infrastructure needs to be more trusted than social media companies.", "keywords": ["based", "time", "person", "find", "phone", "method", "conversation", "app", "safety", "messaging", "medium", "user", "trust", "work", "participant", "use", "usability", "people", "key", "authentication", "security", "page", "number", "application", "survey", "attack", "signal", "shown", "data", "study", "compare", "ceremony", "verify", "account", "asked", "question", "paper", "privacy", "order", "instruction", "code"], "document_vector": [-34.551868, 42.121452], "paragraphs": [{"paragraph_vector": [0.944196, -35.460205], "paragraph_keywords": ["users", "copies", "authentication", "applications"]}, {"paragraph_vector": [0.003965, -36.628845], "paragraph_keywords": ["authentication", "users", "ceremony", "signal"]}, {"paragraph_vector": [2.611163, -33.898925], "paragraph_keywords": ["authentication", "ceremony", "media", "keys"]}, {"paragraph_vector": [0.38868, -33.995403], "paragraph_keywords": ["users", "authentication", "usability", "verification"]}, {"paragraph_vector": [0.843331, -34.002021], "paragraph_keywords": ["authentication", "keybase", "ceremony", "signal"]}, {"paragraph_vector": [1.943057, -35.606967], "paragraph_keywords": ["media", "accounts", "users", "signal"]}, {"paragraph_vector": [0.85602, -36.498714], "paragraph_keywords": ["media", "authentication", "user", "ceremony"]}, {"paragraph_vector": [0.550511, -34.707618], "paragraph_keywords": ["users", "shown", "safety", "figure"]}, {"paragraph_vector": [0.846921, -35.332736], "paragraph_keywords": ["participants", "authentication", "user", "study"]}, {"paragraph_vector": [129.756912, -68.838966], "paragraph_keywords": ["participants", "study", "ceremony", "tax"]}, {"paragraph_vector": [0.970122, -35.83514], "paragraph_keywords": ["participants", "authentication", "ceremony", "methods"]}, {"paragraph_vector": [4.101789, -40.193496], "paragraph_keywords": ["media", "authentication", "participants", "questions"]}, {"paragraph_vector": [-1.811932, -37.302284], "paragraph_keywords": ["participants", "authentication", "rest", "report"]}, {"paragraph_vector": [1.015867, -35.127994], "paragraph_keywords": ["media", "method", "participants", "time"]}, {"paragraph_vector": [-0.073749, -33.360511], "paragraph_keywords": ["method", "person", "tried", "liked"]}, {"paragraph_vector": [1.99471, -37.194904], "paragraph_keywords": ["media", "accounts", "authentication", "participants"]}, {"paragraph_vector": [2.285691, -36.203201], "paragraph_keywords": ["participants", "person", "verify", "safety"]}, {"paragraph_vector": [3.061659, -34.002109], "paragraph_keywords": ["conversation", "participants", "mentioned", "numbers"]}, {"paragraph_vector": [1.620265, -34.548957], "paragraph_keywords": ["participants", "privacy", "conversation", "number"]}, {"paragraph_vector": [1.294304, -37.133197], "paragraph_keywords": ["participants", "authentication", "results", "methods"]}, {"paragraph_vector": [3.3283, -35.594444], "paragraph_keywords": ["authentication", "user", "media", "trust"]}, {"paragraph_vector": [1.658801, -34.401485], "paragraph_keywords": ["users", "method", "accounts", "media"]}, {"paragraph_vector": [1.017332, -35.440231], "paragraph_keywords": ["providers", "authentication", "ceremony", "media"]}, {"paragraph_vector": [0.578353, -36.854454], "paragraph_keywords": ["work", "supported", "science", "authors"]}], "content": {}, "doi": "10.1145/3290605.3300705"}, {"uri": "114", "title": "Geollery: A Mixed Reality Social Media Platform", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Ruofei Du", "David Li"], "summary": "We present Geollery, an interactive mixed reality social media platform for creating, sharing, and exploring geotagged information. Geollery introduces a real-time pipeline to progressively render an interactive mirrored world with threedimensional (3D) buildings, internal user-generated content, and external geotagged social media. This mirrored world allows users to see, chat, and collaborate with remote participants with the same spatial context in an immersive virtual environment. We describe the system architecture of Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300915 Geollery, its key interactive capabilities, and our design decisions. Finally, we conduct a user study with 20 participants to qualitatively compare Geollery with another social media system, Social Street View. Based on the participants\u2019 responses, we discuss the benefits and drawbacks of each system and derive key insights for designing an interactive mirrored world with geotagged social media. User feedback from our study reveals several use cases for Geollery including travel planning, virtual meetings, and family gathering.", "keywords": ["explore", "based", "geollery", "time", "geotagged", "information", "like", "location", "design", "friend", "medium", "user", "model", "work", "building", "participant", "use", "people", "art", "world", "visualization", "billboard", "visualizing", "add", "avatar", "data", "day", "study", "map", "geometry", "system", "reality", "image", "text", "research", "view", "platform", "minute", "texture", "balloon", "asked", "street", "photo", "city", "figure"], "document_vector": [153.048629, 7.728741], "paragraphs": [{"paragraph_vector": [-68.204498, -46.232418], "paragraph_keywords": ["media", "street", "reality", "view"]}, {"paragraph_vector": [-67.140899, -44.343597], "paragraph_keywords": ["media", "system", "world", "geollery"]}, {"paragraph_vector": [-78.237678, -50.575984], "paragraph_keywords": ["media", "maps", "information", "map"]}, {"paragraph_vector": [-64.558242, -43.275505], "paragraph_keywords": ["city", "cities", "work", "approaches"]}, {"paragraph_vector": [-69.173851, -44.702838], "paragraph_keywords": ["media", "geollery", "system", "data"]}, {"paragraph_vector": [-68.242141, -46.065227], "paragraph_keywords": ["media", "buildings", "user", "system"]}, {"paragraph_vector": [-69.404373, -46.858615], "paragraph_keywords": ["media", "geollery", "street", "view"]}, {"paragraph_vector": [-68.426918, -43.315132], "paragraph_keywords": ["geollery", "building", "street", "time"]}, {"paragraph_vector": [-72.381042, -45.881397], "paragraph_keywords": ["users", "text", "media", "billboards"]}, {"paragraph_vector": [-71.745643, -45.960147], "paragraph_keywords": ["media", "users", "stacks", "frame"]}, {"paragraph_vector": [-71.593009, -47.892124], "paragraph_keywords": ["media", "privacy", "users", "day"]}, {"paragraph_vector": [-72.786247, -54.093151], "paragraph_keywords": ["media", "participant", "participants", "interviewer"]}, {"paragraph_vector": [-69.177841, -44.448818], "paragraph_keywords": ["participants", "walk", "asked", "preferred"]}, {"paragraph_vector": [-70.754089, -45.043327], "paragraph_keywords": ["geollery", "participants", "street", "found"]}, {"paragraph_vector": [-71.308448, -46.934528], "paragraph_keywords": ["street", "view", "media", "participants"]}, {"paragraph_vector": [-69.101219, -48.264678], "paragraph_keywords": ["use", "friends", "like", "people"]}, {"paragraph_vector": [-70.073188, -45.184532], "paragraph_keywords": ["users", "media", "geollery", "like"]}, {"paragraph_vector": [-67.718078, -45.25003], "paragraph_keywords": ["street", "geollery", "view", "study"]}, {"paragraph_vector": [-69.579689, -47.103466], "paragraph_keywords": ["geollery", "media", "street", "videos"]}, {"paragraph_vector": [76.753433, 30.85003], "paragraph_keywords": ["article", "expressed", "authors", "recommendations"]}], "content": {}, "doi": "10.1145/3290605.3300592"}, {"uri": "115", "title": "Apprise: Supporting the Critical-Agency of Victims of Human Trafficking in Thailand", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Hannah Thinyane", "Karthik S. Bhat"], "summary": "Human trafficking and forced labor are global issues affecting millions of people around the world. This paper describes an initiative that we are currently undertaking to understand the role technology can play to support the critical-agency of migrant workers in these situations of severe exploitation. Building on five consultations with more than 170 direct and indirect stakeholders in Thailand, the paper presents the co-design, development, and evaluation of Apprise, a mobile app to support the identification of victims of human trafficking using a Value Sensitive Design approach. It also provides a critical reflection on the use of digital technology in the initial screening of potential victims of human trafficking, to understand in what ways Apprise can support the critical agency of migrant workers in vulnerable situations.", "keywords": ["process", "based", "flr", "forced", "population", "time", "information", "worker", "phone", "discussion", "section", "design", "app", "interview", "provide", "thailand", "focus", "exploitation", "figure", "help", "designing", "labor", "user", "communication", "consultation", "work", "language", "use", "participant", "people", "agency", "victim", "identify", "sen", "designed", "lack", "page", "freedom", "understanding", "including", "understand", "identified", "stakeholder", "case", "leave", "flrs", "technology", "sex", "situation", "support", "system", "research", "identification", "screening", "apprise", "question", "paper", "trafficking", "interface", "privacy", "value", "vulnerability", "response"], "document_vector": [133.577728, 63.383029], "paragraphs": [{"paragraph_vector": [119.408287, -62.476554], "paragraph_keywords": ["skipper", "fisher", "leave", "acm"]}, {"paragraph_vector": [64.315551, -45.842864], "paragraph_keywords": ["copies", "sopon", "fishers", "inspector"]}, {"paragraph_vector": [69.960433, -45.234676], "paragraph_keywords": ["victims", "exploitation", "understand", "design"]}, {"paragraph_vector": [67.976562, -45.057754], "paragraph_keywords": ["labor", "work", "forced", "issues"]}, {"paragraph_vector": [65.197975, -42.515262], "paragraph_keywords": ["victim", "survivor", "trafficking", "individuals"]}, {"paragraph_vector": [64.840423, -42.673599], "paragraph_keywords": ["labor", "victims", "work", "workers"]}, {"paragraph_vector": [88.429496, -47.428268], "paragraph_keywords": ["technology", "populations", "challenges", "work"]}, {"paragraph_vector": [75.423713, -47.968139], "paragraph_keywords": ["technology", "sex", "workers", "work"]}, {"paragraph_vector": [108.247299, 4.184334], "paragraph_keywords": ["interfaces", "based", "user", "interface"]}, {"paragraph_vector": [86.292671, -50.173881], "paragraph_keywords": ["freedom", "agency", "constrained", "development"]}, {"paragraph_vector": [103.527107, -48.906112], "paragraph_keywords": ["sen", "agency", "understand", "providing"]}, {"paragraph_vector": [112.67588, -31.858831], "paragraph_keywords": ["design", "vsd", "research", "approach"]}, {"paragraph_vector": [68.858528, -41.13203], "paragraph_keywords": ["stakeholders", "focus", "trafficking", "groups"]}, {"paragraph_vector": [81.35009, -47.601119], "paragraph_keywords": ["dams", "design", "app", "questions"]}, {"paragraph_vector": [69.837821, -42.885513], "paragraph_keywords": ["consultations", "consultation", "notes", "moj"]}, {"paragraph_vector": [70.26136, -46.040157], "paragraph_keywords": ["design", "section", "situation", "worker"]}, {"paragraph_vector": [68.785446, -46.44099], "paragraph_keywords": ["flrs", "workers", "flr", "languages"]}, {"paragraph_vector": [94.061164, -33.40237], "paragraph_keywords": ["flag", "language", "button", "participants"]}, {"paragraph_vector": [61.760585, -45.544517], "paragraph_keywords": ["participants", "participant", "interface", "consultations"]}, {"paragraph_vector": [66.286666, -46.351272], "paragraph_keywords": ["questions", "workers", "app", "time"]}, {"paragraph_vector": [69.886917, -46.311225], "paragraph_keywords": ["workers", "privacy", "worker", "responses"]}, {"paragraph_vector": [70.168937, -44.273071], "paragraph_keywords": ["labor", "suggested", "consultations", "identification"]}, {"paragraph_vector": [66.740417, -41.497322], "paragraph_keywords": ["exploitation", "based", "labor", "indicators"]}, {"paragraph_vector": [63.134944, -40.960308], "paragraph_keywords": ["situation", "help", "use", "vulnerability"]}, {"paragraph_vector": [66.46952, -45.211929], "paragraph_keywords": ["vulnerability", "apprise", "situation", "workers"]}, {"paragraph_vector": [69.077415, -44.826362], "paragraph_keywords": ["workers", "situation", "worker", "work"]}, {"paragraph_vector": [67.916007, -45.02526], "paragraph_keywords": ["support", "apprise", "paper", "helpline"]}, {"paragraph_vector": [69.183975, -43.476058], "paragraph_keywords": ["organization", "information", "responses", "interview"]}, {"paragraph_vector": [72.376579, -44.661937], "paragraph_keywords": ["constraints", "apprise", "design", "workers"]}], "content": {}, "doi": "10.1145/3290605.3300411"}, {"uri": "116", "title": "Color Builder: A Direct Manipulation Interface  for Versatile Color Theme Authoring", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Maria Shugrina", "Wenjia Zhang", "Fanny Chevalier", "Sanja Fidler", "Karan Singh"], "summary": "Color themes or palettes are popular for sharing color combinations across many visual domains. We present a novel interface for creating color themes through direct manipulation of color swatches. Users can create and rearrange swatches, and combine them into smooth and step-based gradients and three-color blends \u2013 all using a seamless touch or mouse input. Analysis of existing solutions reveals a fragmented color design workfow, where separate software is used for swatches, smooth and discrete gradients and for in-context color visualization. Our design unifes these tasks, while encouraging playful creative exploration. Adjusting a color using standard color pickers can break this interaction fow with mechanical slider manipulation. To keep interaction seamless, we additionally design an in situ color tweaking interface for freeform exploration of an entire color neighborhood. We evaluate our interface with a group of professional designers and students majoring in this feld. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proft or commercial advantage and that copies bear this notice and the full citation on the frst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specifc permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed", "keywords": ["manipulation", "direction", "swatch", "allow", "design", "provide", "touch", "user", "exploration", "play", "allows", "work", "tool", "space", "use", "theme", "blend", "paletton", "visualization", "step", "number", "c", "found", "picker", "task", "tweaker", "designer", "map", "builder", "lab", "color", "support", "adjusting", "adjustment", "palette", "software", "interface", "hsv", "gradient"], "document_vector": [121.038314, -34.869731], "paragraphs": [{"paragraph_vector": [114.689399, 67.66851], "paragraph_keywords": ["color", "design", "interface", "interfaces"]}, {"paragraph_vector": [115.233619, 67.193359], "paragraph_keywords": ["color", "design", "palettes", "allows"]}, {"paragraph_vector": [108.204757, 65.813499], "paragraph_keywords": ["gradients", "colors", "palette", "swatch"]}, {"paragraph_vector": [111.636085, 68.053977], "paragraph_keywords": ["color", "interfaces", "palettes", "palette"]}, {"paragraph_vector": [109.046234, 66.363059], "paragraph_keywords": ["color", "hsv", "space", "rgb"]}, {"paragraph_vector": [109.147346, 64.729972], "paragraph_keywords": ["design", "gradients", "swatch", "palettes"]}, {"paragraph_vector": [111.45523, 63.437438], "paragraph_keywords": ["palette", "colors", "swatch", "designer"]}, {"paragraph_vector": [114.661132, 64.07019], "paragraph_keywords": ["design", "exploration", "color", "colors"]}, {"paragraph_vector": [110.149269, 66.70417], "paragraph_keywords": ["color", "goal", "swatches", "manipulation"]}, {"paragraph_vector": [88.895668, 76.334144], "paragraph_keywords": ["gradient", "designer", "endpoints", "swatches"]}, {"paragraph_vector": [154.611541, 89.699417], "paragraph_keywords": ["gradient", "colors", "gradients", "svg"]}, {"paragraph_vector": [106.780014, 66.633972], "paragraph_keywords": ["color", "colors", "map", "view"]}, {"paragraph_vector": [107.274177, 68.071372], "paragraph_keywords": ["color", "directions", "colors", "source"]}, {"paragraph_vector": [110.030799, 68.235351], "paragraph_keywords": ["color", "design", "users", "builder"]}, {"paragraph_vector": [115.597526, 64.376464], "paragraph_keywords": ["color", "task", "touch", "builder"]}, {"paragraph_vector": [123.306182, 58.873039], "paragraph_keywords": ["color", "builder", "task", "users"]}, {"paragraph_vector": [113.484786, 67.87854], "paragraph_keywords": ["color", "users", "found", "play"]}, {"paragraph_vector": [114.194526, 64.418418], "paragraph_keywords": ["color", "constraints", "users", "design"]}, {"paragraph_vector": [111.200798, 66.215637], "paragraph_keywords": ["color", "map", "palette", "users"]}, {"paragraph_vector": [112.091789, 67.628295], "paragraph_keywords": ["color", "tools", "user", "design"]}], "content": {}, "doi": "10.1145/3290605.3300419"}, {"uri": "117", "title": "ModiFiber: Two-Way Morphing Soft Thread Actuators for Tangible Interaction", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jack Forman"], "summary": "Despite thin-line actuators becoming widely adopted in different Human-Computer Interaction (HCI) contexts, including integration into fabrics, paper art, hinges, soft robotics, and human hair, accessible line-based actuators are very limited beyond shape memory alloy (SMA) wire and motor-driven passive tendons. In this paper, we introduce a novel, yet simple and accessible, line-based actuator. ModiFiber is a twisted-then-coiled nylon thread actuator with a silicone coating. This composite thread actuator Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300890 exhibits unique two-way reversible shrinking or twisting behaviors triggered by heat or electrical current (i.e., Joule heating). ModiFiber is soft, flexible, safe to operate and easily woven or sewn, hence it has a great potential as an embedded line-based actuator for HCI purposes. In this paper, we explain the material mechanisms and manufacturing approaches, followed by some performance tests and application demonstrations.", "keywords": ["based", "twisting", "allow", "force", "actuator", "muscle", "temperature", "power", "annealing", "type", "actuation", "interaction", "sample", "allowing", "weight", "length", "page", "sma", "application", "garment", "heating", "coated", "coating", "driven", "string", "thread", "modifiber", "ply", "skin", "hci", "twist", "paper", "silicone", "shrinking", "figure", "heated"], "document_vector": [71.216903, -48.185291], "paragraphs": [{"paragraph_vector": [-45.522129, 55.187862], "paragraph_keywords": ["actuators", "sma", "hci", "actuator"]}, {"paragraph_vector": [-43.767242, 57.003475], "paragraph_keywords": ["actuators", "muscles", "actuation", "achieve"]}, {"paragraph_vector": [-46.133327, 55.467979], "paragraph_keywords": ["actuators", "silicone", "researchers", "actuator"]}, {"paragraph_vector": [-44.187683, 56.159332], "paragraph_keywords": ["modifiber", "actuation", "niti", "actuator"]}, {"paragraph_vector": [-43.499172, 55.327838], "paragraph_keywords": ["thread", "actuation", "twisting", "modifiber"]}, {"paragraph_vector": [-43.145236, 55.698513], "paragraph_keywords": ["actuators", "silicone", "fiber", "twist"]}, {"paragraph_vector": [-40.951084, 59.114048], "paragraph_keywords": ["figure", "coiling", "collecting", "thread"]}, {"paragraph_vector": [-41.872482, 56.184181], "paragraph_keywords": ["silicone", "actuation", "actuator", "minutes"]}, {"paragraph_vector": [-40.969837, 55.529041], "paragraph_keywords": ["actuator", "sample", "actuation", "coated"]}, {"paragraph_vector": [-42.462127, 55.893432], "paragraph_keywords": ["actuator", "test", "sample", "silicone"]}, {"paragraph_vector": [-44.238044, 55.384323], "paragraph_keywords": ["actuator", "actuation", "shirt", "shrinking"]}, {"paragraph_vector": [-43.286277, 56.835056], "paragraph_keywords": ["garment", "actuator", "actuators", "figure"]}, {"paragraph_vector": [-47.757461, 55.251533], "paragraph_keywords": ["thread", "actuator", "bag", "circuit"]}, {"paragraph_vector": [-39.365268, 56.16925], "paragraph_keywords": ["actuators", "allow", "coating", "knitting"]}, {"paragraph_vector": [-43.460117, 55.291255], "paragraph_keywords": ["actuators", "actuator", "string", "shrinking"]}], "content": {}, "doi": "10.1145/3290605.3300231"}, {"uri": "118", "title": "Sustainabot \u2013 Exploring the Use of Everyday Foodstuffs as Output and Input for and with Emergent Users", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Simon Robinson", "Mark D. Holton"], "summary": "Mainstream digital interactions are spread over a plethora of devices and form-factors, from mobiles to laptops; printouts to large screens. For emergent users, however, such abundance of choice is rarely accessible or affordable. In particular, viewing mobile content on a larger screen, or printing out copies, is often not available. In this paper we present Sustainabot \u2013 a small robot printer that uses everyday materials to print shapes and patterns from mobile phones. Sustainabot was proposed and developed by and with emergent users through a series of co-creation workshops. We begin by discussing this process, then detail the open-sourcemobile printer prototype. We carried out two evaluations of Sustainabot, the first focused on printing with materials in situ, and the second on understandability of its output. We present these results, and discuss opportunities and challenges for similar developments. We conclude by highlighting where and how similar devices could be used in future.", "keywords": ["print", "based", "consider", "time", "phone", "design", "provide", "rangoli", "uk", "suggestion", "example", "help", "rover", "user", "command", "house", "interaction", "surface", "workshop", "draw", "sustainabot", "work", "participant", "use", "salt", "create", "material", "group", "way", "range", "printing", "created", "concept", "page", "output", "existing", "content", "moving", "fig", "robot", "suggested", "device", "technology", "study", "image", "icon", "printer", "system", "ball", "focused", "order", "asked", "paper", "printed"], "document_vector": [100.262641, -24.887126], "paragraphs": [{"paragraph_vector": [-120.726692, 18.543672], "paragraph_keywords": ["copies", "systems", "acm", "content"]}, {"paragraph_vector": [-114.426239, 26.311912], "paragraph_keywords": ["sustainabot", "salt", "users", "triangle"]}, {"paragraph_vector": [-113.562332, 31.208015], "paragraph_keywords": ["output", "users", "interaction", "co"]}, {"paragraph_vector": [-117.552108, 25.691267], "paragraph_keywords": ["users", "devices", "provide", "work"]}, {"paragraph_vector": [-111.27536, 47.651397], "paragraph_keywords": ["robots", "output", "example", "moving"]}, {"paragraph_vector": [-110.982582, 37.227546], "paragraph_keywords": ["draw", "rangoli", "patterns", "examples"]}, {"paragraph_vector": [-108.110107, -53.932289], "paragraph_keywords": ["users", "technologies", "paper", "june"]}, {"paragraph_vector": [-135.27388, 0.857585], "paragraph_keywords": ["robot", "rover", "groups", "sessions"]}, {"paragraph_vector": [-133.051223, -2.548892], "paragraph_keywords": ["rover", "robot", "participants", "groups"]}, {"paragraph_vector": [-115.725364, 21.448671], "paragraph_keywords": ["participants", "sustainabot", "materials", "robot"]}, {"paragraph_vector": [-113.678962, 24.360464], "paragraph_keywords": ["participants", "materials", "group", "fig"]}, {"paragraph_vector": [-115.517181, 25.367351], "paragraph_keywords": ["workshop", "image", "material", "group"]}, {"paragraph_vector": [-117.079978, 18.228315], "paragraph_keywords": ["participants", "materials", "suggestions", "colours"]}, {"paragraph_vector": [-113.448745, 25.195844], "paragraph_keywords": ["suggested", "image", "map", "recognise"]}, {"paragraph_vector": [-112.392707, 31.794811], "paragraph_keywords": ["participants", "robot", "materials", "printer"]}, {"paragraph_vector": [-111.067787, 33.851875], "paragraph_keywords": ["robot", "printing", "material", "hopper"]}, {"paragraph_vector": [-110.667114, 30.446121], "paragraph_keywords": ["robot", "sustainabot", "motors", "materials"]}, {"paragraph_vector": [-110.611419, 32.280807], "paragraph_keywords": ["robot", "commands", "design", "sustainabot"]}, {"paragraph_vector": [-112.597236, 30.908443], "paragraph_keywords": ["robot", "ball", "sustainabot", "participants"]}, {"paragraph_vector": [-114.59365, 30.781087], "paragraph_keywords": ["robot", "participants", "materials", "print"]}, {"paragraph_vector": [-115.992256, 24.286869], "paragraph_keywords": ["participants", "house", "ball", "study"]}, {"paragraph_vector": [-115.438819, 27.536975], "paragraph_keywords": ["participants", "robot", "use", "house"]}, {"paragraph_vector": [-115.377975, 27.633022], "paragraph_keywords": ["responses", "output", "suggested", "workshops"]}, {"paragraph_vector": [-115.005516, 27.439756], "paragraph_keywords": ["sustainabot", "participants", "uk", "consider"]}, {"paragraph_vector": [-123.799049, 47.773178], "paragraph_keywords": ["sustainabot", "printing", "example", "outputs"]}], "content": {}, "doi": "10.1145/3290605.3300693"}, {"uri": "119", "title": "A is for Artificial Intelligence", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Randi Williams", "Hae Won Park"], "summary": "We developed a novel early childhood artificial intelligence (AI) platform, PopBots, where preschool children train and interact with social robots to learn threeAI concepts: knowledgebased systems, supervised machine learning, and generative AI. We evaluated how much children learned by using AI assessments we developed for each activity. The median score on the cumulative assessment was 70% and children understood knowledge-based systems the best. Then, we analyzed the impact of the activities on children\u2019s perceptions of robots. Younger children came to see robots as toys that were smarter than them, but their older counterparts saw them more as people that were not as smart as them. Children who performed worse on the AI assessments believed that robots were like toys that were not as smart as them, however children who did better on the assessments saw robots as people who were smarter than them. We believe early AI education can empower children to understand the AI devices that are increasingly in their lives.", "keywords": ["explore", "based", "child", "food", "toy", "belief", "mind", "activity", "assessment", "learn", "theory", "work", "impact", "use", "people", "learning", "given", "ai", "page", "understanding", "found", "understand", "test", "robot", "classroom", "device", "skill", "student", "system", "saw", "popbots", "rule", "question", "paper", "knowledge", "figure"], "document_vector": [-3.615824, -30.358926], "paragraphs": [{"paragraph_vector": [-151.578491, 23.055774], "paragraph_keywords": ["copies", "children", "ai", "impact"]}, {"paragraph_vector": [-152.135345, 21.79421], "paragraph_keywords": ["children", "ai", "robots", "explore"]}, {"paragraph_vector": [-143.406951, 10.107268], "paragraph_keywords": ["children", "robots", "robot", "mind"]}, {"paragraph_vector": [-152.344131, 19.371505], "paragraph_keywords": ["children", "activities", "understanding", "ai"]}, {"paragraph_vector": [-150.985626, 20.897064], "paragraph_keywords": ["children", "robot", "based", "ai"]}, {"paragraph_vector": [-154.714599, 20.016616], "paragraph_keywords": ["children", "robot", "foods", "training"]}, {"paragraph_vector": [-155.839843, 21.782632], "paragraph_keywords": ["robot", "children", "rules", "questions"]}, {"paragraph_vector": [-152.285919, 20.261276], "paragraph_keywords": ["robot", "song", "understand", "category"]}, {"paragraph_vector": [-154.105667, 16.947578], "paragraph_keywords": ["robots", "child", "children", "robot"]}, {"paragraph_vector": [-149.29869, 18.428289], "paragraph_keywords": ["children", "classrooms", "classroom", "ai"]}, {"paragraph_vector": [-150.4794, 20.441871], "paragraph_keywords": ["children", "mdn", "assessment", "understanding"]}, {"paragraph_vector": [-151.144485, 20.385202], "paragraph_keywords": ["children", "robot", "question", "belief"]}, {"paragraph_vector": [-150.817611, 20.525234], "paragraph_keywords": ["children", "robots", "agree", "\u03c7"]}, {"paragraph_vector": [-150.746841, 18.967014], "paragraph_keywords": ["children", "robots", "rules", "test"]}, {"paragraph_vector": [-151.123748, 18.388887], "paragraph_keywords": ["children", "robots", "popbots", "toys"]}, {"paragraph_vector": [-151.912582, 20.0368], "paragraph_keywords": ["children", "ai", "popbots", "understanding"]}, {"paragraph_vector": [-150.790115, 20.261268], "paragraph_keywords": ["children", "activities", "popbots", "skills"]}, {"paragraph_vector": [-151.929855, 20.669925], "paragraph_keywords": ["children", "ai", "popbots", "robots"]}, {"paragraph_vector": [-150.018157, 17.247621], "paragraph_keywords": ["children", "ai", "work", "design"]}, {"paragraph_vector": [73.125816, 32.448162], "paragraph_keywords": ["students", "participated", "experiment", "undergraduate"]}], "content": {}, "doi": "10.1145/3290605.3300368"}, {"uri": "120", "title": "ZeRONE: Safety Drone with Blade-Free Propulsion", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Wataru Yamada", "Hiroyuki Manabe", "Daizo Ikeda"], "summary": "We present ZeRONE, a new indoor drone that does not use rotating blades for propulsion. The proposed device is a helium blimp type drone that uses the wind generated by the ultrasonic vibration of piezo elements for propulsion. Compared to normal drones with rotating propellers, the drone is much safer because its only moving parts are the piezo elements whose surfaces vibrate at the order of micrometers. The drone can oat for a few weeks and the ultrasonic propulsion system is quiet. We implement a prototype of the drone and evaluate its performance and unique characteristics in experiments. Moreover, application scenarios in which ZeRONE coexists with people are also discussed.", "keywords": ["direction", "time", "object", "us", "speed", "battery", "drone", "drive", "zerone", "example", "power", "user", "microblower", "surface", "gas", "interaction", "air", "space", "weight", "use", "movement", "people", "y", "noise", "control", "application", "thrust", "part", "g", "proposed", "con", "propeller", "projector", "buoyancy", "balloon", "prototype", "paper", "microblowers", "figure"], "document_vector": [-176.60469, -39.081272], "paragraphs": [{"paragraph_vector": [-73.185111, -28.177881], "paragraph_keywords": ["drone", "drones", "propeller", "winds"]}, {"paragraph_vector": [-80.361686, -24.838626], "paragraph_keywords": ["zerone", "drones", "space", "discuss"]}, {"paragraph_vector": [-102.13771, 40.874954], "paragraph_keywords": ["objects", "controlling", "concept", "properties"]}, {"paragraph_vector": [-80.855781, -26.42069], "paragraph_keywords": ["drone", "noise", "air", "drones"]}, {"paragraph_vector": [-85.265724, -18.641111], "paragraph_keywords": ["microblowers", "balloon", "thrust", "zerone"]}, {"paragraph_vector": [-83.766128, -26.565271], "paragraph_keywords": ["microblowers", "figure", "direction", "driving"]}, {"paragraph_vector": [-81.068771, -25.527984], "paragraph_keywords": ["figure", "balloon", "gas", "microblowers"]}, {"paragraph_vector": [-82.255775, -24.395708], "paragraph_keywords": ["g", "khz", "output", "parts"]}, {"paragraph_vector": [-81.416046, -24.401193], "paragraph_keywords": ["microblowers", "experiment", "zerone", "speed"]}, {"paragraph_vector": [-80.57891, -26.111719], "paragraph_keywords": ["noise", "zerone", "environment", "buoyancy"]}, {"paragraph_vector": [-82.262107, -27.759244], "paragraph_keywords": ["zerone", "y", "applications", "people"]}, {"paragraph_vector": [-82.285675, -26.145515], "paragraph_keywords": ["surface", "balloon", "user", "zerone"]}, {"paragraph_vector": [-82.405914, -24.28346], "paragraph_keywords": ["air", "thrust", "use", "blowers"]}, {"paragraph_vector": [-82.186767, -25.501878], "paragraph_keywords": ["zerone", "drone", "projectors", "laser"]}, {"paragraph_vector": [-47.971122, 28.540496], "paragraph_keywords": ["zerone", "characteristics", "rm", "con"]}], "content": {}, "doi": "10.1145/3290605.3300510"}, {"uri": "121", "title": "Our Story: Addressing Challenges in Development Contexts for Sustainable Participatory Video", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Tom Bartindale"], "summary": "Participatory Video (PV) is emerging as a rich and valuable method for monitoring and evaluating (M & E) projects in the International Development sector. Although shown to be useful for engaging communities within short-term monitoring exercises or promotion, PV in these contexts presents signifcant complexity and logistical challenges for sustained uptake by Development organizations. In this paper, we present Our Story, a digitally mediated work fow iteratively designed and deployed on initiatives in Indonesia and Namibia. Developed in collaboration with the International Federation of Red Cross and Red Crescent (IFRC), it supports end-to-end PV production in the feld, and was specifcally developed to make PV a more sustainable tool for monitoring. We discuss and evaluate Our Story, reporting on how by lowering skills barriers for facilitators and leveraging consumer technology, PV can be delivered at scale.", "keywords": ["process", "based", "ifrc", "facilitator", "resource", "pipeline", "development", "bootlegger", "specifc", "stage", "staf", "medium", "review", "story", "pv", "production", "deployment", "work", "video", "tool", "building", "participant", "use", "group", "shot", "challenge", "literacy", "working", "voice", "supporting", "page", "existing", "application", "content", "monitoring", "ngo", "-", "produced", "representation", "delivering", "member", "practice", "feld", "data", "editing", "technology", "narrative", "skill", "support", "equipment", "required", "paper", "fow", "value", "context", "community"], "document_vector": [153.97142, 55.020397], "paragraphs": [{"paragraph_vector": [137.601242, -35.973747], "paragraph_keywords": ["video", "communities", "copies", "computing"]}, {"paragraph_vector": [134.835449, -32.604305], "paragraph_keywords": ["story", "ifrc", "video", "pv"]}, {"paragraph_vector": [133.552322, -29.628887], "paragraph_keywords": ["pv", "ngo", "community", "process"]}, {"paragraph_vector": [135.520217, -32.682258], "paragraph_keywords": ["pv", "community", "communities", "context"]}, {"paragraph_vector": [132.268463, -33.150119], "paragraph_keywords": ["community", "video", "participants", "pv"]}, {"paragraph_vector": [136.742736, -32.942935], "paragraph_keywords": ["process", "pv", "production", "knowledge"]}, {"paragraph_vector": [133.495452, -29.205087], "paragraph_keywords": ["supporting", "tools", "content", "process"]}, {"paragraph_vector": [128.730407, -27.705198], "paragraph_keywords": ["production", "pipeline", "technology", "practice"]}, {"paragraph_vector": [127.424163, -21.009714], "paragraph_keywords": ["production", "editing", "video", "bootlegger"]}, {"paragraph_vector": [127.793006, -19.2254], "paragraph_keywords": ["media", "app", "removed", "story"]}, {"paragraph_vector": [130.391906, -27.607156], "paragraph_keywords": ["based", "community", "process", "stories"]}, {"paragraph_vector": [129.457336, -23.566175], "paragraph_keywords": ["videos", "shot", "use", "video"]}, {"paragraph_vector": [129.789382, -17.650112], "paragraph_keywords": ["community", "group", "video", "process"]}, {"paragraph_vector": [132.377563, -28.341081], "paragraph_keywords": ["community", "story", "pmi", "building"]}, {"paragraph_vector": [130.067367, -21.372615], "paragraph_keywords": ["editing", "group", "fow", "work"]}, {"paragraph_vector": [124.885444, -16.355222], "paragraph_keywords": ["group", "videos", "internet", "story"]}, {"paragraph_vector": [133.875274, -31.935205], "paragraph_keywords": ["community", "ifrc", "researchers", "nrcs"]}, {"paragraph_vector": [131.44165, -26.049352], "paragraph_keywords": ["videos", "story", "editing", "captured"]}, {"paragraph_vector": [131.400161, -18.012378], "paragraph_keywords": ["editing", "video", "shooting", "participants"]}, {"paragraph_vector": [124.182594, -20.670356], "paragraph_keywords": ["community", "participants", "pv", "process"]}, {"paragraph_vector": [135.159454, -33.734554], "paragraph_keywords": ["community", "videos", "pv", "produced"]}, {"paragraph_vector": [132.502685, -28.479352], "paragraph_keywords": ["process", "pv", "equipment", "community"]}, {"paragraph_vector": [134.664794, -31.79733], "paragraph_keywords": ["community", "process", "bias", "ngo"]}, {"paragraph_vector": [131.498962, -30.195091], "paragraph_keywords": ["story", "community", "pv", "design"]}, {"paragraph_vector": [87.00251, -8.830117], "paragraph_keywords": ["access", "agreement", "metadata", "record"]}], "content": {}, "doi": "10.1145/3290605.3300618"}, {"uri": "122", "title": "VIPBoard: Improving Screen-Reader Keyboard for Visually Impaired People with Character-Level Auto Correction", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Weinan Shi", "Chun Yu", "Shuyi Fan", "Feng Wang", "Tong Wang", "Xin Yi", "Xiaojun Bi", "Yuanchun Shi"], "summary": "Modern touchscreen keyboards are all powered by the wordlevel auto-correction ability to handle input errors. Unfortunately, visually impaired users are deprived of such beneft because a screen-reader keyboard ofers only character-level input and provides no correction ability. In this paper, we present VIPBoard, a smart keyboard for visually impaired people, which aims at improving the underlying keyboard algorithm without altering the current input interaction. Upon each tap, VIPBoard predicts the probability of each key considering both touch location and language model, and reads \u2020 denotes the corresponding author. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proft or commercial advantage and that copies bear this notice and the full citation on the frst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specifc permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300747 the most likely key, which saves the calibration time when the touchdown point misses the target key. Meanwhile, the keyboard layout automatically scales according to users\u2019 touch point location, which enables them to select other keys easily. A user study shows that compared with the current keyboard technique, VIPBoard can reduce touch error rate by 63.0% and increase text entry speed by 12.6%.", "keywords": ["based", "fnger", "time", "correction", "performance", "method", "rate", "figure", "entry", "touch", "vipboard", "keyboard", "user", "model", "word", "adaption", "use", "participant", "key", "screen", "reader", "according", "character", "layout", "study", "text", "typing", "target", "input", "calculated", "auto", "bvi"], "document_vector": [-63.344467, -68.86782], "paragraphs": [{"paragraph_vector": [-32.919677, -16.588188], "paragraph_keywords": ["word", "users", "bvi", "computing"]}, {"paragraph_vector": [-25.388843, -25.068851], "paragraph_keywords": ["keyboard", "users", "fnger", "vipboard"]}, {"paragraph_vector": [-27.110486, -25.588623], "paragraph_keywords": ["methods", "method", "input", "vipboard"]}, {"paragraph_vector": [-26.551715, -24.813859], "paragraph_keywords": ["users", "keyboard", "character", "bvi"]}, {"paragraph_vector": [-29.559442, -16.283041], "paragraph_keywords": ["methods", "users", "based", "character"]}, {"paragraph_vector": [-28.931699, -30.527173], "paragraph_keywords": ["user", "keyboard", "screen", "reader"]}, {"paragraph_vector": [-26.952974, -24.485286], "paragraph_keywords": ["pre", "layout", "touch", "input"]}, {"paragraph_vector": [-32.156272, -8.03024], "paragraph_keywords": ["layout", "key", "touch", "position"]}, {"paragraph_vector": [-25.732282, -18.433809], "paragraph_keywords": ["key", "touch", "keys", "keyboard"]}, {"paragraph_vector": [-18.55241, -12.412964], "paragraph_keywords": ["input", "keyboard", "system", "word"]}, {"paragraph_vector": [-25.002885, -25.939161], "paragraph_keywords": ["input", "vipboard", "study", "axis"]}, {"paragraph_vector": [-31.167072, -15.862697], "paragraph_keywords": ["keyboards", "phrases", "swipe", "asked"]}, {"paragraph_vector": [-22.062192, -20.523328], "paragraph_keywords": ["input", "time", "typing", "speed"]}, {"paragraph_vector": [-25.727071, -24.452802], "paragraph_keywords": ["time", "vipboard", "input", "keyboard"]}, {"paragraph_vector": [-26.111461, -24.803697], "paragraph_keywords": ["time", "session", "vipboard", "p"]}, {"paragraph_vector": [-25.237411, -24.275585], "paragraph_keywords": ["vipboard", "use", "users", "participants"]}, {"paragraph_vector": [-25.735479, -27.179908], "paragraph_keywords": ["input", "touch", "result", "characters"]}, {"paragraph_vector": [-25.769876, -26.898557], "paragraph_keywords": ["participants", "users", "performance", "touch"]}, {"paragraph_vector": [-26.281314, -22.115085], "paragraph_keywords": ["vipboard", "users", "research", "text"]}], "content": {}, "doi": "10.1145/3290605.3300418"}, {"uri": "123", "title": "Communication Breakdowns Between Families and Alexa", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Erin Beneteau", "Julie A. Kientz", "Olivia K. Richards", "Mingrui Zhang"], "summary": "We investigate how families repair communication breakdowns with digital home assistants. We recruited 10 diverse families to use an Amazon Echo Dot in their homes for four weeks. All families had at least one child between four and 17 years old. Each family participated in preand postdeployment interviews. Their interactions with the Echo Dot (Alexa) were audio recorded throughout the study. We analyzed 59 communication breakdown interactions between family members and Alexa, framing our analysis with concepts from HCI and speech-language pathology. Our findings indicate that family members collaborate using discourse scaffolding (supportive communication guidance) and a variety of speech and language modifications in their attempts to repair communication breakdowns with Alexa. Alexa\u2019s responses also influence the repair strategies that families use. Designers can relieve the communication repair burden that primarily rests with families by increasing digital home assistants\u2019 abilities to collaborate together with users to repair communication breakdowns.", "keywords": ["based", "pause", "child", "breakdown", "strategy", "speech", "information", "mother", "repair", "conversation", "analysis", "home", "provide", "partner", "example", "assistant", "medium", "interaction", "communication", "work", "scaffolding", "language", "word", "use", "dot", "voice", "page", "echo", "switching", "member", "family", "response", "technology", "study", "topic", "skill", "talking", "audio", "discourse", "popsicle", "question", "paper", "son", "alexa", "code"], "document_vector": [123.859916, 68.355018], "paragraphs": [{"paragraph_vector": [132.823974, -55.826091], "paragraph_keywords": ["communication", "voice", "technology", "assistants"]}, {"paragraph_vector": [163.440338, -48.605594], "paragraph_keywords": ["families", "communication", "research", "use"]}, {"paragraph_vector": [165.904464, -48.635086], "paragraph_keywords": ["communication", "repair", "talking", "language"]}, {"paragraph_vector": [171.271896, -52.142436], "paragraph_keywords": ["communication", "parent", "scaffolding", "children"]}, {"paragraph_vector": [166.441223, -52.384113], "paragraph_keywords": ["communication", "repair", "agents", "machine"]}, {"paragraph_vector": [163.846069, -50.925334], "paragraph_keywords": ["communication", "families", "repair", "family"]}, {"paragraph_vector": [144.261123, -61.362228], "paragraph_keywords": ["families", "study", "system", "ages"]}, {"paragraph_vector": [162.546295, -57.347438], "paragraph_keywords": ["communication", "breakdowns", "families", "audio"]}, {"paragraph_vector": [165.752929, -51.108806], "paragraph_keywords": ["communication", "alexa", "family", "interactions"]}, {"paragraph_vector": [171.325073, -50.553836], "paragraph_keywords": ["family", "alexa", "repair", "speech"]}, {"paragraph_vector": [172.090408, -52.647422], "paragraph_keywords": ["communication", "family", "alexa", "response"]}, {"paragraph_vector": [171.2397, -52.169757], "paragraph_keywords": ["alexa", "popsicles", "son", "family"]}, {"paragraph_vector": [168.988616, -49.258937], "paragraph_keywords": ["communication", "alexa", "son", "popsicle"]}, {"paragraph_vector": [168.853897, -52.803241], "paragraph_keywords": ["alexa", "family", "mother", "communication"]}, {"paragraph_vector": [170.83702, -52.626789], "paragraph_keywords": ["alexa", "family", "question", "response"]}, {"paragraph_vector": [171.081832, -50.469757], "paragraph_keywords": ["alexa", "family", "repair", "daughter"]}, {"paragraph_vector": [168.541198, -52.099094], "paragraph_keywords": ["alexa", "family", "communication", "interaction"]}, {"paragraph_vector": [170.69635, -50.747631], "paragraph_keywords": ["alexa", "child", "question", "mother"]}, {"paragraph_vector": [166.510299, -49.210201], "paragraph_keywords": ["alexa", "communication", "child", "children"]}, {"paragraph_vector": [168.255676, -51.330074], "paragraph_keywords": ["alexa", "jokes", "child", "mother"]}, {"paragraph_vector": [167.665878, -50.102638], "paragraph_keywords": ["communication", "alexa", "family", "assistants"]}, {"paragraph_vector": [168.861251, -51.936206], "paragraph_keywords": ["communication", "discourse", "alexa", "code"]}, {"paragraph_vector": [169.429733, -51.602573], "paragraph_keywords": ["communication", "family", "alexa", "home"]}, {"paragraph_vector": [168.044631, -50.384006], "paragraph_keywords": ["communication", "families", "breakdowns", "technology"]}, {"paragraph_vector": [168.033386, -51.156089], "paragraph_keywords": ["communication", "promote", "repair", "home"]}], "content": {}, "doi": "10.1145/3290605.3300442"}, {"uri": "124", "title": "Turn to the Self in Human-Computer Interaction: Care of the Self in Negotiating the Human-Technology Relationship", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Yubo Kou", "Xinning Gui", "Yunan Chen", "Bonnie Nardi"], "summary": "Everyday life is increasingly mediated by technology. Technology is rapidly growing capacity and complexity, especially evident in developments in artificial intelligence and big data analytics. As human-computer interaction (HCI) endeavors to examine and theorize how people act and interact with the ever-evolving technology, an important, emerging concern is how the self\u2014the totality of internal qualities such as consciousness and agency\u2014plays out in relation to the technology-mediated external world. To analyze this question, we draw from Michel Foucault\u2019s ethics of \u201ccare of the self,\u201d which examines how the self is constituted through conscious and reflective work on selftransformation. We present three case studies to illustrate how individuals carry out practices of the self to reflect upon and negotiate their relationship with technology. We discuss the importance of examining the self and foreground the notion of care of the self in HCI research and design.", "keywords": ["caregiver", "concerned", "time", "breakdown", "relation", "foucault", "information", "person", "performance", "discussion", "self", "player", "design", "analysis", "care", "environment", "truth", "example", "power", "medium", "censorship", "work", "participant", "use", "patient", "people", "concern", "quantification", "health", "sense", "mean", "state", "page", "lol", "examination", "understand", "culture", "life", "case", "examine", "practice", "data", "technology", "game", "study", "researcher", "system", "network", "term", "website", "meaning", "hci", "individual", "paper", "structure", "healthcare", "knowledge", "value", "action", "context"], "document_vector": [56.642509, 22.661193], "paragraphs": [{"paragraph_vector": [115.479064, -47.191555], "paragraph_keywords": ["self", "technology", "knowledge", "increasing"]}, {"paragraph_vector": [104.823616, -37.575862], "paragraph_keywords": ["self", "design", "technology", "power"]}, {"paragraph_vector": [130.115417, -38.716754], "paragraph_keywords": ["self", "technology", "case", "care"]}, {"paragraph_vector": [118.639533, -45.807289], "paragraph_keywords": ["power", "foucault", "self", "relations"]}, {"paragraph_vector": [123.262397, -38.950878], "paragraph_keywords": ["self", "person", "foucault", "examination"]}, {"paragraph_vector": [128.959014, -43.499832], "paragraph_keywords": ["self", "care", "health", "tracking"]}, {"paragraph_vector": [120.049766, -43.067344], "paragraph_keywords": ["hci", "technologies", "self", "relationships"]}, {"paragraph_vector": [95.117225, -49.041183], "paragraph_keywords": ["economy", "hci", "self", "labor"]}, {"paragraph_vector": [99.523193, -52.643253], "paragraph_keywords": ["technology", "work", "life", "data"]}, {"paragraph_vector": [105.27362, -38.956668], "paragraph_keywords": ["self", "culture", "projects", "data"]}, {"paragraph_vector": [-152.10498, -25.538345], "paragraph_keywords": ["players", "individuals", "quantification", "self"]}, {"paragraph_vector": [41.296897, -60.183265], "paragraph_keywords": ["technologies", "media", "censorship", "internet"]}, {"paragraph_vector": [41.338527, -55.314792], "paragraph_keywords": ["truth", "censorship", "technologies", "participant"]}, {"paragraph_vector": [34.113067, -57.233654], "paragraph_keywords": ["participants", "information", "technologies", "censorship"]}, {"paragraph_vector": [-154.284194, -27.851097], "paragraph_keywords": ["quantification", "performance", "player", "teammates"]}, {"paragraph_vector": [-116.921463, -7.756478], "paragraph_keywords": ["quantification", "self", "game", "player"]}, {"paragraph_vector": [-155.554214, -28.729475], "paragraph_keywords": ["quantification", "patients", "healthcare", "relations"]}, {"paragraph_vector": [140.877426, -26.666954], "paragraph_keywords": ["healthcare", "work", "insurance", "participant"]}, {"paragraph_vector": [159.83023, -14.683819], "paragraph_keywords": ["healthcare", "websites", "network", "providers"]}, {"paragraph_vector": [150.978683, -26.757726], "paragraph_keywords": ["self", "care", "system", "healthcare"]}, {"paragraph_vector": [117.769096, -41.54364], "paragraph_keywords": ["technologies", "self", "efficiency", "technology"]}, {"paragraph_vector": [94.874023, -51.726146], "paragraph_keywords": ["participants", "authority", "technology", "self"]}, {"paragraph_vector": [132.958251, -43.806941], "paragraph_keywords": ["self", "care", "technology", "people"]}, {"paragraph_vector": [124.728515, -36.400043], "paragraph_keywords": ["self", "practices", "people", "hci"]}, {"paragraph_vector": [118.859169, -41.685443], "paragraph_keywords": ["knowledge", "self", "power", "design"]}, {"paragraph_vector": [102.89083, -39.221527], "paragraph_keywords": ["self", "design", "people", "technology"]}], "content": {}, "doi": "10.1145/3290605.3300446"}, {"uri": "125", "title": "On the Internet, Nobody Knows You\u2019re a Dog... Unless You\u2019re Another Dog", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Ilyena Hirskyj-Douglas"], "summary": "How humans use computers has evolved from human\u2013 machine interfaces to human\u2013human computer mediated communication. Whilst the field of animal\u2013computer interaction has roots in HCI, technology developed in this area currently only supports animal\u2013 computer communication. This design fiction paper presents animal\u2013 animal connected interfaces, using dogs as an instance. Through a co-design workshop, we created six proposals. The designs focused on what a dog internet could look like and how interactions might be presented. Analysis of the narratives and conceived designs indicated that participants\u2019 concerns focused around asymmetries within the interaction. This resulted in the use of objects seen as familiar to dogs. This was conjoined with interest in how to initiate and end interactions, which was often achieved through notification systems. This paper builds upon HCI methods for unconventional users, and applies a design fiction approach to uncover key questions towards the creation of animal-to-animal interfaces.", "keywords": ["process", "al", "allow", "design", "method", "home", "provide", "user", "interaction", "play", "et", "workshop", "work", "video", "participant", "use", "internet", "group", "way", "dog", "idea", "computing", "page", "fiction", "task", "animal", "computer", "human", "device", "technology", "study", "system", "research", "hci", "paper", "question", "interface", "aci"], "document_vector": [92.686538, 5.921943], "paragraphs": [{"paragraph_vector": [-110.195884, -30.249042], "paragraph_keywords": ["animals", "computer", "animal", "humans"]}, {"paragraph_vector": [-110.711044, -30.542562], "paragraph_keywords": ["dog", "dogs", "owner", "animals"]}, {"paragraph_vector": [-111.20082, -29.463775], "paragraph_keywords": ["design", "technology", "animal", "dog"]}, {"paragraph_vector": [-108.973472, -29.546331], "paragraph_keywords": ["animal", "dog", "aci", "buttons"]}, {"paragraph_vector": [-108.364463, -27.452507], "paragraph_keywords": ["dog", "dogs", "participation", "technologies"]}, {"paragraph_vector": [-111.22673, -29.414987], "paragraph_keywords": ["design", "dog", "fiction", "dogs"]}, {"paragraph_vector": [-108.391036, -30.615032], "paragraph_keywords": ["design", "horse", "fictions", "animals"]}, {"paragraph_vector": [-110.989364, -29.94654], "paragraph_keywords": ["participants", "dog", "design", "aci"]}, {"paragraph_vector": [-108.238815, -29.468378], "paragraph_keywords": ["dog", "task", "participants", "group"]}, {"paragraph_vector": [-110.819984, -26.804138], "paragraph_keywords": ["dog", "video", "interaction", "systems"]}, {"paragraph_vector": [-111.042739, -29.839448], "paragraph_keywords": ["ideas", "groups", "designs", "group"]}, {"paragraph_vector": [-111.730087, -29.480405], "paragraph_keywords": ["dog", "dogs", "companion", "ideas"]}, {"paragraph_vector": [-110.819015, -28.161352], "paragraph_keywords": ["dog", "dogs", "walk", "allow"]}, {"paragraph_vector": [-110.366218, -28.201555], "paragraph_keywords": ["dog", "dogs", "rope", "play"]}, {"paragraph_vector": [-109.554687, -29.012538], "paragraph_keywords": ["dog", "dogs", "designs", "design"]}, {"paragraph_vector": [-111.707855, -30.827383], "paragraph_keywords": ["dog", "methods", "design", "interaction"]}, {"paragraph_vector": [-112.894226, -29.47014], "paragraph_keywords": ["dog", "interactions", "interaction", "systems"]}, {"paragraph_vector": [-109.839805, -30.51581], "paragraph_keywords": ["dog", "design", "dogs", "user"]}, {"paragraph_vector": [-110.602409, -29.111692], "paragraph_keywords": ["design", "dog", "interaction", "animal"]}, {"paragraph_vector": [-111.001167, -30.383876], "paragraph_keywords": ["animal", "hci", "interactions", "dog"]}], "content": {}, "doi": "10.1145/3290605.3300395"}, {"uri": "126", "title": "Smart Home Security Cameras and Shifting Lines of Creepiness", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["James Pierce"], "summary": "Through a design-led inquiry focused on smart home security cameras, this research develops three key concepts for research and design pertaining to new and emerging digital consumer technologies. Digital leakage names the propensity for digital information to be shared, stolen, and misused in ways unbeknownst or even harmful to those to whom the data pertains or belongs. Hole-and-corner applications are those functions connected to users\u2019 data, devices, and interactions yet concealed from or downplayed to them, often because they are non-beneficial or harmful to them. Foot-in-the-door devices are product and services with functional offerings and affordances that work to normalize and integrate a technology, thus laying groundwork for future adoption of features that might have earlier been rejected as unacceptable or unnecessary. Developed and illustrated through a set of design studies and explorations, this paper shows how these concepts may be used analytically to investigate issues such as privacy and security, anticipatorily to speculate about the future of technology development and use, and generatively to synthesize design concepts and solutions.", "keywords": ["emerging", "consider", "leakage", "door", "credit", "information", "us", "design", "leaky", "analysis", "home", "technique", "problem", "opportunity", "example", "sensor", "camera", "foot", "user", "activity", "medium", "power", "hole", "work", "video", "scenario", "law", "use", "internet", "people", "line", "issue", "metaphor", "concept", "security", "page", "field", "application", "light", "inquiry", "cam", "case", "device", "data", "technology", "study", "nest", "research", "marketing", "surveillance", "include", "corner", "hci", "paper", "privacy", "harm", "creepiness"], "document_vector": [70.412094, 36.736633], "paragraphs": [{"paragraph_vector": [-12.562789, -83.77777], "paragraph_keywords": ["design", "technology", "concepts", "data"]}, {"paragraph_vector": [110.781105, -69.77787], "paragraph_keywords": ["design", "copies", "creepiness", "technology"]}, {"paragraph_vector": [107.963165, -51.753601], "paragraph_keywords": ["creepiness", "technology", "users", "concepts"]}, {"paragraph_vector": [106.585144, -45.721908], "paragraph_keywords": ["creepiness", "security", "research", "technology"]}, {"paragraph_vector": [-18.894657, -78.274436], "paragraph_keywords": ["design", "paper", "research", "home"]}, {"paragraph_vector": [98.48001, -37.287143], "paragraph_keywords": ["data", "leakage", "information", "research"]}, {"paragraph_vector": [-20.905832, -79.665664], "paragraph_keywords": ["design", "security", "cameras", "leaky"]}, {"paragraph_vector": [-21.388261, -80.485588], "paragraph_keywords": ["sensor", "cameras", "camera", "window"]}, {"paragraph_vector": [-15.997262, -81.019309], "paragraph_keywords": ["sensor", "camera", "blindspots", "ccd"]}, {"paragraph_vector": [-16.487432, -76.807929], "paragraph_keywords": ["data", "maps", "camera", "applications"]}, {"paragraph_vector": [-3.453388, -79.815063], "paragraph_keywords": ["applications", "corner", "edge", "hole"]}, {"paragraph_vector": [13.109426, -67.68357], "paragraph_keywords": ["data", "corner", "scenarios", "software"]}, {"paragraph_vector": [35.342742, -60.355224], "paragraph_keywords": ["application", "credit", "harassment", "use"]}, {"paragraph_vector": [-8.080733, -76.508613], "paragraph_keywords": ["hole", "surveillance", "partner", "design"]}, {"paragraph_vector": [-138.537582, -88.798698], "paragraph_keywords": ["devices", "data", "profiles", "user"]}, {"paragraph_vector": [109.621704, -61.381175], "paragraph_keywords": ["device", "door", "foot", "request"]}, {"paragraph_vector": [38.470905, -83.882247], "paragraph_keywords": ["maya", "design", "security", "cameras"]}, {"paragraph_vector": [-3.81223, -73.975547], "paragraph_keywords": ["security", "nest", "camera", "videos"]}, {"paragraph_vector": [-33.03128, -71.824996], "paragraph_keywords": ["camera", "cameras", "power", "home"]}, {"paragraph_vector": [-67.376861, -82.718688], "paragraph_keywords": ["data", "wall", "concept", "information"]}, {"paragraph_vector": [-4.396931, -78.007766], "paragraph_keywords": ["data", "leakage", "leaks", "security"]}, {"paragraph_vector": [102.760292, -66.776908], "paragraph_keywords": ["door", "applications", "foot", "intent"]}, {"paragraph_vector": [-17.86864, -85.054061], "paragraph_keywords": ["shifts", "design", "door", "normalcy"]}, {"paragraph_vector": [-46.448558, -83.815666], "paragraph_keywords": ["concepts", "design", "issues", "privacy"]}], "content": {}, "doi": "10.1145/3290605.3300844"}, {"uri": "127", "title": "3D Pen + 3D Printer : Exploring the Role of Humans and Fabrication Machines in Creative Making", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Haruki Takahashi"], "summary": "The emergence of a 3D pen brings 3Dmodeling from a screenbased computer-aided design (CAD) system and 3D printing to direct and rapid crafting by 3D doodling. However, 3D doodling remains challenging, requiring craft skills to rapidly express an idea, which is critical in creative making. We explore a new process of 3D modeling using 3D pen + 3D printer. Our pilot study shows that users need support to reduce the number of non-creative tasks to explore a wide design strategy. With the opportunity to invent a new 3D modeling process that needs to incorporate both a pen and printer, we propose techniques and a system that empower users to print while doodling to focus on creative exploration. Our user study shows that users can create diverse 3Dmodels using a pen and printer. We discuss the roles of the human and fabrication machine for the future of fabrication.", "keywords": ["process", "explore", "time", "object", "design", "speed", "craft", "technique", "creativity", "example", "goal", "doodling", "user", "doodled", "surface", "work", "tool", "participant", "use", "create", "material", "size", "printing", "created", "shape", "page", "min", "part", "provided", "task", "hand", "creation", "human", "study", "support", "system", "printer", "machine", "pen", "printed", "paper", "modeling", "fabrication", "figure", "making"], "document_vector": [93.009361, -33.365615], "paragraphs": [{"paragraph_vector": [-106.907844, 50.997222], "paragraph_keywords": ["users", "copies", "cad", "work"]}, {"paragraph_vector": [-108.15084, 50.942523], "paragraph_keywords": ["fabrication", "pen", "printer", "making"]}, {"paragraph_vector": [-107.374641, 52.673049], "paragraph_keywords": ["fabrication", "machines", "users", "craft"]}, {"paragraph_vector": [-107.044052, 50.408706], "paragraph_keywords": ["users", "explore", "work", "making"]}, {"paragraph_vector": [-103.205192, 51.401775], "paragraph_keywords": ["users", "doodling", "pen", "participants"]}, {"paragraph_vector": [-105.179206, 53.016143], "paragraph_keywords": ["users", "figure", "object", "objects"]}, {"paragraph_vector": [-100.991493, 52.713703], "paragraph_keywords": ["users", "printed", "details", "pen"]}, {"paragraph_vector": [-89.2303, 53.926242], "paragraph_keywords": ["printed", "leaf", "pen", "tools"]}, {"paragraph_vector": [-102.758445, 54.753147], "paragraph_keywords": ["printed", "printing", "mm", "doodling"]}, {"paragraph_vector": [-103.232658, 53.035705], "paragraph_keywords": ["printing", "paper", "figure", "edge"]}, {"paragraph_vector": [-107.732917, 50.966102], "paragraph_keywords": ["printer", "pen", "body", "study"]}, {"paragraph_vector": [-101.343292, 51.863002], "paragraph_keywords": ["tools", "participants", "pen", "provided"]}, {"paragraph_vector": [-99.765769, 53.091743], "paragraph_keywords": ["participants", "system", "material", "min"]}, {"paragraph_vector": [124.333419, 45.710472], "paragraph_keywords": ["participants", "tools", "session", "work"]}, {"paragraph_vector": [-101.821327, 52.743484], "paragraph_keywords": ["printer", "participants", "answered", "pen"]}, {"paragraph_vector": [-100.616195, 54.19128], "paragraph_keywords": ["pen", "work", "participants", "said"]}, {"paragraph_vector": [-98.485923, 52.411838], "paragraph_keywords": ["making", "printer", "printed", "participants"]}, {"paragraph_vector": [-102.735435, 49.838615], "paragraph_keywords": ["work", "pen", "print", "printer"]}, {"paragraph_vector": [-100.406311, 49.301231], "paragraph_keywords": ["tools", "tweezers", "printing", "use"]}, {"paragraph_vector": [-99.237342, 50.956348], "paragraph_keywords": ["printer", "users", "efficiency", "parts"]}, {"paragraph_vector": [-102.578857, 51.387226], "paragraph_keywords": ["printing", "users", "pen", "printer"]}, {"paragraph_vector": [-105.369293, 50.428565], "paragraph_keywords": ["printer", "time", "participants", "making"]}], "content": {}, "doi": "10.1145/3290605.3300263"}, {"uri": "128", "title": "Exploring the Plurality of Black Women\u2019s ", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Yolanda A. Rankin"], "summary": "Few gender-focused studies of video games explore the gameplay experiences of women of color, and those that do tend to only emphasize negative phenomena (i.e., racial or gender discrimination). In this paper, we conduct an exploratory case study attending to the motivations and gaming practices of Black college women. Questionnaire responses and focus group discussion illuminate the plurality of gameplay experiences for this specific population of Black college women. Sixty-five percent of this population enjoy the ubiquity of mobile games with casual and puzzle games being the most popular genres. However, academic responsibilities and competing recreational interests inhibit frequent gameplay. Consequently, this population of Black college women represent two types of casual gamers who report positive gameplay experiences, providing insights into creating a more inclusive gaming subculture.", "keywords": ["facilitator", "time", "population", "marginalized", "discussion", "community", "player", "analysis", "friend", "playing", "focus", "puzzle", "gender", "woman", "play", "included", "shared", "engage", "video", "participant", "group", "learning", "experience", "page", "college", "character", "understand", "gameplay", "gaming", "member", "family", "played", "game", "study", "researcher", "student", "color", "framework", "intersectionality", "research", "race", "paper", "motivation", "context", "gamers", "response"], "document_vector": [-18.214698, -1.142322], "paragraphs": [{"paragraph_vector": [-150.397918, -17.478647], "paragraph_keywords": ["women", "studies", "games", "gaming"]}, {"paragraph_vector": [-148.576919, -19.438728], "paragraph_keywords": ["women", "color", "intersectionality", "copies"]}, {"paragraph_vector": [-148.340362, -18.462802], "paragraph_keywords": ["women", "gameplay", "game", "gaming"]}, {"paragraph_vector": [-150.574691, -20.281103], "paragraph_keywords": ["games", "game", "players", "women"]}, {"paragraph_vector": [-149.523742, -18.796888], "paragraph_keywords": ["women", "color", "gameplay", "gamers"]}, {"paragraph_vector": [-147.718566, -20.137559], "paragraph_keywords": ["women", "experiences", "gameplay", "group"]}, {"paragraph_vector": [-148.431533, -17.860536], "paragraph_keywords": ["women", "experiences", "gamers", "gender"]}, {"paragraph_vector": [-148.3553, -19.466697], "paragraph_keywords": ["women", "game", "students", "participants"]}, {"paragraph_vector": [-151.48645, -19.708166], "paragraph_keywords": ["games", "participants", "analysis", "discussion"]}, {"paragraph_vector": [-156.47583, -22.696546], "paragraph_keywords": ["games", "play", "gaming", "video"]}, {"paragraph_vector": [-149.977279, -16.368186], "paragraph_keywords": ["games", "puzzle", "student", "swipe"]}, {"paragraph_vector": [-148.846054, -19.431324], "paragraph_keywords": ["games", "play", "video", "wii"]}, {"paragraph_vector": [-141.60054, -11.827322], "paragraph_keywords": ["play", "games", "time", "learning"]}, {"paragraph_vector": [-149.957397, -19.616422], "paragraph_keywords": ["play", "games", "family", "played"]}, {"paragraph_vector": [-148.484069, -18.875238], "paragraph_keywords": ["games", "play", "playing", "friends"]}, {"paragraph_vector": [-146.888214, -19.312828], "paragraph_keywords": ["games", "women", "video", "college"]}, {"paragraph_vector": [-147.241638, -19.272045], "paragraph_keywords": ["women", "games", "gaming", "intersectionality"]}, {"paragraph_vector": [-147.93428, -19.13449], "paragraph_keywords": ["researcher", "gaming", "games", "marginalized"]}, {"paragraph_vector": [-148.692977, -18.136217], "paragraph_keywords": ["games", "players", "women", "time"]}, {"paragraph_vector": [-147.019241, -19.625473], "paragraph_keywords": ["women", "gaming", "games", "years"]}, {"paragraph_vector": [-147.694992, -19.587196], "paragraph_keywords": ["games", "gaming", "women", "play"]}, {"paragraph_vector": [-147.938308, -19.393417], "paragraph_keywords": ["women", "time", "games", "experiences"]}, {"paragraph_vector": [-147.200408, -19.798194], "paragraph_keywords": ["games", "gameplay", "women", "gaming"]}, {"paragraph_vector": [-150.815612, -18.209703], "paragraph_keywords": ["research", "assistants", "provided", "comments"]}], "content": {}, "doi": "10.1145/3290605.3300594"}, {"uri": "129", "title": "Understanding the Boundaries between Policymaking and HCI", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Anne Spaa", "Abigail Durrant"], "summary": "There is a growing body of literature in HCI examining the intersection between policymaking and technology research. However, what it means to engage in policymaking in our field, or the ways in which evidence from HCI studies is translated into policy, is not well understood. We report on interviews with 11 participants working at the intersection of technology research and policymaking. Analysis of this data highlights how evidence is understood and made sense of in policymaking processes, what forms of evidence are privileged over others, and the work that researchers engage in to meaningfully communicate their work to policymaking audiences. We discuss how our findings pose challenges for certain traditions of research in HCI, yet also open up new policy opportunities for those engaging in more speculative research practices. We conclude by discussing three ways forward that the HCI community can explore to increase engagement with policymaking contexts.", "keywords": ["process", "based", "time", "change", "policy", "need", "development", "evidence", "design", "core", "interview", "provide", "opportunity", "uk", "focus", "example", "tank", "activity", "policymaking", "government", "ebpm", "work", "engage", "impact", "policymakers", "participant", "use", "people", "issue", "way", "think", "future", "challenge", "working", "page", "field", "difficulty", "understanding", "form", "developed", "develop", "described", "practice", "data", "technology", "researcher", "approach", "study", "role", "developing", "research", "informing", "influence", "hci", "paper", "knowledge", "tt", "community"], "document_vector": [74.068336, 53.78453], "paragraphs": [{"paragraph_vector": [105.645271, -35.296623], "paragraph_keywords": ["research", "impact", "copies", "policy"]}, {"paragraph_vector": [98.382812, -27.365087], "paragraph_keywords": ["policy", "researchers", "policymaking", "research"]}, {"paragraph_vector": [101.174362, -28.88676], "paragraph_keywords": ["policy", "hci", "design", "policymaking"]}, {"paragraph_vector": [96.648941, -29.882984], "paragraph_keywords": ["hci", "researchers", "technologies", "policy"]}, {"paragraph_vector": [102.229797, -28.74965], "paragraph_keywords": ["hci", "evidence", "policy", "field"]}, {"paragraph_vector": [103.715988, -27.763746], "paragraph_keywords": ["policymaking", "evidence", "ebpm", "policy"]}, {"paragraph_vector": [103.542556, -28.097305], "paragraph_keywords": ["policy", "evidence", "development", "decisions"]}, {"paragraph_vector": [107.375862, -28.810781], "paragraph_keywords": ["policy", "think", "tanks", "influence"]}, {"paragraph_vector": [103.574005, -28.522314], "paragraph_keywords": ["research", "think", "tanks", "policymaking"]}, {"paragraph_vector": [103.3703, -26.367353], "paragraph_keywords": ["policy", "think", "tanks", "based"]}, {"paragraph_vector": [101.943161, -29.671146], "paragraph_keywords": ["themes", "interviews", "practices", "developed"]}, {"paragraph_vector": [103.515045, -26.613487], "paragraph_keywords": ["evidence", "participants", "policy", "research"]}, {"paragraph_vector": [100.890281, -27.983438], "paragraph_keywords": ["phase", "communities", "citizen", "voice"]}, {"paragraph_vector": [106.087188, -28.102926], "paragraph_keywords": ["policy", "tt", "evidence", "role"]}, {"paragraph_vector": [109.122375, -24.472499], "paragraph_keywords": ["future", "versions", "tt", "horizons"]}, {"paragraph_vector": [104.53881, -24.850072], "paragraph_keywords": ["future", "design", "way", "policy"]}, {"paragraph_vector": [104.258255, -30.123161], "paragraph_keywords": ["evidence", "researchers", "policy", "participants"]}, {"paragraph_vector": [106.86621, -28.948423], "paragraph_keywords": ["work", "tt", "policy", "policymakers"]}, {"paragraph_vector": [104.974342, -27.191682], "paragraph_keywords": ["participants", "policy", "evidence", "policymakers"]}, {"paragraph_vector": [105.70494, -27.181594], "paragraph_keywords": ["design", "thinking", "law", "policy"]}, {"paragraph_vector": [105.1613, -26.804048], "paragraph_keywords": ["think", "know", "researchers", "policymakers"]}, {"paragraph_vector": [104.159332, -28.406364], "paragraph_keywords": ["tt", "research", "described", "participants"]}, {"paragraph_vector": [104.148757, -28.921436], "paragraph_keywords": ["evidence", "work", "research", "ebpm"]}, {"paragraph_vector": [101.226654, -29.329574], "paragraph_keywords": ["research", "field", "hci", "contexts"]}, {"paragraph_vector": [100.447608, -23.185342], "paragraph_keywords": ["hci", "policy", "studies", "field"]}, {"paragraph_vector": [103.29766, -28.154596], "paragraph_keywords": ["hci", "evidence", "think", "tanks"]}, {"paragraph_vector": [101.813209, -28.977266], "paragraph_keywords": ["technologies", "working", "research", "evidence"]}, {"paragraph_vector": [102.30339, -27.329051], "paragraph_keywords": ["policy", "research", "hci", "think"]}, {"paragraph_vector": [104.364845, -27.108381], "paragraph_keywords": ["policy", "research", "hci", "issues"]}, {"paragraph_vector": [104.100288, -27.051971], "paragraph_keywords": ["hci", "evidence", "time", "policymaking"]}], "content": {}, "doi": "10.1145/3290605.3300801"}, {"uri": "130", "title": "Street\u2013Level Algorithms: A Theory at the Gaps Between Policy and Decisions", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Ali Alkhatib", "Michael Bernstein"], "summary": "Errors and biases are earning algorithms increasingly malignant reputations in society. A central challenge is that algorithms must bridge the gap between high\u2013level policy and on\u2013the\u2013ground decisions, making inferences in novel situations where the policy or training data do not readily apply. In this paper, we draw on the theory of street\u2013level bureaucracies, how human bureaucrats such as police and judges interpret policy to make on\u2013the\u2013ground decisions. We present by analogy a theory of street\u2013level algorithms, the algorithms that bridge the gaps between policy and decisions about people in a socio-technical system.We argue that unlike street\u2013level bureaucrats, who re exively re ne their decision criteria as they reason through a novel situation, street\u2013level algorithms at best re ne their criteria only after the decision is made. This loop\u2013and\u2013a\u2013half delay results in illogical decisions when handling new or extenuating circumstances. This theory suggests designs for street\u2013level algorithms that draw on historical design patterns for street\u2013 level bureaucracies, including mechanisms for self\u2013policing and recourse in the case of error.", "keywords": ["police", "recourse", "time", "policy", "need", "worker", "discussion", "training", "seen", "problem", "error", "example", "bail", "power", "gender", "decision", "thinking", "work", "video", "law", "use", "people", "e", "identify", "learning", "way", "sense", "moderation", "circumstance", "algorithm", "page", "ect", "number", "agent", "content", "understand", "decide", "stakeholder", "judge", "case", "bureaucrat", "con", "crowd", "data", "designer", "situation", "system", "today", "outcome", "youtube", "defendant", "street", "paper", "discretion", "evaluate", "di", "bureaucracy", "level", "making"], "document_vector": [-94.576263, 7.586843], "paragraphs": [{"paragraph_vector": [60.262683, -0.832525], "paragraph_keywords": ["systems", "copies", "work", "decisions"]}, {"paragraph_vector": [58.641658, 12.286005], "paragraph_keywords": ["decisions", "algorithms", "gaps", "street"]}, {"paragraph_vector": [59.083885, 4.362575], "paragraph_keywords": ["street", "level", "decisions", "policy"]}, {"paragraph_vector": [58.719257, 5.683576], "paragraph_keywords": ["case", "systems", "street", "algorithms"]}, {"paragraph_vector": [59.498504, 2.056196], "paragraph_keywords": ["street", "level", "power", "decisions"]}, {"paragraph_vector": [58.358459, 2.787778], "paragraph_keywords": ["e", "people", "level", "street"]}, {"paragraph_vector": [58.496681, 1.728346], "paragraph_keywords": ["systems", "use", "level", "street"]}, {"paragraph_vector": [59.169979, 1.542462], "paragraph_keywords": ["level", "algorithms", "street", "systems"]}, {"paragraph_vector": [58.8278, 3.898019], "paragraph_keywords": ["decision", "case", "sense", "situations"]}, {"paragraph_vector": [57.696121, 4.835074], "paragraph_keywords": ["decision", "system", "cases", "facebook"]}, {"paragraph_vector": [60.935279, 5.622124], "paragraph_keywords": ["content", "youtube", "video", "videos"]}, {"paragraph_vector": [57.664863, 4.011913], "paragraph_keywords": ["police", "content", "youtube", "street"]}, {"paragraph_vector": [152.35289, 16.61128], "paragraph_keywords": ["data", "people", "training", "youtube"]}, {"paragraph_vector": [57.015457, 3.946022], "paragraph_keywords": ["work", "algorithms", "workers", "e"]}, {"paragraph_vector": [47.61584, 10.751417], "paragraph_keywords": ["work", "workers", "foremen", "output"]}, {"paragraph_vector": [52.280242, 5.74931], "paragraph_keywords": ["work", "data", "systems", "evaluate"]}, {"paragraph_vector": [57.582664, 1.781198], "paragraph_keywords": ["bureaucrats", "bail", "algorithms", "systems"]}, {"paragraph_vector": [57.894557, 4.733215], "paragraph_keywords": ["circumstances", "street", "level", "traits"]}, {"paragraph_vector": [56.125373, 3.969634], "paragraph_keywords": ["algorithm", "cases", "case", "argue"]}, {"paragraph_vector": [58.598293, 2.243193], "paragraph_keywords": ["system", "recognize", "recourse", "street"]}, {"paragraph_vector": [57.068038, 3.909521], "paragraph_keywords": ["system", "case", "videos", "example"]}, {"paragraph_vector": [57.219402, 3.041882], "paragraph_keywords": ["systems", "designers", "oversight", "defendants"]}, {"paragraph_vector": [59.711307, 3.879667], "paragraph_keywords": ["level", "street", "bureaucrats", "roles"]}, {"paragraph_vector": [58.4622, 3.338483], "paragraph_keywords": ["algorithms", "level", "street", "discretion"]}, {"paragraph_vector": [57.229503, 2.568255], "paragraph_keywords": ["systems", "level", "street", "handle"]}, {"paragraph_vector": [59.437114, 1.456477], "paragraph_keywords": ["discussion", "systems", "work", "level"]}], "content": {}, "doi": "10.1145/3290605.3300793"}, {"uri": "131", "title": "Exploring Media Capture of Meaningful Experiences to Support Families Living with Dementia", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["James Hodge"], "summary": "Although designing interactive media experiences for people with dementia has become a growing interest in HCI, a strong focus on family members has rarely been recognised as worthy of design intervention. This paper presents a research through design (RTD) approach working closely with families living with dementia in order to create personalised media experiences. Three families took part in day trips, which they co-planned, with data collection during these days providing insights into their shared social experiences. Workshops were also held in order to personalise the experience of the media created during these days out. Our qualitative analysis outlines themes focusing on individuality, relationships, and accepting changed realities. Furthermore, we outline directions for future research focusing on designing for contested realities, the personhood of carers, and the ageing body and immersion.", "keywords": ["importance", "capture", "vr", "time", "change", "reminiscence", "degree", "person", "moment", "set", "memory", "allow", "self", "design", "conversation", "care", "opportunity", "focus", "relationship", "medium", "designing", "activity", "interaction", "communication", "sharing", "work", "place", "video", "participant", "use", "create", "people", "captured", "way", "sense", "mean", "theme", "experience", "page", "michael", "including", "life", "member", "family", "lauren", "data", "day", "technology", "study", "instance", "researcher", "dementia", "approach", "role", "support", "reality", "research", "order", "hci", "individual", "paper", "carers"], "document_vector": [105.993675, 40.261684], "paragraphs": [{"paragraph_vector": [130.331665, -45.322067], "paragraph_keywords": ["design", "dementia", "copies", "work"]}, {"paragraph_vector": [-155.746688, -74.038558], "paragraph_keywords": ["dementia", "design", "use", "work"]}, {"paragraph_vector": [-152.266921, -71.14154], "paragraph_keywords": ["dementia", "media", "design", "experiences"]}, {"paragraph_vector": [-166.815109, -79.193794], "paragraph_keywords": ["dementia", "design", "research", "reminiscence"]}, {"paragraph_vector": [-171.908935, -69.685073], "paragraph_keywords": ["family", "person", "dementia", "roles"]}, {"paragraph_vector": [-178.557632, -69.395683], "paragraph_keywords": ["communication", "family", "dementia", "sharing"]}, {"paragraph_vector": [-158.685699, -70.721519], "paragraph_keywords": ["dementia", "media", "person", "experiences"]}, {"paragraph_vector": [-155.939041, -69.620903], "paragraph_keywords": ["dementia", "research", "work", "experiences"]}, {"paragraph_vector": [-150.903182, -70.823982], "paragraph_keywords": ["moments", "problems", "families", "design"]}, {"paragraph_vector": [173.65335, -82.42311], "paragraph_keywords": ["families", "dementia", "research", "participants"]}, {"paragraph_vector": [-144.236007, -75.570129], "paragraph_keywords": ["day", "families", "family", "place"]}, {"paragraph_vector": [-130.025955, -73.203392], "paragraph_keywords": ["family", "participants", "moments", "captured"]}, {"paragraph_vector": [125.122619, -38.180934], "paragraph_keywords": ["data", "analysis", "day", "videos"]}, {"paragraph_vector": [-175.363021, -80.098922], "paragraph_keywords": ["themes", "way", "dementia", "reality"]}, {"paragraph_vector": [-141.006118, -77.475509], "paragraph_keywords": ["family", "reality", "time", "mother"]}, {"paragraph_vector": [-172.970748, -68.606018], "paragraph_keywords": ["family", "videos", "day", "vr"]}, {"paragraph_vector": [-64.756004, -60.73318], "paragraph_keywords": ["milk", "way", "family", "individual"]}, {"paragraph_vector": [168.126373, -84.785484], "paragraph_keywords": ["lauren", "family", "experiences", "dementia"]}, {"paragraph_vector": [-149.332, -72.557754], "paragraph_keywords": ["experiences", "life", "media", "day"]}, {"paragraph_vector": [-147.077713, -75.652732], "paragraph_keywords": ["experiences", "lauren", "finds", "allowing"]}, {"paragraph_vector": [-150.632827, -75.248802], "paragraph_keywords": ["media", "ways", "experiences", "dementia"]}, {"paragraph_vector": [-157.370758, -69.890892], "paragraph_keywords": ["media", "families", "design", "dementia"]}, {"paragraph_vector": [-171.989395, -77.0923], "paragraph_keywords": ["research", "dementia", "lauren", "michael"]}, {"paragraph_vector": [-154.619552, -71.415756], "paragraph_keywords": ["dementia", "participants", "media", "reality"]}, {"paragraph_vector": [-161.75801, -71.290573], "paragraph_keywords": ["dementia", "media", "activities", "person"]}, {"paragraph_vector": [-148.751617, -74.789474], "paragraph_keywords": ["dementia", "participants", "carers", "body"]}, {"paragraph_vector": [-160.138275, -73.655487], "paragraph_keywords": ["dementia", "care", "design", "hand"]}, {"paragraph_vector": [-148.354248, -74.542274], "paragraph_keywords": ["media", "days", "experience", "data"]}], "content": {}, "doi": "10.1145/3290605.3300452"}, {"uri": "132", "title": "DataSelfie: Empowering People to Design Personalized Visuals to Represent Their Data", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["NamWook Kim", "Hyejin Im", "Nathalie Henry Riche", "Nam Wook Kim", "Alicia Wang", "Krzysztof Gajos"], "summary": "Many personal informatics systems allow people to collect and manage personal data and reflect more deeply about themselves. However, these tools rarely offer ways to customize how the data is visualized. In this work, we investigate the question of how to enable people to determine the representation of their data. We analyzed the Dear Data project to gain insights into the design elements of personal visualizations. We developed DataSelfie, a novel system that allows individuals to gather personal data and design custom visuals to represent the collected data. We conducted a user Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300309 study to evaluate the usability of the system as well as its potential for individual and collaborative sensemaking of the data.", "keywords": ["reflection", "based", "time", "represent", "dataselfie", "like", "questionnaire", "self", "allow", "design", "provide", "mapping", "having", "user", "sharing", "creating", "tool", "drawing", "use", "participant", "create", "people", "collection", "insight", "lupi", "visualization", "experience", "visual", "provides", "survey", "visuals", "tracking", "including", "postcard", "data", "study", "instance", "support", "research", "question", "paper", "interface", "project", "option", "context", "figure", "response"], "document_vector": [-169.71936, -8.397362], "paragraphs": [{"paragraph_vector": [-106.297897, 68.626121], "paragraph_keywords": ["data", "tools", "visualization", "people"]}, {"paragraph_vector": [-118.102882, 73.679031], "paragraph_keywords": ["data", "dataselfie", "users", "questionnaire"]}, {"paragraph_vector": [-177.131149, -30.308479], "paragraph_keywords": ["data", "self", "tracking", "informatics"]}, {"paragraph_vector": [-110.998962, 71.235496], "paragraph_keywords": ["data", "visualizations", "visualization", "users"]}, {"paragraph_vector": [-116.223937, 71.162223], "paragraph_keywords": ["data", "visualizations", "postcards", "project"]}, {"paragraph_vector": [-136.628448, 72.713455], "paragraph_keywords": ["data", "items", "layouts", "time"]}, {"paragraph_vector": [-106.505523, 73.163253], "paragraph_keywords": ["lupi", "data", "theme", "dots"]}, {"paragraph_vector": [-141.037658, 68.862976], "paragraph_keywords": ["data", "drawing", "instance", "information"]}, {"paragraph_vector": [-127.683815, 70.614318], "paragraph_keywords": ["data", "postcards", "theme", "week"]}, {"paragraph_vector": [-118.7798, 71.451156], "paragraph_keywords": ["data", "visualization", "variables", "use"]}, {"paragraph_vector": [-122.363479, 70.540748], "paragraph_keywords": ["data", "questionnaire", "collection", "project"]}, {"paragraph_vector": [-125.85897, 73.19329], "paragraph_keywords": ["data", "questionnaire", "mappings", "collection"]}, {"paragraph_vector": [-143.296691, 71.158592], "paragraph_keywords": ["user", "drawing", "figure", "shape"]}, {"paragraph_vector": [-129.667984, 74.516059], "paragraph_keywords": ["data", "response", "visualization", "layer"]}, {"paragraph_vector": [160.27568, 29.9694], "paragraph_keywords": ["questionnaire", "food", "figure", "wants"]}, {"paragraph_vector": [174.431732, 84.006065], "paragraph_keywords": ["survey", "user", "background", "figure"]}, {"paragraph_vector": [94.90512, 53.65406], "paragraph_keywords": ["task", "participants", "use", "questions"]}, {"paragraph_vector": [-142.174026, 69.945098], "paragraph_keywords": ["data", "drawing", "participants", "having"]}, {"paragraph_vector": [-124.92987, 68.540138], "paragraph_keywords": ["use", "time", "saying", "tool"]}, {"paragraph_vector": [-132.561172, 72.155158], "paragraph_keywords": ["data", "study", "use", "participants"]}, {"paragraph_vector": [-120.821235, 70.996986], "paragraph_keywords": ["visuals", "study", "decision", "data"]}], "content": {}, "doi": "10.1145/3290605.3300457"}, {"uri": "133", "title": "Reading Face, Reading Health: Exploring Face Reading Technologies for Everyday Health", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Xianghua Ding", "Yanqi Jiang", "Yunan Chen", "Wenqiang Zhang", "Lizhe Qi", "Xiankang Qin"], "summary": "ACM Reference Format: With the recent advancement in computer vision, Artificial Intelligence (AI), and mobile technologies, it has become technically feasible for computerized Face Reading Technologies (FRTs) to learn about one\u2019s health in everyday settings. However, how to design FRT-based applications for everyday health practices remains unexplored. This paper presents a design study with a technology probe called Faced, a mobile health checkup application based on the facial diagnosis method from Traditional Chinese Medicine (TCM). A field trial of Faced with 10 participants suggests potential usage modes and highlights a number of critical design issues in the use of FRTs for everyday health, including adaptability, practicality, sensitivity, and trustworthiness. We end by discussing design implications to address the unique challenges of fully integrating FRTs into everyday health practices.", "keywords": ["based", "doctor", "time", "change", "condition", "information", "design", "frts", "provide", "suggestion", "example", "help", "tcm", "user", "model", "advice", "sharing", "result", "work", "participant", "use", "patient", "people", "tongue", "designed", "way", "health", "learning", "factor", "page", "score", "application", "found", "face", "diagnosis", "understand", "developed", "life", "suggested", "data", "technology", "study", "system", "image", "term", "faced", "question", "paper", "photo", "considered"], "document_vector": [34.939998, -38.070907], "paragraphs": [{"paragraph_vector": [-169.072937, -49.216037], "paragraph_keywords": ["face", "copies", "acm", "technologies"]}, {"paragraph_vector": [-171.958282, -50.213161], "paragraph_keywords": ["face", "health", "pulse", "frts"]}, {"paragraph_vector": [-172.06697, -50.393287], "paragraph_keywords": ["health", "tcm", "faced", "application"]}, {"paragraph_vector": [-168.42453, -51.404766], "paragraph_keywords": ["frts", "face", "explored", "tongue"]}, {"paragraph_vector": [179.668975, -35.492069], "paragraph_keywords": ["use", "design", "patients", "technologies"]}, {"paragraph_vector": [-175.920501, -38.921718], "paragraph_keywords": ["health", "people", "lives", "technologies"]}, {"paragraph_vector": [-172.111343, -49.814422], "paragraph_keywords": ["tcm", "model", "face", "doctors"]}, {"paragraph_vector": [-163.910949, -54.393878], "paragraph_keywords": ["health", "tongue", "users", "photo"]}, {"paragraph_vector": [-170.775817, -52.150249], "paragraph_keywords": ["users", "health", "faced", "probe"]}, {"paragraph_vector": [124.764198, -64.16397], "paragraph_keywords": ["participants", "use", "health", "trial"]}, {"paragraph_vector": [154.663101, -72.037673], "paragraph_keywords": ["health", "participants", "faced", "data"]}, {"paragraph_vector": [-173.050567, -48.077716], "paragraph_keywords": ["health", "faced", "application", "patients"]}, {"paragraph_vector": [167.062393, -22.03384], "paragraph_keywords": ["time", "faced", "health", "questions"]}, {"paragraph_vector": [-178.047821, -48.767688], "paragraph_keywords": ["health", "changes", "advice", "suggestions"]}, {"paragraph_vector": [159.097778, -21.225042], "paragraph_keywords": ["tcm", "health", "example", "terms"]}, {"paragraph_vector": [165.525466, -23.365934], "paragraph_keywords": ["health", "way", "participants", "faced"]}, {"paragraph_vector": [-178.835708, -40.684692], "paragraph_keywords": ["found", "health", "suggestions", "participants"]}, {"paragraph_vector": [-165.327774, -51.076869], "paragraph_keywords": ["tongue", "considered", "participants", "life"]}, {"paragraph_vector": [-166.075286, -54.089344], "paragraph_keywords": ["images", "camera", "share", "phone"]}, {"paragraph_vector": [-170.707641, -57.699836], "paragraph_keywords": ["participants", "health", "study", "information"]}, {"paragraph_vector": [68.982978, 17.383195], "paragraph_keywords": ["results", "score", "participants", "result"]}, {"paragraph_vector": [174.144943, -48.56443], "paragraph_keywords": ["study", "use", "system", "health"]}, {"paragraph_vector": [-176.40036, -49.848651], "paragraph_keywords": ["health", "based", "time", "data"]}, {"paragraph_vector": [162.489349, -47.003646], "paragraph_keywords": ["health", "way", "users", "based"]}, {"paragraph_vector": [-170.686737, -54.044586], "paragraph_keywords": ["results", "users", "variations", "factors"]}, {"paragraph_vector": [-167.849533, -53.697978], "paragraph_keywords": ["use", "photo", "results", "tongue"]}, {"paragraph_vector": [-168.489974, -56.483684], "paragraph_keywords": ["health", "sharing", "grant", "based"]}], "content": {}, "doi": "10.1145/3290605.3300561"}, {"uri": "134", "title": "Shaping Pro-Social Interaction in VR An Emerging Design Framework", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Joshua McVeigh-Schultz", "Anya Kolesnichenko", "Katherine Isbister"], "summary": "Commercial social VR applications represent a diverse and evolving ecology with competing models of what it means to be social in VR. Drawing from expert interviews, this paper examines how the creators of different social VR applications think about how their platforms frame, support, shape, or constrain social interaction. The study covers a range of applications including: Rec Room, High Fidelity, VRChat, Mozilla Hubs, Altspace VR, AnyLand, and Facebook Spaces. We contextualize design choices underlying these applications, with particular attention paid to the ways that industry experts perceive, and seek to shape, the relationship between user experiences and design choices. We underscore considerations related to: (1) aesthetics of place (2) embodied affordances, (3) social mechanics, (4) and tactics for shaping social norms and mitigating harassment. Drawing on this analysis, we discuss the stakes of these choices, suggest future research directions, and propose an emerging design framework for shaping pro-social behavior in VR. CCS CONCEPTS \u2022 Human-centered computing \u2192 HCI design and evaluation methods; Human-centered computing \u2192 HCI theory, concepts and models; Human-centered computing \u2192 Interactive systems and tools", "keywords": ["mozilla", "fidelity", "vr", "facebook", "time", "altspacevr", "set", "expectation", "design", "feature", "interview", "environment", "stranger", "friend", "expert", "example", "noted", "medium", "user", "activity", "interaction", "shared", "place", "space", "mechanic", "create", "people", "vrchat", "anyland", "way", "world", "rec", "range", "moderation", "interviewee", "sense", "experience", "page", "hub", "application", "content", "including", "embodied", "kind", "avatar", "life", "onboarding", "described", "want", "game", "room", "designer", "role", "system", "reality", "developer", "event", "research", "paper", "question", "harassment", "area", "affordances", "community"], "document_vector": [151.945251, 42.105304], "paragraphs": [{"paragraph_vector": [-115.193344, -40.496795], "paragraph_keywords": ["vr", "applications", "design", "kinds"]}, {"paragraph_vector": [-123.004737, -22.057664], "paragraph_keywords": ["vr", "research", "design", "questions"]}, {"paragraph_vector": [-113.58097, -41.085525], "paragraph_keywords": ["vr", "design", "industry", "interaction"]}, {"paragraph_vector": [-118.476127, -41.969429], "paragraph_keywords": ["facebook", "user", "avatars", "combination"]}, {"paragraph_vector": [-110.979667, -44.321033], "paragraph_keywords": ["users", "vr", "anyland", "developers"]}, {"paragraph_vector": [-112.135871, -44.481899], "paragraph_keywords": ["fidelity", "world", "design", "founder"]}, {"paragraph_vector": [-106.842124, -48.841876], "paragraph_keywords": ["interviews", "environments", "interview", "responses"]}, {"paragraph_vector": [-110.074447, -43.682384], "paragraph_keywords": ["design", "categories", "areas", "role"]}, {"paragraph_vector": [-112.092018, -43.233306], "paragraph_keywords": ["room", "place", "vr", "rec"]}, {"paragraph_vector": [-110.144195, -45.0163], "paragraph_keywords": ["want", "importance", "features", "people"]}, {"paragraph_vector": [-110.365127, -47.829677], "paragraph_keywords": ["noted", "users", "icebreaker", "user"]}, {"paragraph_vector": [-112.900825, -43.411518], "paragraph_keywords": ["activities", "vr", "creation", "altspacevr"]}, {"paragraph_vector": [-112.704093, -44.646995], "paragraph_keywords": ["community", "people", "fidelity", "areas"]}, {"paragraph_vector": [-115.24192, -42.931762], "paragraph_keywords": ["room", "community", "vrchat", "users"]}, {"paragraph_vector": [-121.580451, -44.362937], "paragraph_keywords": ["area", "features", "lenssen", "systems"]}, {"paragraph_vector": [-110.591567, -43.49702], "paragraph_keywords": ["makes", "gestures", "friending", "altspacevr"]}, {"paragraph_vector": [45.299556, 9.900422], "paragraph_keywords": ["person", "blocking", "harassment", "applications"]}, {"paragraph_vector": [-113.775993, -41.101844], "paragraph_keywords": ["users", "space", "user", "room"]}, {"paragraph_vector": [-111.509902, -42.95383], "paragraph_keywords": ["facebook", "hubs", "spaces", "vr"]}, {"paragraph_vector": [-110.503326, -43.668979], "paragraph_keywords": ["design", "world", "vr", "experience"]}, {"paragraph_vector": [-111.685966, -42.67477], "paragraph_keywords": ["vr", "strangers", "mmos", "place"]}, {"paragraph_vector": [-112.961517, -43.074066], "paragraph_keywords": ["vr", "ways", "place", "shared"]}, {"paragraph_vector": [-113.415023, -43.043304], "paragraph_keywords": ["users", "embodied", "vr", "hubs"]}, {"paragraph_vector": [-112.933868, -41.080768], "paragraph_keywords": ["users", "design", "vr", "kind"]}, {"paragraph_vector": [-124.095466, -23.388309], "paragraph_keywords": ["user", "worlds", "reality", "environments"]}, {"paragraph_vector": [-124.026206, -24.504875], "paragraph_keywords": ["design", "new", "life", "user"]}, {"paragraph_vector": [-116.932037, -22.104772], "paragraph_keywords": ["reality", "chi", "conference", "new"]}], "content": {}, "doi": "10.1145/3290605.3300479"}, {"uri": "135", "title": "Making Healthcare Infrastructure Work", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Xinning Gui", "Yunan Chen"], "summary": "The U.S. healthcare infrastructure is fragmented with various breakdowns. Patients or caregivers have to rely on their own to overcome barriers and fix breakdowns in order to obtain necessary service, that is, infrastructuring work to make the healthcare infrastructure work for them. So far little attention has been paid to such infrastructuring work in healthcare. We present an interview study of 32 U.S. parents of young children to discuss the work of infrastructuring our participants carry out to deal with breakdowns within the healthcare infrastructure. We report how they repaired unexpected failures happening at the individual level, aligned components at organizational and cross-organizational level, and circumvented infrastructural constraints (e.g., policy and financial ones) that were perceived as ambiguous and demanding. We discuss infrastructuring work in light of the literature on patients\u2019 and caregivers\u2019 work, reflect upon the notion of patient engagement, and explore nuances along several dimensions of infrastructuring work.", "keywords": ["process", "caregiver", "doctor", "time", "breakdown", "child", "policy", "information", "department", "design", "component", "interview", "care", "home", "bill", "baby", "billing", "engagement", "activity", "involved", "conducted", "work", "ultrasound", "participant", "use", "patient", "cost", "service", "health", "theme", "page", "insurance", "including", "level", "organization", "data", "ob", "infrastructuring", "infrastructure", "fix", "provider", "research", "individual", "constraint", "paper", "hci", "company", "healthcare", "called", "pregnancy", "staff", "hospital", "center", "consumer", "birth"], "document_vector": [140.896575, 76.259971], "paragraphs": [{"paragraph_vector": [142.987899, -21.896799], "paragraph_keywords": ["healthcare", "care", "patients", "caregivers"]}, {"paragraph_vector": [135.661544, -34.778854], "paragraph_keywords": ["healthcare", "work", "breakdowns", "infrastructure"]}, {"paragraph_vector": [154.448364, -20.438758], "paragraph_keywords": ["work", "patients", "cancer", "tasks"]}, {"paragraph_vector": [137.890823, -36.512832], "paragraph_keywords": ["patients", "caregivers", "care", "work"]}, {"paragraph_vector": [124.908996, -41.294227], "paragraph_keywords": ["infrastructure", "work", "information", "design"]}, {"paragraph_vector": [133.512939, -39.823112], "paragraph_keywords": ["work", "infrastructuring", "healthcare", "infrastructure"]}, {"paragraph_vector": [140.800842, -34.147682], "paragraph_keywords": ["participants", "children", "interview", "including"]}, {"paragraph_vector": [129.985397, -37.733486], "paragraph_keywords": ["participants", "data", "interviews", "themes"]}, {"paragraph_vector": [134.84378, -34.399665], "paragraph_keywords": ["breakdowns", "healthcare", "participants", "themes"]}, {"paragraph_vector": [158.152435, -8.846885], "paragraph_keywords": ["surgery", "staff", "individuals", "office"]}, {"paragraph_vector": [142.361495, -23.053548], "paragraph_keywords": ["insurance", "error", "bill", "company"]}, {"paragraph_vector": [141.71701, -24.064538], "paragraph_keywords": ["insurance", "baby", "work", "month"]}, {"paragraph_vector": [142.965896, -21.68748], "paragraph_keywords": ["insurance", "failure", "infrastructure", "work"]}, {"paragraph_vector": [143.688537, -22.18715], "paragraph_keywords": ["department", "billing", "departments", "insurance"]}, {"paragraph_vector": [142.991455, -21.32221], "paragraph_keywords": ["information", "rheumatologist", "clinics", "time"]}, {"paragraph_vector": [152.529159, -12.762452], "paragraph_keywords": ["birth", "security", "centers", "certificate"]}, {"paragraph_vector": [143.461685, -22.861558], "paragraph_keywords": ["insurance", "organizations", "birth", "company"]}, {"paragraph_vector": [143.082015, -26.133937], "paragraph_keywords": ["entities", "healthcare", "insurance", "work"]}, {"paragraph_vector": [144.805496, -22.918357], "paragraph_keywords": ["insurance", "doctor", "constraints", "health"]}, {"paragraph_vector": [145.362274, -20.981054], "paragraph_keywords": ["cost", "constraints", "insurance", "ultrasound"]}, {"paragraph_vector": [141.155319, -22.756652], "paragraph_keywords": ["ob", "insurance", "cost", "consumers"]}, {"paragraph_vector": [136.705505, -36.337619], "paragraph_keywords": ["work", "healthcare", "patients", "infrastructure"]}, {"paragraph_vector": [138.63208, -35.009925], "paragraph_keywords": ["healthcare", "work", "infrastructure", "patients"]}, {"paragraph_vector": [136.360244, -37.114501], "paragraph_keywords": ["engagement", "healthcare", "work", "participants"]}, {"paragraph_vector": [132.531936, -39.564571], "paragraph_keywords": ["infrastructure", "work", "healthcare", "infrastructuring"]}, {"paragraph_vector": [138.97438, -37.77383], "paragraph_keywords": ["infrastructure", "work", "healthcare", "issue"]}], "content": {}, "doi": "10.1145/3290605.3300598"}, {"uri": "136", "title": "PlaneVR: Social Acceptability of Virtual Reality for Aeroplane Passengers", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Julie R. Williamson", "Mark McGill"], "summary": "Virtual reality (VR) headsets allow wearers to escape their physical surroundings, immersing themselves in a virtual world. Although escape may not be realistic or acceptable in many everyday situations, air travel is one context where early adoption of VR could be very attractive. While travelling, passengers are seated in restricted spaces for long durations, reliant on limited seat-back displays or mobile devices. This paper explores the social acceptability and usability of VR for in-flight entertainment. In an initial survey, we captured respondents\u2019 attitudes towards the social acceptability of VR headsets during air travel. Based on the survey results, we developed a VR in-flight entertainment prototype and evaluated this in a focus group study. Our results discuss methods for improving the acceptability of VR inflight, including using mixed reality to help users transition between virtual and physical environments and supporting interruption from other co-located people.", "keywords": ["vr", "time", "headset", "seat", "travelling", "display", "feature", "design", "environment", "provide", "focus", "example", "noted", "comfort", "user", "interaction", "air", "work", "space", "use", "participant", "people", "group", "issue", "screen", "designed", "cabin", "way", "respondent", "control", "spectator", "experience", "page", "entertainment", "application", "content", "passenger", "awareness", "survey", "providing", "travel", "usage", "device", "room", "acceptability", "reality", "view", "ife", "paper", "flight", "interruption"], "document_vector": [157.865829, -29.477073], "paragraphs": [{"paragraph_vector": [-103.092185, -2.658988], "paragraph_keywords": ["displays", "passengers", "seat", "copies"]}, {"paragraph_vector": [-73.896697, -19.010337], "paragraph_keywords": ["vr", "travel", "simulator", "sickness"]}, {"paragraph_vector": [-75.699798, -24.3483], "paragraph_keywords": ["vr", "flight", "acceptability", "entertainment"]}, {"paragraph_vector": [-73.564224, -22.07323], "paragraph_keywords": ["passengers", "ife", "seat", "flight"]}, {"paragraph_vector": [-75.916748, -22.431056], "paragraph_keywords": ["passengers", "ife", "space", "travel"]}, {"paragraph_vector": [-72.283767, -21.963455], "paragraph_keywords": ["passengers", "space", "passenger", "isolation"]}, {"paragraph_vector": [-72.480415, -22.457689], "paragraph_keywords": ["vr", "devices", "flight", "seat"]}, {"paragraph_vector": [-72.199981, -21.309238], "paragraph_keywords": ["vr", "applications", "designed", "passengers"]}, {"paragraph_vector": [-75.392646, -21.812009], "paragraph_keywords": ["vr", "acceptability", "user", "users"]}, {"paragraph_vector": [-74.745979, -22.587852], "paragraph_keywords": ["vr", "use", "acceptability", "flight"]}, {"paragraph_vector": [-75.266677, -21.69787], "paragraph_keywords": ["vr", "user", "seat", "questions"]}, {"paragraph_vector": [-77.096282, -22.575242], "paragraph_keywords": ["devices", "respondents", "displays", "seat"]}, {"paragraph_vector": [-73.809646, -21.555986], "paragraph_keywords": ["vr", "awareness", "respondents", "use"]}, {"paragraph_vector": [-73.994895, -20.397872], "paragraph_keywords": ["seat", "vr", "eyemask", "respondents"]}, {"paragraph_vector": [-73.111968, -20.488912], "paragraph_keywords": ["vr", "p", "person", "eyemask"]}, {"paragraph_vector": [-75.145721, -22.930379], "paragraph_keywords": ["vr", "content", "issues", "application"]}, {"paragraph_vector": [137.706756, -9.194556], "paragraph_keywords": ["vr", "user", "view", "room"]}, {"paragraph_vector": [-69.833328, -15.60037], "paragraph_keywords": ["headset", "vr", "user", "buttons"]}, {"paragraph_vector": [-74.690574, -23.253078], "paragraph_keywords": ["vr", "participants", "headset", "passengers"]}, {"paragraph_vector": [-77.129447, -22.919654], "paragraph_keywords": ["vr", "environment", "travelling", "shared"]}, {"paragraph_vector": [-68.624717, -14.825137], "paragraph_keywords": ["push", "want", "passengers", "feature"]}, {"paragraph_vector": [-73.623855, -19.425628], "paragraph_keywords": ["participants", "vr", "headset", "discussed"]}, {"paragraph_vector": [-74.318946, -19.898462], "paragraph_keywords": ["going", "headset", "participants", "users"]}, {"paragraph_vector": [-75.07167, -21.602916], "paragraph_keywords": ["vr", "headset", "peek", "conversation"]}, {"paragraph_vector": [-74.507232, -22.802614], "paragraph_keywords": ["vr", "camera", "feature", "features"]}, {"paragraph_vector": [-77.069221, -23.880151], "paragraph_keywords": ["spectators", "vr", "user", "users"]}, {"paragraph_vector": [-73.858093, -21.952629], "paragraph_keywords": ["vr", "headsets", "validity", "example"]}, {"paragraph_vector": [-74.504455, -22.895059], "paragraph_keywords": ["vr", "entertainment", "focus", "survey"]}, {"paragraph_vector": [-113.72908, -41.625118], "paragraph_keywords": ["underpinning", "data", "presented", "paper"]}], "content": {}, "doi": "10.1145/3290605.3300894"}, {"uri": "137", "title": "Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Carrie J. Cai", "Emily Reif", "Narayan Hegde", "Jason Hipp", "Been Kim", "Daniel Smilkov", "Martin Wattenberg", "Fernanda Viegas", "Greg S. Corrado", "Martin C. Stumpe", "Michael Terry"], "summary": "Machine learning (ML) is increasingly being used in image retrieval systems for medical decision making. One application of ML is to retrieve visually similar medical images from past patients (e.g. tissue from biopsies) to reference when making a medical decision with a new patient. However, no algorithm can perfectly capture an expert\u2019s ideal notion of similarity for every case: an image that is algorithmically determined to be similar may not be medically relevant to a doctor\u2019s specific diagnostic needs. In this paper, we identified the needs of pathologists when searching for similar images retrieved using a deep learning algorithm, and developed tools that empower users to cope with the search algorithm on-the-fly, communicating what types of similarity are most important at different moments in time. In two evaluations with pathologists, we found that these refinement tools increased the diagnostic utility of images found and increased user trust in the algorithm. The tools were preferred over a traditional interface, without a loss in diagnostic accuracy. We also observed that users adopted new strategies when using refinement tools, re-purposing them to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken together, these findings inform future human-ML collaborative systems for expert decision-making.", "keywords": ["process", "based", "time", "need", "embedding", "cbir", "refine", "slider", "evidence", "feature", "embeddings", "refinement", "expert", "example", "user", "model", "trust", "region", "decision", "result", "work", "tool", "space", "participant", "use", "hypothesis", "given", "range", "think", "concept", "algorithm", "page", "presence", "found", "pathologist", "diagnosis", "gland", "case", "similarity", "query", "crop", "search", "cav", "ml", "image", "system", "paper", "interface", "figure", "making"], "document_vector": [-106.63916, -64.862785], "paragraphs": [{"paragraph_vector": [103.380813, 86.167343], "paragraph_keywords": ["cbir", "copies", "systems", "based"]}, {"paragraph_vector": [71.176345, 89.247299], "paragraph_keywords": ["search", "image", "user", "query"]}, {"paragraph_vector": [-117.542411, 89.965805], "paragraph_keywords": ["tools", "refinement", "users", "algorithm"]}, {"paragraph_vector": [106.009986, 88.156623], "paragraph_keywords": ["image", "systems", "decision", "search"]}, {"paragraph_vector": [133.279266, 80.512626], "paragraph_keywords": ["embeddings", "features", "work", "concepts"]}, {"paragraph_vector": [-81.053993, 87.477569], "paragraph_keywords": ["pathologists", "diagnosis", "directions", "hypotheses"]}, {"paragraph_vector": [-136.878112, 89.769371], "paragraph_keywords": ["features", "pathologists", "images", "want"]}, {"paragraph_vector": [74.575393, 88.393142], "paragraph_keywords": ["images", "image", "search", "query"]}, {"paragraph_vector": [-66.312019, 87.116493], "paragraph_keywords": ["crop", "users", "region", "search"]}, {"paragraph_vector": [-106.076927, 86.644874], "paragraph_keywords": ["concept", "image", "results", "search"]}, {"paragraph_vector": [-134.105987, 88.864685], "paragraph_keywords": ["concepts", "concept", "cav", "labels"]}, {"paragraph_vector": [162.553375, 89.911605], "paragraph_keywords": ["search", "refinement", "results", "users"]}, {"paragraph_vector": [-64.64067, 88.162475], "paragraph_keywords": ["concept", "images", "results", "presence"]}, {"paragraph_vector": [-90.532585, 88.478584], "paragraph_keywords": ["concept", "cav", "refinement", "concepts"]}, {"paragraph_vector": [95.727424, 87.456779], "paragraph_keywords": ["trust", "interface", "decision", "answered"]}, {"paragraph_vector": [-53.428268, 88.617401], "paragraph_keywords": ["participants", "images", "image", "interface"]}, {"paragraph_vector": [-9.514871, 89.796401], "paragraph_keywords": ["interface", "p", "t", "image"]}, {"paragraph_vector": [-38.840637, 89.29425], "paragraph_keywords": ["refine", "users", "example", "features"]}, {"paragraph_vector": [-67.930465, 89.289001], "paragraph_keywords": ["concept", "refine", "example", "sliders"]}, {"paragraph_vector": [-155.5513, 87.968742], "paragraph_keywords": ["concepts", "concept", "examples", "users"]}, {"paragraph_vector": [-0.478985, 89.232627], "paragraph_keywords": ["users", "refinement", "search", "looking"]}, {"paragraph_vector": [155.968414, 89.698104], "paragraph_keywords": ["users", "process", "features", "thought"]}, {"paragraph_vector": [-159.639694, 89.768524], "paragraph_keywords": ["users", "theories", "tools", "search"]}, {"paragraph_vector": [136.839691, 88.625205], "paragraph_keywords": ["algorithm", "users", "variables", "question"]}, {"paragraph_vector": [-104.77742, 89.811363], "paragraph_keywords": ["system", "domains", "experts", "tools"]}, {"paragraph_vector": [66.339492, 53.873989], "paragraph_keywords": ["refinement", "tools", "bias", "users"]}, {"paragraph_vector": [125.773292, 76.39492], "paragraph_keywords": ["work", "ml", "refinement", "domain"]}], "content": {}, "doi": "10.1145/3290605.3300896"}, {"uri": "138", "title": "A Place to Play The (Dis)Abled Embodied Experience for Autistic Children in Online Spaces", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Kathryn E. Ringland"], "summary": "Play is the work of children\u2014but access to play is not equal from child to child. Having access to a place to play is a challenge for marginalized children, such as children with disabilities. For autistic children, playing with other children in the physical world may be uncomfortable or even painful. Yet, having practice in the social skills play provides is essential for childhood development. In this ethnographic work, I explore how one community uses the sense of place and the digital embodied experience in a virtual world specifically to give autistic children access to play with their peers. The contribution of this work is twofold. First, I demonstrate how various physical and virtual spaces work together to make play possible. Second, I demonstrate these spaces, though some of them are digital, are no more or less \u201creal\u201d than the physical spaces making up a schoolyard or playground.", "keywords": ["facebook", "sociality", "child", "time", "body", "minecraft", "player", "community", "hardware", "environment", "example", "mediated", "medium", "user", "play", "interaction", "communication", "creating", "work", "place", "space", "video", "autcraft", "use", "create", "hacker", "world", "experience", "page", "understanding", "found", "including", "face", "embodied", "avatar", "member", "computer", "game", "disability", "technology", "parent", "administrator", "support", "text", "platform", "server", "individual", "software", "paper", "access"], "document_vector": [126.978134, 10.014356], "paragraphs": [{"paragraph_vector": [-137.157531, -35.79084], "paragraph_keywords": ["body", "play", "access", "bodies"]}, {"paragraph_vector": [-135.879974, -36.42572], "paragraph_keywords": ["use", "copies", "embodied", "acm"]}, {"paragraph_vector": [-134.627655, -37.081623], "paragraph_keywords": ["media", "use", "work", "games"]}, {"paragraph_vector": [-139.175811, -37.349498], "paragraph_keywords": ["disabilities", "technology", "youth", "individuals"]}, {"paragraph_vector": [-132.853668, -37.206096], "paragraph_keywords": ["worlds", "user", "users", "world"]}, {"paragraph_vector": [-134.371551, -35.8008], "paragraph_keywords": ["worlds", "world", "disability", "children"]}, {"paragraph_vector": [-137.236557, -38.273326], "paragraph_keywords": ["community", "world", "autcraft", "players"]}, {"paragraph_vector": [-148.773727, -32.74504], "paragraph_keywords": ["community", "data", "themes", "play"]}, {"paragraph_vector": [-136.28247, -34.853206], "paragraph_keywords": ["access", "community", "spaces", "computer"]}, {"paragraph_vector": [-136.035278, -34.651988], "paragraph_keywords": ["children", "child", "computer", "access"]}, {"paragraph_vector": [-136.667205, -34.649677], "paragraph_keywords": ["space", "play", "adjusting", "access"]}, {"paragraph_vector": [-134.696166, -35.801757], "paragraph_keywords": ["minecraft", "community", "access", "autcraft"]}, {"paragraph_vector": [-133.668579, -35.283836], "paragraph_keywords": ["minecraft", "access", "community", "application"]}, {"paragraph_vector": [-131.080947, -24.658945], "paragraph_keywords": ["fuzzybear", "child", "world", "time"]}, {"paragraph_vector": [-137.608779, -35.200416], "paragraph_keywords": ["autcraft", "world", "players", "software"]}, {"paragraph_vector": [-136.998092, -39.288925], "paragraph_keywords": ["world", "autcraft", "video", "players"]}, {"paragraph_vector": [-140.986114, -39.272006], "paragraph_keywords": ["community", "videos", "members", "autcraft"]}, {"paragraph_vector": [-133.77539, -37.080978], "paragraph_keywords": ["experience", "players", "administrators", "profile"]}, {"paragraph_vector": [-132.175292, -39.683582], "paragraph_keywords": ["autcraft", "hackers", "world", "administrators"]}, {"paragraph_vector": [-134.976562, -36.808048], "paragraph_keywords": ["community", "spaces", "autcraft", "members"]}, {"paragraph_vector": [-135.896621, -36.237163], "paragraph_keywords": ["mediated", "world", "face", "experiences"]}, {"paragraph_vector": [-133.859527, -35.958042], "paragraph_keywords": ["play", "spaces", "world", "experiences"]}, {"paragraph_vector": [-135.938034, -39.220287], "paragraph_keywords": ["play", "autcraft", "community", "world"]}, {"paragraph_vector": [-135.920898, -35.064762], "paragraph_keywords": ["play", "place", "autcraft", "playground"]}, {"paragraph_vector": [-137.428176, -37.681163], "paragraph_keywords": ["play", "children", "sociality", "mediated"]}, {"paragraph_vector": [-136.295486, -36.516471], "paragraph_keywords": ["community", "autcraft", "embodied", "children"]}, {"paragraph_vector": [-136.716461, -34.907199], "paragraph_keywords": ["work", "place", "thank", "spaces"]}], "content": {}, "doi": "10.1145/3290605.3300599"}, {"uri": "139", "title": "To Asymmetry and Beyond!", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": [], "summary": "Social play can have numerous health benefits but research has shown that not all multiplayer games are effective at promoting social engagement. Asymmetric cooperative games have shown promise in this regard but the design and dynamics of this unique style of play is not yet well understood. To address this, we present the results of two player experience studies using our custom prototype game BeamMe \u2019Round, Scotty! 2: the first comparing symmetric cooperative play (e.g., where players have the same interface, goals, mechanics, etc.) to asymmetric cooperative play (e.g., where players have differing roles, abilities, interfaces, etc.) and the second comparing the effect of increasing degrees of interdependence Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed", "keywords": ["interdependence", "condition", "al", "need", "ability", "player", "asymmetry", "design", "beam", "playing", "partner", "focus", "example", "engagement", "play", "et", "coupling", "work", "participant", "use", "mechanic", "effect", "m", "challenge", "bomb", "experience", "page", "character", "connectedness", "scotty", "kirk", "gameplay", "game", "study", "element", "role", "asymmetric", "coupled", "support", "research", "order", "perspective", "prototype", "paper", "interface", "pair", "action", "level", "p"], "document_vector": [-7.927766, -0.898717], "paragraphs": [{"paragraph_vector": [-128.190155, -3.082958], "paragraph_keywords": ["games", "play", "interdependence", "players"]}, {"paragraph_vector": [-126.311424, -6.972823], "paragraph_keywords": ["players", "play", "connectedness", "asymmetry"]}, {"paragraph_vector": [-118.651824, -7.471666], "paragraph_keywords": ["interdependence", "games", "players", "task"]}, {"paragraph_vector": [-125.454521, -3.730604], "paragraph_keywords": ["games", "players", "asymmetric", "asymmetries"]}, {"paragraph_vector": [-125.053947, -2.262768], "paragraph_keywords": ["player", "game", "design", "play"]}, {"paragraph_vector": [-124.969802, -6.472661], "paragraph_keywords": ["abilities", "scotty", "game", "player"]}, {"paragraph_vector": [-125.205795, -6.151437], "paragraph_keywords": ["players", "game", "scotty", "play"]}, {"paragraph_vector": [-125.92588, -4.641431], "paragraph_keywords": ["study", "game", "players", "design"]}, {"paragraph_vector": [-123.650932, -1.56479], "paragraph_keywords": ["scotty", "participants", "table", "character"]}, {"paragraph_vector": [-123.494194, -1.365458], "paragraph_keywords": ["game", "playing", "participants", "recorded"]}, {"paragraph_vector": [-126.508354, -3.347744], "paragraph_keywords": ["player", "sub", "study", "players"]}, {"paragraph_vector": [-124.5578, -2.765614], "paragraph_keywords": ["participants", "play", "partner", "playing"]}, {"paragraph_vector": [-128.212677, -3.108934], "paragraph_keywords": ["asymmetric", "play", "conditions", "players"]}, {"paragraph_vector": [-127.253227, -1.18678], "paragraph_keywords": ["bomb", "kirk", "interdependence", "scotty"]}, {"paragraph_vector": [-124.010963, -1.839112], "paragraph_keywords": ["study", "interdependence", "play", "participants"]}, {"paragraph_vector": [-126.12854, -1.937446], "paragraph_keywords": ["conditions", "participants", "coupling", "play"]}, {"paragraph_vector": [-126.017356, -2.153287], "paragraph_keywords": ["participants", "design", "p", "coupling"]}, {"paragraph_vector": [-125.799324, -3.266861], "paragraph_keywords": ["heal", "level", "player", "designed"]}, {"paragraph_vector": [-126.262466, -4.445234], "paragraph_keywords": ["scotty", "cues", "support", "kirk"]}, {"paragraph_vector": [-124.973228, -3.757201], "paragraph_keywords": ["abilities", "players", "coupling", "balance"]}, {"paragraph_vector": [-127.809997, -3.358898], "paragraph_keywords": ["game", "player", "players", "challenge"]}, {"paragraph_vector": [-125.87223, -5.027665], "paragraph_keywords": ["interdependence", "research", "play", "asymmetric"]}], "content": {}, "doi": "10.1145/3290605.3300600"}, {"uri": "140", "title": "Connect-to-Connected Worlds", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Aditi Mallavarapu", "Leilah Lyons", "Stephen Uzzo", "Wren Thompson", "Rinat Levy-Cohen"], "summary": "Immersive open-ended museum exhibits promote ludic engagement and can be a powerful draw for visitors, but these qualities may also make learning more challenging. We describe our efforts to help visitors engage more deeply with an interactive exhibit's content by giving them access to visualizations of data skimmed from their use of the exhibit. We report on the motivations and challenges in designing this reflective tool, which positions visitors as a \u201chuman in the loop\u201d to understand and manage their engagement with the exhibit. We used an iterative design process and qualitative Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300237 methods to explore how and if visitors could (1) access and (2) comprehend the data visualizations, (3) reflect on their prior engagement with the exhibit, (4) plan their future engagement with the exhibit, and (5) act on their plans. We further discuss the essential design challenges and the opportunities made possible for visitors through data-driven reflection tools.", "keywords": ["reflection", "supply", "time", "plant", "need", "information", "needed", "discussion", "connected", "design", "engaged", "visitor", "simulation", "goal", "help", "engagement", "activity", "story", "learner", "work", "use", "participant", "group", "desert", "museum", "learning", "world", "way", "visualization", "water", "page", "state", "number", "supporting", "log", "talk", "segment", "feedback", "form", "representation", "biome", "driven", "data", "ctcw", "support", "exhibit", "adult", "view", "session", "ecosystem", "paper", "plan", "action", "figure"], "document_vector": [148.68872, -6.066401], "paragraphs": [{"paragraph_vector": [-165.081298, 9.539173], "paragraph_keywords": ["design", "exhibit", "exhibits", "engagement"]}, {"paragraph_vector": [-165.831039, 12.879158], "paragraph_keywords": ["visitors", "design", "learning", "data"]}, {"paragraph_vector": [-167.906784, 13.453264], "paragraph_keywords": ["visitors", "goals", "engagement", "exhibit"]}, {"paragraph_vector": [-166.694396, 13.409154], "paragraph_keywords": ["feedback", "visitors", "data", "actions"]}, {"paragraph_vector": [-136.066589, -16.176189], "paragraph_keywords": ["feedback", "learning", "sense", "data"]}, {"paragraph_vector": [-167.573913, 13.532085], "paragraph_keywords": ["data", "visitor", "museum", "conversations"]}, {"paragraph_vector": [-149.490631, 9.901583], "paragraph_keywords": ["water", "screens", "biomes", "exhibit"]}, {"paragraph_vector": [-157.545181, 7.099127], "paragraph_keywords": ["visitors", "simulation", "ecosystem", "plants"]}, {"paragraph_vector": [-159.525573, 10.956842], "paragraph_keywords": ["water", "view", "visitors", "biome"]}, {"paragraph_vector": [-157.901229, 13.36609], "paragraph_keywords": ["view", "visitors", "worlds", "exhibit"]}, {"paragraph_vector": [-163.726913, 13.809131], "paragraph_keywords": ["data", "worlds", "state", "use"]}, {"paragraph_vector": [-166.286972, 11.318623], "paragraph_keywords": ["data", "biome", "visitors", "visitor"]}, {"paragraph_vector": [-151.029876, 13.560355], "paragraph_keywords": ["water", "figure", "biome", "plant"]}, {"paragraph_vector": [-159.710723, 13.695825], "paragraph_keywords": ["use", "data", "cases", "reflection"]}, {"paragraph_vector": [-160.867568, 8.064507], "paragraph_keywords": ["adults", "education", "visitor", "exhibit"]}, {"paragraph_vector": [-153.656463, 16.686063], "paragraph_keywords": ["discussion", "segment", "visualization", "water"]}, {"paragraph_vector": [163.484527, 17.491535], "paragraph_keywords": ["feedback", "data", "visitors", "representation"]}, {"paragraph_vector": [-153.466201, 13.980439], "paragraph_keywords": ["water", "information", "talk", "supply"]}, {"paragraph_vector": [-151.855697, 13.893511], "paragraph_keywords": ["water", "talk", "reflecting", "actions"]}, {"paragraph_vector": [-150.52275, 13.236268], "paragraph_keywords": ["water", "participants", "talk", "team"]}, {"paragraph_vector": [-152.521469, 12.084001], "paragraph_keywords": ["water", "biomes", "plans", "feedback"]}, {"paragraph_vector": [-152.328781, 13.572628], "paragraph_keywords": ["data", "visualizations", "phone", "visitors"]}, {"paragraph_vector": [-152.372497, 15.587106], "paragraph_keywords": ["water", "suggested", "data", "participants"]}, {"paragraph_vector": [-166.410034, 14.913594], "paragraph_keywords": ["visitors", "data", "engagement", "feedback"]}, {"paragraph_vector": [-159.648666, 11.733455], "paragraph_keywords": ["visitors", "data", "feedback", "need"]}, {"paragraph_vector": [-161.792098, 9.274619], "paragraph_keywords": ["visitors", "data", "story", "feedback"]}, {"paragraph_vector": [-167.57463, 12.491737], "paragraph_keywords": ["data", "feedback", "learning", "reflection"]}, {"paragraph_vector": [157.324264, 38.40409], "paragraph_keywords": ["framing", "select", "supported", "science"]}], "content": {}, "doi": "10.1145/3290605.3300581"}, {"uri": "141", "title": "Machine Heuristic: When We Trust Computers More than Humans with Our Personal Information", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["S. Shyam Sundar", "Jinyoung Kim"], "summary": "In this day and age of identity theft, are we likely to trust machines more than humans for handling our personal information? We answer this question by invoking the concept of \u201cmachine heuristic,\u201d which is a rule of thumb that machines are more secure and trustworthy than humans. In an experiment (N = 160) that involved making airline reservations, users were more likely to reveal their credit card information to a machine agent than a human agent. We demonstrate that cues on the interface trigger the machine heuristic by showing that those with higher cognitive accessibility of the heuristic (i.e., stronger prior belief in the rule of thumb) were more likely than those with lower accessibility to disclose to a machine, but they did not differ in their disclosure to a human. These findings have implications for design of interface cues conveying machine vs. human sources of our online interactions.", "keywords": ["credit", "information", "heuristic", "belief", "intention", "user", "trust", "interaction", "decision", "participant", "use", "siri", "card", "effect", "cue", "security", "automated", "page", "tend", "agent", "reveal", "item", "data", "study", "system", "machine", "bias", "paper", "interface", "privacy", "disclosure", "making"], "document_vector": [-76.751335, 4.086191], "paragraphs": [{"paragraph_vector": [24.473125, -84.408233], "paragraph_keywords": ["users", "information", "privacy", "data"]}, {"paragraph_vector": [45.93328, -18.738674], "paragraph_keywords": ["users", "copies", "privacy", "information"]}, {"paragraph_vector": [48.334503, -13.329098], "paragraph_keywords": ["information", "users", "interface", "cues"]}, {"paragraph_vector": [47.265735, -14.001285], "paragraph_keywords": ["machine", "users", "heuristic", "computer"]}, {"paragraph_vector": [48.768535, -12.925276], "paragraph_keywords": ["decision", "machine", "aids", "automated"]}, {"paragraph_vector": [49.169685, -12.803863], "paragraph_keywords": ["machine", "belief", "users", "heuristic"]}, {"paragraph_vector": [47.623851, -14.701817], "paragraph_keywords": ["agent", "participants", "machine", "users"]}, {"paragraph_vector": [48.199512, -11.705294], "paragraph_keywords": ["information", "measured", "items", "machines"]}, {"paragraph_vector": [49.668197, -51.290065], "paragraph_keywords": ["use", "information", "trust", "items"]}, {"paragraph_vector": [46.262504, -14.518966], "paragraph_keywords": ["participants", "machine", "information", "scenario"]}, {"paragraph_vector": [48.077827, -10.69129], "paragraph_keywords": ["machine", "users", "cue", "agent"]}, {"paragraph_vector": [48.330314, -13.689937], "paragraph_keywords": ["machine", "trust", "cues", "interface"]}, {"paragraph_vector": [47.636802, -12.867903], "paragraph_keywords": ["machine", "users", "interface", "heuristic"]}, {"paragraph_vector": [54.405979, -11.23203], "paragraph_keywords": ["machine", "users", "use", "cues"]}, {"paragraph_vector": [56.250038, 8.572926], "paragraph_keywords": ["information", "users", "study", "security"]}, {"paragraph_vector": [48.628993, -15.133287], "paragraph_keywords": ["disclosure", "study", "effect", "apple"]}, {"paragraph_vector": [55.813007, -10.093095], "paragraph_keywords": ["machine", "agents", "design", "ai"]}], "content": {}, "doi": "10.1145/3290605.3300265"}, {"uri": "142", "title": "Finding Information on Non-Rectangular Interfaces", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Florine Simon", "Anne Roudaut", "Pourang Irani", "Marcos Serrano"], "summary": "With upcoming breakthroughs in free-form display technologies, new user interface design challenges have emerged. Here, we investigate a question, which has been widely explored on traditional GUIs but unexplored on non-rectangular interfaces: what are the user strategies in terms of visual search when information is not presented in a traditional rectangular layout? To achieve this, we present two complementary studies investigating eye movements in different visual search tasks. Our results unveil which areas are seen first according to different visual structures. By doing so we address the question of where to place relevant content for the UI designers of non-rectangular displays.", "keywords": ["time", "information", "find", "display", "user", "eye", "result", "work", "participant", "fixation", "shape", "triangle", "found", "content", "circle", "layout", "task", "search", "study", "icon", "grid", "interface", "area"], "document_vector": [-158.689468, -47.618339], "paragraphs": [{"paragraph_vector": [-32.509517, 44.978343], "paragraph_keywords": ["interfaces", "displays", "place", "content"]}, {"paragraph_vector": [-31.685722, 44.381015], "paragraph_keywords": ["search", "exploration", "work", "information"]}, {"paragraph_vector": [-33.401985, 44.141742], "paragraph_keywords": ["information", "shapes", "text", "interfaces"]}, {"paragraph_vector": [-33.001735, 43.772556], "paragraph_keywords": ["number", "task", "search", "icons"]}, {"paragraph_vector": [-34.466945, 47.160209], "paragraph_keywords": ["icons", "shapes", "display", "targets"]}, {"paragraph_vector": [-32.664321, 44.202789], "paragraph_keywords": ["shape", "display", "circle", "grid"]}, {"paragraph_vector": [-26.341625, 39.815017], "paragraph_keywords": ["data", "time", "results", "tracking"]}, {"paragraph_vector": [-32.694728, 45.867607], "paragraph_keywords": ["left", "looked", "results", "grid"]}, {"paragraph_vector": [-31.801853, 44.863296], "paragraph_keywords": ["time", "layout", "left", "grids"]}, {"paragraph_vector": [-31.479366, 45.173633], "paragraph_keywords": ["icons", "time", "search", "target"]}, {"paragraph_vector": [-32.631896, 42.630725], "paragraph_keywords": ["find", "layout", "grid", "results"]}, {"paragraph_vector": [-33.847702, 44.984081], "paragraph_keywords": ["grids", "interface", "users", "search"]}, {"paragraph_vector": [-32.95145, 44.13943], "paragraph_keywords": ["display", "time", "displays", "interface"]}, {"paragraph_vector": [71.357559, 30.319681], "paragraph_keywords": ["research", "agency", "sciences", "perfin"]}], "content": {}, "doi": "10.1145/3290605.3300533"}, {"uri": "143", "title": "RotoSwype: Word-Gesture Typing using a Ring", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Aakar Gupta"], "summary": "We propose RotoSwype, a technique for word-gesture typing using the orientation of a ring worn on the index finger. RotoSwype enables one-handed text-input without encumbering the hand with a device, a desirable quality in many scenarios, including virtual or augmented reality. The method is evaluated using two arm positions: with the hand raised up with the palm parallel to the ground; and with the hand resting at the side with the palm facing the body. A five-day study finds both hand positions achieved speeds of at least 14 words-per-minute (WPM) with uncorrected error rates near 1%, outperforming previous comparable techniques. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300244 CCS CONCEPTS \u2022 Human-centered computing\u2192 Interaction tech.", "keywords": ["based", "finger", "posture", "performance", "us", "speed", "ring", "technique", "mapping", "figure", "entry", "keyboard", "user", "button", "hd", "work", "word", "air", "movement", "use", "participant", "tilt", "range", "control", "gesture", "motion", "letter", "hand", "pointer", "phrase", "device", "day", "study", "text", "typing", "rotoswype", "pt", "wpm", "wrist", "hu"], "document_vector": [-13.574607, -74.460586], "paragraphs": [{"paragraph_vector": [-44.503536, 3.029157], "paragraph_keywords": ["techniques", "word", "ar", "ring"]}, {"paragraph_vector": [-34.673019, -9.89976], "paragraph_keywords": ["rotoswype", "ring", "hand", "input"]}, {"paragraph_vector": [-33.294589, -13.034095], "paragraph_keywords": ["tilting", "tilt", "techniques", "custom"]}, {"paragraph_vector": [-30.69869, -17.344734], "paragraph_keywords": ["hand", "air", "wrist", "finger"]}, {"paragraph_vector": [-34.67419, -9.986708], "paragraph_keywords": ["typing", "headpointing", "vr", "entry"]}, {"paragraph_vector": [-32.829425, -11.229018], "paragraph_keywords": ["ring", "keyboard", "typing", "entry"]}, {"paragraph_vector": [-35.084861, -9.482448], "paragraph_keywords": ["pointer", "ring", "word", "figure"]}, {"paragraph_vector": [-30.757755, -8.608129], "paragraph_keywords": ["control", "keyboard", "android", "position"]}, {"paragraph_vector": [-31.910705, -2.806581], "paragraph_keywords": ["hand", "keyboard", "postures", "palm"]}, {"paragraph_vector": [-29.004276, -2.090271], "paragraph_keywords": ["keyboard", "user", "axis", "range"]}, {"paragraph_vector": [-34.038238, -1.46998], "paragraph_keywords": ["hand", "range", "arm", "pts"]}, {"paragraph_vector": [-31.477077, -7.258318], "paragraph_keywords": ["word", "participants", "typing", "headset"]}, {"paragraph_vector": [-23.710664, -10.365018], "paragraph_keywords": ["word", "phrases", "user", "error"]}, {"paragraph_vector": [-30.679672, -8.864972], "paragraph_keywords": ["day", "study", "speed", "typing"]}, {"paragraph_vector": [-33.49617, -7.977053], "paragraph_keywords": ["day", "participants", "hu", "pts"]}, {"paragraph_vector": [-27.93367, -4.585977], "paragraph_keywords": ["day", "participants", "motion", "word"]}, {"paragraph_vector": [-28.677932, -13.693667], "paragraph_keywords": ["techniques", "performance", "rotoswype", "technique"]}, {"paragraph_vector": [-31.563123, -10.733467], "paragraph_keywords": ["range", "mapping", "hd", "gesture"]}, {"paragraph_vector": [-26.2336, -12.555646], "paragraph_keywords": ["clicking", "press", "button", "submit"]}, {"paragraph_vector": [-31.576002, -13.881777], "paragraph_keywords": ["keyboard", "rotoswype", "entry", "use"]}, {"paragraph_vector": [-30.598762, -14.567932], "paragraph_keywords": ["typing", "hand", "postures", "design"]}], "content": {}, "doi": "10.1145/3290605.3300536"}, {"uri": "144", "title": "Temporal Rhythms and Patterns of Electronic Documentation in Time-Critical Medical Work", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Swathi Jagannath", "Aleksandra Sarcevic", "Victoria Young", "Sage Myers"], "summary": "We examine nursing documentation on a newly implemented electronic flowsheet in medical resuscitations to identify the temporal patterns of documentation and how the recorded information supported time-critical teamwork. To determine when the information was documented, we compared timestamps from 58 flowsheet logs to those of verbal communications derived from video review. We also drew on observations of 95 resuscitations to understand the behaviors of nurse documenters. We found that only 8% of the verbal reports were documented in near real-time (one minute within the verbal report), while 42% of reports were not documented in the electronic flowsheet. In addition, 38% were documented early (before the verbal report) and 12% were documented with a delay, ranging from one to 58 minutes after the report. Our study showed that the electronic flowsheet design posed many challenges for realtime documentation, leading to paper-based workarounds and the use of free-text fields on the flowsheet to visualize and keep track of time, and to communicate temporal information to the team. These findings suggest that documenters shape the temporal rhythms of not only their own work but also the rhythms of the electronic record and medical process. We discuss the implications of these rhythms for EHR redesign to support real-time documentation in high-risk, safety-critical settings.", "keywords": ["process", "ed", "based", "clinician", "time", "information", "ehr", "section", "recorded", "resuscitation", "backcharting", "activity", "rhythm", "assessment", "communication", "documenter", "work", "video", "recording", "patient", "team", "documented", "timestamps", "page", "field", "nurse", "note", "workarounds", "documentation", "member", "flowsheet", "data", "study", "documenters", "administered", "text", "minute", "paper", "report", "observation", "hospital", "medication", "record"], "document_vector": [139.939041, 80.741821], "paragraphs": [{"paragraph_vector": [168.273529, 19.634618], "paragraph_keywords": ["documentation", "team", "communication", "work"]}, {"paragraph_vector": [166.716171, 19.023391], "paragraph_keywords": ["information", "ehr", "documenters", "documentation"]}, {"paragraph_vector": [169.881927, 23.539386], "paragraph_keywords": ["nurse", "team", "resuscitations", "rhythms"]}, {"paragraph_vector": [167.31636, 20.897193], "paragraph_keywords": ["team", "ehr", "time", "care"]}, {"paragraph_vector": [166.992538, 22.192464], "paragraph_keywords": ["documentation", "work", "ehr", "showing"]}, {"paragraph_vector": [169.947311, 22.561521], "paragraph_keywords": ["paper", "work", "flowsheet", "documentation"]}, {"paragraph_vector": [170.008453, 19.102144], "paragraph_keywords": ["flowsheet", "study", "documentation", "hospital"]}, {"paragraph_vector": [166.478469, 16.826698], "paragraph_keywords": ["sections", "navigation", "section", "bar"]}, {"paragraph_vector": [166.996078, 22.224395], "paragraph_keywords": ["resuscitations", "activities", "review", "nurses"]}, {"paragraph_vector": [168.610122, 20.960968], "paragraph_keywords": ["recording", "timestamps", "video", "time"]}, {"paragraph_vector": [168.462371, 20.348045], "paragraph_keywords": ["information", "documentation", "patterns", "documented"]}, {"paragraph_vector": [171.086547, 19.929744], "paragraph_keywords": ["information", "pupil", "time", "resuscitation"]}, {"paragraph_vector": [171.05902, 19.780927], "paragraph_keywords": ["flowsheet", "factors", "nurse", "related"]}, {"paragraph_vector": [169.6389, 20.501411], "paragraph_keywords": ["flowsheet", "information", "nurses", "paper"]}, {"paragraph_vector": [169.818359, 20.572357], "paragraph_keywords": ["nurse", "medications", "medication", "messages"]}, {"paragraph_vector": [169.10469, 22.706684], "paragraph_keywords": ["team", "nurse", "members", "information"]}, {"paragraph_vector": [170.430419, 19.447614], "paragraph_keywords": ["ems", "information", "reports", "nurse"]}, {"paragraph_vector": [169.841705, 19.106288], "paragraph_keywords": ["activities", "medications", "time", "information"]}, {"paragraph_vector": [170.297546, 20.306791], "paragraph_keywords": ["time", "paper", "information", "vitals"]}, {"paragraph_vector": [171.43103, 19.812879], "paragraph_keywords": ["time", "team", "nurse", "information"]}, {"paragraph_vector": [169.274932, 19.867918], "paragraph_keywords": ["text", "information", "resuscitation", "record"]}, {"paragraph_vector": [170.046966, 20.406608], "paragraph_keywords": ["activities", "rhythms", "documenters", "clinicians"]}, {"paragraph_vector": [168.771347, 20.545316], "paragraph_keywords": ["information", "team", "process", "documenters"]}, {"paragraph_vector": [169.194717, 20.155838], "paragraph_keywords": ["flowsheet", "information", "flip", "backcharting"]}, {"paragraph_vector": [169.983886, 19.670852], "paragraph_keywords": ["workarounds", "information", "tasks", "resuscitation"]}, {"paragraph_vector": [168.551544, 19.664424], "paragraph_keywords": ["time", "record", "documentation", "work"]}], "content": {}, "doi": "10.1145/3290605.3300808"}, {"uri": "145", "title": "VARI-SOUND: A Varifocal Lens for Sound", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Gianluca Memoli", "Letizia Chisari", "Jonathan P. Eccles", "Bruce W. Drinkwater"], "summary": "Centuries of development in optics have given us passive devices (i.e. lenses, mirrors and filters) to enrich audience immersivity with light effects, but there is nothing similar for sound. Beam-forming in concert halls and outdoor gigs still requires a large number of speakers, while headphones are still the state-of-the-art for personalized audio immersivity in VR. In this work, we show how 3D printed acoustic metasurfaces, assembled into the equivalent of optical systems, may offer a different solution. We demonstrate how to build them and how to use simple design tools, like the thin-lens equation, also for sound. We present some key Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300713 acoustic devices, like a \u201ccollimator\u201d, to transform a standard computer speaker into an acoustic \u201cspotlight\u201d; and a \u201cmagnifying glass\u201d, to create sound sources coming from distinct locations than the speaker itself. Finally, we demonstrate an acoustic varifocal lens, discussing applications equivalent to auto-focus cameras and VR headsets and the limitations of the technology.", "keywords": ["lens", "based", "position", "metasurfaces", "design", "unit", "source", "method", "mm", "designing", "user", "type", "speaker", "space", "length", "equation", "metamaterials", "size", "page", "experience", "field", "intensity", "khz", "application", "sound", "light", "audience", "distance", "cell", "device", "phase", "array", "microphone", "system", "image", "transmission", "hci", "structure", "paper", "frequency", "metasurface", "wavelength", "level", "figure"], "document_vector": [140.33168, -36.49274], "paragraphs": [{"paragraph_vector": [-153.28215, 40.762405], "paragraph_keywords": ["sound", "devices", "emerging", "lenses"]}, {"paragraph_vector": [-155.212753, 39.363895], "paragraph_keywords": ["devices", "design", "lenses", "sound"]}, {"paragraph_vector": [-153.728759, 42.265281], "paragraph_keywords": ["sound", "sources", "light", "audience"]}, {"paragraph_vector": [-150.19931, 39.036731], "paragraph_keywords": ["speakers", "listener", "sound", "interactions"]}, {"paragraph_vector": [-154.601547, 40.387359], "paragraph_keywords": ["spotlights", "beam", "produce", "lenses"]}, {"paragraph_vector": [-155.371826, 40.123031], "paragraph_keywords": ["unit", "cells", "frequency", "space"]}, {"paragraph_vector": [-155.144332, 40.062843], "paragraph_keywords": ["metasurfaces", "devices", "structures", "metasurface"]}, {"paragraph_vector": [-154.723495, 39.2658], "paragraph_keywords": ["phase", "distribution", "unit", "lens"]}, {"paragraph_vector": [-154.820556, 39.753738], "paragraph_keywords": ["frequency", "transmission", "unit", "phase"]}, {"paragraph_vector": [-154.808334, 39.568447], "paragraph_keywords": ["lenses", "lens", "cells", "section"]}, {"paragraph_vector": [-156.70285, 39.460655], "paragraph_keywords": ["lens", "figure", "distances", "speaker"]}, {"paragraph_vector": [-156.659835, 40.077175], "paragraph_keywords": ["lenses", "equation", "mm", "length"]}, {"paragraph_vector": [-154.5569, 40.099864], "paragraph_keywords": ["lens", "speaker", "divergence", "distance"]}, {"paragraph_vector": [-154.954528, 39.752273], "paragraph_keywords": ["speakers", "sound", "figure", "experiences"]}, {"paragraph_vector": [-155.090789, 41.388244], "paragraph_keywords": ["source", "lens", "image", "position"]}, {"paragraph_vector": [-153.098251, 41.11766], "paragraph_keywords": ["distance", "lens", "telescope", "machine"]}, {"paragraph_vector": [-150.555313, 40.57299], "paragraph_keywords": ["lens", "speaker", "distance", "deliver"]}, {"paragraph_vector": [-155.893997, 38.065299], "paragraph_keywords": ["cells", "unit", "type", "transmission"]}, {"paragraph_vector": [-154.673461, 39.915557], "paragraph_keywords": ["lens", "metamaterials", "devices", "arrays"]}, {"paragraph_vector": [-154.426345, 41.652313], "paragraph_keywords": ["sound", "grant", "funding", "way"]}], "content": {}, "doi": "10.1145/3290605.3300879"}, {"uri": "146", "title": "Painting with CATS: Camera-Aided Texture Synthesis", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Ticha Sethapakdi", "James McCann"], "summary": "We present CATS, a digital painting system that synthesizes textures from live video in real-time, short-cutting the typical brushand texturegathering workflow. Through the use of boundary-aware texture synthesis, CATS produces strokes that are non-repeating and blend smoothly with each other. This allows CATS to produce paintings that would be difficult to create with traditional art supplies or existing software. We evaluated the effectiveness of CATS by asking artists to integrate the tool into their creative practice for two weeks; their paintings and feedback demonstrate that CATS is an expressive tool which can be used to create richly textured paintings. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300287 CCS CONCEPTS \u2022 Human-centered computing \u2192 Interactive systems and tools; \u2022Computingmethodologies\u2192Graphics systems and interfaces; \u2022Computer systems organization \u2192 Real-time systems;", "keywords": ["brush", "process", "capture", "lu", "time", "paint", "artist", "stroke", "user", "painting", "produce", "camera", "allows", "work", "use", "exemplar", "e", "du", "jitter", "function", "cat", "fig", "ann", "synthesis", "study", "canvas", "system", "image", "support", "ye", "texture", "patch"], "document_vector": [115.914535, -44.794559], "paragraphs": [{"paragraph_vector": [150.596405, 83.842193], "paragraph_keywords": ["painting", "brush", "artists", "systems"]}, {"paragraph_vector": [26.765365, 88.539222], "paragraph_keywords": ["brush", "strokes", "stamping", "use"]}, {"paragraph_vector": [130.889755, 83.611389], "paragraph_keywords": ["painting", "texture", "synthesis", "users"]}, {"paragraph_vector": [120.514175, 86.142547], "paragraph_keywords": ["exemplar", "users", "painting", "cats"]}, {"paragraph_vector": [174.262161, 86.923568], "paragraph_keywords": ["texture", "stroke", "users", "canvas"]}, {"paragraph_vector": [103.921279, 87.323722], "paragraph_keywords": ["ann", "set", "patches", "e"]}, {"paragraph_vector": [150.119628, 88.011085], "paragraph_keywords": ["ann", "y", "canvas", "distance"]}, {"paragraph_vector": [162.455703, 85.758941], "paragraph_keywords": ["artists", "study", "paintings", "cats"]}, {"paragraph_vector": [-171.58612, 86.63829], "paragraph_keywords": ["system", "artists", "cats", "curve"]}, {"paragraph_vector": [78.292427, 87.186653], "paragraph_keywords": ["artists", "stroke", "lu", "swatches"]}, {"paragraph_vector": [-149.221267, 85.369194], "paragraph_keywords": ["textures", "camera", "capture", "artists"]}, {"paragraph_vector": [167.755569, 87.147972], "paragraph_keywords": ["painting", "textures", "cats", "settings"]}, {"paragraph_vector": [151.522186, 87.117179], "paragraph_keywords": ["cats", "use", "agreed", "du"]}, {"paragraph_vector": [-159.760604, 87.939659], "paragraph_keywords": ["cats", "painting", "textures", "artists"]}, {"paragraph_vector": [108.671058, 87.205657], "paragraph_keywords": ["process", "scott", "hodgins", "hudson"]}], "content": {}, "doi": "10.1145/3290605.3300435"}, {"uri": "147", "title": "A Badge, Not a Barrier: Designing for\u2013and Throughout\u2013Digital Badge Implementation", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Caroline Pitt"], "summary": "We synthesize insights from a multi-year project involving the design and implementation of a digital badge systemwith youth co-designers at a science center. Using stakeholder interviews and surveys, participatory design session data, and user analytics, we identify the sociotechnical, sociocultural, and technical challenges of long-term badge implementation and propose several recommendations for the design and implementation of future badge systems. By identifying these challenges and providing recommendations that foreground stakeholder values and participation, we show how to support implementation throughout the entire design-toimplementation cycle.", "keywords": ["process", "requires", "time", "set", "training", "education", "design", "feature", "specifc", "interview", "focus", "staf", "credibility", "worked", "involved", "work", "implementation", "use", "recommendation", "integration", "designed", "issue", "group", "team", "learning", "challenge", "youth", "working", "related", "page", "year", "science", "stakeholder", "develop", "partnership", "badge", "value", "practice", "data", "researcher", "student", "system", "support", "required", "research", "focused", "term", "website", "program", "paper", "project", "center"], "document_vector": [55.283462, 30.454261], "paragraphs": [{"paragraph_vector": [121.991058, -6.16406], "paragraph_keywords": ["copies", "design", "acm", "badges"]}, {"paragraph_vector": [119.872467, 1.723558], "paragraph_keywords": ["badges", "challenges", "implementation", "practices"]}, {"paragraph_vector": [120.512962, -0.738221], "paragraph_keywords": ["challenges", "badge", "design", "term"]}, {"paragraph_vector": [121.108978, 1.470623], "paragraph_keywords": ["badges", "implementation", "learning", "work"]}, {"paragraph_vector": [121.746345, 0.000539], "paragraph_keywords": ["badges", "learning", "work", "badge"]}, {"paragraph_vector": [119.925292, -4.127726], "paragraph_keywords": ["design", "values", "vsd", "stakeholder"]}, {"paragraph_vector": [119.62622, -1.897045], "paragraph_keywords": ["work", "children", "design", "learning"]}, {"paragraph_vector": [120.844078, -0.083219], "paragraph_keywords": ["work", "program", "research", "stakeholders"]}, {"paragraph_vector": [-161.882736, 7.228976], "paragraph_keywords": ["youth", "program", "science", "project"]}, {"paragraph_vector": [120.946952, -1.207756], "paragraph_keywords": ["badge", "system", "design", "research"]}, {"paragraph_vector": [122.223007, 1.532122], "paragraph_keywords": ["design", "badge", "year", "youth"]}, {"paragraph_vector": [121.818336, -1.377226], "paragraph_keywords": ["design", "badge", "challenges", "system"]}, {"paragraph_vector": [120.233047, -1.090829], "paragraph_keywords": ["challenges", "system", "badge", "implementation"]}, {"paragraph_vector": [118.945442, 0.747318], "paragraph_keywords": ["students", "science", "badge", "program"]}, {"paragraph_vector": [115.837188, 1.972512], "paragraph_keywords": ["students", "system", "badge", "staf"]}, {"paragraph_vector": [114.929122, 1.811142], "paragraph_keywords": ["badges", "badge", "challenges", "system"]}, {"paragraph_vector": [119.611427, -0.339706], "paragraph_keywords": ["badges", "staf", "value", "project"]}, {"paragraph_vector": [114.387481, 0.987666], "paragraph_keywords": ["credibility", "accomplishments", "way", "college"]}, {"paragraph_vector": [119.761093, 0.066396], "paragraph_keywords": ["students", "badge", "staf", "badges"]}, {"paragraph_vector": [118.125114, -0.139807], "paragraph_keywords": ["required", "changes", "system", "badge"]}, {"paragraph_vector": [121.213562, -0.644005], "paragraph_keywords": ["badge", "work", "stakeholder", "system"]}, {"paragraph_vector": [118.733871, -1.336341], "paragraph_keywords": ["badge", "system", "implementation", "design"]}, {"paragraph_vector": [117.592025, -0.819691], "paragraph_keywords": ["system", "badge", "work", "share"]}, {"paragraph_vector": [119.120826, 2.12251], "paragraph_keywords": ["badge", "system", "badges", "backend"]}, {"paragraph_vector": [119.529388, -2.311023], "paragraph_keywords": ["work", "systems", "design", "implementation"]}, {"paragraph_vector": [120.670135, -0.971499], "paragraph_keywords": ["design", "badge", "projects", "science"]}], "content": {}, "doi": "10.1145/3290605.3300557"}, {"uri": "148", "title": "Thermporal: An Easy-to-DeployTemporal Thermographic Sensor Systemto Support Residential Energy Audits", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Matthew Louis Mauriello", "Brenna McNally", "Jon E. Froehlich"], "summary": "Underperforming, degraded, and missing insulation in US residential buildings is common. Detecting these issues, however, can be difficult. Using thermal cameras during energy audits can aid in locating potential insulation issues, but prior work indicates it is challenging to determine their severity using thermal imagery alone. In this work, we present an easyto-deploy, temporal thermographic sensor system designed to support residential energy audits through quantitative analysis of building envelope performance. We then offer an evaluation of the system through two studies: (i) a one-week, in-home field study in five homes and (ii) a semi-structured interview study with five professional energy auditors. Our results show our system helps raise awareness, improves homeowners\u2019 ability to gauge the severity of issues, and provides opportunities for new interactions between homeowners, building data, and professional auditors.", "keywords": ["based", "time", "condition", "information", "collected", "performance", "wall", "design", "unit", "reported", "home", "analysis", "investigate", "homeowner", "temperature", "audit", "camera", "sensor", "user", "auditor", "assessment", "deployment", "air", "building", "work", "increased", "participant", "thermography", "use", "result", "impact", "recommendation", "issue", "concern", "energy", "challenge", "finding", "page", "insulation", "found", "survey", "humidity", "described", "data", "study", "calibration", "envelope", "system", "ii", "address", "auditing", "paper", "report", "area", "mission", "code"], "document_vector": [100.153572, 48.332092], "paragraphs": [{"paragraph_vector": [-14.218552, -68.612709], "paragraph_keywords": ["building", "copies", "insulation", "computing"]}, {"paragraph_vector": [-16.498785, -61.447032], "paragraph_keywords": ["energy", "audits", "system", "thermography"]}, {"paragraph_vector": [-8.398762, -63.922935], "paragraph_keywords": ["energy", "audits", "cameras", "insulation"]}, {"paragraph_vector": [-11.638182, -62.618381], "paragraph_keywords": ["temperature", "conditions", "building", "thermography"]}, {"paragraph_vector": [-11.031216, -61.948272], "paragraph_keywords": ["data", "system", "sensors", "user"]}, {"paragraph_vector": [-17.987155, -65.759193], "paragraph_keywords": ["sensor", "data", "calibration", "unit"]}, {"paragraph_vector": [-12.993003, -64.731071], "paragraph_keywords": ["data", "building", "scan", "server"]}, {"paragraph_vector": [-10.375614, -64.22705], "paragraph_keywords": ["participants", "home", "questionnaire", "investigate"]}, {"paragraph_vector": [-6.622229, -63.694404], "paragraph_keywords": ["homes", "study", "participants", "insulation"]}, {"paragraph_vector": [-13.971453, -65.781028], "paragraph_keywords": ["participants", "codes", "survey", "data"]}, {"paragraph_vector": [-12.145323, -70.459671], "paragraph_keywords": ["participants", "irr", "insulation", "issues"]}, {"paragraph_vector": [-15.510311, -62.60923], "paragraph_keywords": ["participants", "camera", "agreed", "issues"]}, {"paragraph_vector": [-13.272316, -66.09185], "paragraph_keywords": ["system", "participants", "insulation", "sensor"]}, {"paragraph_vector": [-11.486832, -62.678447], "paragraph_keywords": ["report", "participants", "insulation", "issues"]}, {"paragraph_vector": [-10.644847, -68.359176], "paragraph_keywords": ["data", "participants", "system", "trust"]}, {"paragraph_vector": [-12.894613, -62.588684], "paragraph_keywords": ["participants", "data", "system", "time"]}, {"paragraph_vector": [-13.811236, -63.459274], "paragraph_keywords": ["study", "reported", "issues", "energy"]}, {"paragraph_vector": [-8.667873, -67.249244], "paragraph_keywords": ["participants", "probe", "thermography", "audit"]}, {"paragraph_vector": [-15.029969, -67.500526], "paragraph_keywords": ["thermography", "codes", "data", "coded"]}, {"paragraph_vector": [-11.186491, -65.711219], "paragraph_keywords": ["data", "participants", "thermography", "described"]}, {"paragraph_vector": [-10.971496, -64.844863], "paragraph_keywords": ["energy", "home", "system", "participants"]}, {"paragraph_vector": [-14.576224, -64.740844], "paragraph_keywords": ["participants", "data", "system", "reports"]}, {"paragraph_vector": [-9.973209, -66.771141], "paragraph_keywords": ["homeowners", "system", "buildings", "data"]}, {"paragraph_vector": [-11.688006, -64.43193], "paragraph_keywords": ["issues", "energy", "findings", "assumptions"]}, {"paragraph_vector": [-14.718221, -64.956314], "paragraph_keywords": ["data", "homeowners", "conversations", "results"]}, {"paragraph_vector": [-7.274024, -66.181472], "paragraph_keywords": ["participants", "energy", "user", "auditors"]}], "content": {}, "doi": "10.1145/3290605.3300835"}, {"uri": "149", "title": "Understanding the Impact of Information Representation on Willingness to Share Information", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Stefan Schneegass", "Romina Poguntke"], "summary": "Since the release of the first activity tracker, there has been a steady increase in the number of sensors embedded in wearable devices and with it in the amount and diversity of information that can be derived from these sensors. This development leads to novel privacy threats for users. In a web survey with 248 participants, we explored whether users\u2019 willingness to share private data is dependent on how the data is requested by an application. Specifically, requests can be formulated as access to sensor data or as access to information derived from the sensor data (e.g., accelerometer vs. sleep quality). We show that non-expert users lack an understanding of how the two representation levels relate to each other. The results suggest that the willingness to share sensor data over derived information is governed by whether the derived information has positive or negative connotations (e.g., training intensity vs. life expectancy). Using the results of the survey, we derive implications for supporting users in protecting their private data collected via wearable sensors.", "keywords": ["information", "willingness", "sensor", "user", "type", "sharing", "expertise", "work", "result", "participant", "group", "derived", "application", "understand", "representation", "accelerometer", "device", "data", "target", "privacy", "fitness", "share", "level", "p"], "document_vector": [-3.275435, 53.927539], "paragraphs": [{"paragraph_vector": [157.499679, -75.1837], "paragraph_keywords": ["information", "copies", "textiles", "acm"]}, {"paragraph_vector": [-128.802566, -87.565544], "paragraph_keywords": ["privacy", "data", "users", "applications"]}, {"paragraph_vector": [170.81842, -68.70417], "paragraph_keywords": ["information", "data", "derived", "sensor"]}, {"paragraph_vector": [169.384002, -63.194168], "paragraph_keywords": ["sensor", "information", "participants", "share"]}, {"paragraph_vector": [159.888534, -65.988754], "paragraph_keywords": ["data", "participants", "target", "applied"]}, {"paragraph_vector": [156.923248, -66.10527], "paragraph_keywords": ["expertise", "p", "target", "level"]}, {"paragraph_vector": [160.232147, -68.75341], "paragraph_keywords": ["level", "representation", "share", "p"]}, {"paragraph_vector": [166.077743, -65.354995], "paragraph_keywords": ["information", "data", "derived", "willingness"]}, {"paragraph_vector": [171.249298, -71.14421], "paragraph_keywords": ["information", "data", "users", "sharing"]}, {"paragraph_vector": [166.776763, -68.78057], "paragraph_keywords": ["information", "users", "derived", "connotations"]}], "content": {}, "doi": "10.1145/3290605.3300416"}, {"uri": "150", "title": "Beyond Schematic Capture", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Richard Lin", "Rohit Ramesh", "Antonio Iannopollo", "Alberto Sangiovanni Vincentelli", "Prabal Dutta", "Elad Alon", "Bj\u00f6rn Hartmann", "Alberto Sangio"], "summary": "Printed Circuit Board (PCB) design tools are critical in helping users build non-trivial electronics devices. While recent work recognizes deficiencies with current tools and explores novel methods, little has been done to understand modern designers and their needs. To gain better insight into their practices, we interview fifteen electronics designers of a variety of backgrounds. Our open-ended, semi-structured interviews examine both overarching design flows and details of individual steps. One major finding was that most creative engineering work happens during system architecture, yet current tools operate at lower abstraction levels and create significant tedious work for designers. From that insight, we conceptualize abstractions and primitives for higher-level tools and elicit feedback from our participants Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for thirdparty components of this work must be honored. For all other uses, contact the owner/author(s). CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-5970-2/19/05. https://doi.org/10.1145/3290605.3300513 on clickthrough mockups of design flows through an example project. We close with our observation on opportunities for improving board design tools and discuss generalizability of our findings beyond the electronics domain.", "keywords": ["library", "process", "capture", "breadboard", "based", "time", "mentioned", "need", "board", "diagram", "requirement", "design", "interview", "abstraction", "hcl", "example", "noted", "user", "pcb", "pcbs", "eda", "work", "tool", "participant", "use", "concept", "step", "page", "electronics", "part", "including", "feedback", "block", "check", "layout", "circuit", "device", "architecture", "data", "flow", "study", "reference", "designer", "routing", "system", "support", "mockup", "paper", "interface", "level", "community"], "document_vector": [72.125083, -24.015539], "paragraphs": [{"paragraph_vector": [25.346622, 33.592273], "paragraph_keywords": ["tools", "circuit", "design", "ways"]}, {"paragraph_vector": [25.74195, 31.759813], "paragraph_keywords": ["tools", "eda", "design", "work"]}, {"paragraph_vector": [28.405349, 32.701122], "paragraph_keywords": ["tools", "time", "design", "system"]}, {"paragraph_vector": [23.498218, 31.879177], "paragraph_keywords": ["breadboards", "tools", "work", "practices"]}, {"paragraph_vector": [22.974182, 29.686262], "paragraph_keywords": ["design", "level", "tools", "takes"]}, {"paragraph_vector": [80.509788, 41.341594], "paragraph_keywords": ["participants", "design", "tools", "designs"]}, {"paragraph_vector": [29.005775, 33.692363], "paragraph_keywords": ["design", "requirements", "system", "tools"]}, {"paragraph_vector": [24.949741, 30.723945], "paragraph_keywords": ["participants", "diagrams", "boards", "tools"]}, {"paragraph_vector": [24.314266, 29.59415], "paragraph_keywords": ["design", "layout", "reference", "designs"]}, {"paragraph_vector": [27.387258, 28.542886], "paragraph_keywords": ["parts", "layout", "design", "projects"]}, {"paragraph_vector": [23.684091, 27.752346], "paragraph_keywords": ["design", "mentioned", "features", "rules"]}, {"paragraph_vector": [24.051935, 30.347452], "paragraph_keywords": ["design", "tools", "system", "architecture"]}, {"paragraph_vector": [25.869686, 28.53178], "paragraph_keywords": ["tools", "block", "circuits", "level"]}, {"paragraph_vector": [25.188175, 30.7942], "paragraph_keywords": ["libraries", "block", "blocks", "implementations"]}, {"paragraph_vector": [23.857069, 28.306043], "paragraph_keywords": ["design", "example", "block", "blocks"]}, {"paragraph_vector": [25.492801, 31.516712], "paragraph_keywords": ["design", "participants", "showing", "block"]}, {"paragraph_vector": [32.120273, 31.117364], "paragraph_keywords": ["design", "participants", "noted", "automated"]}, {"paragraph_vector": [28.512111, 28.997545], "paragraph_keywords": ["libraries", "system", "mentioned", "trust"]}, {"paragraph_vector": [98.716941, 52.485317], "paragraph_keywords": ["hcl", "participants", "interface", "designs"]}, {"paragraph_vector": [25.781385, 30.68295], "paragraph_keywords": ["time", "system", "design", "level"]}, {"paragraph_vector": [26.76128, 31.91035], "paragraph_keywords": ["design", "tools", "mockup", "user"]}, {"paragraph_vector": [25.339078, 30.599157], "paragraph_keywords": ["design", "pcb", "capture", "ambiguity"]}, {"paragraph_vector": [27.095615, 30.611192], "paragraph_keywords": ["design", "tools", "system", "concept"]}, {"paragraph_vector": [74.635597, 29.592988], "paragraph_keywords": ["state", "reflect", "expressed", "united"]}], "content": {}, "doi": "10.1145/3290605.3300681"}, {"uri": "151", "title": "Understanding the Shared Experiences of Runners and Spectators in Long-Distance Running Events", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Tao Bi", "Nadia Bianchi-Berthouze", "Aneesha Singh", "Enrico Costanza"], "summary": "Increasingly popular, long-distance running events (LDRE) attract not just runners but an exponentially increasing number of spectators. Due to the long duration and broad geographic spread of such events, interactions between them are limited to brief moments when runners (R) pass by their supporting spectators (S). Current technology is limited in its potential for supporting interactions and mainly measures and displays basic running information to spectators who passively consume it. In this paper, we conducted qualitative studies for an in-depth understanding of the R&S\u2019 shared experience during LDRE and how technology can enrich this experience. We propose a twolayer DyPECS framework, highlighting the rich dynamics of the R&S multi-faceted running journey and of their micro-encounters. DyPECS is enriched by the findings from our in depth qualitative studies. We finally present design implications for the multi-facet co-experience of R&S during LDRE. CCS CONCEPTS \u2022 Human-centered computing \u2192 Empirical studies in HCI;", "keywords": ["based", "identity", "strategy", "time", "need", "marathon", "information", "ldre", "body", "training", "design", "literature", "sensation", "app", "component", "journey", "sensor", "pain", "interaction", "sharing", "start", "runner", "il", "team", "run", "ol", "sense", "spectator", "experience", "page", "c", "understanding", "identified", "-", "understand", "described", "encounter", "distance", "phase", "cheering", "technology", "study", "feel", "map", "running", "said", "support", "event", "race", "paper", "supporter", "share", "dypecs"], "document_vector": [14.421296, -0.461803], "paragraphs": [{"paragraph_vector": [-116.186561, -8.379146], "paragraph_keywords": ["events", "ldre", "spectators", "runners"]}, {"paragraph_vector": [-116.637306, -8.900413], "paragraph_keywords": ["ldre", "runners", "copies", "experiences"]}, {"paragraph_vector": [-112.583145, -4.310146], "paragraph_keywords": ["runners", "sensations", "exertion", "strategies"]}, {"paragraph_vector": [-117.371467, -8.823129], "paragraph_keywords": ["spectators", "experience", "understanding", "events"]}, {"paragraph_vector": [-116.072036, -7.554639], "paragraph_keywords": ["spectators", "running", "information", "runners"]}, {"paragraph_vector": [-115.855247, -6.020509], "paragraph_keywords": ["spectators", "runners", "runner", "experience"]}, {"paragraph_vector": [-116.316116, -9.754782], "paragraph_keywords": ["spectators", "marathon", "runners", "participants"]}, {"paragraph_vector": [-117.759582, -10.445676], "paragraph_keywords": ["based", "ldre", "blogs", "marathon"]}, {"paragraph_vector": [-117.92971, -10.392749], "paragraph_keywords": ["c", "runner", "phases", "spectators"]}, {"paragraph_vector": [-116.497886, -8.946804], "paragraph_keywords": ["runner", "runners", "spectator", "spectators"]}, {"paragraph_vector": [-113.619651, -6.7839], "paragraph_keywords": ["runners", "sensations", "run", "running"]}, {"paragraph_vector": [-111.807937, -3.90765], "paragraph_keywords": ["runners", "run", "pain", "described"]}, {"paragraph_vector": [-115.329132, -6.92719], "paragraph_keywords": ["runners", "dypecs", "ol", "doubt"]}, {"paragraph_vector": [-114.718101, -7.285154], "paragraph_keywords": ["runners", "going", "support", "cheering"]}, {"paragraph_vector": [-117.026077, -8.234025], "paragraph_keywords": ["runner", "runners", "spectators", "said"]}, {"paragraph_vector": [-115.10511, -7.868876], "paragraph_keywords": ["runner", "spectators", "said", "lack"]}, {"paragraph_vector": [-116.976844, -8.340808], "paragraph_keywords": ["team", "process", "runners", "identity"]}, {"paragraph_vector": [-117.4206, -7.363455], "paragraph_keywords": ["training", "runner", "months", "support"]}, {"paragraph_vector": [-116.007575, -7.617354], "paragraph_keywords": ["share", "runners", "spectators", "-"]}, {"paragraph_vector": [-116.147003, -7.22791], "paragraph_keywords": ["experience", "map", "said", "pain"]}, {"paragraph_vector": [-111.373977, -3.36939], "paragraph_keywords": ["sensors", "body", "states", "discriminate"]}, {"paragraph_vector": [-107.444717, -2.636059], "paragraph_keywords": ["runner", "runners", "maps", "experience"]}, {"paragraph_vector": [-116.54512, -6.852372], "paragraph_keywords": ["runner", "spectators", "design", "technology"]}, {"paragraph_vector": [-116.417999, -6.987569], "paragraph_keywords": ["encounters", "support", "dypecs", "building"]}, {"paragraph_vector": [-116.834152, -7.95064], "paragraph_keywords": ["spectators", "propose", "support", "need"]}], "content": {}, "doi": "10.1145/3290605.3300259"}, {"uri": "152", "title": "Can Children Understand Machine Learning Concepts? The Effect of Uncovering Black Boxes", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Tom Hitron"], "summary": "Machine Learning services are integrated into various aspects of everyday life. Their underlying processes are typically black-boxed to increase ease-of-use. Consequently, children lack the opportunity to explore such processes and develop essential mental models. We present a gesture recognition research platform, designed to support learning from experience by uncovering Machine Learning building blocks: Data Labeling and Evaluation. Children used the platform to perform physical gestures, iterating between sampling and evaluation. Their understanding was tested in a pre/post experimental design, in three conditions: learning activity uncovering Data Labeling only, Evaluation only, or both. Our findings show that both building blocks are imperative to enhance children\u2019s understanding of basic Machine Learning concepts. Children were able to apply their new knowledge to everyday life context, including personally meaningful applications. We conclude that children\u2019s interaction with uncovered black boxes of Machine Learning contributes to a better understanding of the world around them.", "keywords": ["process", "based", "child", "condition", "labeling", "explanation", "class", "design", "feature", "analysis", "example", "model", "sample", "work", "building", "evaluation", "pretest", "designed", "learning", "concept", "experience", "gesture", "understanding", "feedback", "provided", "including", "block", "recognition", "car", "device", "data", "ml", "system", "research", "detect", "knowledge", "recognize"], "document_vector": [-26.943267, -54.716613], "paragraphs": [{"paragraph_vector": [-161.126342, 63.166469], "paragraph_keywords": ["ml", "learning", "copies", "novices"]}, {"paragraph_vector": [-172.887542, 71.436279], "paragraph_keywords": ["processes", "ml", "children", "models"]}, {"paragraph_vector": [-157.367874, 63.372032], "paragraph_keywords": ["data", "model", "examples", "classification"]}, {"paragraph_vector": [-163.503768, 62.988857], "paragraph_keywords": ["ml", "children", "concepts", "system"]}, {"paragraph_vector": [-149.045104, 55.4785], "paragraph_keywords": ["children", "ml", "learning", "design"]}, {"paragraph_vector": [-94.59423, 43.653217], "paragraph_keywords": ["data", "recognition", "learning", "gesture"]}, {"paragraph_vector": [162.803924, 3.114603], "paragraph_keywords": ["learning", "knowledge", "based", "processes"]}, {"paragraph_vector": [-85.101516, 45.823253], "paragraph_keywords": ["data", "system", "device", "children"]}, {"paragraph_vector": [-67.520401, 22.423332], "paragraph_keywords": ["features", "system", "learning", "warping"]}, {"paragraph_vector": [-148.931777, 56.255107], "paragraph_keywords": ["children", "ml", "gestures", "examples"]}, {"paragraph_vector": [-4.558459, 56.864551], "paragraph_keywords": ["car", "ml", "system", "children"]}, {"paragraph_vector": [-68.770652, 28.455064], "paragraph_keywords": ["children", "system", "gesture", "sample"]}, {"paragraph_vector": [-81.47454, 35.664279], "paragraph_keywords": ["children", "asked", "circle", "system"]}, {"paragraph_vector": [-164.418746, 50.259723], "paragraph_keywords": ["system", "children", "child", "understanding"]}, {"paragraph_vector": [-153.259841, 54.275386], "paragraph_keywords": ["children", "examples", "learning", "ml"]}, {"paragraph_vector": [-140.642456, 56.32595], "paragraph_keywords": ["system", "children", "examples", "conditions"]}, {"paragraph_vector": [-153.706008, 58.592903], "paragraph_keywords": ["system", "device", "conditions", "children"]}, {"paragraph_vector": [-156.116088, 78.78099], "paragraph_keywords": ["car", "children", "detect", "system"]}, {"paragraph_vector": [-145.746047, 22.23236], "paragraph_keywords": ["children", "ml", "like", "processes"]}, {"paragraph_vector": [-156.245834, 58.222805], "paragraph_keywords": ["children", "data", "system", "learning"]}, {"paragraph_vector": [-154.003051, 62.428333], "paragraph_keywords": ["learning", "ml", "children", "gender"]}, {"paragraph_vector": [-160.809158, 59.493846], "paragraph_keywords": ["children", "building", "blocks", "ml"]}], "content": {}, "doi": "10.1145/3290605.3300372"}, {"uri": "153", "title": "Thinking Too Classically: Research Topics in Human-Quantum Computer Interaction", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Zahra Ashktorab", "Justin D. Weisz", "Maryam Ashoori"], "summary": "Quantum computing is a fundamentally different way of performing computation than classical computing. Many problems that are considered hard for classical computers may have efficient solutions using quantum computers. Recently, technology companies including IBM, Microsoft, and Google have invested in developing both quantum computing hardware and software to explore the potential of quantum computing. Because of the radical shift in computing paradigms that quantum represents, we see an opportunity to study the unique needs people have when interacting with quantum systems, what we call Quantum HCI (QHCI). Based on interviews with experts in quantum computing, we identify four areas in which HCI researchers can contribute to the field of quantum computing. These areas include understanding current and future quantum users, tools for programming and debugging quantum algorithms, visualizations of quantum states, and educational materials to train the first generation of \u201cquantum native\u201d programmers.", "keywords": ["capture", "gate", "quantum", "time", "expressed", "development", "qubit", "qubits", "problem", "expert", "debugging", "user", "workflow", "qiskit", "expertise", "work", "tool", "use", "participant", "people", "material", "superposition", "learning", "think", "run", "concept", "computing", "state", "visualization", "field", "composer", "understanding", "programming", "computer", "want", "researcher", "scientist", "system", "ibm", "developer", "research", "physicist", "hci", "paper", "question", "level", "community", "code"], "document_vector": [-143.263916, 24.424524], "paragraphs": [{"paragraph_vector": [59.979801, 25.118827], "paragraph_keywords": ["quantum", "computing", "computers", "copies"]}, {"paragraph_vector": [58.621093, 34.170597], "paragraph_keywords": ["quantum", "computing", "materials", "hci"]}, {"paragraph_vector": [69.693023, 29.768238], "paragraph_keywords": ["quantum", "state", "qubits", "learning"]}, {"paragraph_vector": [60.343032, 31.535591], "paragraph_keywords": ["quantum", "hci", "computing", "state"]}, {"paragraph_vector": [62.294918, 27.788013], "paragraph_keywords": ["quantum", "computing", "participants", "organization"]}, {"paragraph_vector": [66.407669, 33.060897], "paragraph_keywords": ["quantum", "users", "computing", "hci"]}, {"paragraph_vector": [60.459281, 29.005605], "paragraph_keywords": ["quantum", "computers", "molecules", "problem"]}, {"paragraph_vector": [59.737651, 30.090923], "paragraph_keywords": ["quantum", "use", "programming", "composer"]}, {"paragraph_vector": [59.973636, 30.853391], "paragraph_keywords": ["quantum", "gates", "developers", "ibm"]}, {"paragraph_vector": [64.240074, 27.464632], "paragraph_keywords": ["quantum", "computing", "code", "efforts"]}, {"paragraph_vector": [65.107505, 27.118053], "paragraph_keywords": ["quantum", "players", "superposition", "game"]}, {"paragraph_vector": [62.791446, 28.255636], "paragraph_keywords": ["quantum", "experts", "computing", "questions"]}, {"paragraph_vector": [64.961654, 28.247631], "paragraph_keywords": ["quantum", "people", "computing", "spend"]}, {"paragraph_vector": [67.410133, 29.72425], "paragraph_keywords": ["quantum", "expertise", "programming", "questions"]}, {"paragraph_vector": [62.039741, 29.163108], "paragraph_keywords": ["tools", "quantum", "composer", "paper"]}, {"paragraph_vector": [63.742835, 34.122337], "paragraph_keywords": ["quantum", "paper", "tools", "domains"]}, {"paragraph_vector": [63.927013, 32.376632], "paragraph_keywords": ["quantum", "debugging", "computing", "workflows"]}, {"paragraph_vector": [60.438934, 30.340772], "paragraph_keywords": ["quantum", "level", "debugging", "programming"]}, {"paragraph_vector": [60.818729, 30.345142], "paragraph_keywords": ["programming", "quantum", "debugging", "tools"]}, {"paragraph_vector": [63.593189, 33.01168], "paragraph_keywords": ["qubit", "quantum", "state", "visualization"]}, {"paragraph_vector": [62.745903, 31.613292], "paragraph_keywords": ["quantum", "visualizations", "computing", "development"]}, {"paragraph_vector": [63.922969, 27.786785], "paragraph_keywords": ["quantum", "computing", "practice", "hci"]}, {"paragraph_vector": [49.19234, -1.960798], "paragraph_keywords": ["quantum", "hci", "contrasts", "grudin"]}], "content": {}, "doi": "10.1145/3290605.3300629"}, {"uri": "154", "title": "Student Perspectives on Digital Phenotyping", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["John Rooksby", "Alistair Morrison"], "summary": "There is a mental health crisis facing universities internationally. A growing body of interdisciplinary research has successfully demonstrated that using sensor and interaction data from students\u2019 smartphones can give insight into stress, depression, mood, suicide risk and more. The approach, which is sometimes termed Digital Phenotyping, has potential to transform how mental health and wellbeing can be monitored and understood. The approach could also transform how interventions are designed, delivered and evaluated. To date, little work has addressed the human and ethical side of digital phenotyping, including how students feel about being monitored. In this paper we report findings from in-depth focus groups, prototyping and interviews with students. We find they are positive about mental health technology, but also that there are multi-layered issues to address if digital phenotyping is to become acceptable. Using an acceptability framework, we set out the key design challenges that need to be addressed.", "keywords": ["based", "need", "information", "collected", "self", "app", "wellbeing", "care", "problem", "focus", "user", "work", "participant", "use", "people", "discussed", "group", "concern", "collection", "health", "page", "experience", "university", "form", "monitoring", "tracking", "table", "data", "technology", "study", "student", "acceptability", "system", "research", "phenotyping", "order", "perspective", "paper", "question", "consent", "value"], "document_vector": [160.524383, 82.384429], "paragraphs": [{"paragraph_vector": [143.115402, -53.972412], "paragraph_keywords": ["health", "copies", "students", "uk"]}, {"paragraph_vector": [140.486038, -51.290073], "paragraph_keywords": ["students", "monitoring", "health", "research"]}, {"paragraph_vector": [146.321334, -48.630947], "paragraph_keywords": ["data", "phenotyping", "use", "monitoring"]}, {"paragraph_vector": [153.696395, -52.151508], "paragraph_keywords": ["data", "self", "collected", "table"]}, {"paragraph_vector": [142.096984, -47.352249], "paragraph_keywords": ["students", "tracking", "data", "research"]}, {"paragraph_vector": [128.375381, -49.820743], "paragraph_keywords": ["acceptability", "phenotyping", "perspective", "term"]}, {"paragraph_vector": [152.673629, -50.272251], "paragraph_keywords": ["study", "students", "work", "health"]}, {"paragraph_vector": [143.691986, -54.242824], "paragraph_keywords": ["data", "discussed", "people", "table"]}, {"paragraph_vector": [178.663803, -64.314453], "paragraph_keywords": ["data", "themes", "analysis", "app"]}, {"paragraph_vector": [136.924057, -52.710849], "paragraph_keywords": ["health", "university", "value", "opinions"]}, {"paragraph_vector": [137.0811, -50.800228], "paragraph_keywords": ["technology", "health", "research", "problems"]}, {"paragraph_vector": [138.989685, -49.005352], "paragraph_keywords": ["health", "feel", "participants", "university"]}, {"paragraph_vector": [132.432189, -51.833889], "paragraph_keywords": ["data", "student", "information", "university"]}, {"paragraph_vector": [146.900299, -50.71923], "paragraph_keywords": ["participants", "data", "health", "questions"]}, {"paragraph_vector": [133.493087, -52.880691], "paragraph_keywords": ["students", "acceptability", "data", "participants"]}, {"paragraph_vector": [137.718719, -51.470417], "paragraph_keywords": ["data", "concerns", "phenotyping", "students"]}, {"paragraph_vector": [139.893234, -51.023403], "paragraph_keywords": ["students", "phenotyping", "participants", "health"]}, {"paragraph_vector": [115.440765, 19.978067], "paragraph_keywords": ["challenge", "time", "determination", "analytics"]}], "content": {}, "doi": "10.1145/3290605.3300295"}, {"uri": "155", "title": "Effects of Local Latency on Game Pointing Devices and Game Pointing Tasks", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Michael Long", "Carl Gutwin"], "summary": "Studies have shown certain game tasks such as targeting to be negatively and significantly affected by latencies as low as 41ms. Therefore it is important to understand the relationship between local latency \u2013 delays between an input action and resulting change in the display \u2013 and common gaming tasks such as targeting and tracking. In addition, games now use a variety of input devices, including touchscreens, mice, tablets and controllers. These devices provide very different combinations of direct/indirect input, absolute/relativemovement, and position/rate control, and are likely to be affected by latency in different ways. We performed a study evaluating and comparing the effects of latency across four devices (touchscreen, mouse, controller and drawing tablet) on targeting and interception tasks. We analyze both throughput and path characteristics, identify differences between devices, and provide design considerations for game designers.", "keywords": ["tablet", "direction", "controller", "time", "performance", "cursor", "touchscreen", "pointing", "touch", "path", "user", "movement", "participant", "drawing", "screen", "effect", "moving", "found", "task", "device", "lag", "game", "study", "target", "interception", "input", "mouse", "axis", "latency", "ip"], "document_vector": [-64.657546, -53.488021], "paragraphs": [{"paragraph_vector": [-29.496053, 10.71118], "paragraph_keywords": ["games", "latency", "input", "targeting"]}, {"paragraph_vector": [-28.466691, 9.717633], "paragraph_keywords": ["devices", "input", "characteristics", "latency"]}, {"paragraph_vector": [-28.820697, 10.507804], "paragraph_keywords": ["latency", "drawing", "network", "avatar"]}, {"paragraph_vector": [-26.279708, 10.278555], "paragraph_keywords": ["latency", "task", "pointing", "path"]}, {"paragraph_vector": [-28.08443, 19.33521], "paragraph_keywords": ["cursor", "task", "movement", "axis"]}, {"paragraph_vector": [-29.363893, 8.413598], "paragraph_keywords": ["tablets", "latency", "performance", "mouse"]}, {"paragraph_vector": [-29.325162, 9.676712], "paragraph_keywords": ["mouse", "latency", "week", "devices"]}, {"paragraph_vector": [-29.824794, 8.125678], "paragraph_keywords": ["latency", "target", "participants", "screen"]}, {"paragraph_vector": [-28.106058, 15.257132], "paragraph_keywords": ["latency", "target", "device", "performance"]}, {"paragraph_vector": [-28.258394, 11.23369], "paragraph_keywords": ["latency", "path", "direction", "p"]}, {"paragraph_vector": [-29.475294, 18.012222], "paragraph_keywords": ["latency", "tablet", "direction", "increased"]}, {"paragraph_vector": [-28.674795, 11.308911], "paragraph_keywords": ["target", "controller", "r", "latency"]}, {"paragraph_vector": [-26.842369, 11.460405], "paragraph_keywords": ["latency", "target", "ip", "performance"]}, {"paragraph_vector": [-24.499124, 14.051419], "paragraph_keywords": ["latency", "target", "participants", "performance"]}, {"paragraph_vector": [-27.417852, 11.372623], "paragraph_keywords": ["performance", "path", "touchscreen", "tablet"]}, {"paragraph_vector": [-27.02917, 12.375186], "paragraph_keywords": ["target", "tasks", "movement", "touchscreen"]}, {"paragraph_vector": [-29.401227, 8.985497], "paragraph_keywords": ["users", "input", "task", "latency"]}, {"paragraph_vector": [-29.997011, 10.450491], "paragraph_keywords": ["latency", "devices", "touchscreen", "pointing"]}], "content": {}, "doi": "10.1145/3290605.3300915"}, {"uri": "156", "title": "Tracking the Consumption of Home Essentials", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Carolina Fuentes", "Martin Porcheron", "Joel E. Fischer", "Obaid Malik", "Sarvapali D. Ramchurn"], "summary": "Predictions of people\u2019s behaviour increasingly drive interactions with a new generation of IoT services designed to support everyday life in the home, from shopping to heating. Based on the premise that such automation is difficult due to the contingent nature of people\u2019s practices, in this work we explore the nature of these contingencies in depth. We have designed and conducted a technology probe that made use of simple linear predictions as a provocation, and invited people to track the life of their household essentials over a two-month period. Through a mixed-method approach we demonstrate the challenges of simple predictions, and in turn identify eight categories of contingencies that influenced prediction accuracy. We discuss strategies for how designers of future predictive IoT systems may take the contingencies into account by removing, hiding, revealing, managing, or exploiting the system uncertainty at the core of the issue.", "keywords": ["stock", "based", "food", "time", "consumption", "change", "brand", "location", "design", "home", "example", "uncertainty", "accuracy", "user", "engagement", "shopping", "scan", "work", "product", "use", "participant", "people", "list", "challenge", "contingency", "factor", "page", "iot", "household", "number", "experience", "found", "including", "feedback", "variety", "probe", "item", "data", "technology", "study", "approach", "designer", "prediction", "system", "statement", "asked", "paper", "equivalency"], "document_vector": [71.738876, 55.529903], "paragraphs": [{"paragraph_vector": [83.417915, -59.448707], "paragraph_keywords": ["copies", "shopping", "computing", "acm"]}, {"paragraph_vector": [34.179573, -28.291549], "paragraph_keywords": ["consumption", "address", "household", "internet"]}, {"paragraph_vector": [36.70914, -28.707822], "paragraph_keywords": ["home", "system", "systems", "users"]}, {"paragraph_vector": [32.739223, -28.829933], "paragraph_keywords": ["food", "shopping", "data", "al"]}, {"paragraph_vector": [35.910102, -27.95911], "paragraph_keywords": ["data", "work", "probe", "food"]}, {"paragraph_vector": [34.838409, -26.955591], "paragraph_keywords": ["items", "item", "product", "probe"]}, {"paragraph_vector": [32.026611, -27.155946], "paragraph_keywords": ["items", "products", "feedback", "predictions"]}, {"paragraph_vector": [31.155046, -26.083162], "paragraph_keywords": ["list", "items", "participants", "shopping"]}, {"paragraph_vector": [29.749645, -27.265298], "paragraph_keywords": ["probe", "use", "feedback", "shopping"]}, {"paragraph_vector": [31.534349, -26.102027], "paragraph_keywords": ["shopping", "use", "items", "household"]}, {"paragraph_vector": [31.142234, -27.65537], "paragraph_keywords": ["items", "probe", "number", "participants"]}, {"paragraph_vector": [30.507814, -27.209564], "paragraph_keywords": ["items", "list", "probe", "predictions"]}, {"paragraph_vector": [27.648948, -30.213354], "paragraph_keywords": ["household", "error", "consumption", "probe"]}, {"paragraph_vector": [29.819395, -26.040616], "paragraph_keywords": ["items", "data", "accuracy", "cycles"]}, {"paragraph_vector": [30.959224, -28.25455], "paragraph_keywords": ["use", "changes", "day", "work"]}, {"paragraph_vector": [29.902368, -24.326177], "paragraph_keywords": ["products", "items", "people", "product"]}, {"paragraph_vector": [24.280042, -18.589229], "paragraph_keywords": ["items", "products", "grapes", "use"]}, {"paragraph_vector": [27.248321, -22.42851], "paragraph_keywords": ["shop", "offers", "brand", "bought"]}, {"paragraph_vector": [33.154869, -26.602825], "paragraph_keywords": ["product", "consumption", "variability", "predictions"]}, {"paragraph_vector": [36.485748, -24.776191], "paragraph_keywords": ["uncertainty", "design", "system", "strategies"]}, {"paragraph_vector": [71.875183, 39.621093], "paragraph_keywords": ["system", "uncertainty", "work", "home"]}, {"paragraph_vector": [71.920722, 33.690505], "paragraph_keywords": ["items", "system", "experience", "user"]}, {"paragraph_vector": [31.688171, -27.662235], "paragraph_keywords": ["use", "probe", "engagement", "accuracy"]}, {"paragraph_vector": [34.681976, -26.944868], "paragraph_keywords": ["product", "uncertainty", "contingencies", "research"]}], "content": {}, "doi": "10.1145/3290605.3300482"}, {"uri": "157", "title": "Methodological Gaps in PredictingMental Health States from Social Media: Triangulating Diagnostic Signals", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Sindhu Kiranmai Ernala", "Michael L. Birnbaum", "Kristin A. Candan", "Asra F. Rizvi", "William A. Sterling"], "summary": "A growing body of research is combining social media data with machine learning to predict mental health states of individuals. An implication of this research lies in informing evidence-based diagnosis and treatment. However, obtaining clinically valid diagnostic information from sensitive patient populations is challenging. Consequently, researchers have operationalized characteristic online behaviors as \u201cproxy diagnostic signals\u201d for building these models. This paper posits a challenge in using these diagnostic signals, purported to support clinical decision-making. Focusing on three commonly used proxy diagnostic signals derived from social media, we find that predictive models built on these data, although offer strong internal validity, suffer from poor external validity whentestedonmentalhealthpatients.Adeeperdivereveals issues of population and sampling bias, aswell as of uncertainty in construct validity inherent in these proxies. We discuss the methodological and clinical implications of these gaps and provide remedial guidelines for future research.", "keywords": ["gap", "based", "clinician", "facebook", "population", "information", "body", "collected", "performance", "self", "class", "illness", "validity", "feature", "provide", "medium", "model", "datasets", "sample", "work", "affiliation", "use", "patient", "construct", "issue", "post", "treatment", "health", "learning", "classifier", "control", "state", "page", "dataset", "content", "schizophrenia", "diagnosis", "effort", "validated", "signal", "data", "researcher", "approach", "twitter", "support", "research", "proxy", "bias", "individual", "paper", "report", "behavior", "validation", "appraised"], "document_vector": [-82.496658, 53.326045], "paragraphs": [{"paragraph_vector": [65.924644, -15.711887], "paragraph_keywords": ["media", "data", "copies", "work"]}, {"paragraph_vector": [66.873733, -16.790874], "paragraph_keywords": ["signals", "media", "data", "health"]}, {"paragraph_vector": [63.758075, -15.180941], "paragraph_keywords": ["signals", "validity", "schizophrenia", "data"]}, {"paragraph_vector": [68.334312, -17.453123], "paragraph_keywords": ["health", "signals", "data", "media"]}, {"paragraph_vector": [63.723022, -15.637895], "paragraph_keywords": ["signals", "health", "media", "data"]}, {"paragraph_vector": [69.116264, -17.306047], "paragraph_keywords": ["self", "health", "schizophrenia", "approaches"]}, {"paragraph_vector": [66.377082, -16.291545], "paragraph_keywords": ["signals", "data", "validity", "datasets"]}, {"paragraph_vector": [68.124084, -16.648675], "paragraph_keywords": ["data", "schizophrenia", "self", "twitter"]}, {"paragraph_vector": [67.374763, -16.217054], "paragraph_keywords": ["self", "report", "twitter", "control"]}, {"paragraph_vector": [66.035537, -14.730169], "paragraph_keywords": ["controls", "facebook", "data", "based"]}, {"paragraph_vector": [63.146301, -19.307151], "paragraph_keywords": ["data", "facebook", "twitter", "sources"]}, {"paragraph_vector": [68.047348, -13.080609], "paragraph_keywords": ["data", "schizophrenia", "datasets", "class"]}, {"paragraph_vector": [67.917243, -14.968045], "paragraph_keywords": ["model", "features", "performance", "validation"]}, {"paragraph_vector": [67.518463, -15.107415], "paragraph_keywords": ["self", "model", "accuracy", "report"]}, {"paragraph_vector": [68.070518, -15.889601], "paragraph_keywords": ["performance", "model", "validity", "classifier"]}, {"paragraph_vector": [67.493522, -14.484412], "paragraph_keywords": ["model", "performance", "proxy", "classifiers"]}, {"paragraph_vector": [67.117401, -16.442472], "paragraph_keywords": ["schizophrenia", "health", "example", "\u03b2"]}, {"paragraph_vector": [66.423904, -14.986759], "paragraph_keywords": ["data", "analysis", "schizophrenia", "shift"]}, {"paragraph_vector": [67.067451, -15.15244], "paragraph_keywords": ["features", "help", "model", "self"]}, {"paragraph_vector": [67.806716, -16.774229], "paragraph_keywords": ["model", "signals", "support", "class"]}, {"paragraph_vector": [66.683593, -16.917232], "paragraph_keywords": ["health", "information", "schizophrenia", "illness"]}, {"paragraph_vector": [66.281539, -14.940361], "paragraph_keywords": ["signals", "information", "frameworks", "media"]}, {"paragraph_vector": [65.824165, -17.06031], "paragraph_keywords": ["signals", "illness", "media", "patients"]}, {"paragraph_vector": [65.247894, -16.935577], "paragraph_keywords": ["treatment", "validity", "patients", "clinicians"]}, {"paragraph_vector": [64.180564, -16.293067], "paragraph_keywords": ["data", "populations", "models", "efforts"]}, {"paragraph_vector": [64.763839, -17.751192], "paragraph_keywords": ["data", "patients", "research", "thepredictivemodels"]}, {"paragraph_vector": [65.601745, -16.362915], "paragraph_keywords": ["signals", "paper", "media", "health"]}, {"paragraph_vector": [66.363693, -16.630609], "paragraph_keywords": ["data", "health", "research", "effort"]}], "content": {}, "doi": "10.1145/3290605.3300269"}, {"uri": "158", "title": "Career Mentoring in Online Communities: Seeking and Receiving Advice from an Online Community", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Maria Tomprou", "Laura Dabbish", "Robert E. Kraut", "Fannie Liu"], "summary": "Although people frequently seek mentoring or advice for their career, most mentoring is performed in person. Little research has examined the nature and quality of career mentoring online. To address this gap, we study how people use online Q&A forums for career advice. We develop a taxonomy of career advice requests based on a qualitative analysis of posts in a career-related online forum, identifying three key types: best practices, career threats, and time-sensitive requests. Our quantitative analysis of responses shows that both requesters and external viewers value general information, encouragement, and guidance, but not role modeling. We found no relation between the type of requests and features of responses, nor differences in responses valued by requesters versus external viewers. We present design recommendations for supporting online career advice exchange.", "keywords": ["career", "mentoring", "time", "information", "mentor", "development", "requester", "relationship", "help", "example", "mentorship", "type", "user", "interaction", "advice", "work", "forum", "people", "post", "workplace", "working", "page", "seek", "function", "guidance", "item", "data", "extent", "study", "role", "support", "system", "research", "request", "taxonomy", "question", "paper", "seeking", "value", "community", "response"], "document_vector": [-81.69136, 42.693275], "paragraphs": [{"paragraph_vector": [123.959938, 9.137114], "paragraph_keywords": ["mentoring", "career", "copies", "work"]}, {"paragraph_vector": [122.373382, 9.481738], "paragraph_keywords": ["career", "mentoring", "support", "advice"]}, {"paragraph_vector": [124.338073, 8.504384], "paragraph_keywords": ["career", "mentoring", "advice", "research"]}, {"paragraph_vector": [124.16027, 9.944948], "paragraph_keywords": ["mentoring", "career", "forums", "communities"]}, {"paragraph_vector": [122.032119, 7.787904], "paragraph_keywords": ["career", "mentoring", "support", "people"]}, {"paragraph_vector": [121.337066, 9.75162], "paragraph_keywords": ["advice", "mentoring", "career", "support"]}, {"paragraph_vector": [123.857337, 8.470883], "paragraph_keywords": ["career", "questions", "workplace", "advice"]}, {"paragraph_vector": [122.881042, 9.660457], "paragraph_keywords": ["posts", "workplace", "stackexchange", "data"]}, {"paragraph_vector": [105.405059, -32.067054], "paragraph_keywords": ["posts", "data", "process", "themes"]}, {"paragraph_vector": [112.463073, 3.654031], "paragraph_keywords": ["career", "advice", "posts", "time"]}, {"paragraph_vector": [121.051483, 7.82435], "paragraph_keywords": ["career", "time", "advice", "seek"]}, {"paragraph_vector": [119.626663, 9.305909], "paragraph_keywords": ["functions", "responses", "workers", "support"]}, {"paragraph_vector": [120.249794, 8.233717], "paragraph_keywords": ["support", "items", "survey", "extent"]}, {"paragraph_vector": [119.636566, 8.010978], "paragraph_keywords": ["response", "value", "request", "items"]}, {"paragraph_vector": [115.999526, 11.152295], "paragraph_keywords": ["response", "judgments", "responses", "value"]}, {"paragraph_vector": [122.643081, 9.460059], "paragraph_keywords": ["career", "advice", "functions", "requests"]}, {"paragraph_vector": [121.824958, 10.17292], "paragraph_keywords": ["mentoring", "career", "support", "advice"]}, {"paragraph_vector": [121.899162, 9.748006], "paragraph_keywords": ["responses", "career", "support", "advice"]}, {"paragraph_vector": [119.421348, 10.742094], "paragraph_keywords": ["response", "advice", "career", "responses"]}], "content": {}, "doi": "10.1145/3290605.3300447"}, {"uri": "159", "title": "Facilitating Self-reflection about Values and Self-care among Individuals with Chronic Conditions", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Catherine Y. Lim", "Andrew B.L. Berry", "Andrea L. Hartzler", "David S. Carrell", "Zo\u00eb A. Bermet", "James D. Ralston"], "summary": "Individuals with multiple chronic conditions (MCC) experience the overwhelming burden of treating MCC and frequently disagree with their providers on priorities for care. Aligning self-care with patients\u2019 values may improve healthcare for these patients. However, patients\u2019 values are not routinely discussed in clinical conversations and patients may not actively share this information with providers. In a qualitative field study, we interviewed 15 patients in their homes to investigate techniques that encourage patients to articulate values, self-care, and how they relate. Study activities facilitated self-reflection on values and self-care and produced varying responses, including: raising consciousness, evolving perspectives, identifying misalignments, and considering changes. We discuss how our findings extend prior work on supporting reflection in HCI and inform the design of tools for improving care for people with MCC.", "keywords": ["importance", "reflection", "condition", "change", "need", "connection", "self", "home", "care", "technique", "interview", "relationship", "help", "thought", "activity", "work", "tool", "participant", "patient", "card", "people", "treatment", "health", "think", "theme", "worksheet", "finding", "page", "found", "visit", "life", "family", "described", "study", "support", "provider", "perspective", "asked", "paper", "healthcare", "index", "value", "making"], "document_vector": [-38.134033, 89.054016], "paragraphs": [{"paragraph_vector": [154.6035, -30.095315], "paragraph_keywords": ["work", "care", "values", "self"]}, {"paragraph_vector": [159.476974, -22.29545], "paragraph_keywords": ["values", "patients", "care", "self"]}, {"paragraph_vector": [158.488021, -22.646242], "paragraph_keywords": ["work", "patients", "values", "providers"]}, {"paragraph_vector": [158.842712, -22.116533], "paragraph_keywords": ["reflection", "informatics", "work", "self"]}, {"paragraph_vector": [156.848419, -26.774147], "paragraph_keywords": ["patients", "participants", "conditions", "worksheet"]}, {"paragraph_vector": [158.956924, -30.618186], "paragraph_keywords": ["worksheet", "patients", "care", "self"]}, {"paragraph_vector": [159.196105, -27.460519], "paragraph_keywords": ["cards", "patients", "photo", "visit"]}, {"paragraph_vector": [139.601425, -33.592582], "paragraph_keywords": ["cards", "patient", "activity", "asked"]}, {"paragraph_vector": [139.530319, -34.476524], "paragraph_keywords": ["themes", "self", "care", "values"]}, {"paragraph_vector": [159.83818, -31.089641], "paragraph_keywords": ["cards", "value", "connections", "patients"]}, {"paragraph_vector": [158.128051, -27.019309], "paragraph_keywords": ["think", "values", "self", "care"]}, {"paragraph_vector": [166.661544, -32.498401], "paragraph_keywords": ["self", "think", "care", "values"]}, {"paragraph_vector": [159.034957, -32.094745], "paragraph_keywords": ["values", "self", "care", "value"]}, {"paragraph_vector": [157.729034, -36.633354], "paragraph_keywords": ["importance", "ratings", "think", "value"]}, {"paragraph_vector": [160.181991, -27.637168], "paragraph_keywords": ["telling", "misalignments", "described", "values"]}, {"paragraph_vector": [159.69786, -27.323867], "paragraph_keywords": ["family", "tv", "values", "value"]}, {"paragraph_vector": [-172.45758, -31.305353], "paragraph_keywords": ["activity", "need", "kept", "activities"]}, {"paragraph_vector": [171.178466, -33.166435], "paragraph_keywords": ["self", "care", "cards", "retirement"]}, {"paragraph_vector": [157.57376, -21.424928], "paragraph_keywords": ["reflection", "findings", "values", "work"]}, {"paragraph_vector": [155.714019, -27.80319], "paragraph_keywords": ["values", "reflection", "tools", "self"]}, {"paragraph_vector": [159.421188, -24.069334], "paragraph_keywords": ["reflection", "values", "people", "help"]}, {"paragraph_vector": [156.948684, -27.68873], "paragraph_keywords": ["patients", "reflection", "care", "cgs"]}, {"paragraph_vector": [159.037139, -24.099893], "paragraph_keywords": ["reflection", "institutes", "authors", "research"]}], "content": {}, "doi": "10.1145/3290605.3300481"}, {"uri": "160", "title": "Managing Multimorbidity: Identifying Design Requirements for a Digital Self-Management Tool to Support Older Adults with Multiple Chronic Conditions", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Julie Doyle"], "summary": "Older adults with multiple chronic conditions (multimorbidity) face complex self-management routines, including symptom monitoring, managing multiple medications, coordinating healthcare visits, communicating with multiple healthcare providers and processing and managing potentially conflicting advice on conditions. While much research exists on single disease management, little, if any research has explored the topic of technology to support those with multimorbidity, particularly older adults, to self-manage with support from a care network. This paper describes a large qualitative study with 125 participants, including older adults with multimorbidity and those who care for them, across two European countries. Key findings related to the: impact of multimorbidity, complexities involved in self-management, motivators and barriers to self-management, sources of support and poor communication as a barrier to care coordination. We present important concepts and design features for a digital health system that aim to address requirements derived from this study. CCS CONCEPTS \u2022 Human Centred Computing \u2192 Human Computer Interaction; Empirical Studies in HCI.", "keywords": ["pwms", "condition", "time", "need", "hcps", "information", "person", "managing", "self", "appointment", "multimorbidity", "design", "ireland", "care", "ic", "home", "reported", "disease", "example", "help", "noted", "goal", "having", "selfmanagement", "activity", "belgium", "communication", "pwm", "work", "management", "patient", "people", "issue", "treatment", "health", "challenge", "lack", "finding", "page", "understanding", "including", "identified", "monitoring", "-", "burden", "providing", "data", "manage", "symptom", "setting", "support", "research", "paper", "diabetes", "medication"], "document_vector": [74.779426, 84.8414], "paragraphs": [{"paragraph_vector": [174.699569, -15.698445], "paragraph_keywords": ["management", "conditions", "self", "people"]}, {"paragraph_vector": [167.483016, -19.900941], "paragraph_keywords": ["solutions", "pwms", "support", "technology"]}, {"paragraph_vector": [169.817565, -20.248325], "paragraph_keywords": ["care", "data", "people", "support"]}, {"paragraph_vector": [172.545059, -19.958732], "paragraph_keywords": ["people", "patients", "disease", "time"]}, {"paragraph_vector": [170.607376, -17.2509], "paragraph_keywords": ["health", "programmes", "need", "applications"]}, {"paragraph_vector": [167.95874, -15.667737], "paragraph_keywords": ["health", "hcps", "patients", "multimorbidity"]}, {"paragraph_vector": [172.019897, -18.99357], "paragraph_keywords": ["design", "groups", "focus", "recruited"]}, {"paragraph_vector": [142.195022, -34.705745], "paragraph_keywords": ["themes", "ireland", "belgium", "multimorbidity"]}, {"paragraph_vector": [178.148071, -32.788608], "paragraph_keywords": ["years", "burden", "heart", "changes"]}, {"paragraph_vector": [171.222488, -23.758041], "paragraph_keywords": ["time", "care", "medications", "pwm"]}, {"paragraph_vector": [170.003753, -26.355646], "paragraph_keywords": ["care", "pwms", "day", "medications"]}, {"paragraph_vector": [163.065597, -3.984312], "paragraph_keywords": ["appointments", "pwms", "reported", "importance"]}, {"paragraph_vector": [169.437423, -21.777181], "paragraph_keywords": ["increased", "devices", "home", "monitored"]}, {"paragraph_vector": [175.706466, -23.130899], "paragraph_keywords": ["self", "conditions", "pwms", "management"]}, {"paragraph_vector": [-179.16365, -26.875499], "paragraph_keywords": ["weight", "lack", "mobility", "thresholds"]}, {"paragraph_vector": [169.388961, -19.075334], "paragraph_keywords": ["patients", "pwms", "noted", "pwm"]}, {"paragraph_vector": [169.017211, -17.645036], "paragraph_keywords": ["goals", "care", "pwms", "plan"]}, {"paragraph_vector": [168.24562, -24.264158], "paragraph_keywords": ["care", "support", "pwm", "health"]}, {"paragraph_vector": [162.670227, -13.37191], "paragraph_keywords": ["communication", "providing", "information", "management"]}, {"paragraph_vector": [160.932052, -10.031876], "paragraph_keywords": ["hospital", "communication", "carers", "medication"]}, {"paragraph_vector": [161.23262, -14.238764], "paragraph_keywords": ["information", "pwms", "hcps", "noted"]}, {"paragraph_vector": [169.32579, -17.57653], "paragraph_keywords": ["conditions", "management", "requirements", "example"]}, {"paragraph_vector": [171.073394, -18.979438], "paragraph_keywords": ["tasks", "conditions", "self", "activities"]}, {"paragraph_vector": [167.638793, -16.895233], "paragraph_keywords": ["information", "selfmanagement", "hcps", "help"]}, {"paragraph_vector": [176.187973, -24.08016], "paragraph_keywords": ["condition", "person", "management", "ensure"]}, {"paragraph_vector": [168.466293, -15.524295], "paragraph_keywords": ["support", "conditions", "scaffolding", "learning"]}, {"paragraph_vector": [168.742431, -17.626869], "paragraph_keywords": ["setting", "goals", "pwms", "findings"]}, {"paragraph_vector": [171.252731, -18.273033], "paragraph_keywords": ["support", "health", "care", "conditions"]}], "content": {}, "doi": "10.1145/3290605.3300609"}, {"uri": "161", "title": "Serpentine: A Reversibly Deformable Cord Sensor for Human Input", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Fereshteh Shahmiri", "Chaoyu Chen", "Yi-Cheng Wang", "Zhong Lin Wang"], "summary": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300775 ABSTRACT We introduce Serpentine, a self-powered sensor that is a reversibly deformable cord capable of sensing a variety of human input. The material properties and structural design of Serpentine allow it to be flexible, twistable, stretchable and squeezable, enabling a broad variety of expressive input modalities. The sensor operates using the principle of Triboelectric Nanogenerators (TENG), which allows it to sense mechanical deformation without an external power source. The affordances of the cord include six interactions\u2014 Pluck, Twirl, Stretch, Pinch, Wiggle and Twist. Serpentine demonstrates the ability to simultaneously recognize these inputs through a single physical interface. A 12-participant CHI 2019 Paper CHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK", "keywords": ["stretch", "based", "time", "set", "performance", "self", "wiggle", "design", "layer", "classification", "sensor", "power", "user", "accuracy", "interaction", "rubber", "copper", "participant", "use", "length", "nylon", "material", "energy", "contact", "computing", "twirl", "page", "charge", "gesture", "electrode", "pinch", "part", "form", "feedback", "cord", "parameter", "signal", "data", "study", "system", "skin", "prototype", "paper", "pluck", "twist", "silicone", "input", "window", "figure"], "document_vector": [64.130928, -51.922065], "paragraphs": [{"paragraph_vector": [-51.966236, 50.323818], "paragraph_keywords": ["computing", "signal", "based", "interactions"]}, {"paragraph_vector": [-53.048629, 50.003879], "paragraph_keywords": ["interfaces", "cord", "principles", "sensor"]}, {"paragraph_vector": [-51.0708, 51.1637], "paragraph_keywords": ["materials", "charge", "teng", "sensor"]}, {"paragraph_vector": [-48.848529, 52.58509], "paragraph_keywords": ["silicone", "rubber", "layer", "core"]}, {"paragraph_vector": [-51.935752, 54.607555], "paragraph_keywords": ["cord", "silicone", "skin", "field"]}, {"paragraph_vector": [-54.169864, 48.771713], "paragraph_keywords": ["parameters", "silicone", "mode", "concept"]}, {"paragraph_vector": [-51.294853, 51.672237], "paragraph_keywords": ["silicone", "rubber", "strength", "electrode"]}, {"paragraph_vector": [-62.96294, 17.786046], "paragraph_keywords": ["data", "window", "signal", "stream"]}, {"paragraph_vector": [-66.410156, 15.893078], "paragraph_keywords": ["signal", "energy", "window", "points"]}, {"paragraph_vector": [-68.354766, 10.71144], "paragraph_keywords": ["user", "controller", "switch", "music"]}, {"paragraph_vector": [-95.038017, 30.245668], "paragraph_keywords": ["users", "user", "study", "game"]}, {"paragraph_vector": [-64.575431, 22.916767], "paragraph_keywords": ["user", "system", "session", "interactions"]}, {"paragraph_vector": [-65.513153, 21.337413], "paragraph_keywords": ["system", "prototype", "participants", "user"]}, {"paragraph_vector": [-64.011634, 20.440635], "paragraph_keywords": ["user", "accuracy", "participants", "twist"]}, {"paragraph_vector": [-64.575042, 27.118354], "paragraph_keywords": ["interactions", "participants", "string", "feeling"]}, {"paragraph_vector": [-62.188941, 21.447708], "paragraph_keywords": ["interactions", "participants", "pluck", "gestures"]}, {"paragraph_vector": [-46.331928, 42.830673], "paragraph_keywords": ["signal", "communication", "sensor", "interactions"]}, {"paragraph_vector": [-63.353393, 43.17255], "paragraph_keywords": ["interactions", "gestures", "hands", "cord"]}, {"paragraph_vector": [-64.933441, 22.793502], "paragraph_keywords": ["interaction", "sensor", "signal", "gesture"]}, {"paragraph_vector": [-55.51971, 51.352966], "paragraph_keywords": ["sensor", "study", "length", "performance"]}, {"paragraph_vector": [-53.104789, 48.250171], "paragraph_keywords": ["interactions", "self", "user", "sensing"]}, {"paragraph_vector": [-58.649574, 20.045181], "paragraph_keywords": ["feedback", "thank", "way", "computing"]}], "content": {}, "doi": "10.1145/3290605.3300404"}, {"uri": "162", "title": "SwarmHaptics: Haptic Display with Swarm Robots", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Lawrence H. Kim", "Sean Follmer"], "summary": "This paper seeks to better understand the use of haptic feedback in abstract, ubiquitous robotic interfaces. We introduce and provide preliminary evaluations of SwarmHaptics, a new type of haptic display using a swarm of small, wheeled robots. These robots move on a fat surface and apply haptic patterns to the user\u2019s hand, arm, or any other accessible body parts. We explore the design space of SwarmHaptics including individual and collective robot parameters, and demonstrate example scenarios including remote social touch using the Zooids platform. To gain insights into human perception, we applied haptic patterns with varying number of robots, force type, frequency, and amplitude and obtained user\u2019s perception in terms of emotion, urgency, and Human-Robot Interaction metrics. In a separate elicitation study, users generated a set of haptic patterns for social touch. The results from the two studies help inform how users perceive and generate haptic patterns with SwarmHaptics.", "keywords": ["perceived", "arm", "need", "efect", "display", "force", "diferent", "provide", "touch", "user", "type", "interaction", "swarm", "result", "work", "space", "participant", "swarmhaptics", "use", "perception", "people", "cue", "valence", "contact", "forearm", "control", "number", "referent", "feedback", "stimulus", "amplitude", "motion", "robot", "parameter", "hand", "shown", "study", "instance", "urgency", "pattern", "paper", "frequency"], "document_vector": [96.310485, -60.143611], "paragraphs": [{"paragraph_vector": [-93.133445, -10.437323], "paragraph_keywords": ["robots", "swarm", "copies", "acm"]}, {"paragraph_vector": [-91.399223, -12.1338], "paragraph_keywords": ["robots", "touch", "force", "display"]}, {"paragraph_vector": [-92.402275, -10.315076], "paragraph_keywords": ["robots", "touch", "interaction", "robot"]}, {"paragraph_vector": [-92.099998, -10.482396], "paragraph_keywords": ["robots", "swarm", "interaction", "user"]}, {"paragraph_vector": [-92.625022, -9.411435], "paragraph_keywords": ["robot", "force", "touch", "frequency"]}, {"paragraph_vector": [-92.93415, -7.859177], "paragraph_keywords": ["robots", "robot", "efect", "location"]}, {"paragraph_vector": [-92.863761, -9.450558], "paragraph_keywords": ["robots", "users", "need", "forces"]}, {"paragraph_vector": [-92.56707, -8.863114], "paragraph_keywords": ["force", "robots", "user", "provide"]}, {"paragraph_vector": [-93.183822, -10.134876], "paragraph_keywords": ["robots", "paper", "users", "stimuli"]}, {"paragraph_vector": [-92.346755, -10.397804], "paragraph_keywords": ["robots", "force", "robot", "surface"]}, {"paragraph_vector": [-91.497695, -7.397791], "paragraph_keywords": ["robots", "number", "force", "participant"]}, {"paragraph_vector": [-93.507766, -6.492899], "paragraph_keywords": ["robots", "perception", "force", "amplitude"]}, {"paragraph_vector": [-91.798065, -10.652966], "paragraph_keywords": ["emotion", "perceived", "amplitude", "efect"]}, {"paragraph_vector": [-80.529006, -0.885316], "paragraph_keywords": ["participants", "arm", "robots", "p"]}, {"paragraph_vector": [-91.629714, -6.051395], "paragraph_keywords": ["force", "perceived", "efect", "frequency"]}, {"paragraph_vector": [-92.115646, -9.977221], "paragraph_keywords": ["robots", "results", "likeability", "urgency"]}, {"paragraph_vector": [-91.577239, -8.287963], "paragraph_keywords": ["participants", "touch", "patterns", "amplitude"]}, {"paragraph_vector": [-92.641181, -9.208448], "paragraph_keywords": ["robots", "torque", "control", "force"]}, {"paragraph_vector": [-91.003448, -10.147211], "paragraph_keywords": ["interactions", "clarity", "relied", "robots"]}, {"paragraph_vector": [-93.499916, -9.54403], "paragraph_keywords": ["robots", "robot", "referents", "participants"]}, {"paragraph_vector": [-91.115531, -9.250864], "paragraph_keywords": ["robots", "study", "values", "provide"]}, {"paragraph_vector": [-92.335464, -9.807327], "paragraph_keywords": ["robots", "provide", "display", "paper"]}], "content": {}, "doi": "10.1145/3290605.3300847"}, {"uri": "163", "title": "What is Mixed Reality?", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Maximilian Speicher", "Brian D. Hall", "Michael Nebeling"], "summary": "What is Mixed Reality (MR)? To revisit this question given the many recent developments, we conducted interviews with ten AR/VR experts from academia and industry, as well as a literature survey of 68 papers. We find that, while there are prominent examples, there is no universally agreed on, one-size-fits-all definition of MR. Rather, we identified six partially competing notions from the literature and experts\u2019 responses. We then started to isolate the different aspects of reality relevant forMR experiences, going beyond the primarily visual notions and extending to audio, motion, haptics, taste, and smell. We distill our findings into a conceptual framework with seven dimensions to characterize MR applications in terms of the number of environments, number of users, level of immersion, level of virtuality, degree of interaction, input, and output. Our goal with this paper is to support classification and discussion of MR applications\u2019 design and provide a better means to researchers to contextualize their work within the increasingly fragmented MR landscape.", "keywords": ["virtuality", "vr", "based", "mentioned", ".", "author", "source", "literature", "interview", "environment", "expert", "example", "user", "aspect", "review", "interaction", "work", "space", "use", "world", "sense", "acm", "interviewee", "working", "experience", "page", "definition", "according", "understanding", "motion", "mr", "framework", "reality", "ar", "notion", "research", "term", "continuum", "hci", "paper", "immersion", "input"], "document_vector": [144.587692, -29.195518], "paragraphs": [{"paragraph_vector": [-112.200225, 22.782711], "paragraph_keywords": ["reality", "mr", "ar", "copies"]}, {"paragraph_vector": [-107.73973, 24.474563], "paragraph_keywords": ["mr", "continuum", "paper", "understanding"]}, {"paragraph_vector": [-122.422126, 36.844264], "paragraph_keywords": ["mr", "working", "definition", "notions"]}, {"paragraph_vector": [-109.415473, 26.611129], "paragraph_keywords": ["mr", "reality", "literature", "notions"]}, {"paragraph_vector": [-107.197715, 23.257333], "paragraph_keywords": ["mr", "continuum", "reality", "displays"]}, {"paragraph_vector": [-96.145225, 14.087564], "paragraph_keywords": ["ar", "vr", "motion", "smell"]}, {"paragraph_vector": [-107.510253, 25.486265], "paragraph_keywords": ["mr", "ar", "vr", "examples"]}, {"paragraph_vector": [-109.022766, 26.252271], "paragraph_keywords": ["ar", "world", "registration", "glass"]}, {"paragraph_vector": [-109.131553, 23.571733], "paragraph_keywords": ["vr", "mentioned", "described", "head"]}, {"paragraph_vector": [-110.240043, 26.531858], "paragraph_keywords": ["mr", "ar", "example", "hololens"]}, {"paragraph_vector": [-105.938133, 24.895454], "paragraph_keywords": ["mr", "user", "music", "aspects"]}, {"paragraph_vector": [-105.447998, 25.107694], "paragraph_keywords": ["mr", "experts", ".", "environment"]}, {"paragraph_vector": [-111.347305, 27.035585], "paragraph_keywords": ["mr", "definitions", "devices", "vr"]}, {"paragraph_vector": [-112.435485, 24.159759], "paragraph_keywords": ["mr", "based", "ar", "experts"]}, {"paragraph_vector": [-111.56607, 23.027969], "paragraph_keywords": ["search", "mr", "reality", "term"]}, {"paragraph_vector": [82.741622, -1.310673], "paragraph_keywords": ["mr", "paper", "papers", "understanding"]}, {"paragraph_vector": [-108.808013, 27.150974], "paragraph_keywords": ["ar", "mr", "world", "definition"]}, {"paragraph_vector": [-105.778877, 27.547767], "paragraph_keywords": ["ar", "vr", "notion", "system"]}, {"paragraph_vector": [-108.272254, 27.241147], "paragraph_keywords": ["mr", "ar", "towers", "motion"]}, {"paragraph_vector": [-107.991744, 26.738595], "paragraph_keywords": ["reality", "mr", "aspects", "."]}, {"paragraph_vector": [-107.249214, 28.927139], "paragraph_keywords": ["mr", "notion", "papers", "referred"]}, {"paragraph_vector": [-176.808532, 17.089618], "paragraph_keywords": ["papers", "mr", "sources", "references"]}, {"paragraph_vector": [-121.687416, 34.494541], "paragraph_keywords": ["mr", "notions", "definition", "sources"]}, {"paragraph_vector": [-107.076118, 25.231239], "paragraph_keywords": ["mr", "user", "interaction", "content"]}, {"paragraph_vector": [-105.65776, 25.218261], "paragraph_keywords": ["mr", "output", "experiences", "environment"]}, {"paragraph_vector": [-106.915786, 23.534175], "paragraph_keywords": ["mr", "interaction", "level", "environments"]}, {"paragraph_vector": [-110.959327, 26.8686], "paragraph_keywords": ["mr", "notions", "framework", "based"]}, {"paragraph_vector": [133.448135, 47.10588], "paragraph_keywords": ["interviews", "mr", "time", "definitions"]}], "content": {}, "doi": "10.1145/3290605.3300364"}, {"uri": "164", "title": "Co-Design Beyond Words: \u2018Moments of Interaction\u2019 with Minimally-Verbal Children on the Autism Spectrum", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Cara Wilson"], "summary": "Existing co-design methods support verbal children on the autism spectrum in the design process, while their minimallyverbal peers are overlooked. We describe Co-Design Beyond Words (CDBW), an approach which merges existing codesign methods with practice-based methods from Speech and Language Therapy which are child-led and interestsbased. These emphasise the rich detail that can be conveyed in the moment, through recognising occurrences of, for example, Joint Attention, Turn Taking and Imitation. We worked in an autism-specific primary school over 20 weeks with ten children, aged 5 to 8. We co-designed a playful prototype, the TangiBall, using the three iterative phases of CDBW; the Foundation Phase (preparation for interaction), the Interaction Phase (designing-and-reflecting in the moment) and the Reflection Phase (reflection-on-action). We contribute a novel co-design approach and present moments of interaction, the micro instances in design in which minimallyverbal children on the spectrum can convey meaning beyond words, through their actions, interactions, and attentional foci. These moments of interaction provide design insight, shape design direction, and reveal unique strengths, interests, and abilities. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300251 CCS CONCEPTS \u2022Human-centered computing\u2192HCI design and evaluation methods.", "keywords": ["process", "reflection", "based", "suggest", "child", "need", "moment", "ability", "design", "method", "looking", "technique", "ro", "focus", "co", "example", "sticker", "bob", "autism", "activity", "button", "engagement", "interaction", "play", "communication", "work", "word", "language", "use", "sam", "people", "group", "interest", "way", "existing", "understanding", "understand", "-", "ann", "attention", "phase", "researcher", "approach", "chris", "support", "ball", "session", "spectrum", "prototype", "paper", "ja", "cdbw", "turn", "action", "context"], "document_vector": [126.507194, 22.308012], "paragraphs": [{"paragraph_vector": [-174.98381, -6.578003], "paragraph_keywords": ["design", "autism", "language", "child"]}, {"paragraph_vector": [-174.619873, -7.337617], "paragraph_keywords": ["existing", "design", "children", "methods"]}, {"paragraph_vector": [-173.308502, -8.518427], "paragraph_keywords": ["design", "children", "interaction", "autism"]}, {"paragraph_vector": [-173.795974, -8.840451], "paragraph_keywords": ["design", "children", "co", "approaches"]}, {"paragraph_vector": [-172.409973, -7.181185], "paragraph_keywords": ["design", "children", "-", "co"]}, {"paragraph_vector": [-175.977188, -5.495083], "paragraph_keywords": ["design", "children", "approach", "analysis"]}, {"paragraph_vector": [-172.260391, -5.902381], "paragraph_keywords": ["child", "interaction", "approaches", "interactions"]}, {"paragraph_vector": [-171.747528, -4.764901], "paragraph_keywords": ["child", "attention", "interaction", "children"]}, {"paragraph_vector": [-174.236022, -3.938297], "paragraph_keywords": ["child", "interests", "interaction", "observe"]}, {"paragraph_vector": [-174.354629, -8.170845], "paragraph_keywords": ["children", "work", "participants", "design"]}, {"paragraph_vector": [-166.57402, -10.403349], "paragraph_keywords": ["children", "ball", "design", "velcro"]}, {"paragraph_vector": [-173.940368, -6.529987], "paragraph_keywords": ["interaction", "approach", "design", "sessions"]}, {"paragraph_vector": [-173.952743, -7.423144], "paragraph_keywords": ["interaction", "child", "children", "researcher"]}, {"paragraph_vector": [-174.956787, -5.903357], "paragraph_keywords": ["interaction", "child", "attention", "-"]}, {"paragraph_vector": [-175.920944, -8.001225], "paragraph_keywords": ["child", "preferences", "interaction", "techniques"]}, {"paragraph_vector": [-174.683502, -5.89411], "paragraph_keywords": ["child", "action", "people", "listen"]}, {"paragraph_vector": [-176.911376, -3.676038], "paragraph_keywords": ["action", "child", "design", "reflection"]}, {"paragraph_vector": [-173.339294, -7.240696], "paragraph_keywords": ["design", "reflection", "interaction", "understanding"]}, {"paragraph_vector": [-170.412704, -5.229176], "paragraph_keywords": ["researcher", "bob", "ann", "words"]}, {"paragraph_vector": [-168.258636, -5.661794], "paragraph_keywords": ["ann", "ros", "bob", "ball"]}, {"paragraph_vector": [-168.841903, -7.414108], "paragraph_keywords": ["ball", "bob", "ann", "sticker"]}, {"paragraph_vector": [-170.405075, -4.457631], "paragraph_keywords": ["interaction", "children", "prototype", "words"]}, {"paragraph_vector": [-167.806823, -6.982761], "paragraph_keywords": ["sam", "ball", "ros", "chris"]}, {"paragraph_vector": [-168.163803, -7.306813], "paragraph_keywords": ["chris", "sam", "button", "ros"]}, {"paragraph_vector": [-168.683639, -6.951642], "paragraph_keywords": ["design", "button", "motor", "ball"]}, {"paragraph_vector": [-174.223709, -8.034795], "paragraph_keywords": ["design", "interaction", "moments", "attention"]}, {"paragraph_vector": [-173.720855, -9.198633], "paragraph_keywords": ["design", "children", "child", "interests"]}, {"paragraph_vector": [-174.865173, -7.450417], "paragraph_keywords": ["child", "design", "ways", "children"]}, {"paragraph_vector": [-172.347091, -8.13578], "paragraph_keywords": ["design", "needs", "prototype", "use"]}, {"paragraph_vector": [-172.272171, -7.730148], "paragraph_keywords": ["design", "children", "child", "changes"]}, {"paragraph_vector": [-169.438568, -6.569971], "paragraph_keywords": ["children", "interaction", "design", "support"]}, {"paragraph_vector": [-174.26686, -6.830516], "paragraph_keywords": ["child", "children", "researchers", "design"]}], "content": {}, "doi": "10.1145/3290605.3300724"}, {"uri": "165", "title": "City Explorer: The Design and Evaluation of a Location-Based Community Information System", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Carolyn Pang", "Rui Pan", "Carman Neustaedter", "Kate Hennessy"], "summary": "Many working professionals commute via public transit, yet they have limited tools for learning about their urban neighborhoods and fellow commuters. We designed a location-based game called City Explorer to investigate how transit commuters capture, share, and view community information that is specifically tied to locations. Through a four-week field study, we found that participants valued the increased awareness of their personal travel routines that they gained through City Explorer. When viewing community information, they preferred information that was factual rather than opinion-based and was presented at the start and end of their commutes. Participants found less value in connecting with other transit riders because transit rides were often seen as opportunities to disengage from others. We discuss how location-based technologies can be designed to display factual community information before, during, and at the end of transit commutes.", "keywords": ["explore", "based", "point", "time", "need", "information", "set", "player", "location", "design", "interview", "bus", "friend", "wanted", "example", "medium", "user", "activity", "news", "play", "sharing", "shared", "work", "participant", "use", "people", "explorer", "way", "challenge", "route", "neighborhood", "page", "existing", "content", "found", "including", "awareness", "described", "data", "played", "game", "study", "transit", "routine", "connect", "twitter", "research", "commuter", "paper", "week", "commute", "city", "community"], "document_vector": [138.138259, 29.47566], "paragraphs": [{"paragraph_vector": [-133.340896, -53.241596], "paragraph_keywords": ["people", "information", "community", "activities"]}, {"paragraph_vector": [-131.682495, -54.500034], "paragraph_keywords": ["community", "information", "transit", "city"]}, {"paragraph_vector": [-130.147201, -60.946063], "paragraph_keywords": ["community", "information", "people", "communities"]}, {"paragraph_vector": [45.464912, -73.806411], "paragraph_keywords": ["information", "people", "residents", "systems"]}, {"paragraph_vector": [-131.38533, -53.935478], "paragraph_keywords": ["location", "based", "sharing", "participation"]}, {"paragraph_vector": [-134.682266, -51.933448], "paragraph_keywords": ["players", "transit", "points", "game"]}, {"paragraph_vector": [-134.237854, -54.043453], "paragraph_keywords": ["players", "transit", "game", "range"]}, {"paragraph_vector": [-134.40895, -49.348682], "paragraph_keywords": ["player", "players", "challenge", "challenges"]}, {"paragraph_vector": [-132.846862, -51.134418], "paragraph_keywords": ["players", "hour", "game", "time"]}, {"paragraph_vector": [-136.70671, -54.515846], "paragraph_keywords": ["transit", "participants", "study", "data"]}, {"paragraph_vector": [-136.845153, -52.915279], "paragraph_keywords": ["participants", "transit", "city", "interviews"]}, {"paragraph_vector": [-133.199691, -51.575832], "paragraph_keywords": ["content", "city", "participants", "game"]}, {"paragraph_vector": [-142.880645, -51.46429], "paragraph_keywords": ["content", "twitter", "city", "explorer"]}, {"paragraph_vector": [-134.198608, -53.414268], "paragraph_keywords": ["game", "interviews", "commutes", "transit"]}, {"paragraph_vector": [-139.896789, -48.385375], "paragraph_keywords": ["information", "participants", "min", "played"]}, {"paragraph_vector": [-138.338806, -54.647033], "paragraph_keywords": ["game", "points", "players", "way"]}, {"paragraph_vector": [-146.90921, -45.229999], "paragraph_keywords": ["city", "time", "bus", "explorer"]}, {"paragraph_vector": [-132.74591, -54.038803], "paragraph_keywords": ["community", "information", "commutes", "commute"]}, {"paragraph_vector": [-130.777999, -59.209911], "paragraph_keywords": ["information", "participants", "shared", "interests"]}, {"paragraph_vector": [-131.243942, -57.700355], "paragraph_keywords": ["news", "participants", "filter", "content"]}, {"paragraph_vector": [-134.063293, -57.31195], "paragraph_keywords": ["activities", "work", "events", "transit"]}, {"paragraph_vector": [-134.332138, -52.026363], "paragraph_keywords": ["participants", "connecting", "city", "people"]}, {"paragraph_vector": [-87.362869, -65.361694], "paragraph_keywords": ["described", "brazil", "faces", "people"]}, {"paragraph_vector": [-145.493316, -61.764663], "paragraph_keywords": ["people", "self", "way", "information"]}, {"paragraph_vector": [-135.377487, -62.102287], "paragraph_keywords": ["information", "time", "people", "transit"]}, {"paragraph_vector": [-134.487274, -57.11853], "paragraph_keywords": ["information", "community", "transit", "people"]}, {"paragraph_vector": [-134.293685, -53.227611], "paragraph_keywords": ["transit", "people", "existing", "time"]}, {"paragraph_vector": [-131.538162, -53.463554], "paragraph_keywords": ["transit", "game", "city", "results"]}, {"paragraph_vector": [-140.228271, -64.89151], "paragraph_keywords": ["people", "community", "research", "information"]}], "content": {}, "doi": "10.1145/3290605.3300735"}, {"uri": "166", "title": "Augmenting Couples\u2019 Communication with Lifelines: Shared Timelines of Mixed Contextual Information", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Carla F. Griggio", "Joanna McGrenere", "Wendy E. Mackay"], "summary": "Couples exhibit special communication practices, but apps rarely offer couple-specific functionality. Research shows that sharing streams of contextual information (e.g. location, motion) helps couples coordinate and feel more connected. Most studies explored a single, ephemeral stream; we study how couples\u2019 communication changes when sharing multiple, persistent streams. We designed Lifelines, a mobile-app technology probe that visualizes up to six streams on a shared timeline: closeness to home, battery level, steps, media playing, texts and calls. A month-long study with nine couples showed that partners interpreted information mostly from individual streams, but also combined them for more nuanced interpretations. Persistent streams allowed missing data to become meaningful and provided new ways of understanding each other. Unexpected patterns from any stream can trigger calls and texts, whereas seeing expected data can replace direct communication, which may improve or disrupt established communication practices. We conclude with design implications for mediating awareness within couples.", "keywords": ["message", "time", "change", "information", "moment", "find", "phone", "location", "lifeline", "design", "app", "home", "interview", "battery", "sm", "partner", "playing", "help", "medium", "user", "communication", "sharing", "shared", "work", "apps", "show", "participant", "use", "concern", "step", "page", "felt", "look", "android", "hugo", "call", "awareness", "stream", "probe", "data", "technology", "study", "routine", "couple", "research", "paper", "week", "privacy", "share", "knowledge", "context", "figure"], "document_vector": [65.716186, 89.7332], "paragraphs": [{"paragraph_vector": [129.992385, -63.957839], "paragraph_keywords": ["couples", "apps", "copies", "computing"]}, {"paragraph_vector": [166.569442, -68.9188], "paragraph_keywords": ["communication", "information", "couples", "data"]}, {"paragraph_vector": [166.836074, -70.136062], "paragraph_keywords": ["couples", "communication", "relationships", "share"]}, {"paragraph_vector": [163.893463, -65.0316], "paragraph_keywords": ["information", "partners", "location", "music"]}, {"paragraph_vector": [164.816894, -66.417617], "paragraph_keywords": ["streams", "context", "data", "technology"]}, {"paragraph_vector": [175.084197, -67.898666], "paragraph_keywords": ["streams", "data", "help", "lifelines"]}, {"paragraph_vector": [171.033065, -71.594551], "paragraph_keywords": ["lifelines", "app", "users", "data"]}, {"paragraph_vector": [178.1958, -72.11853], "paragraph_keywords": ["lifelines", "phone", "android", "stated"]}, {"paragraph_vector": [160.636611, -70.29], "paragraph_keywords": ["lifeline", "lifelines", "data", "participants"]}, {"paragraph_vector": [163.742645, -69.210166], "paragraph_keywords": ["lifelines", "interview", "interviews", "week"]}, {"paragraph_vector": [129.485382, -40.507667], "paragraph_keywords": ["data", "streams", "information", "codes"]}, {"paragraph_vector": [164.092681, -67.743118], "paragraph_keywords": ["stream", "partner", "data", "meant"]}, {"paragraph_vector": [172.156646, -66.944473], "paragraph_keywords": ["home", "media", "partners", "lifeline"]}, {"paragraph_vector": [173.609237, -67.898735], "paragraph_keywords": ["communication", "hugo", "message", "home"]}, {"paragraph_vector": [160.496597, -66.186706], "paragraph_keywords": ["data", "participants", "perspective", "dancing"]}, {"paragraph_vector": [163.720291, -69.278839], "paragraph_keywords": ["phone", "data", "partner", "partners"]}, {"paragraph_vector": [-120.738578, 64.334281], "paragraph_keywords": ["participants", "design", "concerns", "partner"]}, {"paragraph_vector": [172.771591, -60.378448], "paragraph_keywords": ["felt", "media", "information", "home"]}, {"paragraph_vector": [145.115219, -69.384254], "paragraph_keywords": ["lifelines", "location", "barry", "participants"]}, {"paragraph_vector": [147.838912, -64.456268], "paragraph_keywords": ["data", "streams", "couples", "partners"]}, {"paragraph_vector": [164.007705, -67.526802], "paragraph_keywords": ["streams", "partners", "data", "lifelines"]}, {"paragraph_vector": [164.530792, -66.466316], "paragraph_keywords": ["streams", "data", "communication", "partners"]}, {"paragraph_vector": [71.599006, 34.497409], "paragraph_keywords": ["comments"]}], "content": {}, "doi": "10.1145/3290605.3300763"}, {"uri": "167", "title": "Gehna: Exploring the Design Space of Jewelry as an Input Modality", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jatin Arora", "Aryan Saini"], "summary": "Jewelry weaves into our everyday lives as no other wearable does. It comes in many wearable forms, is fashionable, and can adorn any part of the body. In this paper, through an exploratory, Research through Design (RtD) process, we tap into this vast potential space of input interaction that jewelry can enable. We do so by frst identifying a small set of fundamental structural elements \u2014 called Jewelements \u2014 that any jewelry is composed of, and then defning their properties that enable the interaction. We leverage this synthesis along with observational data and literature to formulate a Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proft or commercial advantage and that copies bear this notice and the full citation on the frst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specifc permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300751 design space of jewelry-enabled input techniques. This work encapsulates both the extensions of common existing input methods (e.g., touch) as well as new ones inspired by jewelry. Furthermore, we discuss our prototypical sensor-based implementations. Through this work, we invite the community to engage in the conversation on how jewelry as a material can help shape wearable-based input.", "keywords": ["cabochon", "manipulation", "based", "fnger", "set", "body", "design", "ring", "technique", "ear", "touch", "exploration", "interaction", "eforts", "length", "explored", "material", "pendant", "sense", "neck", "chain", "shape", "gesture", "bead", "worn", "ornament", "form", "observed", "plate", "element", "jewelry", "stone", "research", "enable", "input", "artifact", "necklace", "figure", "earring", "fgure"], "document_vector": [64.082794, -18.189903], "paragraphs": [{"paragraph_vector": [-65.540939, 36.753982], "paragraph_keywords": ["jewelry", "design", "computing", "input"]}, {"paragraph_vector": [-68.784477, 36.897979], "paragraph_keywords": ["jewelry", "design", "set", "based"]}, {"paragraph_vector": [-66.913146, 36.049571], "paragraph_keywords": ["jewelry", "based", "eforts", "design"]}, {"paragraph_vector": [-66.204704, 39.944381], "paragraph_keywords": ["touch", "input", "interaction", "skin"]}, {"paragraph_vector": [-69.122787, 36.657077], "paragraph_keywords": ["jewelry", "artifacts", "design", "set"]}, {"paragraph_vector": [-73.767387, 41.24578], "paragraph_keywords": ["chain", "jewelry", "drill", "bead"]}, {"paragraph_vector": [-67.096588, 38.135581], "paragraph_keywords": ["jewelry", "figure", "artifacts", "body"]}, {"paragraph_vector": [-66.38021, 36.068191], "paragraph_keywords": ["ear", "worn", "form", "jewelry"]}, {"paragraph_vector": [-68.951797, 39.020748], "paragraph_keywords": ["interactions", "jewelry", "set", "artifacts"]}, {"paragraph_vector": [-64.855087, 45.523994], "paragraph_keywords": ["touch", "cabochon", "plate", "necklace"]}, {"paragraph_vector": [-62.38908, 40.064388], "paragraph_keywords": ["shape", "interaction", "touch", "necklace"]}, {"paragraph_vector": [-63.641826, 44.828243], "paragraph_keywords": ["earring", "plate", "interaction", "figure"]}, {"paragraph_vector": [-62.444854, 45.583156], "paragraph_keywords": ["necklace", "jewelry", "touch", "fgure"]}, {"paragraph_vector": [-69.648468, 33.220409], "paragraph_keywords": ["earring", "necklace", "chain", "figure"]}, {"paragraph_vector": [-65.082366, 40.715946], "paragraph_keywords": ["chain", "action", "sense", "pendant"]}, {"paragraph_vector": [-70.645256, 38.256122], "paragraph_keywords": ["jewelry", "gestures", "figure", "neck"]}, {"paragraph_vector": [-68.545845, 38.160388], "paragraph_keywords": ["jewelry", "gestures", "design", "serve"]}, {"paragraph_vector": [-44.952098, 1.844227], "paragraph_keywords": ["input", "self", "having", "touch"]}, {"paragraph_vector": [-65.105667, 41.140117], "paragraph_keywords": ["jewelry", "enable", "connection", "fgure"]}], "content": {}, "doi": "10.1145/3290605.3300375"}, {"uri": "168", "title": "How Do One\u2019s Peers on a Leaderboard Affect Oneself?", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Weiwen Leung"], "summary": "Leaderboards are a workhorse of the gamification literature. While the effect of a leaderboard has been well studied, there is much less evidence how one\u2019s peer group affects the treatment effect of a leaderboard. Through a pre-registered field experiment involving more than 1000 users on an online movie recommender website, we expose users to leaderboards, but different sets of users are exposed to different peer groups. Contrary to what a standard behavioral model would predict, we find that a user\u2019s contribution increases when their peer\u2019s scores are more dispersed. We also find that decreasing average peer contributions motivates a user to contribute more. Moreover, these effects are themselves mediated by group size. This sheds new light on existing theories of motivation and demotivation with regards to leaderboards, and also illustrates the potential of using personalized leaderboards to increase contributions. ACM Reference Format: Weiwen Leung. 2019. How Do One\u2019s Peers on a Leaderboard Affect Oneself?. In CHI Conference on Human Factors in Computing Systems Proceedings (CHI 2019), May 4\u20139, 2019, Glasgow, Scotland Uk. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/ 3290605.3300397", "keywords": ["point", "deviation", "peer", "experiment", "gamification", "email", "example", "user", "model", "activity", "result", "work", "increased", "use", "participant", "people", "group", "increase", "effect", "given", "size", "mean", "rank", "page", "ranked", "found", "movie", "affect", "study", "variable", "contribution", "leaderboard", "paper", "week", "leaderboards", "affected"], "document_vector": [-82.203933, 36.660724], "paragraphs": [{"paragraph_vector": [73.968765, 1.668213], "paragraph_keywords": ["leaderboard", "work", "copies", "gamification"]}, {"paragraph_vector": [70.509956, 2.554451], "paragraph_keywords": ["group", "peers", "leaderboards", "users"]}, {"paragraph_vector": [69.923126, 2.025651], "paragraph_keywords": ["contributions", "group", "groups", "peer"]}, {"paragraph_vector": [73.658859, 3.054756], "paragraph_keywords": ["leaderboard", "leaderboards", "group", "scorers"]}, {"paragraph_vector": [72.485198, 2.333221], "paragraph_keywords": ["participants", "leaderboard", "studies", "app"]}, {"paragraph_vector": [71.374885, 3.417474], "paragraph_keywords": ["peer", "found", "studies", "rank"]}, {"paragraph_vector": [68.121452, 13.46366], "paragraph_keywords": ["group", "users", "movie", "found"]}, {"paragraph_vector": [70.315559, 2.143527], "paragraph_keywords": ["users", "given", "points", "leaderboard"]}, {"paragraph_vector": [70.884201, 4.573054], "paragraph_keywords": ["users", "email", "group", "groups"]}, {"paragraph_vector": [70.312118, 2.812633], "paragraph_keywords": ["period", "user", "contributions", "use"]}, {"paragraph_vector": [70.714447, 2.443188], "paragraph_keywords": ["group", "outliers", "mean", "changing"]}, {"paragraph_vector": [70.230133, 3.158029], "paragraph_keywords": ["rank", "based", "mood", "affected"]}, {"paragraph_vector": [68.779716, 3.214399], "paragraph_keywords": ["group", "mean", "rank", "contributions"]}, {"paragraph_vector": [71.797363, 2.640232], "paragraph_keywords": ["effect", "models", "group", "deviation"]}, {"paragraph_vector": [70.658752, 3.094385], "paragraph_keywords": ["group", "model", "models", "points"]}, {"paragraph_vector": [68.449882, 2.453522], "paragraph_keywords": ["results", "leaderboard", "points", "group"]}, {"paragraph_vector": [72.157135, 3.285993], "paragraph_keywords": ["email", "experiment", "tags", "users"]}, {"paragraph_vector": [70.590896, 3.55765], "paragraph_keywords": ["rank", "user", "group", "users"]}, {"paragraph_vector": [70.288406, 3.119841], "paragraph_keywords": ["group", "contributions", "rank", "coefficients"]}, {"paragraph_vector": [71.142829, 5.591334], "paragraph_keywords": ["group", "rank", "users", "groups"]}, {"paragraph_vector": [73.279731, 2.677969], "paragraph_keywords": ["group", "studies", "size", "results"]}, {"paragraph_vector": [69.925292, 2.709074], "paragraph_keywords": ["user", "leaderboard", "users", "variables"]}, {"paragraph_vector": [70.11573, 1.851686], "paragraph_keywords": ["users", "group", "friends", "country"]}], "content": {}, "doi": "10.1145/3290605.3300685"}, {"uri": "169", "title": "A System for Conducting Distributed End-User Elicitation and Identification Studies", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Abdullah X. Ali", "Jacob O. Wobbrock"], "summary": "End-user elicitation studies are a popular design method. Currently, such studies are usually confined to a lab, limiting the number and diversity of participants, and therefore the representativeness of their results. Furthermore, the quality of the results from such studies generally lacks any formal means of evaluation. In this paper, we address some of the limitations of elicitation studies through the creation of the Crowdlicit system along with the introduction of end-user identification studies, which are the reverse of elicitation studies. Crowdlicit is a new web-based system that enables researchers to conduct online and in-lab elicitation and identification studies. We used Crowdlicit to run a crowd-powered elicitation study based on Morris\u2019s \u201cWeb on the Wall\u201d study (2012) with 78 participants, arriving at a set of symbols that included six new symbols different from Morris\u2019s. We evaluated the effectiveness of 49 symbols (43 from Morris and six from Crowdlicit) by conducting a crowd-powered identification study. We show that the Crowdlicit elicitation study resulted in a set of symbols that was significantly more identifiable than Morris\u2019s.", "keywords": ["based", "agreement", "al", "crowdlicit", "set", "method", "collect", "morris", "user", "command", "interaction", "et", "symbol", "work", "result", "participant", "use", "voice", "page", "gesture", "referent", "survey", "proposed", "task", "crowd", "data", "researcher", "study", "lab", "elicitation", "system", "text", "identification", "research", "end", "paper", "interface", "option"], "document_vector": [-43.013053, 23.351297], "paragraphs": [{"paragraph_vector": [23.923563, 13.263132], "paragraph_keywords": ["studies", "interactions", "copies", "work"]}, {"paragraph_vector": [30.700723, 9.723841], "paragraph_keywords": ["studies", "participants", "study", "shown"]}, {"paragraph_vector": [25.944005, 11.864493], "paragraph_keywords": ["crowdlicit", "symbols", "study", "studies"]}, {"paragraph_vector": [28.954225, 14.564264], "paragraph_keywords": ["method", "user", "elicitation", "interactions"]}, {"paragraph_vector": [27.425865, 10.836268], "paragraph_keywords": ["elicitation", "work", "studies", "interactions"]}, {"paragraph_vector": [31.418569, 10.441094], "paragraph_keywords": ["elicitation", "end", "studies", "symbols"]}, {"paragraph_vector": [22.672216, 13.070076], "paragraph_keywords": ["referents", "referent", "elicitation", "studies"]}, {"paragraph_vector": [29.533067, 18.629835], "paragraph_keywords": ["study", "referent", "researchers", "system"]}, {"paragraph_vector": [25.551967, 11.899621], "paragraph_keywords": ["symbols", "collect", "add", "elicitation"]}, {"paragraph_vector": [31.338788, 11.877251], "paragraph_keywords": ["participants", "study", "page", "researchers"]}, {"paragraph_vector": [25.094629, 15.131088], "paragraph_keywords": ["symbol", "participants", "page", "input"]}, {"paragraph_vector": [33.756175, 9.528067], "paragraph_keywords": ["study", "participants", "crowdlicit", "studies"]}, {"paragraph_vector": [29.274003, 12.19786], "paragraph_keywords": ["participants", "study", "referent", "survey"]}, {"paragraph_vector": [17.054618, 12.949025], "paragraph_keywords": ["referents", "referent", "symbols", "symbol"]}, {"paragraph_vector": [28.221128, 12.894417], "paragraph_keywords": ["participants", "symbols", "study", "referents"]}, {"paragraph_vector": [40.127666, 8.234743], "paragraph_keywords": ["participants", "study", "studies", "crowdlicit"]}, {"paragraph_vector": [31.221801, 9.995977], "paragraph_keywords": ["spam", "answers", "work", "crowd"]}, {"paragraph_vector": [25.156579, 13.045017], "paragraph_keywords": ["agreement", "gestures", "voice", "set"]}, {"paragraph_vector": [29.350751, 9.248794], "paragraph_keywords": ["studies", "elicitation", "participants", "study"]}, {"paragraph_vector": [30.332721, 10.668546], "paragraph_keywords": ["studies", "elicitation", "work", "crowdlicit"]}], "content": {}, "doi": "10.1145/3290605.3300690"}, {"uri": "170", "title": "An Exploratory Study on Visual Exploration  of Model Simulations by Multiple Types of Experts", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Nadia Boukhelifa"], "summary": "Experts in different domains rely increasingly on simulation models of complex processes to reach insights, make decisions, and plan future projects. These models are often used to study possible trade-offs, as experts try to optimise multiple conflicting objectives in a single investigation. Understanding all the model intricacies, however, is challenging for a single domain expert. We propose a simple approach to support multiple experts when exploring complex model results. First, we reduce the model exploration space, then present the results on a shared interactive surface, in the form of a scatterplot matrix and linked views. To explore how multiple experts analyse trade-offs using this setup, we carried out an observational study focusing on the link between expertise and insight generation during the analysis process. Our results reveal the different exploration strategies and multi-storyline approaches that domain experts adopt Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300874 during trade-off analysis, and inform our recommendations for collaborative model exploration systems.", "keywords": ["process", "explore", "based", "point", "strategy", "time", "dimension", "refine", "analysis", "trade", "expert", "criterion", "simulation", "help", "storytelling", "exploration", "model", "type", "expertise", "result", "work", "scenario", "tool", "participant", "use", "space", "insight", "domain", "related", "visualization", "finding", "page", "-", "case", "search", "data", "study", "wheat", "approach", "event", "research", "term", "objective", "question", "paper", "reached", "optimisation", "knowledge"], "document_vector": [-133.920928, -6.757221], "paragraphs": [{"paragraph_vector": [-23.879636, 85.747276], "paragraph_keywords": ["experts", "wheat", "models", "domain"]}, {"paragraph_vector": [-0.499135, 86.710929], "paragraph_keywords": ["domain", "experts", "model", "understand"]}, {"paragraph_vector": [-20.97956, 88.324813], "paragraph_keywords": ["expertise", "model", "study", "work"]}, {"paragraph_vector": [132.065261, 87.890464], "paragraph_keywords": ["insight", "model", "describe", "knowledge"]}, {"paragraph_vector": [-54.569828, 89.521186], "paragraph_keywords": ["model", "exploration", "experts", "problem"]}, {"paragraph_vector": [-13.264964, 87.961624], "paragraph_keywords": ["visualization", "decision", "thousands", "technique"]}, {"paragraph_vector": [-41.500881, 88.739402], "paragraph_keywords": ["experts", "data", "dimensions", "points"]}, {"paragraph_vector": [18.230068, 88.831886], "paragraph_keywords": ["expertise", "experts", "visualization", "optimisation"]}, {"paragraph_vector": [18.460073, 89.303184], "paragraph_keywords": ["domain", "participants", "model", "expertise"]}, {"paragraph_vector": [13.030884, 87.681915], "paragraph_keywords": ["participants", "study", "case", "asked"]}, {"paragraph_vector": [-145.444549, 88.838951], "paragraph_keywords": ["scheme", "event", "video", "annotation"]}, {"paragraph_vector": [-62.367176, 84.433975], "paragraph_keywords": ["exploration", "objects", "dimensions", "data"]}, {"paragraph_vector": [160.466262, 88.166313], "paragraph_keywords": ["exploration", "scenarios", "scenario", "research"]}, {"paragraph_vector": [14.609901, 88.619522], "paragraph_keywords": ["exploration", "scenarios", "scenario", "use"]}, {"paragraph_vector": [111.849891, 87.281059], "paragraph_keywords": ["exploration", "scenarios", "experts", "number"]}, {"paragraph_vector": [128.524459, 88.471786], "paragraph_keywords": ["scenario", "experts", "dimensions", "scenarios"]}, {"paragraph_vector": [4.380246, 82.821121], "paragraph_keywords": ["experts", "objectives", "exploration", "case"]}, {"paragraph_vector": [-176.071182, 89.008964], "paragraph_keywords": ["insights", "insight", "event", "experts"]}, {"paragraph_vector": [-47.847183, 87.560966], "paragraph_keywords": ["expertise", "point", "model", "exploration"]}, {"paragraph_vector": [-22.648448, 88.13227], "paragraph_keywords": ["model", "correlation", "exploration", "strategies"]}, {"paragraph_vector": [2.80821, 85.57051], "paragraph_keywords": ["exploration", "tool", "model", "storytelling"]}, {"paragraph_vector": [115.048789, 89.584175], "paragraph_keywords": ["exploration", "scenarios", "questions", "research"]}, {"paragraph_vector": [-41.627399, 87.372886], "paragraph_keywords": ["exploration", "dimensions", "experts", "model"]}, {"paragraph_vector": [-148.235839, 88.466796], "paragraph_keywords": ["exploration", "expertise", "model", "findings"]}, {"paragraph_vector": [141.17926, 89.235183], "paragraph_keywords": ["exploration", "section", "knowledge", "tools"]}, {"paragraph_vector": [2.680234, 87.745178], "paragraph_keywords": ["expertise", "exploration", "experts", "model"]}, {"paragraph_vector": [147.709869, 85.737014], "paragraph_keywords": ["identified", "work", "role", "analytics"]}], "content": {}, "doi": "10.1145/3290605.3300530"}, {"uri": "171", "title": "./trilaterate: A Fabrication Pipeline to Design and 3D Print Hover-, Touch-, and Force-Sensitive Objects", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Martin Schmitz", "Martin Stitz", "Florian M\u00fcller"], "summary": "Hover, touch, and force are promising input modalities that get increasingly integrated into screens and everyday objects. However, these interactions are often limited to fat surfaces and the integration of suitable sensors is time-consuming and costly. To alleviate these limitations, we contribute Trilaterate: A fabrication pipeline to 3D print custom objects that detect the 3D position of a fnger hovering, touching, or forcing them by combining multiple capacitance measurements via capacitive trilateration. Trilaterate places and routes actively-shielded sensors inside the object and operates on consumer-level 3D printers. We present technical evaluations and example applications that validate and demonstrate the wide applicability of Trilaterate. CCS CONCEPTS \u2022 Human-centered computing \u2192 Interaction devices; \u2022 Hardware\u2192 Tactile and hand-based interfaces;", "keywords": ["position", "fnger", "trace", "point", "need", "object", "sensing", "set", "force", "mm", "trilateration", "shield", "sensor", "touch", "model", "user", "volume", "surface", "interaction", "space", "e", "capacitance", "printing", "algorithm", "electrode", "test", "require", "distance", "approach", "routing", "target", "structure", "printed", "padding", "paper", "input", "fabrication", "board", "figure"], "document_vector": [71.579452, -58.870845], "paragraphs": [{"paragraph_vector": [-60.141159, 36.533027], "paragraph_keywords": ["touch", "sensing", "objects", "copies"]}, {"paragraph_vector": [-72.976959, 54.246917], "paragraph_keywords": ["objects", "force", "require", "position"]}, {"paragraph_vector": [-71.58245, 48.343608], "paragraph_keywords": ["objects", "sensing", "object", "deformation"]}, {"paragraph_vector": [-71.870826, 53.929943], "paragraph_keywords": ["objects", "require", "object", "sensors"]}, {"paragraph_vector": [-69.924644, 56.190246], "paragraph_keywords": ["traces", "electrodes", "object", "figure"]}, {"paragraph_vector": [-69.231414, 57.332229], "paragraph_keywords": ["electrodes", "object", "user", "figure"]}, {"paragraph_vector": [-50.678256, 52.457679], "paragraph_keywords": ["electrodes", "object", "electrode", "sensor"]}, {"paragraph_vector": [-47.360496, 48.323638], "paragraph_keywords": ["object", "electrodes", "surface", "e"]}, {"paragraph_vector": [-45.641494, 47.638786], "paragraph_keywords": ["electrodes", "surface", "algorithm", "performance"]}, {"paragraph_vector": [-51.932086, 53.135879], "paragraph_keywords": ["object", "electrodes", "traces", "trace"]}, {"paragraph_vector": [-69.374496, 56.081565], "paragraph_keywords": ["shielding", "pla", "traces", "c"]}, {"paragraph_vector": [-69.920761, 55.08374], "paragraph_keywords": ["distance", "distances", "capacitance", "object"]}, {"paragraph_vector": [-47.775463, 37.33675], "paragraph_keywords": ["position", "distance", "electrodes", "point"]}, {"paragraph_vector": [4.31278, 32.392044], "paragraph_keywords": ["position", "interaction", "model", "sensor"]}, {"paragraph_vector": [-70.441909, 52.53149], "paragraph_keywords": ["electrodes", "positions", "surface", "object"]}, {"paragraph_vector": [-27.431669, 23.467348], "paragraph_keywords": ["position", "distance", "electrodes", "target"]}, {"paragraph_vector": [-31.941482, 26.098592], "paragraph_keywords": ["force", "target", "participant", "position"]}, {"paragraph_vector": [-112.149864, 47.177066], "paragraph_keywords": ["figure", "platform", "pyramid", "touch"]}, {"paragraph_vector": [-63.947769, 54.278995], "paragraph_keywords": ["electrodes", "alarm", "objects", "object"]}, {"paragraph_vector": [-70.444595, 51.37239], "paragraph_keywords": ["mm", "distance", "electrode", "air"]}, {"paragraph_vector": [-52.610538, 55.698062], "paragraph_keywords": ["electrodes", "sensing", "fnger", "force"]}, {"paragraph_vector": [-69.200637, 53.364677], "paragraph_keywords": ["printed", "electrodes", "objects", "position"]}], "content": {}, "doi": "10.1145/3290605.3300300"}, {"uri": "172", "title": "A Bayesian Cognition Approach  to Improve Data Visualization", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Yea-Seul Kim"], "summary": "People naturally bring their prior beliefs to bear on how they interpret the new information, yet few formal models exist for accounting for the influence of users\u2019 prior beliefs in interactions with data presentations like visualizations. We demonstrate a Bayesian cognitive model for understanding how people interpret visualizations in light of prior beliefs and show how this model provides a guide for improving visualization evaluation. In a first study, we show how applying a Bayesian cognition model to a simple visualization scenario indicates that people\u2019s judgments are consistent with a hypothesis that they are doing approximate Bayesian inference. In a second study, we evaluate how sensitive our observations of Bayesian behavior are to different techniques for eliciting people subjective distributions, and to different datasets. We find that people don\u2019t behave consistently with Bayesian predictions for large sample size datasets, and this difference cannot be explained by elicitation technique. In a final study, we show how normative Bayesian inference can be used as an evaluation framework for visualizations, including of uncertainty.", "keywords": ["bayesian", "based", "tech", "condition", "belief", "person", "information", "evidence", "distribution", "design", "technique", "provide", "uncertainty", "model", "sample", "work", "result", "proportion", "participant", "use", "people", "prior", "probability", "given", "size", "visualization", "page", "number", "dataset", "inference", "cognition", "log", "observed", "data", "kld", "study", "approach", "elicitation", "presented", "evaluate", "knowledge", "value", "response"], "document_vector": [-140.508773, -5.808869], "paragraphs": [{"paragraph_vector": [86.008049, 89.569831], "paragraph_keywords": ["visualization", "copies", "data", "design"]}, {"paragraph_vector": [179.247772, 89.928749], "paragraph_keywords": ["data", "beliefs", "visualization", "people"]}, {"paragraph_vector": [-41.533603, 88.859519], "paragraph_keywords": ["visualization", "data", "bayesian", "people"]}, {"paragraph_vector": [-8.611902, 87.034042], "paragraph_keywords": ["data", "distribution", "beliefs", "bayesian"]}, {"paragraph_vector": [-24.979469, 85.353103], "paragraph_keywords": ["bayesian", "beliefs", "distribution", "participants"]}, {"paragraph_vector": [-31.503192, 86.649238], "paragraph_keywords": ["people", "data", "bayesian", "beliefs"]}, {"paragraph_vector": [42.832519, 83.906196], "paragraph_keywords": ["people", "visualization", "bayesian", "beliefs"]}, {"paragraph_vector": [14.16197, 82.638404], "paragraph_keywords": ["participants", "proportion", "distribution", "bayesian"]}, {"paragraph_vector": [19.099821, 73.717704], "paragraph_keywords": ["distributions", "participants", "distribution", "bayesian"]}, {"paragraph_vector": [26.056915, 73.486145], "paragraph_keywords": ["kld", "log", "participants", "data"]}, {"paragraph_vector": [18.117118, 73.698348], "paragraph_keywords": ["uncertainty", "elicitation", "techniques", "technique"]}, {"paragraph_vector": [25.407381, 74.371215], "paragraph_keywords": ["sample", "samples", "person", "provide"]}, {"paragraph_vector": [22.580848, 73.476654], "paragraph_keywords": ["distribution", "outcomes", "balls", "bins"]}, {"paragraph_vector": [-32.020141, 81.830718], "paragraph_keywords": ["data", "participants", "proportion", "health"]}, {"paragraph_vector": [32.684841, 65.320976], "paragraph_keywords": ["participants", "sample", "distribution", "samples"]}, {"paragraph_vector": [21.712039, 73.020721], "paragraph_keywords": ["distribution", "means", "bins", "elicitation"]}, {"paragraph_vector": [25.391538, 73.387145], "paragraph_keywords": ["sample", "people", "log", "datasets"]}, {"paragraph_vector": [20.060123, 76.621437], "paragraph_keywords": ["sample", "data", "people", "perceived"]}, {"paragraph_vector": [-5.792473, 88.082832], "paragraph_keywords": ["uncertainty", "study", "participants", "dataset"]}, {"paragraph_vector": [25.718873, 73.087043], "paragraph_keywords": ["participants", "elicitation", "distributions", "log"]}, {"paragraph_vector": [8.466777, 83.868354], "paragraph_keywords": ["sample", "uncertainty", "dataset", "size"]}, {"paragraph_vector": [-87.374519, 88.916358], "paragraph_keywords": ["bayesian", "visualization", "people", "beliefs"]}, {"paragraph_vector": [33.032958, 86.486328], "paragraph_keywords": ["beliefs", "data", "users", "bayesian"]}, {"paragraph_vector": [11.441915, 84.228813], "paragraph_keywords": ["data", "distributions", "sample", "values"]}, {"paragraph_vector": [3.722287, 85.085289], "paragraph_keywords": ["work", "data", "bayesian", "priors"]}, {"paragraph_vector": [94.900978, 2.405786], "paragraph_keywords": ["award", "foundation", "gordon", "betty"]}], "content": {}, "doi": "10.1145/3290605.3300841"}, {"uri": "173", "title": "Cultivating Care through Ambiguity: Lessons from a Service Learning Course", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Samar Sabie", "Tapan Parikh"], "summary": "Given the focus of professional graduate ICT programs on technical and managerial skills, pedagogical engagement with external organizations tends to be transactional and artifact-centered. This inhibits the students\u2019 ability to understand social, technical and ethical issues in context, or to develop affective relationships with users and other stakeholders. To address this, we designed a service learning course that partnered students with non-profit organizations to help with their technology challenges. The service project was deliberately left open-ended to force students (and partners) to tackle important questions around project scoping and impact. By drawing parallels to soil care practices, we explore how \u201ccare time\u201d emerged in this context, and how the incorporation of ambiguity galvanized students, community, and faculty to make time to navigate it. This led to non-tangible yet vital outcomes such as overcoming social limitations, building symbiotic relationships, and enacting acts of care necessary for more ethical orchestration of technology.", "keywords": ["resident", "emerging", "analysis", "know", "helped", "collaboration", "life", "organization", "support", "course", "timeframes", "city", "process", "institution", "food", "need", "relation", "island", "class", "interview", "learn", "innovation", "side", "sense", "working", "experience", "member", "driven", "data", "technology", "soil", "knowledge", "value", "project", "context", "code", "tech", "time", "remaking", "partner", "relationship", "co", "people", "material", "service", "learning", "world", "techno", "attention", "practice", "commitment", "ambiguity", "skill", "outcome", "program", "making", "interdependence", "design", "care", "thing", "help", "engagement", "uncertainty", "work", "building", "dynamic", "impact", "idea", "page", "-", "approach", "student", "research", "term", "paper", "campus", "community"], "document_vector": [-170.17134, 49.543266], "paragraphs": [{"paragraph_vector": [105.943893, -47.111251], "paragraph_keywords": ["lives", "future", "world", "tech"]}, {"paragraph_vector": [128.689147, -13.956356], "paragraph_keywords": ["care", "copies", "paper", "work"]}, {"paragraph_vector": [126.827308, -15.239142], "paragraph_keywords": ["students", "learning", "service", "problem"]}, {"paragraph_vector": [127.860557, -17.92041], "paragraph_keywords": ["community", "learning", "service", "relationships"]}, {"paragraph_vector": [122.849281, -16.566781], "paragraph_keywords": ["design", "care", "work", "relationships"]}, {"paragraph_vector": [127.405761, -26.00842], "paragraph_keywords": ["care", "community", "time", "interdependency"]}, {"paragraph_vector": [131.702163, -19.778701], "paragraph_keywords": ["care", "soil", "timeframes", "technology"]}, {"paragraph_vector": [127.417808, -17.90623], "paragraph_keywords": ["soil", "students", "term", "production"]}, {"paragraph_vector": [130.129211, -19.593677], "paragraph_keywords": ["community", "students", "sustain", "relate"]}, {"paragraph_vector": [120.252319, -18.880502], "paragraph_keywords": ["island", "community", "campus", "office"]}, {"paragraph_vector": [135.653228, -29.049325], "paragraph_keywords": ["students", "island", "care", "community"]}, {"paragraph_vector": [127.214706, -15.478458], "paragraph_keywords": ["organizations", "students", "partners", "project"]}, {"paragraph_vector": [125.196685, -14.425624], "paragraph_keywords": ["island", "students", "gis", "partners"]}, {"paragraph_vector": [126.448028, -20.731794], "paragraph_keywords": ["island", "students", "course", "project"]}, {"paragraph_vector": [127.296875, -27.455888], "paragraph_keywords": ["students", "course", "interview", "interviews"]}, {"paragraph_vector": [118.73484, -3.418273], "paragraph_keywords": ["students", "partners", "codes", "project"]}, {"paragraph_vector": [108.786285, -1.059718], "paragraph_keywords": ["students", "partners", "student", "cycles"]}, {"paragraph_vector": [109.619171, -0.627326], "paragraph_keywords": ["meetings", "partner", "students", "reported"]}, {"paragraph_vector": [117.222831, -1.766411], "paragraph_keywords": ["partners", "students", "community", "things"]}, {"paragraph_vector": [113.176979, 11.745094], "paragraph_keywords": ["course", "students", "talking", "learning"]}, {"paragraph_vector": [129.415588, -14.465117], "paragraph_keywords": ["students", "partner", "student", "network"]}, {"paragraph_vector": [127.536125, -16.429378], "paragraph_keywords": ["students", "care", "student", "persistence"]}, {"paragraph_vector": [115.854156, -4.123347], "paragraph_keywords": ["students", "partners", "process", "making"]}, {"paragraph_vector": [114.63681, -3.032722], "paragraph_keywords": ["time", "care", "community", "class"]}, {"paragraph_vector": [126.107147, -22.713562], "paragraph_keywords": ["care", "innovation", "repair", "win"]}, {"paragraph_vector": [122.874366, -20.437589], "paragraph_keywords": ["technology", "relationship", "conversation", "community"]}, {"paragraph_vector": [112.746551, -8.684955], "paragraph_keywords": ["design", "care", "present", "people"]}, {"paragraph_vector": [130.181472, -13.948931], "paragraph_keywords": ["students", "projects", "ways", "partners"]}, {"paragraph_vector": [126.476387, -18.052431], "paragraph_keywords": ["care", "design", "time", "technology"]}, {"paragraph_vector": [97.45774, 16.084678], "paragraph_keywords": ["help", "foundation", "support", "partners"]}], "content": {}, "doi": "10.1145/3290605.3300464"}, {"uri": "174", "title": "Follow the Money: Managing Personal Finance Digitally", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Makayla Lewis", "Mark Perry"], "summary": "The move towards digital payments and mobile money, and away from physical cash and banking services, offers users opportunities to change the ways that they can spend, save and manage their money through a variety of personal financial management services. However, set against ordinary, everyday patterns of spending, saving and other forms of financial transaction, it is not clear how users might interact with, understand, or value financial management services that utilise rich data and connected digital content for their personal use. In order to explore how people might engage with such systems, we conducted a study of financial activity, following people\u2019s transactional activity over time, and interviewing them about their practices, understandings, needs, concerns and expectations of current and future financial technologies. Drawing from the everyday activities and practices observed, we identify implications for the design of digitally enabled, personal financial systems.", "keywords": ["process", "payment", "finance", "time", "need", "information", "set", "like", "reported", "interview", "cash", "relationship", "income", "record", "spending", "user", "activity", "medium", "interaction", "saving", "shared", "work", "place", "management", "participant", "bank", "use", "people", "card", "service", "given", "debt", "page", "debit", "household", "understanding", "taking", "charlotte", "sarah", "money", "track", "described", "practice", "diary", "james", "data", "day", "logged", "study", "spent", "pattern", "system", "support", "transaction", "account", "paper", "individual", "budgeting", "access", "making"], "document_vector": [26.886135, 59.177486], "paragraphs": [{"paragraph_vector": [22.082374, -37.871383], "paragraph_keywords": ["users", "payment", "services", "management"]}, {"paragraph_vector": [20.350381, -37.679618], "paragraph_keywords": ["practices", "users", "paper", "management"]}, {"paragraph_vector": [22.739141, -36.22681], "paragraph_keywords": ["money", "work", "relationships", "interactions"]}, {"paragraph_vector": [21.207439, -37.317245], "paragraph_keywords": ["money", "paper", "track", "users"]}, {"paragraph_vector": [23.318834, -38.503086], "paragraph_keywords": ["users", "services", "payment", "money"]}, {"paragraph_vector": [21.139581, -39.112899], "paragraph_keywords": ["participants", "people", "age", "study"]}, {"paragraph_vector": [21.543754, -38.440486], "paragraph_keywords": ["day", "participants", "transactions", "email"]}, {"paragraph_vector": [22.234493, -37.718013], "paragraph_keywords": ["participants", "transaction", "diary", "card"]}, {"paragraph_vector": [21.533514, -35.883438], "paragraph_keywords": ["participants", "transaction", "activities", "transactions"]}, {"paragraph_vector": [36.751846, -42.915771], "paragraph_keywords": ["activities", "narratives", "sarah", "clothes"]}, {"paragraph_vector": [20.545547, -37.827304], "paragraph_keywords": ["spending", "bank", "parents", "savings"]}, {"paragraph_vector": [17.652507, -37.960914], "paragraph_keywords": ["money", "spending", "participants", "overdrafts"]}, {"paragraph_vector": [16.94547, -38.30392], "paragraph_keywords": ["card", "debit", "money", "cash"]}, {"paragraph_vector": [19.788627, -39.022987], "paragraph_keywords": ["cash", "payment", "charlotte", "use"]}, {"paragraph_vector": [19.038751, -36.370639], "paragraph_keywords": ["card", "participants", "cards", "transactions"]}, {"paragraph_vector": [22.021921, -37.226459], "paragraph_keywords": ["loans", "money", "repayment", "participants"]}, {"paragraph_vector": [18.822216, -35.316711], "paragraph_keywords": ["payment", "pay", "participants", "dinner"]}, {"paragraph_vector": [21.664087, -35.707412], "paragraph_keywords": ["taking", "charlotte", "turn", "making"]}, {"paragraph_vector": [21.412448, -37.057521], "paragraph_keywords": ["liam", "bank", "account", "savings"]}, {"paragraph_vector": [20.101873, -38.783588], "paragraph_keywords": ["saving", "process", "charlotte", "involved"]}, {"paragraph_vector": [19.278486, -37.032661], "paragraph_keywords": ["households", "household", "shared", "charlotte"]}, {"paragraph_vector": [18.360849, -37.244762], "paragraph_keywords": ["charlotte", "payment", "month", "kerry"]}, {"paragraph_vector": [20.868562, -36.106319], "paragraph_keywords": ["spending", "categorisation", "track", "required"]}, {"paragraph_vector": [17.922475, -34.418598], "paragraph_keywords": ["spending", "reported", "parents", "banking"]}, {"paragraph_vector": [22.534767, -37.31599], "paragraph_keywords": ["notifications", "spending", "record", "participants"]}, {"paragraph_vector": [22.059934, -40.313426], "paragraph_keywords": ["participants", "practices", "management", "data"]}, {"paragraph_vector": [21.115631, -40.577743], "paragraph_keywords": ["users", "activities", "spending", "data"]}, {"paragraph_vector": [20.129196, -38.880168], "paragraph_keywords": ["debt", "money", "obligations", "participants"]}, {"paragraph_vector": [18.952604, -39.352687], "paragraph_keywords": ["way", "understanding", "users", "household"]}, {"paragraph_vector": [20.733673, -37.078643], "paragraph_keywords": ["activities", "money", "participants", "data"]}], "content": {}, "doi": "10.1145/3290605.3300312"}, {"uri": "175", "title": "Accessible Gesture Typing for Non-Visual Text Entry on Smartphones", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Syed Masum Billah", "Yu-Jung Ko"], "summary": "Gesture typing\u2013entering a word by gliding the finger sequentially over letter to letter\u2013 has been widely supported on smartphones for sighted users. However, this input paradigm is currently inaccessible to blind users: it is difficult to draw shape gestures on a virtual keyboard without access to key visuals. This paper describes the design of accessible gesture typing, to bring this input paradigm to blind users. To Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300606 help blind users figure out key locations, the design incorporates the familiar screen-reader supported touch exploration that narrates the keys as the user drags the finger across the keyboard. The design allows users to seamlessly switch between exploration and gesture typing mode by simply lifting the finger. Continuous touch-exploration like audio feedback is provided during word shape construction that helps the user glide in the right direction of the key locations constituting the word. Exploration mode resumes once word shape is completed. Distinct earcons help distinguish gesture typing mode from touch exploration mode, and thereby avoid unintended mix-ups. A user study with 14 blind people shows 35% increment in their typing speed, indicative of the promise and potential of gesture typing technology for non-visual text entry.", "keywords": ["based", "time", "finger", "al", "tap", "set", "pivot", "design", "entry", "touch", "user", "keyboard", "exploration", "model", "transition", "et", "word", "participant", "people", "key", "screen", "backspace", "pilot", "shape", "number", "gesture", "character", "feedback", "voiceover", "agtex", "phrase", "smartphones", "study", "choice", "text", "typing", "mode", "paper", "enter", "letter", "default", "figure"], "document_vector": [-26.145576, -72.190879], "paragraphs": [{"paragraph_vector": [-34.363029, -9.183176], "paragraph_keywords": ["screen", "computing", "text", "people"]}, {"paragraph_vector": [-31.840549, -13.554857], "paragraph_keywords": ["keyboard", "letter", "gesture", "typing"]}, {"paragraph_vector": [-34.363536, -12.751174], "paragraph_keywords": ["typing", "gesture", "exploration", "agtex"]}, {"paragraph_vector": [-39.768779, -6.210874], "paragraph_keywords": ["typing", "et", "touch", "research"]}, {"paragraph_vector": [-35.1893, -11.733967], "paragraph_keywords": ["users", "gesture", "entry", "finger"]}, {"paragraph_vector": [-35.717189, -12.50888], "paragraph_keywords": ["gesture", "users", "entry", "typing"]}, {"paragraph_vector": [-34.55825, -12.201091], "paragraph_keywords": ["word", "gesture", "direction", "typing"]}, {"paragraph_vector": [-34.321407, -9.639576], "paragraph_keywords": ["gesture", "finger", "typing", "key"]}, {"paragraph_vector": [-26.106164, -20.630952], "paragraph_keywords": ["participants", "study", "model", "set"]}, {"paragraph_vector": [-37.643608, -9.328906], "paragraph_keywords": ["study", "gesture", "experimenter", "text"]}, {"paragraph_vector": [-33.890388, -12.097456], "paragraph_keywords": ["word", "typing", "number", "users"]}, {"paragraph_vector": [-22.316894, -17.235445], "paragraph_keywords": ["word", "gesture", "backspace", "key"]}, {"paragraph_vector": [-34.087303, -11.098547], "paragraph_keywords": ["key", "participants", "wanted", "finger"]}, {"paragraph_vector": [-35.550426, -11.934044], "paragraph_keywords": ["gesture", "typing", "choices", "key"]}, {"paragraph_vector": [-36.455364, -11.093644], "paragraph_keywords": ["key", "gesture", "exploration", "agtex"]}, {"paragraph_vector": [-26.974761, -16.466316], "paragraph_keywords": ["backspace", "word", "press", "key"]}, {"paragraph_vector": [-22.942247, -13.400412], "paragraph_keywords": ["study", "participants", "pilot", "typing"]}, {"paragraph_vector": [-28.534446, -16.859729], "paragraph_keywords": ["typing", "keys", "word", "agtex"]}, {"paragraph_vector": [-28.710605, -14.00121], "paragraph_keywords": ["gesture", "users", "mode", "agtex"]}, {"paragraph_vector": [-30.311334, -16.067111], "paragraph_keywords": ["gesture", "typing", "agtex", "key"]}, {"paragraph_vector": [-34.862731, -10.915908], "paragraph_keywords": ["typing", "gesture", "study", "char"]}], "content": {}, "doi": "10.1145/3290605.3300827"}, {"uri": "176", "title": "WhatFutures: Designing Large-Scale Engagements on WhatsApp", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Daniel Lambton-Howard", "Shaun Hazeldine", "Carlos Alvarez", "John A. Sweeney"], "summary": "WhatsApp, as the world\u2019s most popular messaging application, offers significant opportunities for improving the reach and effectiveness of engagement projects. In collaboration with the International Federation of Red Cross and Red Crescent Societies (IFRC) we designedWhatFutures, a collaborative future forecasting engagement for global youth using WhatsApp. WhatFutures was successfully deployed with 487 players across 5 countries (Kenya, Bulgaria, Finland, Australia and Hong Kong) to inform strategic change within the IFRC. Based on our analysis of the activity including 16,100 messages, 95 multimedia artifacts, and a post-engagement survey we present a reflection upon the design decisions underpinningWhatFutures and identify how decisions made around group structures, processes and externalization of outputs influenced engagement and data quality. We conclude with the wider implications of our findings for the design of engagements that best utilize the affordances of existing messaging applications. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for thirdparty components of this work must be honored. For all other uses, contact the owner/author(s). CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-5970-2/19/05. https://doi.org/10.1145/3290605.3300389 CCS CONCEPTS \u2022Human-centered computing\u2192Collaborative content creation.", "keywords": ["message", "process", "ifrc", "time", "information", "set", "player", "guide", "design", "reported", "method", "analysis", "whatsapp", "engagement", "activity", "production", "communication", "engage", "work", "participant", "use", "people", "group", "distributed", "designed", "team", "issue", "challenge", "participation", "page", "existing", "understanding", "content", "found", "scale", "volunteer", "member", "membership", "data", "whatfutures", "game", "role", "support", "text", "conference", "quality", "platform", "structure", "paper", "multimedia", "sent", "question", "crowdsourcing", "artifact", "response"], "document_vector": [-171.139572, 63.530765], "paragraphs": [{"paragraph_vector": [167.646331, -38.282859], "paragraph_keywords": ["whatsapp", "engagement", "designed", "scale"]}, {"paragraph_vector": [-161.543411, -42.702159], "paragraph_keywords": ["whatfutures", "engagement", "design", "distributed"]}, {"paragraph_vector": [49.159816, 4.044561], "paragraph_keywords": ["platforms", "collaboration", "activities", "tasks"]}, {"paragraph_vector": [-148.238952, -37.926883], "paragraph_keywords": ["game", "players", "data", "design"]}, {"paragraph_vector": [-147.169982, -43.620166], "paragraph_keywords": ["distributed", "participants", "data", "group"]}, {"paragraph_vector": [111.412544, -29.353891], "paragraph_keywords": ["ifrc", "process", "volunteers", "activities"]}, {"paragraph_vector": [-158.132537, -43.043323], "paragraph_keywords": ["group", "whatsapp", "activity", "groups"]}, {"paragraph_vector": [-152.537689, -35.819412], "paragraph_keywords": ["game", "group", "whatsapp", "participants"]}, {"paragraph_vector": [-151.350265, -33.517677], "paragraph_keywords": ["players", "group", "production", "game"]}, {"paragraph_vector": [-151.563186, -35.209117], "paragraph_keywords": ["players", "teams", "conferences", "learning"]}, {"paragraph_vector": [-151.790679, -35.322528], "paragraph_keywords": ["challenges", "ifrc", "challenge", "guides"]}, {"paragraph_vector": [-149.29396, -26.470462], "paragraph_keywords": ["game", "players", "teams", "ifrc"]}, {"paragraph_vector": [-151.090454, -35.294624], "paragraph_keywords": ["share", "game", "players", "volunteers"]}, {"paragraph_vector": [-151.701141, -28.031387], "paragraph_keywords": ["data", "sent", "messages", "game"]}, {"paragraph_vector": [-152.122787, -29.508197], "paragraph_keywords": ["quality", "data", "challenges", "challenge"]}, {"paragraph_vector": [118.743171, -25.163894], "paragraph_keywords": ["data", "text", "artifacts", "issue"]}, {"paragraph_vector": [-153.877777, -29.800743], "paragraph_keywords": ["game", "consisting", "country", "players"]}, {"paragraph_vector": [-141.90715, 0.199154], "paragraph_keywords": ["reported", "game", "team", "group"]}, {"paragraph_vector": [171.246017, -41.31628], "paragraph_keywords": ["artifacts", "ifrc", "data", "engage"]}, {"paragraph_vector": [-155.280868, -37.228271], "paragraph_keywords": ["communication", "whatfutures", "volunteers", "effect"]}, {"paragraph_vector": [-151.105499, -31.854158], "paragraph_keywords": ["whatfutures", "players", "game", "issues"]}, {"paragraph_vector": [-154.267807, -27.112808], "paragraph_keywords": ["game", "whatfutures", "data", "processing"]}, {"paragraph_vector": [-152.327957, -34.915599], "paragraph_keywords": ["whatfutures", "design", "data", "analysis"]}, {"paragraph_vector": [-155.363067, -42.537078], "paragraph_keywords": ["qualities", "groups", "role", "roles"]}, {"paragraph_vector": [50.577175, -49.371376], "paragraph_keywords": ["data", "red", "training", "civics"]}], "content": {}, "doi": "10.1145/3290605.3300495"}, {"uri": "177", "title": "Keeping Rumors in Proportion:Managing Uncertainty in Rumor Systems", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Peter M. Krafft", "Emma S. Spiro"], "summary": "The study of rumors has garnered wider attention as regulators and researchers turn towards problems of misinformation on social media. One goal has been to discover and implement mechanisms that promote healthy information ecosystems. Classically defined as regarding ambiguous situations, rumors pose the unique difficulty of intrinsic uncertainty around their veracity. Further complicating matters, rumors can serve the public when they do spread valuable true information. To address these challenges, we develop an approach that reifies \u201crumor proportions\u201d as central to the theory of systems for managing rumors. We use this lens to advocate for systems that, rather than aiming to stifle rumors entirely or aiming to stop only false rumors, aim to prevent rumors from growing out of proportion relative to normative benchmark representations of intrinsic uncertainty.", "keywords": ["based", "housing", "time", "change", "belief", "information", "discussion", "evidence", "mechanism", "design", "analysis", "focus", "criterion", "example", "credibility", "medium", "uncertainty", "model", "work", "proportion", "use", "people", "e", "probability", "world", "given", "factor", "page", "sampling", "existing", "function", "content", "science", "case", "rumor", "approach", "fact", "framework", "system", "consideration", "veracity", "affirmation", "r", "paper", "seattle", "behavior"], "document_vector": [-62.216655, 25.334129], "paragraphs": [{"paragraph_vector": [62.856037, -25.556774], "paragraph_keywords": ["copies", "housing", "acm", "rumors"]}, {"paragraph_vector": [154.065734, 27.357521], "paragraph_keywords": ["rumors", "information", "people", "misinformation"]}, {"paragraph_vector": [152.707839, 23.608446], "paragraph_keywords": ["rumors", "rumor", "work", "uncertainty"]}, {"paragraph_vector": [152.928817, 24.605129], "paragraph_keywords": ["rumors", "promote", "uncertainty", "situations"]}, {"paragraph_vector": [153.910522, 25.751932], "paragraph_keywords": ["rumors", "people", "belief", "approach"]}, {"paragraph_vector": [152.482421, 24.139583], "paragraph_keywords": ["rumors", "rumor", "approach", "checking"]}, {"paragraph_vector": [153.089248, 26.629352], "paragraph_keywords": ["rumor", "rumors", "proportions", "people"]}, {"paragraph_vector": [152.538558, 26.074262], "paragraph_keywords": ["rumor", "proportions", "post", "rate"]}, {"paragraph_vector": [153.325927, 29.642534], "paragraph_keywords": ["rumor", "design", "people", "approach"]}, {"paragraph_vector": [153.244537, 26.231548], "paragraph_keywords": ["people", "rumors", "r", "rumor"]}, {"paragraph_vector": [154.023498, 25.674875], "paragraph_keywords": ["rumor", "world", "evidence", "criteria"]}, {"paragraph_vector": [150.489013, 29.333372], "paragraph_keywords": ["probability", "r", "evidence", "given"]}, {"paragraph_vector": [151.128326, 27.258563], "paragraph_keywords": ["e", "sampling", "people", "beliefs"]}, {"paragraph_vector": [152.153518, 26.077226], "paragraph_keywords": ["rumor", "people", "rumors", "support"]}, {"paragraph_vector": [152.652267, 25.517602], "paragraph_keywords": ["behavior", "rumor", "proportion", "people"]}, {"paragraph_vector": [153.778564, 25.774759], "paragraph_keywords": ["rumor", "evidence", "proportions", "approach"]}, {"paragraph_vector": [153.030136, 25.078557], "paragraph_keywords": ["rumor", "proportions", "media", "rumors"]}, {"paragraph_vector": [153.616561, 25.246757], "paragraph_keywords": ["proportion", "rumor", "rumors", "people"]}, {"paragraph_vector": [153.001724, 25.109922], "paragraph_keywords": ["rumor", "climate", "case", "proportions"]}, {"paragraph_vector": [154.843475, 23.352321], "paragraph_keywords": ["seattle", "proportion", "rumor", "comments"]}, {"paragraph_vector": [154.20285, 26.380828], "paragraph_keywords": ["rumor", "mechanism", "framework", "contribution"]}, {"paragraph_vector": [153.207321, 25.405519], "paragraph_keywords": ["rumor", "rumors", "extensions", "sampling"]}, {"paragraph_vector": [152.689895, 26.008775], "paragraph_keywords": ["rumors", "rumor", "foundation", "award"]}], "content": {}, "doi": "10.1145/3290605.3300861"}, {"uri": "178", "title": "Developing Accessible Services", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Michael Crabb", "Michael Heron", "Robert Gordon"], "summary": "When creating digital artefacts, it is important to ensure that the product being made is accessible to as much of the population as is possible. Many guidelines and supporting tools exist to assist reaching this goal. However, little is known about developers\u2019 understanding of accessible practice and the methods that are used to implement this. We present findings from an accessibility design workshop that was carried out with a mixture of 197 developers and digital technology students. We discuss perceptions of accessibility, techniques that are used when designing accessible products, and what areas of accessibility development participants believed were important. We show that there are gaps in the knowledge needed to develop accessible products despite the effort to promote accessible design. Our participants are themselves aware of where these gaps are and have suggested a number of areas where tools, techniques and guidance would improve their practice.", "keywords": ["information", "development", "design", "method", "technique", "focus", "user", "activity", "aspect", "accessibility", "communication", "workshop", "creating", "work", "product", "tool", "implementation", "participant", "use", "people", "discussed", "relating", "issue", "range", "challenge", "related", "exist", "factor", "number", "application", "including", "impairment", "described", "practice", "technology", "disability", "developing", "developer", "text", "research", "focused", "colour", "asked", "software", "paper", "area", "assist", "knowledge", "level"], "document_vector": [71.341438, 15.720274], "paragraphs": [{"paragraph_vector": [-156.775283, 40.641498], "paragraph_keywords": ["accessibility", "copies", "services", "people"]}, {"paragraph_vector": [-156.472427, 42.042427], "paragraph_keywords": ["accessibility", "developers", "workshop", "practice"]}, {"paragraph_vector": [-147.641616, 40.152442], "paragraph_keywords": ["accessibility", "issues", "exist", "barriers"]}, {"paragraph_vector": [158.009399, 34.296863], "paragraph_keywords": ["accessibility", "developers", "techniques", "software"]}, {"paragraph_vector": [-158.782546, 42.662059], "paragraph_keywords": ["accessibility", "level", "implementing", "developers"]}, {"paragraph_vector": [-150.618316, 42.612228], "paragraph_keywords": ["accessibility", "participants", "workshop", "challenges"]}, {"paragraph_vector": [-154.695755, 40.205814], "paragraph_keywords": ["participants", "accessibility", "issues", "paper"]}, {"paragraph_vector": [116.663909, 50.922389], "paragraph_keywords": ["participants", "asked", "workshop", "activity"]}, {"paragraph_vector": [113.483268, 20.774686], "paragraph_keywords": ["participants", "work", "workshops", "workshop"]}, {"paragraph_vector": [-128.911087, 51.948928], "paragraph_keywords": ["accessibility", "activity", "data", "areas"]}, {"paragraph_vector": [-141.397933, 40.630897], "paragraph_keywords": ["issues", "accessibility", "participants", "relating"]}, {"paragraph_vector": [-140.36502, 41.024127], "paragraph_keywords": ["discussed", "accessibility", "relating", "participants"]}, {"paragraph_vector": [-140.343032, 41.615184], "paragraph_keywords": ["areas", "accessibility", "issues", "participants"]}, {"paragraph_vector": [-139.996536, 41.360252], "paragraph_keywords": ["accessibility", "participants", "users", "impairments"]}, {"paragraph_vector": [-144.195388, 47.25698], "paragraph_keywords": ["participants", "colour", "assist", "information"]}, {"paragraph_vector": [-142.060623, 45.953151], "paragraph_keywords": ["participants", "issues", "users", "area"]}, {"paragraph_vector": [-139.4561, 45.276756], "paragraph_keywords": ["participants", "users", "techniques", "mobility"]}, {"paragraph_vector": [-52.180171, 1.026708], "paragraph_keywords": ["assist", "participants", "users", "design"]}, {"paragraph_vector": [-145.099609, 44.927639], "paragraph_keywords": ["techniques", "accessibility", "discussed", "speech"]}, {"paragraph_vector": [-144.485458, 43.091747], "paragraph_keywords": ["discussed", "participants", "methods", "techniques"]}, {"paragraph_vector": [-145.926742, 42.442634], "paragraph_keywords": ["challenges", "accessibility", "participants", "developers"]}, {"paragraph_vector": [-165.944351, 42.361], "paragraph_keywords": ["accessibility", "developers", "techniques", "people"]}, {"paragraph_vector": [-162.587234, 41.64294], "paragraph_keywords": ["accessibility", "participants", "work", "design"]}, {"paragraph_vector": [-153.028717, 43.712463], "paragraph_keywords": ["accessibility", "participants", "research", "technology"]}], "content": {}, "doi": "10.1145/3290605.3300276"}, {"uri": "179", "title": "A Practice-Led Account of the Conceptual Evolution of UX Knowledge", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Yubo Kou"], "summary": "The contours of user experience (UX) design practice have been shaped by a diverse array of practitioners and disciplines, resulting in a difuse and decentralized body of UXspecifc disciplinary knowledge. The rapidly shifting space that UX knowledge occupies, in conjunction with a longexisting research-practice gap, presents unique challenges and opportunities to UX educators and aspiring UX designers. In this paper, we analyzed a corpus of question and answer communication on UX Stack Exchange using a practice-led approach, identifying and documenting practitioners\u2019 conceptions of UX knowledge over a nine year period. Specifcally, we used natural language processing techniques and qualitative content analysis to identify a disciplinary vocabulary invoked by UX designers in this online community, as well as conceptual trajectories spanning over nine years which could shed light on the evolution of UX practice. We further describe the implications of our fndings for HCI research and UX education.", "keywords": ["process", "based", "vocabulary", "time", "need", "information", "design", "method", "analysis", "specifc", "increasing", "industry", "problem", "category", "user", "interaction", "communication", "work", "word", "use", "people", "related", "idea", "concept", "page", "experience", "year", "practitioner", "exchange", "understanding", "including", "form", "practice", "answer", "study", "researcher", "designer", "discipline", "identifed", "ux", "research", "focused", "term", "quality", "stack", "hci", "question", "paper", "knowledge", "level", "community"], "document_vector": [-148.989135, 47.803615], "paragraphs": [{"paragraph_vector": [116.228553, -35.000709], "paragraph_keywords": ["knowledge", "copies", "computing", "design"]}, {"paragraph_vector": [111.03041, -7.323888], "paragraph_keywords": ["knowledge", "practitioners", "research", "practice"]}, {"paragraph_vector": [105.349029, -14.706912], "paragraph_keywords": ["knowledge", "design", "increasing", "interaction"]}, {"paragraph_vector": [103.773788, -11.324688], "paragraph_keywords": ["design", "companies", "business", "practitioners"]}, {"paragraph_vector": [112.105804, -10.406779], "paragraph_keywords": ["design", "situations", "research", "practitioners"]}, {"paragraph_vector": [109.061157, -16.687648], "paragraph_keywords": ["design", "designers", "practice", "research"]}, {"paragraph_vector": [106.475341, -15.839242], "paragraph_keywords": ["design", "designers", "communities", "knowledge"]}, {"paragraph_vector": [105.860794, -15.57128], "paragraph_keywords": ["design", "designers", "knowledge", "use"]}, {"paragraph_vector": [100.21537, -14.081233], "paragraph_keywords": ["practitioners", "researchers", "community", "stack"]}, {"paragraph_vector": [95.014396, 16.727285], "paragraph_keywords": ["questions", "community", "answers", "work"]}, {"paragraph_vector": [108.07106, 2.034482], "paragraph_keywords": ["concept", "coders", "list", "concepts"]}, {"paragraph_vector": [104.853759, -9.304529], "paragraph_keywords": ["knowledge", "level", "practitioners", "categories"]}, {"paragraph_vector": [103.086212, -2.268799], "paragraph_keywords": ["design", "knowledge", "specifc", "category"]}, {"paragraph_vector": [100.793907, -0.265974], "paragraph_keywords": ["words", "vocabulary", "design", "knowledge"]}, {"paragraph_vector": [105.309349, -1.53163], "paragraph_keywords": ["terms", "design", "research", "user"]}, {"paragraph_vector": [100.275962, -11.162061], "paragraph_keywords": ["vocabulary", "practitioners", "knowledge", "design"]}, {"paragraph_vector": [100.407119, -13.042844], "paragraph_keywords": ["knowledge", "practitioners", "research", "study"]}, {"paragraph_vector": [102.95475, -17.254943], "paragraph_keywords": ["practice", "terms", "practitioners", "design"]}, {"paragraph_vector": [115.582939, -10.434687], "paragraph_keywords": ["vocabulary", "knowledge", "hci", "practice"]}, {"paragraph_vector": [120.597503, 3.40813], "paragraph_keywords": ["community", "design", "knowledge", "practices"]}, {"paragraph_vector": [107.357658, -15.679457], "paragraph_keywords": ["design", "knowledge", "researchers", "practice"]}, {"paragraph_vector": [101.848709, -12.545517], "paragraph_keywords": ["knowledge", "community", "identifed", "communication"]}, {"paragraph_vector": [114.208274, -5.951436], "paragraph_keywords": ["analysis", "knowledge", "sources", "data"]}], "content": {}, "doi": "10.1145/3290605.3300799"}, {"uri": "180", "title": "\u201cLike Popcorn\u201d: Crossmodal Correspondences Between Scents, 3D Shapes and Emotions in Children", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Oussama Metatla", "Emanuela Maggioni", "Marianna Obrist"], "summary": "There is increasing interest in multisensory experiences in HCI. However, little research considers how sensory modalities interact with each other and how this may impact interactive experiences. We investigate how children associate emotions with scents and 3D shapes. 14 participants (10-17yrs) completed crossmodal association tasks to attribute emotional characteristics to variants of the \u201cBouba/Kiki\u201d stimuli, presented as 3D tangible models, in conjunction with lemon and vanilla scents. Our findings support pre-existing mappings between shapes and scents, and confirm the associations between the combination of angular shapes (\u201cKiki\u201d ) and lemon scent with arousing emotion, and of round shapes (\u201cBouba\u201d ) and vanilla scent with calming emotion. This extends prior work on crossmodal correspondences in terms of stimuli (3D as opposed to 2D shapes), sample (children), and conveyed content (emotions). We outline how these findings can contribute to designing more inclusive interactive multisensory technologies.", "keywords": ["smell", "explore", "scent", "child", "correspondence", "association", "set", "display", "design", "experiment", "example", "vanilla", "touch", "storytelling", "interaction", "story", "work", "participant", "use", "perception", "effect", "demonstrated", "valence", "bouba", "olfactory", "shape", "finding", "experience", "emotion", "page", "multisensory", "sound", "stimulus", "task", "sens", "study", "presentation", "tactile", "modality", "combination", "presented", "research", "influence", "hci", "paper", "printed", "lemon", "kiki"], "document_vector": [75.769744, -8.666711], "paragraphs": [{"paragraph_vector": [-97.167846, -13.413267], "paragraph_keywords": ["smell", "copies", "acm", "multisensory"]}, {"paragraph_vector": [-99.216049, -2.276995], "paragraph_keywords": ["influence", "interactions", "research", "touch"]}, {"paragraph_vector": [-100.042472, -2.805051], "paragraph_keywords": ["shapes", "children", "scent", "experiences"]}, {"paragraph_vector": [-99.044067, -3.212978], "paragraph_keywords": ["design", "modalities", "people", "interaction"]}, {"paragraph_vector": [-99.395034, -2.290943], "paragraph_keywords": ["shapes", "correspondences", "demonstrated", "found"]}, {"paragraph_vector": [-99.973068, -3.165037], "paragraph_keywords": ["emotions", "stimuli", "correspondences", "valence"]}, {"paragraph_vector": [-97.789985, -2.855841], "paragraph_keywords": ["smell", "hci", "emotion", "stimuli"]}, {"paragraph_vector": [-99.374542, -3.329023], "paragraph_keywords": ["shapes", "associations", "participants", "tasks"]}, {"paragraph_vector": [-95.958671, -3.797035], "paragraph_keywords": ["scent", "participants", "air", "stimuli"]}, {"paragraph_vector": [-104.225463, 4.531417], "paragraph_keywords": ["shapes", "boxes", "shape", "participants"]}, {"paragraph_vector": [-100.797691, -4.067278], "paragraph_keywords": ["associations", "scale", "experimenter", "scent"]}, {"paragraph_vector": [-98.025917, -2.799362], "paragraph_keywords": ["scent", "shape", "differences", "tests"]}, {"paragraph_vector": [-99.250968, -3.321817], "paragraph_keywords": ["participants", "smell", "shape", "association"]}, {"paragraph_vector": [-100.819755, -1.784784], "paragraph_keywords": ["shapes", "associations", "bouba", "kiki"]}, {"paragraph_vector": [-99.739112, -2.238193], "paragraph_keywords": ["scent", "shape", "bouba", "effect"]}, {"paragraph_vector": [-99.849159, -3.14441], "paragraph_keywords": ["scent", "exposure", "effect", "shapes"]}, {"paragraph_vector": [-98.770477, -2.687176], "paragraph_keywords": ["scent", "scents", "strategies", "dimensions"]}, {"paragraph_vector": [-101.019638, -0.456653], "paragraph_keywords": ["design", "shape", "approaches", "storytelling"]}, {"paragraph_vector": [-102.376899, -1.972492], "paragraph_keywords": ["children", "schools", "technologies", "storytelling"]}, {"paragraph_vector": [-102.697639, 0.876054], "paragraph_keywords": ["research", "design", "ssds", "bouba"]}, {"paragraph_vector": [-100.859184, -4.09479], "paragraph_keywords": ["stimuli", "olfactory", "story", "shapes"]}, {"paragraph_vector": [-101.498832, -2.352824], "paragraph_keywords": ["scent", "design", "children", "shapes"]}], "content": {}, "doi": "10.1145/3290605.3300840"}, {"uri": "181", "title": "VelociWatch: Designing and Evaluating a Virtual Keyboard for the Input of Challenging Text", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Keith Vertanen", "Dylan Gaines", "Crystal Fletcher", "Alex M. Stanage", "Robbie Watling", "Per Ola Kristensson"], "summary": "Virtual keyboard typing is typically aided by an auto-correct method that decodes a user\u2019s noisy taps into their intended text. This decoding process can reduce error rates and possibly increase entry rates by allowing users to type faster but less precisely. However, virtual keyboard decoders sometimes make mistakes that change a user\u2019s desired word into another. This is particularly problematic for challenging text such as proper names. We investigate whether users can guess words that are likely to cause auto-correct problems and whether users can adjust their behavior to assist the decoder. We conduct computational experiments to decide what predictions to ofer in a virtual keyboard and design a smartwatch keyboard named VelociWatch. Novice users were able to use the features of VelociWatch to enter challenging text at 17 words-per-minute with a corrected error rate of 3%. Interestingly, they wrote slightly faster and just as accurately on a simpler keyboard with limited correction options. Our fnding suggest users may be able to type diffcult words on a smartwatch simply by tapping precisely without the use of auto-correct.", "keywords": ["based", "lock", "time", "tap", "correction", "condition", "set", "performance", "sentence", "oov", "selection", "feature", "design", "rate", "experiment", "error", "entry", "decoder", "keyboard", "user", "model", "smartwatch", "work", "word", "language", "result", "participant", "use", "screen", "recognition", "phrase", "data", "swipe", "locking", "study", "slot", "text", "typing", "paper", "input", "velociwatch", "letter", "option"], "document_vector": [-54.488491, -60.807056], "paragraphs": [{"paragraph_vector": [-35.922706, -12.395649], "paragraph_keywords": ["text", "input", "copies", "entry"]}, {"paragraph_vector": [-21.452741, -24.18324], "paragraph_keywords": ["text", "language", "decoder", "model"]}, {"paragraph_vector": [-23.358427, -21.948894], "paragraph_keywords": ["decoder", "users", "letter", "user"]}, {"paragraph_vector": [-20.885824, -21.252391], "paragraph_keywords": ["error", "keyboards", "users", "word"]}, {"paragraph_vector": [-16.75745, -23.34394], "paragraph_keywords": ["keyboard", "users", "smartwatch", "text"]}, {"paragraph_vector": [-23.318082, -19.956581], "paragraph_keywords": ["keyboard", "typing", "users", "decoder"]}, {"paragraph_vector": [-21.025566, -23.288534], "paragraph_keywords": ["users", "decoder", "letter", "predict"]}, {"paragraph_vector": [-15.090942, -18.300912], "paragraph_keywords": ["phrases", "based", "phrase", "entry"]}, {"paragraph_vector": [-11.566499, -15.20549], "paragraph_keywords": ["sentences", "phrases", "words", "set"]}, {"paragraph_vector": [-21.578552, -24.823722], "paragraph_keywords": ["experiments", "input", "experiment", "keyboards"]}, {"paragraph_vector": [-23.593513, -21.361551], "paragraph_keywords": ["keyboard", "recognition", "user", "screen"]}, {"paragraph_vector": [-17.627998, -20.374942], "paragraph_keywords": ["tap", "locking", "decoder", "keyboard"]}, {"paragraph_vector": [-19.593954, -25.014516], "paragraph_keywords": ["participants", "phrases", "model", "experiment"]}, {"paragraph_vector": [-17.559516, -19.303709], "paragraph_keywords": ["participants", "phrase", "rate", "error"]}, {"paragraph_vector": [-20.048971, -19.936048], "paragraph_keywords": ["words", "participants", "lock", "locked"]}, {"paragraph_vector": [-18.598751, -21.22339], "paragraph_keywords": ["lock", "feature", "decoder", "words"]}, {"paragraph_vector": [-19.098663, -24.780357], "paragraph_keywords": ["word", "use", "assume", "slots"]}, {"paragraph_vector": [-17.860635, -24.014583], "paragraph_keywords": ["slots", "slot", "performance", "fve"]}, {"paragraph_vector": [-18.733314, -20.624294], "paragraph_keywords": ["slot", "slots", "keyboard", "text"]}, {"paragraph_vector": [-18.886873, -21.18682], "paragraph_keywords": ["text", "slots", "recognition", "area"]}, {"paragraph_vector": [-17.118545, -17.651], "paragraph_keywords": ["participants", "tap", "swipe", "phrases"]}, {"paragraph_vector": [-19.878267, -21.378059], "paragraph_keywords": ["slot", "conditions", "participants", "text"]}, {"paragraph_vector": [-17.049184, -23.267852], "paragraph_keywords": ["participants", "tap", "text", "selected"]}, {"paragraph_vector": [-18.629636, -22.219799], "paragraph_keywords": ["keyboard", "word", "users", "options"]}, {"paragraph_vector": [-18.644313, -19.457252], "paragraph_keywords": ["participants", "condition", "keyboard", "velociwatch"]}, {"paragraph_vector": [-17.313724, -21.774511], "paragraph_keywords": ["participants", "swipe", "velociwatch", "selections"]}, {"paragraph_vector": [-16.657045, -23.271554], "paragraph_keywords": ["participants", "words", "word", "twoslot"]}, {"paragraph_vector": [-23.104232, -18.155458], "paragraph_keywords": ["words", "participants", "entry", "target"]}, {"paragraph_vector": [-18.092182, -23.091838], "paragraph_keywords": ["users", "keyboard", "text", "word"]}, {"paragraph_vector": [-17.674541, -20.970003], "paragraph_keywords": ["keyboard", "velociwatch", "experiments", "slot"]}], "content": {}, "doi": "10.1145/3290605.3300634"}, {"uri": "182", "title": "Dynamic Difficulty Adjustment Impact on Players\u2019 Confidence", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Thomas Constant", "Guillaume Levieux"], "summary": "Difficulty is one of the major motivational pull of video games, and thus many games use Dynamic Difficulty Adjustment (DDA) systems to improve the game experience. This paper describes our research investigating the influence of DDA systems on player\u2019s confidence, evaluated using an in-game bet system. Our hypothesis is that DDA systems may lead players to overconfidence, revealed by an overestimation of their success chances when betting. This boost of confidence may be a part of the positive impact of DDA systems on the quality of game experience. We explain our method to evaluate player\u2019s confidence and implement it into three games related to logical, motor and sensory difficulties. We describe two experimental conditions where difficulty is either randomly chosen or adapted using a DDA algorithm. Results show how DDA systems can lead players to high level of overconfidence.", "keywords": ["success", "based", "condition", "perceived", "time", "chance", "performance", "self", "player", "dda", "psychology", "result", "video", "impact", "motor", "use", "perception", "confidence", "effect", "hypothesis", "challenge", "experience", "difficulty", "estimation", "parameter", "task", "flow", "game", "skill", "square", "system", "overconfidence", "order", "influence", "evaluate", "bet", "motivation", "level"], "document_vector": [-18.054466, -20.389245], "paragraphs": [{"paragraph_vector": [-124.151786, 20.220663], "paragraph_keywords": ["difficulty", "confidence", "copies", "acm"]}, {"paragraph_vector": [-122.395812, 20.791503], "paragraph_keywords": ["difficulty", "challenge", "player", "flow"]}, {"paragraph_vector": [-122.52143, 18.797782], "paragraph_keywords": ["difficulty", "player", "games", "confidence"]}, {"paragraph_vector": [-122.134216, 19.550142], "paragraph_keywords": ["difficulty", "player", "effort", "challenge"]}, {"paragraph_vector": [-124.42517, 20.84316], "paragraph_keywords": ["difficulty", "player", "challenge", "impact"]}, {"paragraph_vector": [-124.895622, 18.279405], "paragraph_keywords": ["players", "game", "difficulty", "challenge"]}, {"paragraph_vector": [-123.875915, 20.843864], "paragraph_keywords": ["players", "systems", "dda", "link"]}, {"paragraph_vector": [-126.439277, 20.373603], "paragraph_keywords": ["confidence", "difficulty", "task", "games"]}, {"paragraph_vector": [-123.956321, 21.380533], "paragraph_keywords": ["players", "player", "confidence", "success"]}, {"paragraph_vector": [-125.304656, 19.231916], "paragraph_keywords": ["difficulty", "player", "game", "gap"]}, {"paragraph_vector": [-124.210296, 20.255523], "paragraph_keywords": ["players", "challenge", "difficulty", "player"]}, {"paragraph_vector": [-127.604026, 18.512855], "paragraph_keywords": ["participants", "game", "based", "games"]}, {"paragraph_vector": [-101.158065, 25.931348], "paragraph_keywords": ["squares", "grid", "difficulty", "players"]}, {"paragraph_vector": [-122.443008, 14.292463], "paragraph_keywords": ["players", "game", "betting", "difficulty"]}, {"paragraph_vector": [-123.883453, 16.570224], "paragraph_keywords": ["difficulty", "players", "effect", "game"]}, {"paragraph_vector": [-125.162368, 17.313083], "paragraph_keywords": ["difficulty", "players", "perceived", "conditions"]}, {"paragraph_vector": [-123.533668, 18.969472], "paragraph_keywords": ["difficulty", "condition", "game", "perceived"]}, {"paragraph_vector": [-123.64463, 17.938489], "paragraph_keywords": ["difficulty", "effect", "players", "game"]}, {"paragraph_vector": [-121.110504, 18.725997], "paragraph_keywords": ["difficulty", "players", "chances", "player"]}, {"paragraph_vector": [-124.077186, 17.677904], "paragraph_keywords": ["difficulty", "players", "decision", "estimation"]}, {"paragraph_vector": [-123.389739, 18.871488], "paragraph_keywords": ["players", "difficulty", "confidence", "player"]}, {"paragraph_vector": [-123.445739, 18.920869], "paragraph_keywords": ["difficulty", "game", "effect", "players"]}, {"paragraph_vector": [-124.145309, 19.021846], "paragraph_keywords": ["difficulty", "player", "impact", "confidence"]}, {"paragraph_vector": [73.41893, 33.984638], "paragraph_keywords": ["paper", "page", "help"]}], "content": {}, "doi": "10.1145/3290605.3300890"}, {"uri": "183", "title": "The Heat is On: Exploring User Behaviour in a Multisensory Virtual Environment for Fire Evacuation", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Emily Shaw"], "summary": "Understanding validity of user behaviour in Virtual Environments (VEs) is critical as they are increasingly being used for serious Health and Safety applications such as predicting human behaviour and training in hazardous situations. This paper presents a comparative study exploring user behaviour in VE-based fire evacuation and investigates whether this is affected by the addition of thermal and olfactory simulation. Participants (N=43) were exposed to a virtual fire in an office building. Quantitative and qualitative analyses of participant attitudes and behaviours found deviations from those we would expect in real life (e.g. pre-evacuation actions), but also valid behaviours like fire avoidance. Potentially important differences were found between multisensory and audiovisual-only conditions (e.g. perceived urgency). We conclude VEs have significant potential in safety-related applications, and that multimodality may afford additional uses in this context, but the identified limitations of behavioural validity must be carefully considered to avoid misapplication of the technology.", "keywords": ["smell", "based", "vr", "condition", "perceived", "av", "time", "emergency", "door", "behaviour", "training", "validity", "safety", "fire", "example", "simulation", "user", "interaction", "risk", "work", "building", "scenario", "increased", "participant", "use", "people", "m", "world", "think", "route", "finding", "experience", "page", "fragrance", "feedback", "-", "incident", "ve", "task", "data", "heat", "study", "room", "situation", "research", "evacuation", "exit", "paper", "action", "level", "f", "response"], "document_vector": [153.977706, -35.437137], "paragraphs": [{"paragraph_vector": [-97.47187, -10.51292], "paragraph_keywords": ["fire", "copies", "incidents", "studies"]}, {"paragraph_vector": [-95.720214, -13.360592], "paragraph_keywords": ["behaviour", "ves", "fire", "research"]}, {"paragraph_vector": [-97.59082, -13.639885], "paragraph_keywords": ["ve", "fire", "simulation", "behaviours"]}, {"paragraph_vector": [-93.442489, -12.83423], "paragraph_keywords": ["fire", "feedback", "ve", "evacuation"]}, {"paragraph_vector": [-96.730209, -14.481003], "paragraph_keywords": ["people", "ve", "evacuation", "fire"]}, {"paragraph_vector": [-92.879066, -11.077668], "paragraph_keywords": ["heat", "hardware", "ve", "designed"]}, {"paragraph_vector": [-93.162521, -11.564749], "paragraph_keywords": ["scent", "heat", "delivery", "fragrance"]}, {"paragraph_vector": [-97.950065, -16.049955], "paragraph_keywords": ["fire", "smell", "user", "users"]}, {"paragraph_vector": [-93.761459, -11.941926], "paragraph_keywords": ["evacuation", "experience", "task", "participants"]}, {"paragraph_vector": [-95.314857, -6.468105], "paragraph_keywords": ["participants", "data", "information", "control"]}, {"paragraph_vector": [-92.76873, -13.887876], "paragraph_keywords": ["task", "building", "fire", "participants"]}, {"paragraph_vector": [-94.743484, -15.056065], "paragraph_keywords": ["fire", "actions", "evacuation", "participants"]}, {"paragraph_vector": [-95.078002, -13.74867], "paragraph_keywords": ["evacuation", "time", "participants", "times"]}, {"paragraph_vector": [-96.13034, -15.850676], "paragraph_keywords": ["fire", "participants", "route", "room"]}, {"paragraph_vector": [-98.052078, -13.222786], "paragraph_keywords": ["fire", "room", "participants", "analysed"]}, {"paragraph_vector": [-94.834831, -13.092438], "paragraph_keywords": ["participants", "fire", "risk", "behaviour"]}, {"paragraph_vector": [-93.285255, -13.476139], "paragraph_keywords": ["fire", "example", "ms", "participant"]}, {"paragraph_vector": [-93.884002, -10.744163], "paragraph_keywords": ["fire", "participants", "ms", "av"]}, {"paragraph_vector": [-96.028541, -14.748884], "paragraph_keywords": ["fire", "behaviours", "participants", "risk"]}, {"paragraph_vector": [-97.328254, -16.097452], "paragraph_keywords": ["fire", "evacuation", "ve", "participants"]}, {"paragraph_vector": [-96.24028, -15.416522], "paragraph_keywords": ["ve", "actions", "safety", "behaviours"]}, {"paragraph_vector": [-95.242378, -14.108819], "paragraph_keywords": ["behaviour", "ve", "behaviours", "fire"]}, {"paragraph_vector": [-95.417449, -5.631871], "paragraph_keywords": ["user", "senses", "users", "risk"]}, {"paragraph_vector": [-95.961082, -14.268475], "paragraph_keywords": ["fire", "people", "scenario", "interaction"]}, {"paragraph_vector": [-87.8199, -17.967941], "paragraph_keywords": ["work", "reviewers", "building", "acs"]}], "content": {}, "doi": "10.1145/3290605.3300420"}, {"uri": "184", "title": "From Gender Biases to Gender-Inclusive Design:   An Empirical Investigation", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Mihaela Vorvoreanu", "Lingyi Zhang", "Yun-Han Huang", "Claudia Hilderbrand", "Zoe Steine-Hanson", "Margaret Burnett"], "summary": "In recent years, research has revealed gender biases in numerous software products. But although some researchers have found ways to improve gender participation in specific software projects, general methods focus mainly on detecting gender biases\u2014not fixing them. To help fill this gap, we investigated whether the GenderMag bias detection method can lead directly to designs with fewer gender biases. In our 3-step investigation, two HCI researchers analyzed an industrial software product using GenderMag; we derived design changes to the product using the biases they found; and ran an empirical study of participants using the original product versus the new version. The results showed that using the method in this way did improve the software\u2019s inclusiveness: women succeeded more often in the new version than in the original; men\u2019s success rates improved too; and the gender gap entirely disappeared.", "keywords": ["process", "subgoal", "abby", "information", "analyst", "facet", "design", "style", "method", "analysis", "problem", "example", "gender", "woman", "tim", "result", "product", "participant", "use", "issue", "learning", "step", "page", "identified", "men", "table", "data", "research", "gendermag", "difference", "bias", "software", "paper", "filter", "microsoft", "inclusiveness", "value", "action", "figure"], "document_vector": [-109.762268, 42.555496], "paragraphs": [{"paragraph_vector": [82.756294, 21.111087], "paragraph_keywords": ["biases", "step", "gender", "software"]}, {"paragraph_vector": [82.616897, 18.264577], "paragraph_keywords": ["software", "gender", "methods", "inclusiveness"]}, {"paragraph_vector": [83.607559, 16.776851], "paragraph_keywords": ["women", "category", "software", "approach"]}, {"paragraph_vector": [83.22969, 15.192143], "paragraph_keywords": ["gender", "method", "software", "facets"]}, {"paragraph_vector": [88.347511, 21.826517], "paragraph_keywords": ["product", "microsoft", "conducted", "analysis"]}, {"paragraph_vector": [81.336509, 16.457702], "paragraph_keywords": ["abby", "issue", "identified", "tim"]}, {"paragraph_vector": [83.573326, 17.815744], "paragraph_keywords": ["participants", "fidelity", "paper", "field"]}, {"paragraph_vector": [85.267456, 18.160272], "paragraph_keywords": ["participants", "facets", "abby", "participant"]}, {"paragraph_vector": [83.443389, 18.122468], "paragraph_keywords": ["participants", "issues", "value", "participant"]}, {"paragraph_vector": [84.785316, 17.285482], "paragraph_keywords": ["issues", "abby", "tim", "facet"]}, {"paragraph_vector": [82.669433, 17.251754], "paragraph_keywords": ["abby", "tim", "motivations", "learning"]}, {"paragraph_vector": [80.235343, 23.848752], "paragraph_keywords": ["abby", "information", "tim", "filter"]}, {"paragraph_vector": [82.276451, 24.176233], "paragraph_keywords": ["abby", "tim", "information", "style"]}, {"paragraph_vector": [87.04084, 21.670967], "paragraph_keywords": ["participants", "institution", "facets", "participant"]}, {"paragraph_vector": [86.431259, 18.12783], "paragraph_keywords": ["feedback", "analysts", "issue", "issues"]}, {"paragraph_vector": [82.47158, 19.86384], "paragraph_keywords": ["issue", "tim", "information", "abby"]}, {"paragraph_vector": [84.160675, 16.522413], "paragraph_keywords": ["gendermag", "issues", "gender", "analysts"]}, {"paragraph_vector": [84.103515, 17.15661], "paragraph_keywords": ["facets", "gender", "participants", "data"]}, {"paragraph_vector": [81.638252, 18.256004], "paragraph_keywords": ["gender", "software", "differences", "genders"]}, {"paragraph_vector": [84.360054, 16.39229], "paragraph_keywords": ["gender", "participants", "software", "results"]}], "content": {}, "doi": "10.1145/3290605.3300723"}, {"uri": "185", "title": "The Effect of Stereo Display Deficiencies on Virtual Hand Pointing", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Mayra Donaji Barrera", "Wolfgang Stuerzlinger"], "summary": "The limitations of stereo display systems affect depth perception, e.g., due to the vergence-accommodation conflict or diplopia. We performed three studies to understand how stereo display deficiencies impact 3D pointing for targets in front of a screen and close to the user, i.e., in peripersonal space. Our first two experiments compare movements with and without a change in visual depth for virtual respectively physical targets. Results indicate that selecting targets along the depth axis is slower and has less throughput for virtual targets, while physical pointing demonstrates the opposite result. We then propose a new 3D extension for Fitts\u2019 law that models the effect of stereo display deficiencies. Next, our third experiment verifies the model and measures more broadly how the change in visual depth between targets affects pointing performance in peripersonal space and confirms significant effects on time and throughput. Finally, we discuss implications for 3D user interface design.", "keywords": ["direction", "based", "time", "change", "performance", "selection", "display", "fitts", "pointing", "model", "user", "eye", "work", "result", "law", "movement", "participant", "perception", "effect", "deficiency", "screen", "cm", "stereo", "found", "identified", "distance", "hand", "vergence", "data", "study", "d", "system", "target", "difference", "view", "depth", "figure"], "document_vector": [-157.817611, -58.065155], "paragraphs": [{"paragraph_vector": [-45.677612, 4.930034], "paragraph_keywords": ["copies", "objects", "stereo", "use"]}, {"paragraph_vector": [-48.784458, 1.368545], "paragraph_keywords": ["selection", "depth", "targets", "user"]}, {"paragraph_vector": [-47.48653, 0.288213], "paragraph_keywords": ["depth", "affect", "stereo", "model"]}, {"paragraph_vector": [-48.306427, 1.572795], "paragraph_keywords": ["depth", "pointing", "hand", "stereo"]}, {"paragraph_vector": [-44.96099, 5.057711], "paragraph_keywords": ["depth", "target", "accommodation", "distances"]}, {"paragraph_vector": [-48.933673, 0.043952], "paragraph_keywords": ["depth", "target", "found", "distance"]}, {"paragraph_vector": [-45.76062, 2.413463], "paragraph_keywords": ["plane", "throughput", "law", "fitts"]}, {"paragraph_vector": [-49.71413, 3.059141], "paragraph_keywords": ["target", "depth", "wand", "stereo"]}, {"paragraph_vector": [-48.307331, 4.220691], "paragraph_keywords": ["targets", "participants", "target", "screen"]}, {"paragraph_vector": [-29.61425, 25.033231], "paragraph_keywords": ["targets", "participants", "target", "task"]}, {"paragraph_vector": [-32.477603, 24.251783], "paragraph_keywords": ["data", "direction", "analyzed", "movement"]}, {"paragraph_vector": [-32.132736, 23.3239], "paragraph_keywords": ["movements", "direction", "depth", "view"]}, {"paragraph_vector": [-49.516811, 0.542112], "paragraph_keywords": ["study", "movement", "targets", "effect"]}, {"paragraph_vector": [-45.593982, 20.675704], "paragraph_keywords": ["target", "study", "pointing", "targets"]}, {"paragraph_vector": [-33.202625, 24.009822], "paragraph_keywords": ["target", "participants", "direction", "error"]}, {"paragraph_vector": [-32.238319, 20.331933], "paragraph_keywords": ["movements", "direction", "effect", "figure"]}, {"paragraph_vector": [-48.205219, 0.020299], "paragraph_keywords": ["movements", "study", "results", "difference"]}, {"paragraph_vector": [-47.271247, 1.726796], "paragraph_keywords": ["movement", "difference", "study", "work"]}, {"paragraph_vector": [-46.287273, 1.587562], "paragraph_keywords": ["ctd", "models", "d", "study"]}, {"paragraph_vector": [-28.482105, 26.369094], "paragraph_keywords": ["target", "participants", "direction", "targets"]}, {"paragraph_vector": [-31.519601, 25.797327], "paragraph_keywords": ["data", "target", "ctd", "results"]}, {"paragraph_vector": [-46.079555, 3.697382], "paragraph_keywords": ["model", "cm", "depth", "target"]}, {"paragraph_vector": [-46.500984, 1.730887], "paragraph_keywords": ["depth", "movements", "pointing", "study"]}, {"paragraph_vector": [-47.227897, 0.995091], "paragraph_keywords": ["model", "displays", "stereo", "distance"]}, {"paragraph_vector": [-47.099014, 3.261097], "paragraph_keywords": ["stereo", "hand", "pointing", "performance"]}, {"paragraph_vector": [-47.328437, 0.47396], "paragraph_keywords": ["depth", "vergence", "accommodation", "investigate"]}], "content": {}, "doi": "10.1145/3290605.3300355"}, {"uri": "186", "title": "Trolled by the Trolley Problem", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Alexander G. Mirnig", "Alexander Meschtscherjakov"], "summary": "Automated vehicles have to make decisions, such as driving maneuvers or rerouting, based on environment data and decision algorithms. There is a question whether ethical aspects should be considered in these algorithms. When all available decisions within a situation have fatal consequences, this leads to a dilemma. Contemporary discourse surrounding this issue is dominated by the trolley problem, a specifc version of such a dilemma. Based on an outline of its origins, we discuss the trolley problem and its viability to help Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proft or commercial advantage and that copies bear this notice and the full citation on the frst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specifc permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300739 solve the questions regarding ethical decision making in automated vehicles. We show that the trolley problem serves several important functions but is an ill-suited benchmark for the success or failure of an automated algorithm. We argue that research and design should focus on avoiding trolley-like problems at all rather than trying to solve an unsolvable dilemma and discuss alternative approaches on how to feasibly address ethical issues in automated agents.", "keywords": ["based", "position", "strategy", "information", "consequence", "intention", "provide", "problem", "example", "vehicle", "decision", "people", "way", "mean", "calculus", "automated", "agent", "norm", "life", "case", "technology", "solution", "situation", "dilemma", "trolley", "choice", "morality", "machine", "driver", "outcome", "individual", "hci", "paper", "question", "driving", "kill", "action", "level", "context", "making"], "document_vector": [-105.493286, -22.008535], "paragraphs": [{"paragraph_vector": [9.290272, -9.033964], "paragraph_keywords": ["automated", "vehicle", "technology", "trolley"]}, {"paragraph_vector": [8.220127, -10.400748], "paragraph_keywords": ["vehicle", "problem", "trolley", "automated"]}, {"paragraph_vector": [7.448562, -12.889691], "paragraph_keywords": ["trolley", "problem", "robots", "hci"]}, {"paragraph_vector": [7.856917, -11.796191], "paragraph_keywords": ["vehicles", "automated", "vehicle", "driving"]}, {"paragraph_vector": [7.206634, -12.609865], "paragraph_keywords": ["automated", "vehicle", "vehicles", "decisions"]}, {"paragraph_vector": [7.147931, -12.656782], "paragraph_keywords": ["problem", "trolley", "track", "individuals"]}, {"paragraph_vector": [6.224723, -12.943021], "paragraph_keywords": ["dilemma", "trolley", "dilemmas", "action"]}, {"paragraph_vector": [9.077664, -13.059073], "paragraph_keywords": ["position", "morality", "society", "sense"]}, {"paragraph_vector": [7.795489, -15.238924], "paragraph_keywords": ["norms", "norm", "individual", "situation"]}, {"paragraph_vector": [6.957495, -12.54799], "paragraph_keywords": ["dilemma", "topic", "dilemmas", "problem"]}, {"paragraph_vector": [6.413575, -13.90138], "paragraph_keywords": ["norm", "choice", "priority", "action"]}, {"paragraph_vector": [6.883422, -14.433152], "paragraph_keywords": ["action", "agent", "intentions", "save"]}, {"paragraph_vector": [6.331326, -13.674084], "paragraph_keywords": ["dilemma", "agent", "dilemmas", "drive"]}, {"paragraph_vector": [7.10097, -12.668276], "paragraph_keywords": ["situation", "calculus", "solution", "calculate"]}, {"paragraph_vector": [6.672927, -13.409578], "paragraph_keywords": ["vehicle", "intentions", "strategy", "dilemma"]}, {"paragraph_vector": [5.464073, -14.636917], "paragraph_keywords": ["trolley", "dilemma", "information", "place"]}, {"paragraph_vector": [7.874501, -12.703042], "paragraph_keywords": ["problem", "dilemma", "trolley", "dilemmas"]}, {"paragraph_vector": [6.738633, -12.454532], "paragraph_keywords": ["dilemma", "problem", "kill", "decision"]}, {"paragraph_vector": [6.792889, -11.968729], "paragraph_keywords": ["trolley", "problem", "dilemma", "decision"]}, {"paragraph_vector": [8.643805, -11.831543], "paragraph_keywords": ["vehicle", "decision", "sensor", "capabilities"]}, {"paragraph_vector": [9.211516, -10.457745], "paragraph_keywords": ["trolley", "problem", "automated", "vehicle"]}, {"paragraph_vector": [9.270649, -12.507091], "paragraph_keywords": ["decision", "trolley", "problem", "austrian"]}], "content": {}, "doi": "10.1145/3290605.3300527"}, {"uri": "187", "title": "Exploring the Opportunities for Technologies to Enhance Quality of Life with People who have Experienced Vision Loss", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Rachel Bartlett", "Yi Xuan Khoo"], "summary": "Research predicts that 196 million people will be diagnosed with Age-Related Macular Degeneration (AMD) by 2020. People who experience AMD and other vision loss face barriers that affect their Quality of Life (QoL). People experience only modest improvement from technologies (e.g., screen readers, CCTV), tools (e.g., magnifying glasses, tactile buttons), and human help (e.g., friends, blindness organizations). Further, there are issues to accessing these resources based on one\u2019s place of residence. To explore these challenges and determine design implications to support people who have experienced vision loss (PVL), we conducted a qualitative semi-structured interview study exploring QoL with 10 PVL. We uncovered themes of supporting creative work, recognizing the impact of one\u2019s living in a non-urban setting on QoL, and increasing efficiency at accomplishing tasks. We motivate the inclusion of PVL in the design process because they learned skills while sighted and are now low vision or blind.", "keywords": ["qol", "reading", "time", "mentioned", "vision", "pvl", "design", "interview", "example", "help", "activity", "accessibility", "et", "work", "read", "impact", "participant", "use", "tool", "people", "list", "service", "art", "page", "loss", "including", "efficiency", "search", "item", "technology", "researcher", "solution", "support", "research", "paper", "affected"], "document_vector": [174.75093, -41.356307], "paragraphs": [{"paragraph_vector": [-138.062088, 43.147769], "paragraph_keywords": ["people", "vision", "copies", "health"]}, {"paragraph_vector": [-138.430496, 41.706462], "paragraph_keywords": ["pvl", "vision", "loss", "qol"]}, {"paragraph_vector": [-140.999618, 44.065364], "paragraph_keywords": ["interviews", "vision", "participants", "loss"]}, {"paragraph_vector": [-135.727523, 43.57146], "paragraph_keywords": ["list", "product", "table", "technology"]}, {"paragraph_vector": [-140.736038, 43.308963], "paragraph_keywords": ["people", "participants", "items", "accessibility"]}, {"paragraph_vector": [-147.496658, 35.723594], "paragraph_keywords": ["including", "counting", "accessibility", "capacity"]}, {"paragraph_vector": [-28.680078, 1.124557], "paragraph_keywords": ["text", "mouse", "nvda", "cursor"]}, {"paragraph_vector": [-126.420654, 35.512443], "paragraph_keywords": ["art", "continue", "vision", "activities"]}, {"paragraph_vector": [-131.445358, 40.933761], "paragraph_keywords": ["people", "mentioned", "created", "solutions"]}, {"paragraph_vector": [-147.379241, -65.144371], "paragraph_keywords": ["solutions", "town", "grocery", "people"]}, {"paragraph_vector": [-169.722702, 47.875003], "paragraph_keywords": ["reading", "vision", "speed", "read"]}, {"paragraph_vector": [-143.8134, 41.217201], "paragraph_keywords": ["pvl", "reading", "participants", "research"]}, {"paragraph_vector": [-135.030151, 40.635803], "paragraph_keywords": ["work", "support", "design", "pvl"]}], "content": {}, "doi": "10.1145/3290605.3300501"}, {"uri": "188", "title": "User Attitudes towards Algorithmic Opacity and Transparency in Online Reviewing Platforms", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Motahhare Eslami", "Kristen Vaccaro", "Min Kyung Lee", "Amit Elazari"], "summary": "Algorithms exert great power in curating online information, yet are often opaque in their operation, and even existence. Since opaque algorithms sometimes make biased or deceptive decisions, many have called for increased transparency. However, little is known about how users perceive and interact with potentially biased and deceptive opaque algorithms. What factors are associated with these perceptions, and how does adding transparency into algorithmic systems change user attitudes? To address these questions, we conducted two studies: 1) an analysis of 242 users\u2019 online discussions about the Yelp review filtering algorithm and 2) an interview study with 15 Yelp users disclosing the algorithm\u2019s existence via a tool. We found that users question or defend this algorithm and its opacity depending on their engagement with and personal gain from the algorithm. We also found adding transparency into the algorithm changed users\u2019 attitudes towards the algorithm: users reported their intention to either write for the algorithm in future reviews or leave the platform.", "keywords": ["process", "time", "change", "discussion", "design", "attitude", "analysis", "provide", "example", "help", "user", "engagement", "review", "know", "theory", "work", "result", "impact", "participant", "existence", "use", "people", "operation", "perception", "way", "factor", "algorithm", "page", "adding", "found", "reviewer", "business", "understand", "suggested", "want", "advertising", "transparency", "study", "researcher", "filtering", "owner", "system", "yelp", "opacity", "platform", "argued", "bias", "paper", "interface", "filtered", "filter", "rating", "asked", "making"], "document_vector": [-56.942207, 19.337217], "paragraphs": [{"paragraph_vector": [30.912172, 1.008867], "paragraph_keywords": ["users", "copies", "opacity", "acm"]}, {"paragraph_vector": [28.549531, 2.810359], "paragraph_keywords": ["users", "algorithm", "yelp", "algorithms"]}, {"paragraph_vector": [31.633352, 1.150764], "paragraph_keywords": ["users", "algorithm", "algorithms", "system"]}, {"paragraph_vector": [27.494695, 1.2717], "paragraph_keywords": ["transparency", "users", "opacity", "algorithm"]}, {"paragraph_vector": [25.343669, 2.871448], "paragraph_keywords": ["users", "business", "reviews", "yelp"]}, {"paragraph_vector": [24.32908, 3.828788], "paragraph_keywords": ["yelp", "algorithm", "users", "opacity"]}, {"paragraph_vector": [31.563983, 4.715634], "paragraph_keywords": ["algorithm", "users", "yelp", "discussion"]}, {"paragraph_vector": [31.368225, -0.067366], "paragraph_keywords": ["users", "algorithm", "review", "filtered"]}, {"paragraph_vector": [26.086755, 3.466822], "paragraph_keywords": ["participants", "review", "yelp", "users"]}, {"paragraph_vector": [26.592372, 2.687292], "paragraph_keywords": ["users", "algorithm", "review", "asked"]}, {"paragraph_vector": [32.978099, -0.789816], "paragraph_keywords": ["users", "yelp", "themes", "algorithm"]}, {"paragraph_vector": [26.340686, 2.230058], "paragraph_keywords": ["users", "yelp", "filtering", "filtered"]}, {"paragraph_vector": [27.219615, 3.750248], "paragraph_keywords": ["reviews", "users", "algorithm", "robot"]}, {"paragraph_vector": [28.000928, 2.934142], "paragraph_keywords": ["yelp", "users", "filter", "reviews"]}, {"paragraph_vector": [25.273662, 2.185334], "paragraph_keywords": ["reviews", "algorithm", "yelp", "review"]}, {"paragraph_vector": [26.811126, 2.333508], "paragraph_keywords": ["yelp", "algorithm", "users", "filtered"]}, {"paragraph_vector": [27.678529, 2.081884], "paragraph_keywords": ["operation", "yelp", "algorithm", "users"]}, {"paragraph_vector": [30.754405, 2.851681], "paragraph_keywords": ["users", "reviews", "theories", "yelp"]}, {"paragraph_vector": [25.338716, 1.886021], "paragraph_keywords": ["algorithm", "review", "reviews", "filter"]}, {"paragraph_vector": [24.821611, 3.626478], "paragraph_keywords": ["reviews", "users", "algorithm", "review"]}, {"paragraph_vector": [24.653709, 2.272979], "paragraph_keywords": ["yelp", "reviews", "business", "filtered"]}, {"paragraph_vector": [25.598302, 4.768494], "paragraph_keywords": ["algorithm", "users", "reviews", "filtered"]}, {"paragraph_vector": [25.109289, 1.795378], "paragraph_keywords": ["algorithm", "yelp", "reviews", "operation"]}, {"paragraph_vector": [32.902034, 0.650541], "paragraph_keywords": ["algorithm", "user", "users", "stance"]}, {"paragraph_vector": [31.363094, 1.342235], "paragraph_keywords": ["users", "algorithm", "user", "yelp"]}, {"paragraph_vector": [26.976003, 3.212698], "paragraph_keywords": ["reviews", "algorithm", "business", "review"]}, {"paragraph_vector": [29.98863, 1.652101], "paragraph_keywords": ["data", "users", "yelp", "use"]}, {"paragraph_vector": [30.085596, 2.391203], "paragraph_keywords": ["algorithm", "users", "existence", "transparency"]}, {"paragraph_vector": [27.817462, 1.803267], "paragraph_keywords": ["algorithm", "yelp", "operation", "impacts"]}, {"paragraph_vector": [26.44556, 2.872199], "paragraph_keywords": ["users", "work", "platform", "algorithm"]}, {"paragraph_vector": [32.443344, 1.465227], "paragraph_keywords": ["users", "systems", "algorithm", "system"]}, {"paragraph_vector": [31.54906, 2.576411], "paragraph_keywords": ["design", "opacity", "systems", "complicating"]}], "content": {}, "doi": "10.1145/3290605.3300274"}, {"uri": "189", "title": "On the Shoulder of the Giant: A Multi-Scale Mixed Reality Collaboration with 360 Video Sharing and Tangible Interaction", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Thammathip Piumsomboon", "Gun A. Lee", "Andrew Irlitti", "Barrett Ens", "Bruce H. Thomas", "Mark Billinghurst"], "summary": "We propose a multi-scale Mixed Reality (MR) collaboration between the Giant, a local Augmented Reality user, and the Miniature, a remote Virtual Reality user, in Giant-Miniature Collaboration (GMC). The Miniature is immersed in a 360-video shared by the Giant who can physically manipulate the Miniature through a tangible interface, a combined 360-camera with a 6 DOF tracker. We implemented a prototype system as a proof of concept and conducted a user study (n=24) comprising of four parts comparing: A) two types of virtual representations, B) three levels of Miniature control, C) three levels of 360-video view dependencies, and D) four 360-camera placement positions on the Giant. The results show users prefer a shoulder mounted camera view, while a view frustum with a complimentary avatar is a good visualization for the Miniature virtual representation. From the results, we give design recommendations and demonstrate an example Giant-Miniature Interaction.", "keywords": ["vr", "condition", "frustum", "object", "design", "gmc", "environment", "camera", "user", "interaction", "sharing", "communication", "shared", "result", "video", "space", "participant", "cue", "actor", "control", "page", "presence", "collaboration", "collaborator", "found", "level", "head", "representation", "avatar", "scale", "task", "attention", "mr", "hand", "study", "room", "system", "ar", "viewing", "research", "view", "mode", "giant", "paper", "panorama", "miniature", "figure"], "document_vector": [150.731826, -33.091129], "paragraphs": [{"paragraph_vector": [-67.428092, 40.46125], "paragraph_keywords": ["collaboration", "sharing", "offers", "user"]}, {"paragraph_vector": [-68.798675, 39.456718], "paragraph_keywords": ["user", "collaboration", "video", "sharing"]}, {"paragraph_vector": [-58.958164, 39.954437], "paragraph_keywords": ["sharing", "camera", "video", "cues"]}, {"paragraph_vector": [-65.608215, 40.226921], "paragraph_keywords": ["panorama", "shared", "sharing", "users"]}, {"paragraph_vector": [-72.716293, 40.332061], "paragraph_keywords": ["collaboration", "vr", "users", "scales"]}, {"paragraph_vector": [-71.075996, 37.884243], "paragraph_keywords": ["user", "collaboration", "ar", "panorama"]}, {"paragraph_vector": [-67.05735, 39.940788], "paragraph_keywords": ["camera", "giant", "vr", "user"]}, {"paragraph_vector": [-76.266578, 39.807369], "paragraph_keywords": ["user", "vr", "avatar", "giant"]}, {"paragraph_vector": [-75.776367, 39.028083], "paragraph_keywords": ["giant", "miniature", "participants", "figure"]}, {"paragraph_vector": [-69.335304, 33.543041], "paragraph_keywords": ["study", "figure", "b", "space"]}, {"paragraph_vector": [-71.87255, 42.2733], "paragraph_keywords": ["study", "frustum", "giant", "avatar"]}, {"paragraph_vector": [-0.312255, 46.72533], "paragraph_keywords": ["object", "task", "interest", "participants"]}, {"paragraph_vector": [-6.237046, 43.958076], "paragraph_keywords": ["frustum", "errors", "tct", "condition"]}, {"paragraph_vector": [-5.513148, 45.631668], "paragraph_keywords": ["frustum", "cop", "msg", "avatar"]}, {"paragraph_vector": [-70.254508, 40.157852], "paragraph_keywords": ["frustum", "task", "avatar", "view"]}, {"paragraph_vector": [-13.819998, 46.094413], "paragraph_keywords": ["avatar", "participants", "control", "representation"]}, {"paragraph_vector": [-1.014627, 43.992965], "paragraph_keywords": ["object", "participants", "control", "task"]}, {"paragraph_vector": [-1.721484, 43.769004], "paragraph_keywords": ["condition", "yielded", "msg", "control"]}, {"paragraph_vector": [-63.607189, 35.959247], "paragraph_keywords": ["video", "control", "view", "study"]}, {"paragraph_vector": [-66.228233, 30.221271], "paragraph_keywords": ["video", "camera", "presence", "task"]}, {"paragraph_vector": [-62.546295, 30.12021], "paragraph_keywords": ["condition", "video", "dependency", "order"]}, {"paragraph_vector": [-62.172096, 31.145315], "paragraph_keywords": ["condition", "movement", "difference", "results"]}, {"paragraph_vector": [-56.772617, 37.98764], "paragraph_keywords": ["positions", "camera", "task", "hand"]}, {"paragraph_vector": [-71.776496, 28.547639], "paragraph_keywords": ["user", "camera", "participants", "house"]}, {"paragraph_vector": [-69.871765, 40.038311], "paragraph_keywords": ["user", "control", "ar", "having"]}, {"paragraph_vector": [-64.443939, 36.677185], "paragraph_keywords": ["participants", "camera", "control", "study"]}, {"paragraph_vector": [-62.071842, 38.24686], "paragraph_keywords": ["study", "gmc", "participants", "video"]}, {"paragraph_vector": [-62.547164, 39.368583], "paragraph_keywords": ["device", "collaboration", "based", "user"]}], "content": {}, "doi": "10.1145/3290605.3300619"}, {"uri": "190", "title": "Improving Touch Accuracy on Smartphones for People with Motor and Situational Impairments", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Martez E. Mott", "Jacob O. Wobbrock"], "summary": "We present Cluster Touch, a combined user-independent and user-specific touch offset model that improves the accuracy of touch input on smartphones for people with motor impairments, and for people experiencing situational impairments while walking. Cluster Touch combines touch examples from multiple users to create a shared user-independent touch model, which is then updated with touch examples provided by an individual user to make it user-specific. Owing to this combination, Cluster Touch allows people to quickly improve the accuracy of their smartphones by providing only 20 touch examples. In a user study with 12 people with motor impairments and 12 people without motor impairments, but who were walking, Cluster Touch improved touch accuracy by 14.65% for the former group and 6.81% for the latter group over the native touch sensor. Furthermore, in an offline analysis of existing mobile interfaces, Cluster Touch improved touch accuracy by 8.21% and 4.84% over the native touch sensor for the two user groups, respectively.", "keywords": ["based", "finger", "intended", "location", "improve", "analysis", "technique", "provide", "error", "example", "offset", "touch", "user", "model", "accuracy", "crosshairs", "work", "motor", "participant", "people", "screen", "y", "created", "walking", "page", "found", "impairment", "smartphones", "target", "paper", "input", "cluster"], "document_vector": [12.689415, -63.280052], "paragraphs": [{"paragraph_vector": [-37.988891, 6.583099], "paragraph_keywords": ["touch", "smartphones", "work", "copies"]}, {"paragraph_vector": [-33.240791, 7.33735], "paragraph_keywords": ["touch", "users", "impairments", "motor"]}, {"paragraph_vector": [-31.838544, 5.818042], "paragraph_keywords": ["touch", "cluster", "impairments", "motor"]}, {"paragraph_vector": [-35.382888, 5.617405], "paragraph_keywords": ["touch", "users", "impairments", "motor"]}, {"paragraph_vector": [-35.341018, 7.693907], "paragraph_keywords": ["touch", "users", "target", "user"]}, {"paragraph_vector": [-34.696125, 3.692198], "paragraph_keywords": ["touch", "input", "users", "impairments"]}, {"paragraph_vector": [-37.24274, 3.186839], "paragraph_keywords": ["users", "touch", "based", "user"]}, {"paragraph_vector": [-34.945858, 8.189035], "paragraph_keywords": ["touch", "motor", "impairments", "participants"]}, {"paragraph_vector": [-35.289749, 13.052154], "paragraph_keywords": ["screen", "touch", "crosshairs", "direction"]}, {"paragraph_vector": [-31.838359, 10.723994], "paragraph_keywords": ["touches", "crosshairs", "screen", "participants"]}, {"paragraph_vector": [-34.308662, 12.335844], "paragraph_keywords": ["touch", "participants", "y", "offset"]}, {"paragraph_vector": [-32.956989, 6.638478], "paragraph_keywords": ["touch", "user", "offsets", "impairments"]}, {"paragraph_vector": [-30.612579, 9.445961], "paragraph_keywords": ["touch", "y", "screen", "partitions"]}, {"paragraph_vector": [-31.702009, 5.787538], "paragraph_keywords": ["cluster", "offsets", "touch", "model"]}, {"paragraph_vector": [-32.224464, 7.876615], "paragraph_keywords": ["touch", "cluster", "clusters", "training"]}, {"paragraph_vector": [-31.608173, 9.825939], "paragraph_keywords": ["touch", "participants", "impairments", "study"]}, {"paragraph_vector": [-32.258083, 12.274174], "paragraph_keywords": ["touch", "participants", "completed", "target"]}, {"paragraph_vector": [-33.550136, 5.591771], "paragraph_keywords": ["touch", "technique", "models", "nexus"]}, {"paragraph_vector": [-32.086059, 10.054272], "paragraph_keywords": ["hit", "rate", "impairments", "participants"]}, {"paragraph_vector": [-32.160129, 8.258826], "paragraph_keywords": ["touch", "cluster", "impairments", "motor"]}, {"paragraph_vector": [-33.811618, 7.372096], "paragraph_keywords": ["touch", "cluster", "impairments", "models"]}, {"paragraph_vector": [-33.221092, 7.692732], "paragraph_keywords": ["touch", "motor", "people", "users"]}, {"paragraph_vector": [-33.12849, 8.375], "paragraph_keywords": ["touch", "accuracy", "cluster", "people"]}], "content": {}, "doi": "10.1145/3290605.3300907"}, {"uri": "191", "title": "Group Interactions in Location-Based Gaming:A Case Study of Raiding in Poke\u0301mon GO", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Arpita Bhattacharya", "Travis W. Windleharth", "Anthony Ishii", "Ivy M. Acevedo", "Cecilia R. Aragon", "Julie A. Kientz", "Jason C. Yip", "Jin Ha Lee"], "summary": "Raiding is a format in digital gaming that requires groups of people to collaborate and/or compete for a common goal. In 2017, the raiding format was introduced in the locationbased mobile game Pok\u00e9mon GO, which ofers a mixed reality experience to friends and strangers coordinating for in-person raids. To understand this technology-mediated social phenomenon, we conducted over a year of participant observations, surveys with 510 players, and interviews with 25 players who raid in Pok\u00e9mon GO. Using the analytical lens of Arrow, McGrath, and Berdahl's theory of small groups as complex systems, we identify global, local, and contextual dynamics in location-based raiding that support and challenge ad-hoc group formation in real life. Based on this empirical and theoretical understanding, we discuss implications to design for transparency, social afordances, and bridging gaps between global and contextual dynamics for increased positive and inclusive community interactions.", "keywords": ["based", "facebook", "irl", "time", "coordinate", "requires", "coordinating", "raiding", "player", "location", "gym", "design", "specifc", "interview", "feature", "provide", "stranger", "safety", "goal", "interaction", "play", "battle", "dynamic", "participant", "bos", "use", "people", "group", "interact", "team", "pok\u00e9mon", "page", "number", "survey", "form", "age", "ex", "member", "discord", "afordances", "raid", "data", "game", "study", "said", "japan", "explained", "paper", "area", "observation", "capital", "level", "community", "coordination"], "document_vector": [159.344711, 45.163032], "paragraphs": [{"paragraph_vector": [-132.26918, -39.547061], "paragraph_keywords": ["pok\u00e9mon", "groups", "players", "games"]}, {"paragraph_vector": [-132.28482, -41.017345], "paragraph_keywords": ["raiding", "interactions", "pok\u00e9mon", "raids"]}, {"paragraph_vector": [-134.125915, -41.988662], "paragraph_keywords": ["players", "interactions", "game", "games"]}, {"paragraph_vector": [-133.340957, -40.156707], "paragraph_keywords": ["players", "pok\u00e9mon", "discussed", "strangers"]}, {"paragraph_vector": [-147.768371, -36.615283], "paragraph_keywords": ["groups", "pok\u00e9mon", "raid", "game"]}, {"paragraph_vector": [-157.099334, -42.794368], "paragraph_keywords": ["group", "dynamics", "members", "interactions"]}, {"paragraph_vector": [-136.578872, -45.520359], "paragraph_keywords": ["raid", "boss", "player", "level"]}, {"paragraph_vector": [-137.454559, -46.674266], "paragraph_keywords": ["players", "time", "raid", "data"]}, {"paragraph_vector": [-141.566421, -46.06121], "paragraph_keywords": ["survey", "raid", "observations", "participated"]}, {"paragraph_vector": [-138.049621, -45.731952], "paragraph_keywords": ["raiding", "raids", "time", "table"]}, {"paragraph_vector": [120.756263, -37.264629], "paragraph_keywords": ["interviews", "interview", "participants", "survey"]}, {"paragraph_vector": [-176.195236, -48.712398], "paragraph_keywords": ["groups", "group", "dynamics", "raid"]}, {"paragraph_vector": [-139.757263, -45.425903], "paragraph_keywords": ["players", "raid", "people", "group"]}, {"paragraph_vector": [-144.891189, -45.907581], "paragraph_keywords": ["group", "raid", "members", "coordination"]}, {"paragraph_vector": [-138.410461, -45.547924], "paragraph_keywords": ["raid", "raids", "players", "japan"]}, {"paragraph_vector": [-137.839385, -46.785011], "paragraph_keywords": ["raid", "people", "location", "group"]}, {"paragraph_vector": [-138.596694, -45.959342], "paragraph_keywords": ["players", "raids", "raid", "members"]}, {"paragraph_vector": [-136.820312, -41.201251], "paragraph_keywords": ["people", "lack", "raids", "accessibility"]}, {"paragraph_vector": [-137.176284, -45.675449], "paragraph_keywords": ["game", "raid", "people", "spoofng"]}, {"paragraph_vector": [-137.544143, -44.749809], "paragraph_keywords": ["raids", "people", "safety", "based"]}, {"paragraph_vector": [-137.628295, -59.973033], "paragraph_keywords": ["participants", "concerns", "safety", "raid"]}, {"paragraph_vector": [-138.688552, -43.786273], "paragraph_keywords": ["raid", "interactions", "ex", "group"]}, {"paragraph_vector": [-133.999526, -45.198719], "paragraph_keywords": ["provide", "players", "community", "location"]}, {"paragraph_vector": [-136.773376, -44.649478], "paragraph_keywords": ["players", "game", "raid", "provide"]}, {"paragraph_vector": [-136.368118, -44.728412], "paragraph_keywords": ["raid", "game", "people", "locations"]}, {"paragraph_vector": [-136.599533, -44.4972], "paragraph_keywords": ["groups", "design", "activities", "based"]}], "content": {}, "doi": "10.1145/3290605.3300351"}, {"uri": "192", "title": "SuperVision: Playing with Gaze Aversion  and Peripheral Vision", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Argenis Ramirez Gomez", "Hans Gellersen"], "summary": "In this work, we challenge the Gaze interaction paradigm \"What you see is what you get\" to introduce \"playing with peripheral vision\". We developed the conceptual framework to introduce this novel gaze-aware game dynamic. We illustrated the concept with SuperVision, a collection of three games that play with peripheral vision. We propose perceptual and interaction challenges that require players not to look and rely on their periphery. To validate the game dynamic and experience, we conducted a user study with twenty-four participants. Results show how the game concept created an engaging and playful experience playing with peripheral vision. Participants showed proficiency in overcoming the game challenges, developing clear strategies to succeed. Moreover, we found evidence that playing the game can affect our visual skills, with greater peripheral awareness.", "keywords": ["based", "time", "need", "vision", "object", "player", "design", "looking", "gaze", "focus", "playing", "user", "interaction", "play", "eye", "cyclops", "work", "result", "participant", "use", "screen", "challenge", "size", "control", "experience", "look", "field", "supervision", "gameplay", "medusa", "test", "task", "attention", "game", "study", "periphery", "color", "rule", "balloon", "mouse", "level", "figure", "protractor"], "document_vector": [-114.01432, -50.084701], "paragraphs": [{"paragraph_vector": [-117.737007, 4.851152], "paragraph_keywords": ["gaze", "copies", "interaction", "work"]}, {"paragraph_vector": [-121.065483, 4.873398], "paragraph_keywords": ["vision", "game", "players", "playing"]}, {"paragraph_vector": [-118.035194, 5.033963], "paragraph_keywords": ["gaze", "game", "players", "interaction"]}, {"paragraph_vector": [-119.866455, 4.595546], "paragraph_keywords": ["game", "attention", "eye", "based"]}, {"paragraph_vector": [-119.019569, 5.686035], "paragraph_keywords": ["vision", "focus", "tasks", "games"]}, {"paragraph_vector": [-119.25357, 3.495611], "paragraph_keywords": ["objects", "vision", "periphery", "interaction"]}, {"paragraph_vector": [-119.369873, 4.31432], "paragraph_keywords": ["objects", "game", "gaze", "players"]}, {"paragraph_vector": [-117.80117, 6.615911], "paragraph_keywords": ["game", "interaction", "play", "button"]}, {"paragraph_vector": [-122.215431, 4.688095], "paragraph_keywords": ["balloons", "game", "fan", "color"]}, {"paragraph_vector": [-121.545166, 3.578694], "paragraph_keywords": ["love", "mushrooms", "medusa", "size"]}, {"paragraph_vector": [-124.302665, 4.871964], "paragraph_keywords": ["game", "frames", "pixels", "gaze"]}, {"paragraph_vector": [-118.158988, 4.608045], "paragraph_keywords": ["game", "protractor", "playing", "study"]}, {"paragraph_vector": [-126.446716, 6.45773], "paragraph_keywords": ["game", "flow", "immersion", "affect"]}, {"paragraph_vector": [-117.25885, 4.513556], "paragraph_keywords": ["participants", "asked", "protractor", "play"]}, {"paragraph_vector": [-120.988571, 6.592203], "paragraph_keywords": ["participants", "games", "playing", "test"]}, {"paragraph_vector": [-126.620933, 5.57936], "paragraph_keywords": ["game", "games", "medusa", "look"]}, {"paragraph_vector": [-120.889808, 5.60664], "paragraph_keywords": ["game", "players", "participants", "gameplay"]}, {"paragraph_vector": [-118.952163, 5.008001], "paragraph_keywords": ["game", "players", "gaze", "screen"]}, {"paragraph_vector": [-118.695487, 5.008691], "paragraph_keywords": ["participants", "playing", "test", "results"]}, {"paragraph_vector": [-118.284515, 2.935385], "paragraph_keywords": ["playing", "periphery", "challenges", "experience"]}, {"paragraph_vector": [-118.6203, 3.731547], "paragraph_keywords": ["games", "periphery", "players", "vision"]}, {"paragraph_vector": [-118.200874, 5.046516], "paragraph_keywords": ["control", "impulse", "players", "look"]}, {"paragraph_vector": [-119.486244, 3.546674], "paragraph_keywords": ["periphery", "playing", "games", "psychology"]}], "content": {}, "doi": "10.1145/3290605.3300834"}, {"uri": "193", "title": "Augmented Reality Views for Occluded Interaction", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Klemen Lilija", "Henning Pohl"], "summary": "Werelyonour sightwhenmanipulatingobjects.Whenobjects are occluded, manipulation becomes difficult. Such occluded objects canbe shownvia augmented reality to re-enable visual guidance. However, it is unclear how to do so to best support object manipulation. We compare four views of occluded objects and their effect on performance and satisfaction across a set of everyday manipulation tasks of varying complexity. The best performing views were a see-through view and a displaced 3D view. The former enabled participants to observe the manipulated object through the occluder, while the latter showed the 3D view of the manipulated object offset from the object\u2019s real location. The worst performing view showed remote imagery froma simulatedhand-mounted camera. Our results suggest that alignment of virtual objects with their real-world location is less important than an appropriate point-of-view and view stability. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300676 CCS CONCEPTS \u2022 Human-centered computing \u2192 Mixed / augmented reality; Empirical studies in HCI .", "keywords": ["manipulation", "position", "point", "time", "placed", "mentioned", "finger", "object", "al", "imagery", "performance", "scene", "plugging", "location", "experiment", "error", "example", "camera", "cloned", "user", "interaction", "result", "movement", "participant", "use", "hololens", "orientation", "visualization", "state", "page", "trial", "mounted", "task", "hand", "data", "reality", "view", "enable", "perspective", "figure"], "document_vector": [170.715347, -41.229782], "paragraphs": [{"paragraph_vector": [-55.440807, 13.241576], "paragraph_keywords": ["view", "reality", "camera", "object"]}, {"paragraph_vector": [-55.03284, 37.06398], "paragraph_keywords": ["cameras", "view", "views", "camera"]}, {"paragraph_vector": [-55.944904, 29.957542], "paragraph_keywords": ["camera", "view", "cameras", "al"]}, {"paragraph_vector": [-49.519031, 22.228139], "paragraph_keywords": ["projection", "perspective", "feedback", "user"]}, {"paragraph_vector": [-68.296775, 32.731983], "paragraph_keywords": ["interaction", "objects", "users", "studies"]}, {"paragraph_vector": [-54.00782, 19.336917], "paragraph_keywords": ["object", "interaction", "tasks", "users"]}, {"paragraph_vector": [-52.627002, 36.863552], "paragraph_keywords": ["user", "cameras", "camera", "hand"]}, {"paragraph_vector": [-53.15155, 36.062973], "paragraph_keywords": ["object", "user", "view", "expect"]}, {"paragraph_vector": [-54.875045, 39.511936], "paragraph_keywords": ["participants", "required", "camera", "views"]}, {"paragraph_vector": [-55.437477, 39.094474], "paragraph_keywords": ["participants", "object", "objects", "task"]}, {"paragraph_vector": [-51.816474, 26.150529], "paragraph_keywords": ["task", "tasks", "optitrack", "participants"]}, {"paragraph_vector": [-34.502403, 22.3376], "paragraph_keywords": ["participants", "tasks", "time", "error"]}, {"paragraph_vector": [-32.893402, 59.36417], "paragraph_keywords": ["participants", "trials", "view", "analysis"]}, {"paragraph_vector": [-53.962799, 38.344188], "paragraph_keywords": ["task", "view", "manipulation", "differences"]}, {"paragraph_vector": [-44.890266, 32.092609], "paragraph_keywords": ["error", "view", "task", "visualization"]}, {"paragraph_vector": [-45.630832, 43.706932], "paragraph_keywords": ["view", "participants", "ratings", "effect"]}, {"paragraph_vector": [-52.199558, 39.068954], "paragraph_keywords": ["view", "participants", "camera", "objects"]}, {"paragraph_vector": [-53.022109, 37.334003], "paragraph_keywords": ["object", "participants", "cloned", "mentioned"]}, {"paragraph_vector": [-55.355239, 36.772109], "paragraph_keywords": ["view", "stability", "point", "views"]}, {"paragraph_vector": [-54.556213, 32.728088], "paragraph_keywords": ["objects", "experiment", "view", "participants"]}, {"paragraph_vector": [-52.776, 33.552726], "paragraph_keywords": ["views", "hand", "support", "objects"]}, {"paragraph_vector": [77.474716, 27.88421], "paragraph_keywords": ["research", "innovation", "program", "horizon"]}], "content": {}, "doi": "10.1145/3290605.3300575"}, {"uri": "194", "title": "Life-Afirming Biosensing in Public: Sounding Heartbeats on a Red Bench", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Noura Howell", "Greg Niemeyer", "Kimiko Ryokai"], "summary": "\u201cSmart city\u201d narratives promise IoT data-driven innovations leveraging biosensing technologies. We argue this overlooks a potential beneft of city living: afrmation. We designed the Heart Sounds Bench, which amplifes the heart sounds of those sitting on it, as well as recording and playing back the heart sounds of previous sitters. We outline our design intent to invite rest, refection, and recognition of others\u2019 lives in public space. We share results from a study with 19 participants. Participants expressed feeling connected to a shared life energy including others and the environment, and described heart sounds as feeling intimate yet anonymous. Finally, we elaborate the concept of life-afrmation in terms of recognition of others\u2019 lives, feeling connection, and respecting untranslatable diferences with opacity, as a way of helping \u201csmart city\u201d designs embrace a multiplicity of desires.", "keywords": ["explore", "feeling", "based", "connection", "time", "person", "sensing", "ability", "biosensing", "bench", "design", "rate", "stethoscope", "environment", "category", "partner", "help", "diference", "work", "space", "participant", "use", "helped", "people", "explored", "living", "way", "heart", "sense", "computing", "contribute", "voice", "experience", "listening", "page", "felt", "sound", "provided", "ftness", "recognition", "life", "efciency", "described", "refection", "afrmation", "data", "feel", "study", "technology", "narrative", "term", "opacity", "potential", "passerby", "build", "paper", "knowledge", "city"], "document_vector": [80.169311, 45.296493], "paragraphs": [{"paragraph_vector": [-75.617324, -51.158084], "paragraph_keywords": ["city", "copies", "biosensing", "heartrate"]}, {"paragraph_vector": [-41.765502, -72.774063], "paragraph_keywords": ["people", "cities", "efciency", "design"]}, {"paragraph_vector": [-75.878219, -53.654838], "paragraph_keywords": ["city", "data", "computing", "categories"]}, {"paragraph_vector": [-77.844085, -53.737323], "paragraph_keywords": ["afrmation", "space", "needs", "terms"]}, {"paragraph_vector": [-80.647232, -55.673507], "paragraph_keywords": ["city", "explored", "passerby", "bench"]}, {"paragraph_vector": [-77.494728, -51.745155], "paragraph_keywords": ["heart", "sounds", "bench", "sound"]}, {"paragraph_vector": [-77.949615, -43.409763], "paragraph_keywords": ["heart", "dancers", "potential", "rate"]}, {"paragraph_vector": [-78.68077, -50.407794], "paragraph_keywords": ["heart", "design", "bench", "sounds"]}, {"paragraph_vector": [-77.652137, -51.797485], "paragraph_keywords": ["sounds", "heart", "bench", "voice"]}, {"paragraph_vector": [-77.813636, -49.547828], "paragraph_keywords": ["bench", "heart", "sounds", "space"]}, {"paragraph_vector": [-83.707122, -54.911598], "paragraph_keywords": ["participants", "sounds", "heart", "study"]}, {"paragraph_vector": [-77.317268, -51.616046], "paragraph_keywords": ["sense", "heart", "feeling", "charlie"]}, {"paragraph_vector": [-78.307189, -49.710861], "paragraph_keywords": ["sounds", "heart", "bench", "life"]}, {"paragraph_vector": [-78.747817, -50.700698], "paragraph_keywords": ["heart", "sounds", "participants", "sense"]}, {"paragraph_vector": [-78.911399, -52.046352], "paragraph_keywords": ["heart", "sounds", "health", "partner"]}, {"paragraph_vector": [-79.960746, -54.636486], "paragraph_keywords": ["heart", "sounds", "person", "participants"]}, {"paragraph_vector": [-78.472717, -49.576995], "paragraph_keywords": ["stethoscope", "heart", "sounds", "bench"]}, {"paragraph_vector": [-77.81723, -53.547767], "paragraph_keywords": ["heart", "sounds", "afrmation", "design"]}, {"paragraph_vector": [-79.209144, -52.897506], "paragraph_keywords": ["afrmation", "connection", "city", "life"]}, {"paragraph_vector": [-73.012092, -54.833217], "paragraph_keywords": ["recognition", "life", "connection", "people"]}, {"paragraph_vector": [-81.720428, -58.86045], "paragraph_keywords": ["opacity", "understanding", "transparency", "connection"]}, {"paragraph_vector": [-80.530265, -59.29713], "paragraph_keywords": ["users", "information", "ambiguity", "data"]}, {"paragraph_vector": [-80.669929, -57.559749], "paragraph_keywords": ["opacity", "ability", "data", "knowledge"]}, {"paragraph_vector": [-76.904869, -53.561393], "paragraph_keywords": ["afrmation", "explore", "life", "city"]}, {"paragraph_vector": [-78.201202, -53.247714], "paragraph_keywords": ["provided", "helped", "bench", "afrmed"]}], "content": {}, "doi": "10.1145/3290605.3300374"}, {"uri": "195", "title": "SmartManikin: Virtual Humans with Agency for Design Tools", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Bokyung Lee", "Taeil Jin", "Sung-Hee Lee"], "summary": "When designing comfort and usability in products, designers need to evaluate aspects ranging from anthropometrics to use scenarios. Therefore, virtual and poseable mannequins are employed as a reference in early-stage tools and for evaluation in the later stages. However, tools to intuitively interact with virtual humans are lacking. In this paper, we introduce SmartManikin, a mannequin with agency that responds to high-level commands and to real-time design changes. We first captured human poses with respect to desk configurations, identified key features of the pose and trained regression functions to estimate the optimal features at a given desk setup. The SmartManikin\u2019s pose is generated by the predicted features as well as by using forward and inverse kinematics. We present our design, implementation, and an evaluation with expert designers. The results revealed that Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300814 SmartManikin enhances the design experience by providing feedback concerning comfort and health in real time.", "keywords": ["process", "based", "position", "respect", "time", "watching", "body", "design", "feature", "example", "comfort", "user", "aspect", "type", "work", "product", "tool", "use", "participant", "people", "agency", "m", "given", "sitting", "desk", "generate", "kinematics", "mannequin", "hand", "human", "item", "study", "designer", "height", "system", "smartmanikin", "typing", "target", "furniture", "pose", "action", "figure"], "document_vector": [41.204086, -60.333683], "paragraphs": [{"paragraph_vector": [-79.79927, 20.286062], "paragraph_keywords": ["design", "tools", "use", "agency"]}, {"paragraph_vector": [-78.184783, 20.014295], "paragraph_keywords": ["design", "features", "mannequin", "agency"]}, {"paragraph_vector": [-77.987815, 19.933629], "paragraph_keywords": ["humans", "design", "actions", "simulate"]}, {"paragraph_vector": [-79.784675, 20.887905], "paragraph_keywords": ["poses", "design", "given", "context"]}, {"paragraph_vector": [-78.938095, 21.809961], "paragraph_keywords": ["poses", "participants", "pose", "angles"]}, {"paragraph_vector": [-80.012908, 21.65566], "paragraph_keywords": ["design", "poses", "smartmanikin", "needs"]}, {"paragraph_vector": [-77.104606, 22.161859], "paragraph_keywords": ["pose", "poses", "figure", "study"]}, {"paragraph_vector": [-77.365081, 23.329862], "paragraph_keywords": ["desk", "participants", "height", "m"]}, {"paragraph_vector": [-78.857406, 19.371656], "paragraph_keywords": ["position", "desk", "pose", "height"]}, {"paragraph_vector": [-77.427062, 19.178089], "paragraph_keywords": ["desk", "regressors", "trained", "smartmanikin"]}, {"paragraph_vector": [-77.526794, 21.580036], "paragraph_keywords": ["desk", "designers", "height", "item"]}, {"paragraph_vector": [-78.255287, 20.236003], "paragraph_keywords": ["smartmanikin", "position", "kinematics", "height"]}, {"paragraph_vector": [-79.653861, 21.883829], "paragraph_keywords": ["desk", "smartmanikin", "system", "designers"]}, {"paragraph_vector": [-77.487541, 21.624029], "paragraph_keywords": ["smartmanikin", "poses", "design", "designers"]}, {"paragraph_vector": [-78.081771, 20.924337], "paragraph_keywords": ["mannequin", "smartmanikin", "designers", "design"]}, {"paragraph_vector": [-78.554855, 21.136318], "paragraph_keywords": ["design", "smartmanikin", "poses", "mannequin"]}, {"paragraph_vector": [-77.145828, 21.150608], "paragraph_keywords": ["poses", "design", "comfort", "designers"]}, {"paragraph_vector": [-79.293533, 21.349872], "paragraph_keywords": ["agency", "hand", "design", "poses"]}, {"paragraph_vector": [-110.574928, 24.527496], "paragraph_keywords": ["funded", "reality", "ar", "science"]}], "content": {}, "doi": "10.1145/3290605.3300869"}, {"uri": "196", "title": "Causeway: Scaling Situated Learning with Micro-Role Hierarchies", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["David T. Lee", "Emily S. Hamedian", "Greg Wolff", "Amy Liu"], "summary": "While educational technologies such as MOOCs have helped scale content-based learning, scaling situated learning is still challenging. The time it takes to define a real-world project and to mentor learners is often prohibitive, especially given the limited contributions that novices are able to make. This paper introduces micro-role hierarchies, a form of coordination that integrates workflows and hierarchies to help short-term novices predictably contribute to complex projects. Individuals contribute through microroles, small experiential assignments taking roughly 2 hours. These micro-roles support execution of the desired work process, but also sequence into learning pathways, resulting in a learning dynamic similar to moving up an organizational hierarchy. We demonstrate micro-role hierarchies through Causeway, a platform for learning web development while building websites for nonprofits. We carry out a proof-ofconcept study in which learners built static websites for refugee resettlement agencies in 2 hour long roles.", "keywords": ["micro", "html", "based", "time", "hierarchy", "component", "participate", "manager", "help", "workflow", "learner", "learn", "work", "building", "participant", "completed", "learning", "world", "step", "page", "experience", "-", "task", "novice", "layout", "practice", "study", "element", "role", "support", "developer", "tutorial", "website", "paper", "crowdsourcing", "causeway", "action", "context", "figure", "code"], "document_vector": [-159.175674, 37.132431], "paragraphs": [{"paragraph_vector": [128.190078, 5.923657], "paragraph_keywords": ["learning", "copies", "work", "acm"]}, {"paragraph_vector": [108.885772, 16.358993], "paragraph_keywords": ["goal", "learning", "roles", "role"]}, {"paragraph_vector": [106.530532, 15.946989], "paragraph_keywords": ["learning", "time", "websites", "knowledge"]}, {"paragraph_vector": [89.08509, 18.536281], "paragraph_keywords": ["learning", "work", "practice", "tasks"]}, {"paragraph_vector": [87.103576, 18.37578], "paragraph_keywords": ["workflows", "-", "tasks", "hierarchies"]}, {"paragraph_vector": [92.155273, 13.662985], "paragraph_keywords": ["-", "tasks", "services", "roles"]}, {"paragraph_vector": [102.734405, 29.740779], "paragraph_keywords": ["participants", "workflows", "roles", "steps"]}, {"paragraph_vector": [97.021057, 27.329475], "paragraph_keywords": ["delegated", "steps", "roles", "step"]}, {"paragraph_vector": [101.725708, 25.884164], "paragraph_keywords": ["learning", "master", "roles", "role"]}, {"paragraph_vector": [102.999237, 15.389058], "paragraph_keywords": ["learning", "time", "learners", "set"]}, {"paragraph_vector": [104.525749, 17.362874], "paragraph_keywords": ["learning", "developer", "learners", "elements"]}, {"paragraph_vector": [109.546302, 52.85905], "paragraph_keywords": ["layout", "elements", "page", "needed"]}, {"paragraph_vector": [110.358802, 31.629861], "paragraph_keywords": ["exercises", "section", "tutorials", "intro"]}, {"paragraph_vector": [107.295288, 21.169786], "paragraph_keywords": ["participants", "participate", "component", "page"]}, {"paragraph_vector": [100.835823, 38.881862], "paragraph_keywords": ["participants", "components", "condition", "page"]}, {"paragraph_vector": [107.216552, 20.971061], "paragraph_keywords": ["page", "completed", "components", "information"]}, {"paragraph_vector": [108.706359, 30.364526], "paragraph_keywords": ["components", "participants", "causeway", "errors"]}, {"paragraph_vector": [102.457252, 42.579799], "paragraph_keywords": ["participants", "time", "pages", "round"]}, {"paragraph_vector": [106.787139, 14.39594], "paragraph_keywords": ["websites", "learning", "hierarchies", "-"]}, {"paragraph_vector": [104.35807, 20.634149], "paragraph_keywords": ["hierarchies", "role", "learning", "-"]}, {"paragraph_vector": [135.699951, -2.105715], "paragraph_keywords": ["learning", "moving", "work", "thank"]}], "content": {}, "doi": "10.1145/3290605.3300377"}, {"uri": "197", "title": "Voice Presentation Attack Detection through Text-Converted Voice Command Analysis", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Il-Youp Kwak", "Jun Ho Huh", "Seung Taek Han", "Jiwon Yoon", "Iljoo Kim"], "summary": "Voice assistants are quickly being upgraded to support advanced, security-critical commands such as unlocking devices, checking emails, and making payments. In this paper, we explore the feasibility of using users\u2019 text-converted voice command utterances as classification features to help identify users\u2019 genuine commands, and detect suspicious commands. To maintain high detection accuracy, our approach starts with a globally trained attack detection model (immediately available for new users), and gradually switches to a userspecific model tailored to the utterance patterns of a target user. To evaluate accuracy, we used a real-world voice assistant dataset consisting of about 34.6 million voice commands collected from 2.6 million users. Our evaluation results show that this approach is capable of achieving about 3.4% equal error rate (EER), detecting 95.7% of attacks when an optimal threshold value is used. As for those who frequently use security-critical (attack-like) commands, we still achieve EER below 5%.", "keywords": ["based", "time", "set", "processing", "training", "section", "feature", "generated", "classification", "assistant", "user", "model", "command", "accuracy", "result", "speaker", "selected", "work", "use", "victim", "detection", "authentication", "learning", "security", "voice", "page", "number", "existing", "dataset", "application", "regression", "attack", "test", "device", "data", "eers", "solution", "target", "paper", "tailored"], "document_vector": [-69.403327, -28.008916], "paragraphs": [{"paragraph_vector": [-6.009561, -38.013076], "paragraph_keywords": ["voice", "security", "copies", "users"]}, {"paragraph_vector": [-7.447322, -38.515644], "paragraph_keywords": ["voice", "users", "detection", "command"]}, {"paragraph_vector": [-4.716183, -38.474956], "paragraph_keywords": ["voice", "commands", "use", "authentication"]}, {"paragraph_vector": [-4.166763, -38.499034], "paragraph_keywords": ["voice", "users", "attack", "commands"]}, {"paragraph_vector": [-2.014119, -38.949996], "paragraph_keywords": ["voice", "victim", "attacker", "commands"]}, {"paragraph_vector": [-2.368196, -37.451076], "paragraph_keywords": ["voice", "command", "processed", "commands"]}, {"paragraph_vector": [-2.630413, -37.230392], "paragraph_keywords": ["voice", "users", "commands", "assistant"]}, {"paragraph_vector": [-3.02994, -36.835521], "paragraph_keywords": ["users", "application", "set", "combinations"]}, {"paragraph_vector": [-1.431858, -37.370346], "paragraph_keywords": ["commands", "category", "command", "risk"]}, {"paragraph_vector": [-5.571375, -37.664848], "paragraph_keywords": ["commands", "attack", "set", "voice"]}, {"paragraph_vector": [-5.260118, -36.458801], "paragraph_keywords": ["users", "assistant", "voice", "command"]}, {"paragraph_vector": [-7.095722, -34.300788], "paragraph_keywords": ["user", "command", "attack", "model"]}, {"paragraph_vector": [-5.253719, -36.466056], "paragraph_keywords": ["model", "user", "commands", "attack"]}, {"paragraph_vector": [-7.430128, -32.253143], "paragraph_keywords": ["parameters", "commands", "classification", "set"]}, {"paragraph_vector": [-6.025691, -34.686168], "paragraph_keywords": ["commands", "attack", "target", "selected"]}, {"paragraph_vector": [-4.567339, -35.342353], "paragraph_keywords": ["user", "attack", "commands", "command"]}, {"paragraph_vector": [-4.877634, -33.917232], "paragraph_keywords": ["models", "user", "time", "detection"]}, {"paragraph_vector": [-4.829169, -34.286685], "paragraph_keywords": ["model", "commands", "user", "frrs"]}, {"paragraph_vector": [-5.894245, -35.710281], "paragraph_keywords": ["user", "commands", "voice", "security"]}, {"paragraph_vector": [-6.654655, -37.716835], "paragraph_keywords": ["security", "attack", "voice", "user"]}, {"paragraph_vector": [-6.803274, -38.05532], "paragraph_keywords": ["use", "voice", "devices", "accuracy"]}, {"paragraph_vector": [-5.729689, -33.297302], "paragraph_keywords": ["user", "voice", "model", "detection"]}], "content": {}, "doi": "10.1145/3290605.3300532"}, {"uri": "198", "title": "Seeing with New Eyes: Designing for In-the-Wild Museum Gifting", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jocelyn Spence", "Benjamin Bedwell", "Boriana N. Koleva"], "summary": "This paper presents the GIFT smartphone app, an artist-led Research through Design project benefitting from a threeday in-the-wild deployment. The app takes as its premise the generative potential of combining the contexts of gifting and museum visits. Visitors explore the museum, searching for objects that would most appeal to the gift-receiver they have in mind, then photographing those objects and adding audio messages for their receivers describing the motivation for their choices. This paper charts the designers\u2019 key aim of creating a new frame of mind using voice, and the most striking findings discovered during in-the-wild deployment in a museum \u2013 \u2018seeing with new eyes\u2019 and fostering personal connections. We discuss empathy, motivation, and bottomup personalisation in the productive space revealed by this combination of contexts. We suggest that this work reveals opportunities for designers of gifting services as well as those working in cultural heritage. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300235 CCS CONCEPTS \u2022Human-centered computing\u2192User centered design; Empirical studies in interaction design; Computer supported cooperative work.", "keywords": ["process", "based", "feeling", "time", "al", "connection", "object", "person", "giving", "design", "app", "looking", "seen", "personalisation", "visitor", "relationship", "engagement", "user", "blast", "theory", "et", "work", "space", "participant", "use", "create", "people", "designed", "gift", "museum", "way", "sense", "voice", "experience", "felt", "gifting", "visit", "empathy", "effort", "gave", "hunter", "practice", "research", "term", "meaning", "receiver", "giver", "paper", "staff", "response"], "document_vector": [109.459449, 11.88663], "paragraphs": [{"paragraph_vector": [-165.592758, 5.656754], "paragraph_keywords": ["museum", "design", "experiences", "technology"]}, {"paragraph_vector": [-165.648254, 4.965647], "paragraph_keywords": ["museum", "visitors", "devices", "exhibits"]}, {"paragraph_vector": [-164.036849, 6.75175], "paragraph_keywords": ["gifting", "al", "et", "gift"]}, {"paragraph_vector": [-167.756607, 7.714787], "paragraph_keywords": ["al", "et", "probes", "gifting"]}, {"paragraph_vector": [-166.080627, 4.190727], "paragraph_keywords": ["app", "museum", "visitors", "led"]}, {"paragraph_vector": [-165.65216, 5.582858], "paragraph_keywords": ["museum", "design", "app", "receiver"]}, {"paragraph_vector": [-164.93518, 5.718218], "paragraph_keywords": ["app", "gift", "receivers", "design"]}, {"paragraph_vector": [-166.152816, 5.578944], "paragraph_keywords": ["museum", "staff", "come", "museums"]}, {"paragraph_vector": [-167.193664, 6.414857], "paragraph_keywords": ["museum", "visitors", "voice", "hunter"]}, {"paragraph_vector": [-166.336669, 4.973789], "paragraph_keywords": ["hunter", "visitor", "tone", "voice"]}, {"paragraph_vector": [-169.634017, 2.115174], "paragraph_keywords": ["gift", "effort", "giver", "skills"]}, {"paragraph_vector": [-167.044998, 3.815094], "paragraph_keywords": ["app", "museum", "gave", "gifts"]}, {"paragraph_vector": [-164.619903, 6.682963], "paragraph_keywords": ["objects", "responses", "participants", "looking"]}, {"paragraph_vector": [-156.165588, -0.832334], "paragraph_keywords": ["looking", "objects", "receiver", "connection"]}, {"paragraph_vector": [-162.816513, 3.674276], "paragraph_keywords": ["objects", "felt", "family", "object"]}, {"paragraph_vector": [-165.190429, 5.566103], "paragraph_keywords": ["app", "visit", "voice", "person"]}, {"paragraph_vector": [-167.225662, 6.894481], "paragraph_keywords": ["participants", "museum", "experience", "described"]}, {"paragraph_vector": [-164.279159, 3.930087], "paragraph_keywords": ["design", "gifting", "museum", "process"]}, {"paragraph_vector": [-164.104888, -0.46045], "paragraph_keywords": ["objects", "participants", "feelings", "empathy"]}, {"paragraph_vector": [-167.451507, 5.308475], "paragraph_keywords": ["effort", "gift", "motivation", "design"]}, {"paragraph_vector": [-164.582229, 5.43775], "paragraph_keywords": ["app", "museum", "personalisation", "effort"]}, {"paragraph_vector": [-164.146713, 6.884215], "paragraph_keywords": ["museum", "objects", "visitors", "sense"]}, {"paragraph_vector": [-164.805191, 4.965128], "paragraph_keywords": ["museum", "space", "gifts", "design"]}, {"paragraph_vector": [-163.97377, 5.252078], "paragraph_keywords": ["museum", "visitors", "staff", "museums"]}, {"paragraph_vector": [73.92736, 35.086212], "paragraph_keywords": ["paper", "page"]}], "content": {}, "doi": "10.1145/3290605.3300498"}, {"uri": "199", "title": "Care and Design: An Ethnography of Mutual Recognition in the Context of Advanced Dementia", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Sarah Foley", "Nadia Pantidi"], "summary": "While there have been considerable developments in designing for dementia within HCI, there is still a lack of empirical understanding of the experience of people with advanced dementia and the ways in which design can support and enrich their lives. In this paper, we present our findings from a long-term ethnographic study, which aimed to gain an understanding of their lived experience and inform design practices for and with people with advanced dementia in residential care. We present our findings using the social theory of recognition as an analytic lens to account for recognition in practice and its challenges in care and research. We discuss how we, as the HCI community, can pragmatically engage with people with advanced dementia and propose a set of considerations for those who wish to design for and with the values of recognition theory to promote collaboration, agency and social identity in advanced dementia care.", "keywords": ["resident", "expression", "respect", "trying", "time", "need", ".", "person", "design", "recognise", "care", "opportunity", "relationship", "example", "engagement", "activity", "aspect", "interaction", "theory", "creating", "work", "engage", "space", "use", "people", "agency", "group", "way", "sense", "mean", "experience", "page", "recognised", "understanding", "embodied", "recognition", "nature", "family", "hand", "member", "researcher", "approach", "role", "dementia", "contribution", "support", "sit", "ethnography", "research", "hci", "paper", "say", "acknowledge", "context"], "document_vector": [106.054206, 38.804859], "paragraphs": [{"paragraph_vector": [125.934333, -63.3372], "paragraph_keywords": ["dementia", "design", "research", "people"]}, {"paragraph_vector": [130.000823, -83.373878], "paragraph_keywords": ["design", "dementia", "recognition", "work"]}, {"paragraph_vector": [153.43309, -86.336349], "paragraph_keywords": ["dementia", "design", "experience", "people"]}, {"paragraph_vector": [-175.025131, -82.464691], "paragraph_keywords": ["dementia", "design", "care", "gillian"]}, {"paragraph_vector": [-144.058883, -86.945663], "paragraph_keywords": ["dementia", "people", "understanding", "care"]}, {"paragraph_vector": [145.092468, -89.923469], "paragraph_keywords": ["recognition", "theory", "need", "recognised"]}, {"paragraph_vector": [-124.145736, -87.643981], "paragraph_keywords": ["recognition", "dementia", "care", "identity"]}, {"paragraph_vector": [105.528121, -86.075019], "paragraph_keywords": ["place", "residents", "care", "took"]}, {"paragraph_vector": [149.825531, -69.745613], "paragraph_keywords": ["recognition", "activities", "theory", "care"]}, {"paragraph_vector": [127.739196, -89.527374], "paragraph_keywords": ["recognition", "dementia", "people", "need"]}, {"paragraph_vector": [-141.988769, -76.948455], "paragraph_keywords": ["researcher", "understanding", "resident", "scarf"]}, {"paragraph_vector": [-136.94841, -72.793952], "paragraph_keywords": ["says", "help", "starts", "people"]}, {"paragraph_vector": [179.825302, -88.241828], "paragraph_keywords": ["recognition", "concern", "mother", "dementia"]}, {"paragraph_vector": [-131.15422, -84.213623], "paragraph_keywords": ["dementia", "people", "recognition", "care"]}, {"paragraph_vector": [-145.472702, -80.895591], "paragraph_keywords": ["dementia", "recognition", "bus", "reassure"]}, {"paragraph_vector": [-127.444915, -83.88372], "paragraph_keywords": ["recognition", "person", "illness", "relationship"]}, {"paragraph_vector": [-146.525283, -73.484046], "paragraph_keywords": ["dementia", "researcher", "musician", "today"]}, {"paragraph_vector": [153.769775, -88.05014], "paragraph_keywords": ["dementia", "recognition", "role", "respect"]}, {"paragraph_vector": [176.388763, -88.238159], "paragraph_keywords": ["residents", "group", "working", "capabilities"]}, {"paragraph_vector": [-123.724777, -88.07357], "paragraph_keywords": ["dementia", "sit", "agency", "need"]}, {"paragraph_vector": [-157.613174, -84.861877], "paragraph_keywords": ["carol", "collaboration", "hand", "agency"]}, {"paragraph_vector": [-117.746116, -85.737899], "paragraph_keywords": ["dementia", "people", "care", "recognition"]}, {"paragraph_vector": [150.597274, -87.180061], "paragraph_keywords": ["recognition", "dementia", "people", "design"]}, {"paragraph_vector": [-167.999847, -86.106124], "paragraph_keywords": ["design", "dementia", "recognition", "respond"]}, {"paragraph_vector": [105.346481, -86.108642], "paragraph_keywords": ["dementia", "design", "recognition", "experience"]}, {"paragraph_vector": [-124.405418, -89.206558], "paragraph_keywords": ["recognition", "dementia", "person", "care"]}, {"paragraph_vector": [-73.737861, -89.81034], "paragraph_keywords": ["recognition", "dementia", "agency", "design"]}, {"paragraph_vector": [158.804199, -86.737892], "paragraph_keywords": ["dementia", "recognition", "people", "family"]}, {"paragraph_vector": [111.062057, -82.322608], "paragraph_keywords": ["design", "recognition", "dementia", "engagement"]}], "content": {}, "doi": "10.1145/3290605.3300657"}, {"uri": "200", "title": "Engaging Lived and Virtual Realities", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Aditya Vishwanath"], "summary": "We examined the integration of VR into informal and lessstructured learning environments in Atlanta (USA) andMumbai (India) through a process of co-design, co-creation, and colearning with students and teachers where students learned to use VR to engage with their economic, social, and cultural realities. Using qualitative methods, we engaged students and teachers at both sites in VR content creation activities; through these activities, we attempt to uncover a deeper understanding of the challenges and opportunities of introducing low-cost mobile VR for content generation, consumption, and sharing in underserved learning contexts. We also motivate future work that looks at integrating VR in new contexts, using flexible methods, across borders. The larger vision of our research is to advance us towards greater accessibility and inclusivity of VR across diverse learning environments.", "keywords": ["process", "explore", "vr", "respect", "time", "need", "degree", "object", "vision", "mumbai", "scene", "design", "method", "atlanta", "environment", "stage", "co", "videography", "camera", "storytelling", "engagement", "user", "story", "work", "engage", "space", "use", "participant", "engaging", "create", "integration", "cost", "team", "learning", "way", "experience", "page", "field", "teacher", "content", "movie", "-", "taking", "stakeholder", "classroom", "volunteer", "north", "creation", "data", "day", "technology", "study", "role", "setting", "student", "storyboarding", "support", "viewing", "research", "meaning", "site", "paper", "affordances", "value", "context", "making"], "document_vector": [-166.311325, 43.135395], "paragraphs": [{"paragraph_vector": [142.011566, -7.645187], "paragraph_keywords": ["copies", "vr", "vision", "influence"]}, {"paragraph_vector": [140.240264, -9.74175], "paragraph_keywords": ["vr", "stakeholders", "reflect", "contexts"]}, {"paragraph_vector": [135.74765, -8.572332], "paragraph_keywords": ["vr", "technologies", "research", "communication"]}, {"paragraph_vector": [139.303466, -9.993033], "paragraph_keywords": ["vr", "learning", "studies", "environments"]}, {"paragraph_vector": [138.560134, -10.168917], "paragraph_keywords": ["vr", "technology", "learning", "integration"]}, {"paragraph_vector": [-122.920425, 21.507322], "paragraph_keywords": ["students", "sites", "vr", "years"]}, {"paragraph_vector": [136.609634, -7.430726], "paragraph_keywords": ["vr", "students", "sites", "exposure"]}, {"paragraph_vector": [137.268585, -15.147863], "paragraph_keywords": ["teachers", "students", "sites", "vr"]}, {"paragraph_vector": [137.855361, -9.709464], "paragraph_keywords": ["students", "stage", "vr", "adults"]}, {"paragraph_vector": [137.162246, -11.945929], "paragraph_keywords": ["vr", "images", "data", "degree"]}, {"paragraph_vector": [139.197845, -10.802465], "paragraph_keywords": ["vr", "mumbai", "technology", "students"]}, {"paragraph_vector": [139.712615, -10.505714], "paragraph_keywords": ["vr", "teachers", "students", "learning"]}, {"paragraph_vector": [137.357849, -8.90529], "paragraph_keywords": ["vr", "students", "cameras", "teachers"]}, {"paragraph_vector": [136.898178, -8.331239], "paragraph_keywords": ["cameras", "use", "camera", "students"]}, {"paragraph_vector": [137.276657, -9.021567], "paragraph_keywords": ["storyboarding", "students", "devices", "storytelling"]}, {"paragraph_vector": [133.760604, -13.252259], "paragraph_keywords": ["students", "teams", "atlanta", "co"]}, {"paragraph_vector": [136.78009, -11.459161], "paragraph_keywords": ["camera", "operator", "students", "scene"]}, {"paragraph_vector": [-59.706077, -53.513801], "paragraph_keywords": ["day", "person", "food", "perspective"]}, {"paragraph_vector": [133.998626, -14.138735], "paragraph_keywords": ["students", "content", "movies", "locations"]}, {"paragraph_vector": [132.900634, -12.623095], "paragraph_keywords": ["movie", "mode", "viewing", "vr"]}, {"paragraph_vector": [135.021942, -12.429759], "paragraph_keywords": ["students", "vr", "content", "teachers"]}, {"paragraph_vector": [133.650695, -12.887355], "paragraph_keywords": ["students", "storyboarding", "mumbai", "engagement"]}, {"paragraph_vector": [134.641586, -14.463601], "paragraph_keywords": ["students", "respect", "mumbai", "movie"]}, {"paragraph_vector": [135.317703, -15.912647], "paragraph_keywords": ["students", "farmers", "thought", "realized"]}, {"paragraph_vector": [135.920333, -12.764385], "paragraph_keywords": ["students", "vr", "process", "reflected"]}, {"paragraph_vector": [138.079162, -8.408851], "paragraph_keywords": ["vr", "environments", "learning", "ways"]}, {"paragraph_vector": [134.443817, -8.369734], "paragraph_keywords": ["vr", "content", "explore", "students"]}, {"paragraph_vector": [137.340682, -10.471194], "paragraph_keywords": ["vr", "meaning", "learning", "cameras"]}, {"paragraph_vector": [137.453948, -11.007488], "paragraph_keywords": ["students", "storyboarding", "vr", "cameras"]}, {"paragraph_vector": [136.789932, -12.638633], "paragraph_keywords": ["vr", "students", "work", "stories"]}, {"paragraph_vector": [136.601531, -10.037197], "paragraph_keywords": ["vr", "north", "technology", "learning"]}, {"paragraph_vector": [136.877548, -7.018332], "paragraph_keywords": ["vr", "realms", "learning", "storytelling"]}], "content": {}, "doi": "10.1145/3290605.3300526"}, {"uri": "201", "title": "Understanding Life Transitions: A Case Study of Support Needs of Low-Income Mothers ", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Annu Sible Prabhakar", "Erik Stolterman"], "summary": "Life transitions are an integral part of the human experience. However, research shows that lack of support during life transitions can result in adverse health outcomes. To better understand the support needs and structures of low-income women during transition to motherhood, we interviewed 10 women and their 14 supporters during the transition. Our findings suggest that support needs and structures of mothers evolve during transition, and that they also vary by socio-economic contexts. In this paper, we detail our study design and findings. Informed by our findings, we posit that all life-transitions are not the same, and that therefore, the optimal support intervention point varies for different life transitions. Currently there are no tools available to identify optimal support intervention points during life transitions. To this end, we also introduce a preliminary framework the Strength-Stress-Analysis (SSA) framework to identify optimal support intervention points during life-transitions.", "keywords": ["boyfriend", "need", "information", "got", "mother", "depression", "analysis", "interview", "income", "woman", "transition", "intervention", "motherhood", "participant", "people", "living", "identify", "health", "page", "experience", "mom", "including", "life", "phase", "data", "study", "element", "stress", "said", "framework", "support", "childbirth", "research", "paper", "pregnancy", "supporter", "strength"], "document_vector": [119.532897, 77.503967], "paragraphs": [{"paragraph_vector": [146.667083, -49.37648], "paragraph_keywords": ["transitions", "copies", "computing", "health"]}, {"paragraph_vector": [144.786621, -48.995803], "paragraph_keywords": ["support", "income", "mothers", "include"]}, {"paragraph_vector": [145.985244, -49.24868], "paragraph_keywords": ["support", "transitions", "life", "research"]}, {"paragraph_vector": [145.534271, -45.861934], "paragraph_keywords": ["support", "health", "women", "transition"]}, {"paragraph_vector": [152.46051, -52.653598], "paragraph_keywords": ["life", "women", "transitions", "relationship"]}, {"paragraph_vector": [134.785339, -51.269844], "paragraph_keywords": ["women", "participants", "supporters", "mothers"]}, {"paragraph_vector": [144.647308, -44.115081], "paragraph_keywords": ["interview", "interviews", "data", "participants"]}, {"paragraph_vector": [132.7807, -39.206821], "paragraph_keywords": ["going", "participants", "pregnancy", "data"]}, {"paragraph_vector": [147.68103, -46.042411], "paragraph_keywords": ["feel", "pregnancy", "life", "mom"]}, {"paragraph_vector": [145.703948, -42.101509], "paragraph_keywords": ["pregnancy", "study", "depression", "women"]}, {"paragraph_vector": [150.813919, -42.796192], "paragraph_keywords": ["living", "smoking", "stop", "housing"]}, {"paragraph_vector": [149.629165, -45.201934], "paragraph_keywords": ["said", "contact", "interview", "know"]}, {"paragraph_vector": [147.354431, -44.264968], "paragraph_keywords": ["support", "women", "interview", "partner"]}, {"paragraph_vector": [147.291748, -44.605831], "paragraph_keywords": ["study", "support", "money", "working"]}, {"paragraph_vector": [147.113555, -45.363063], "paragraph_keywords": ["support", "living", "supporters", "gon"]}, {"paragraph_vector": [143.501281, -45.763034], "paragraph_keywords": ["support", "transition", "need", "intervention"]}, {"paragraph_vector": [143.943099, -50.340061], "paragraph_keywords": ["strength", "support", "elements", "phase"]}, {"paragraph_vector": [145.211883, -47.333465], "paragraph_keywords": ["support", "intervention", "strength", "elements"]}, {"paragraph_vector": [143.005126, -46.860908], "paragraph_keywords": ["support", "life", "women", "framework"]}], "content": {}, "doi": "10.1145/3290605.3300503"}, {"uri": "202", "title": "Comparing Effectiveness and Engagement of Data Comics and Infographics", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Zezhong Wang", "Shunming Wang", "Matteo Farinella", "Dave Murray-Rust", "Nathalie Henry Riche", "Benjamin Bach"], "summary": "This paper compares the effectiveness of data comics and infographics for data-driven storytelling. While infographics are widely used, comics are increasingly popular for explaining complex and scientific concepts. However, empirical evidence comparing the effectiveness and engagement of infographics, comics and illustrated texts is still lacking. We report on the results of two complementary studies, one in a controlled setting and one in the wild. Our results suggest participants largely prefer data comics in terms of enjoyment, focus, and overall engagement and that comics improve understanding and recall of information in the stories. Our Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed", "keywords": ["message", "reading", "time", "information", "design", "reported", "technique", "visitor", "comic", "engagement", "story", "result", "read", "participant", "infographics", "use", "people", "material", "group", "reader", "visualization", "page", "compared", "understanding", "infographic", "found", "content", "including", "feedback", "illustrated", "data", "study", "alliance", "support", "picture", "text", "format", "order", "paper", "question", "panel", "level", "figure", "illustratedtext"], "document_vector": [3.884389, 11.624759], "paragraphs": [{"paragraph_vector": [167.560073, 51.086765], "paragraph_keywords": ["data", "comics", "audiences", "communication"]}, {"paragraph_vector": [173.142852, 50.513137], "paragraph_keywords": ["data", "comics", "infographics", "study"]}, {"paragraph_vector": [168.44284, 50.834213], "paragraph_keywords": ["comics", "understanding", "information", "text"]}, {"paragraph_vector": [166.790435, 52.342388], "paragraph_keywords": ["data", "comics", "infographics", "formats"]}, {"paragraph_vector": [170.92102, 51.683315], "paragraph_keywords": ["text", "picture", "formats", "integration"]}, {"paragraph_vector": [167.513824, 51.873916], "paragraph_keywords": ["study", "participants", "text", "stories"]}, {"paragraph_vector": [167.368927, 78.557807], "paragraph_keywords": ["energy", "changed", "alliances", "stories"]}, {"paragraph_vector": [169.361083, 52.003719], "paragraph_keywords": ["text", "understanding", "paper", "design"]}, {"paragraph_vector": [167.066101, 49.937911], "paragraph_keywords": ["participants", "story", "formats", "information"]}, {"paragraph_vector": [168.994735, 51.277503], "paragraph_keywords": ["participants", "read", "story", "format"]}, {"paragraph_vector": [169.861419, 50.818012], "paragraph_keywords": ["accuracy", "techniques", "participants", "understanding"]}, {"paragraph_vector": [169.088409, 52.570392], "paragraph_keywords": ["fact", "participants", "information", "performance"]}, {"paragraph_vector": [168.859436, 49.921218], "paragraph_keywords": ["participants", "text", "figure", "order"]}, {"paragraph_vector": [169.3031, 51.10876], "paragraph_keywords": ["found", "rated", "reading", "figure"]}, {"paragraph_vector": [168.818572, 52.09613], "paragraph_keywords": ["time", "participants", "overview", "information"]}, {"paragraph_vector": [170.426055, 51.204505], "paragraph_keywords": ["format", "study", "text", "comics"]}, {"paragraph_vector": [170.058547, 50.547851], "paragraph_keywords": ["infographic", "study", "visitors", "comics"]}, {"paragraph_vector": [165.390655, 52.003433], "paragraph_keywords": ["groups", "format", "comics", "people"]}, {"paragraph_vector": [170.52301, 53.00896], "paragraph_keywords": ["comics", "participants", "information", "data"]}, {"paragraph_vector": [167.71846, 49.777908], "paragraph_keywords": ["panels", "comics", "information", "overview"]}, {"paragraph_vector": [170.661361, 51.972518], "paragraph_keywords": ["visualization", "panels", "comics", "studies"]}, {"paragraph_vector": [171.990341, 51.574169], "paragraph_keywords": ["text", "infographics", "topics", "people"]}, {"paragraph_vector": [170.89151, 51.297313], "paragraph_keywords": ["comics", "data", "study", "infographics"]}], "content": {}, "doi": "10.1145/3290605.3300871"}, {"uri": "203", "title": "RayCursor: A 3D Pointing Facilitation Technique based on Raycasting", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Marc Baloup", "Thomas Pietrzak"], "summary": "Raycasting is the most common target pointing technique in virtual reality environments. However, performance on small and distant targets is impacted by the accuracy of the pointing device and the user\u2019s motor skills. Current pointing facilitation techniques are currently only applied in the context of the virtual hand, i.e. for targets within reach. We propose enhancements to Raycasting: filtering the ray, and adding a controllable cursor on the ray to select the nearest target. We describe a series of studies for the design of the visual feedforward, filtering technique, as well as a comparative study between different 3D pointing techniques. Our results show that highlighting the nearest target is one of the most efficient visual feedforward technique. We also show that filtering the ray reduces error rate in a drastic way. Finally we show the benefits of RayCursor compared to Raycasting and another technique from the literature. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300331 CCS CONCEPTS \u2022Human-centered computing\u2192Virtual reality;Pointing; Gestural input;", "keywords": ["transfer", "position", "controller", "time", "object", "selection", "performance", "cursor", "rate", "technique", "pointing", "experiment", "error", "environment", "raycursor", "user", "et", "selected", "participant", "use", "effect", "bubble", "function", "freedom", "distance", "hand", "raycasting", "ray", "study", "filtering", "select", "target", "paper", "filter"], "document_vector": [-167.695358, -51.319038], "paragraphs": [{"paragraph_vector": [-35.62321, 22.528476], "paragraph_keywords": ["techniques", "technique", "devices", "objects"]}, {"paragraph_vector": [-28.506982, 24.594215], "paragraph_keywords": ["techniques", "ray", "cursor", "raycasting"]}, {"paragraph_vector": [-15.434962, 17.57545], "paragraph_keywords": ["objects", "target", "depth", "ray"]}, {"paragraph_vector": [-25.263677, 26.933515], "paragraph_keywords": ["selection", "ray", "based", "select"]}, {"paragraph_vector": [-42.420963, 20.590204], "paragraph_keywords": ["pointing", "targets", "technique", "cursor"]}, {"paragraph_vector": [-34.056259, 31.739349], "paragraph_keywords": ["cursor", "bubble", "techniques", "ray"]}, {"paragraph_vector": [-42.740501, 8.375144], "paragraph_keywords": ["transfer", "function", "cursor", "speed"]}, {"paragraph_vector": [-31.375846, 25.12033], "paragraph_keywords": ["target", "cursor", "distance", "bubble"]}, {"paragraph_vector": [-26.957565, 26.98888], "paragraph_keywords": ["ray", "controller", "filter", "filtering"]}, {"paragraph_vector": [-19.45856, 29.744085], "paragraph_keywords": ["target", "error", "targets", "participants"]}, {"paragraph_vector": [-24.182922, 27.784994], "paragraph_keywords": ["target", "participants", "feedforwards", "time"]}, {"paragraph_vector": [-21.206285, 26.730726], "paragraph_keywords": ["effect", "p", "applied", "techniques"]}, {"paragraph_vector": [-21.044685, 34.22546], "paragraph_keywords": ["raycasting", "error", "rate", "performance"]}, {"paragraph_vector": [-26.403236, 22.672893], "paragraph_keywords": ["function", "position", "distprop", "target"]}, {"paragraph_vector": [-20.847902, 28.590288], "paragraph_keywords": ["targets", "participants", "filtering", "experiment"]}, {"paragraph_vector": [-21.222679, 29.55713], "paragraph_keywords": ["selection", "error", "effect", "target"]}, {"paragraph_vector": [-25.19382, 25.933], "paragraph_keywords": ["cursor", "ray", "raycursor", "user"]}, {"paragraph_vector": [-27.399978, 28.224655], "paragraph_keywords": ["technique", "raycursor", "cursor", "control"]}, {"paragraph_vector": [-22.211111, 27.890466], "paragraph_keywords": ["user", "error", "targets", "e"]}, {"paragraph_vector": [-21.844203, 30.132778], "paragraph_keywords": ["effect", "g", "comparisons", "pairwise"]}, {"paragraph_vector": [-23.915763, 29.232477], "paragraph_keywords": ["selection", "raycursor", "effect", "error"]}, {"paragraph_vector": [-28.49065, 26.406566], "paragraph_keywords": ["raycasting", "ray", "cursor", "technique"]}, {"paragraph_vector": [-25.604988, 27.036281], "paragraph_keywords": ["work", "enable", "raycursor", "selection"]}], "content": {}, "doi": "10.1145/3290605.3300889"}, {"uri": "204", "title": "\u201cCollective Wisdom\u201d: Inquiring into Collective Homes as a Site for HCI Design", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jo Shin", "Gabriela Aceves Sep\u00falveda", "William Odom"], "summary": "The home has been a major focus of the HCI community for over two decades. Despite this body of research, nascent works have argued that HCI\u2019s characterization of \u2018the home\u2019 remains narrow and requires more diverse accounts of domestic configurations. Our work contributes to this area through a four-month ethnography of three collective homes in Vancouver, Canada. Collective homes represent an alternative housing model that offers agency to individual members and the collective group by sharing values, resources, labour, space and memory. Our paper offers two contributions. First, we offer an in-depth design ethnography of three collective homes, attending to the values, ownership models, practices, and everyday interactions observed in the ongoing making of these domestic settings. Second, we interpret and synthesize our findings to provide new opportunities for expanding the way we conceptualize and design for \u2018the home\u2019 in HCI.", "keywords": ["based", "housing", "time", "need", "person", "resource", "design", "home", "environment", "ownership", "thing", "house", "sharing", "shared", "mountainview", "work", "space", "participant", "people", "group", "living", "agency", "owned", "think", "page", "household", "year", "property", "including", "peter", "provided", "culture", "collective", "labour", "member", "life", "practice", "contribution", "study", "owner", "chris", "support", "system", "union", "research", "club", "term", "hci", "spectrum", "site", "paper", "share", "value", "city", "community", "vancouver"], "document_vector": [103.565505, 38.528099], "paragraphs": [{"paragraph_vector": [-62.127338, -62.4248], "paragraph_keywords": ["ownership", "home", "hci", "house"]}, {"paragraph_vector": [-67.256591, -63.562412], "paragraph_keywords": ["home", "hci", "space", "works"]}, {"paragraph_vector": [-67.809196, -64.314331], "paragraph_keywords": ["home", "living", "housing", "research"]}, {"paragraph_vector": [-78.89785, -71.966049], "paragraph_keywords": ["housing", "vancouver", "study", "houses"]}, {"paragraph_vector": [-62.884635, -62.606143], "paragraph_keywords": ["participants", "household", "interviews", "interview"]}, {"paragraph_vector": [130.535522, -38.130603], "paragraph_keywords": ["living", "data", "population", "themes"]}, {"paragraph_vector": [-61.22684, -62.646057], "paragraph_keywords": ["house", "household", "collective", "albert"]}, {"paragraph_vector": [-60.539134, -61.653564], "paragraph_keywords": ["house", "members", "community", "chris"]}, {"paragraph_vector": [-59.738204, -62.49229], "paragraph_keywords": ["ownership", "households", "house", "home"]}, {"paragraph_vector": [-57.648998, -63.284225], "paragraph_keywords": ["members", "chris", "resources", "mountainview"]}, {"paragraph_vector": [-62.103958, -62.566513], "paragraph_keywords": ["home", "peter", "agency", "things"]}, {"paragraph_vector": [-65.000251, -60.921501], "paragraph_keywords": ["house", "time", "members", "changes"]}, {"paragraph_vector": [-62.207443, -59.559494], "paragraph_keywords": ["ownership", "spectrum", "members", "labour"]}, {"paragraph_vector": [-60.146697, -63.641437], "paragraph_keywords": ["labour", "meals", "needs", "chore"]}, {"paragraph_vector": [-54.858482, -62.976627], "paragraph_keywords": ["labour", "space", "balance", "think"]}, {"paragraph_vector": [-70.195808, -61.463996], "paragraph_keywords": ["house", "members", "people", "space"]}, {"paragraph_vector": [-59.026321, -62.765628], "paragraph_keywords": ["members", "house", "piano", "ownership"]}, {"paragraph_vector": [-59.450973, -64.227127], "paragraph_keywords": ["beer", "diy", "households", "term"]}, {"paragraph_vector": [-64.555465, -66.167076], "paragraph_keywords": ["consensus", "term", "group", "decision"]}, {"paragraph_vector": [-56.737251, -69.17443], "paragraph_keywords": ["property", "owners", "case", "leases"]}, {"paragraph_vector": [-61.868125, -61.609104], "paragraph_keywords": ["home", "living", "collectives", "members"]}, {"paragraph_vector": [-58.807453, -61.435474], "paragraph_keywords": ["ownership", "support", "things", "people"]}, {"paragraph_vector": [-58.778022, -62.662506], "paragraph_keywords": ["ownership", "owned", "things", "house"]}, {"paragraph_vector": [-63.620235, -62.403831], "paragraph_keywords": ["ownership", "labour", "space", "include"]}, {"paragraph_vector": [-58.150669, -62.10781], "paragraph_keywords": ["shared", "user", "power", "support"]}, {"paragraph_vector": [-61.773918, -69.563125], "paragraph_keywords": ["work", "house", "systems", "design"]}, {"paragraph_vector": [-59.88422, -62.226989], "paragraph_keywords": ["ownership", "households", "support", "hci"]}], "content": {}, "doi": "10.1145/3290605.3300703"}, {"uri": "205", "title": "The Impact of Web Browser Reader Views on Reading Speed and User Experience", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Qisheng Li"], "summary": "As reading increasingly shifts from paper to online media, many web browsers now provide a \u201cReader View,\u201d which modifies web page layout and design for better readability. However, research has yet to establish whether Reader Views are effective in improving readability and how they might change the user experience. We characterize how Mozilla Firefox\u2019s Reader View significantly reduces the visual complexity of websites by excluding menus, images, and content. We then conducted an online study with 391 participants (including 42 who self-reported having been diagnosed with dyslexia), showing that compared to standard websites the Reader View increased reading speed by 5% for readers on average, and significantly improved perceived readability and visual appeal. We suggest guidelines for the design of websites and browsers that better support people with varying reading skills.", "keywords": ["reading", "perceived", "dyslexia", "aesthetic", "comprehension", "node", "contain", "design", "speed", "duration", "avoid", "provide", "user", "work", "word", "read", "result", "participant", "use", "web", "people", "line", "readability", "screen", "reader", "firefox", "page", "experience", "number", "content", "found", "including", "diagnosed", "shown", "study", "element", "image", "text", "view", "website", "webpage", "question", "paper"], "document_vector": [-125.278869, -66.000038], "paragraphs": [{"paragraph_vector": [-173.813568, 49.760807], "paragraph_keywords": ["reading", "people", "copies", "reader"]}, {"paragraph_vector": [-169.534225, 51.355178], "paragraph_keywords": ["reader", "view", "reading", "webpages"]}, {"paragraph_vector": [-171.629043, 49.78038], "paragraph_keywords": ["reading", "websites", "comprehension", "speed"]}, {"paragraph_vector": [-172.972717, 50.427391], "paragraph_keywords": ["text", "people", "screen", "readability"]}, {"paragraph_vector": [-169.181594, 51.928108], "paragraph_keywords": ["view", "reader", "text", "avoid"]}, {"paragraph_vector": [152.73851, 69.65789], "paragraph_keywords": ["reader", "content", "view", "html"]}, {"paragraph_vector": [140.062011, 68.860214], "paragraph_keywords": ["content", "elements", "class", "view"]}, {"paragraph_vector": [155.762222, 66.87046], "paragraph_keywords": ["reader", "view", "pages", "images"]}, {"paragraph_vector": [178.552825, 59.162078], "paragraph_keywords": ["reader", "view", "webpages", "website"]}, {"paragraph_vector": [-170.727905, 49.705879], "paragraph_keywords": ["reader", "view", "study", "reading"]}, {"paragraph_vector": [-167.942413, 50.182994], "paragraph_keywords": ["webpages", "view", "participants", "reader"]}, {"paragraph_vector": [-178.238922, 48.969501], "paragraph_keywords": ["webpage", "questions", "participants", "duration"]}, {"paragraph_vector": [-168.90335, 48.500675], "paragraph_keywords": ["participants", "webpage", "questions", "condition"]}, {"paragraph_vector": [-168.663024, 51.603031], "paragraph_keywords": ["participants", "reading", "variables", "models"]}, {"paragraph_vector": [-167.277313, 51.128429], "paragraph_keywords": ["participants", "reading", "speed", "diagnosed"]}, {"paragraph_vector": [-172.24794, 51.022686], "paragraph_keywords": ["view", "reader", "webpages", "participants"]}, {"paragraph_vector": [-172.719375, 51.518024], "paragraph_keywords": ["reader", "reading", "view", "speed"]}, {"paragraph_vector": [-175.629562, 53.987071], "paragraph_keywords": ["view", "reading", "reader", "images"]}, {"paragraph_vector": [-177.744232, 54.389328], "paragraph_keywords": ["view", "reader", "websites", "content"]}, {"paragraph_vector": [-168.86621, 50.649948], "paragraph_keywords": ["reader", "view", "developers", "reading"]}, {"paragraph_vector": [-170.873382, 51.644096], "paragraph_keywords": ["reader", "view", "reading", "websites"]}, {"paragraph_vector": [-169.712554, 53.831356], "paragraph_keywords": ["dataset", "websites", "study", "view"]}], "content": {}, "doi": "10.1145/3290605.3300554"}, {"uri": "206", "title": "Mapping the Landscape of Creativity Support  Tools in HCI", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jonas Frich"], "summary": "Creativity Support Tools (CSTs) play a fundamental role in the study of creativity inHuman-Computer Interaction (HCI). Even so, there is no consensus definition of the term \u2018CST\u2019 in HCI, and in most studies, CSTs have been construed as oneoff exploratory prototypes, typically built by the researchers themselves. This makes it difficult to clearly demarcate CST research, but also to compare findings across studies, which impedes advancement in digital creativity as a growing field of research. Based on a literature review of 143 papers from the ACM Digital Library (1999-2018), we contribute a first overview of the key characteristics of CSTs developed by the HCI community. Moreover, we propose a tentative definition of a CST to help strengthen knowledge sharing across CST studies. We end by discussing our study\u2019s implications for future HCI research on CSTs and digital creativity.", "keywords": ["complexity", "process", "based", "time", "trend", "al", "development", "intended", "sampled", "design", "analysis", "problem", "creativity", "focus", "model", "type", "et", "sample", "thinking", "work", "cst", "tool", "evaluation", "use", "publication", "acm", "page", "number", "field", "year", "definition", "developed", "generation", "study", "researcher", "designer", "contribution", "ideation", "support", "research", "coding", "order", "hci", "paper", "level", "community", "code"], "document_vector": [42.043518, -6.613234], "paragraphs": [{"paragraph_vector": [131.477249, 47.639102], "paragraph_keywords": ["creativity", "hci", "copies", "tools"]}, {"paragraph_vector": [134.652221, 50.348175], "paragraph_keywords": ["csts", "research", "hci", "creativity"]}, {"paragraph_vector": [133.041198, 49.284481], "paragraph_keywords": ["research", "hci", "csts", "studies"]}, {"paragraph_vector": [131.503189, 47.589118], "paragraph_keywords": ["research", "development", "csts", "tools"]}, {"paragraph_vector": [134.328033, 45.981483], "paragraph_keywords": ["creativity", "research", "studies", "model"]}, {"paragraph_vector": [129.133499, 49.1156], "paragraph_keywords": ["creativity", "research", "hci", "wave"]}, {"paragraph_vector": [134.070159, 47.877365], "paragraph_keywords": ["creativity", "process", "model", "product"]}, {"paragraph_vector": [129.588165, 50.272811], "paragraph_keywords": ["creativity", "csts", "hci", "paper"]}, {"paragraph_vector": [86.677597, 1.434702], "paragraph_keywords": ["papers", "sample", "activity", "years"]}, {"paragraph_vector": [74.256752, 54.245552], "paragraph_keywords": ["category", "codes", "number", "researchers"]}, {"paragraph_vector": [130.276458, 49.705646], "paragraph_keywords": ["csts", "devices", "evaluation", "publications"]}, {"paragraph_vector": [135.96907, 50.744216], "paragraph_keywords": ["publications", "complexity", "csts", "cst"]}, {"paragraph_vector": [129.674118, 48.520046], "paragraph_keywords": ["publications", "sample", "csts", "process"]}, {"paragraph_vector": [131.023178, 51.968624], "paragraph_keywords": ["publications", "csts", "trends", "sample"]}, {"paragraph_vector": [129.579284, 49.286666], "paragraph_keywords": ["csts", "representation", "sample", "tools"]}, {"paragraph_vector": [126.870971, 49.166622], "paragraph_keywords": ["csts", "creativity", "coding", "research"]}, {"paragraph_vector": [127.955841, 49.055122], "paragraph_keywords": ["thinking", "csts", "community", "evaluation"]}, {"paragraph_vector": [129.55841, 48.516372], "paragraph_keywords": ["research", "process", "implementation", "given"]}, {"paragraph_vector": [131.665222, 48.790222], "paragraph_keywords": ["research", "csts", "tools", "creativity"]}, {"paragraph_vector": [127.657661, 48.564319], "paragraph_keywords": ["research", "csts", "creativity", "definition"]}, {"paragraph_vector": [129.02507, 48.825603], "paragraph_keywords": ["csts", "research", "tools", "creativity"]}, {"paragraph_vector": [132.168518, 48.246456], "paragraph_keywords": ["creativity", "tools", "research", "grant"]}], "content": {}, "doi": "10.1145/3290605.3300398"}, {"uri": "207", "title": "TrackCap: Enabling Smartphones for 3D Interaction on Mobile Head-Mounted Displays-.15cm", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Peter Mohr", "Markus Tatzgern", "Tobias Langlotz", "Andreas Lang", "Dieter Schmalstieg", "Denis Kalkofen"], "summary": "The latest generation of consumer market Head-mounted displays (HMD) now include self-contained inside-out tracking of head motions, which makes them suitable for mobile applications. However, 3D tracking of input devices is either not included at all or requires to keep the device in sight, so that it can be observed from a sensor mounted on the HMD. Both approaches make natural interactions cumbersome in mobile applications. TrackCap, a novel approach for 3D tracking of input devices, turns a conventional smartphone into a precise 6DOF input device for an HMD user. The device can be conveniently operated both inside and Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300815 outside the HMD\u2019s field of view, while it provides additional 2D input and output capabilities.", "keywords": ["manipulation", "based", "controller", "hmd", "time", "object", "phone", "selection", "performance", "hardware", "experiment", "pointing", "environment", "error", "provide", "camera", "user", "interaction", "tango", "participant", "use", "drift", "trackcap", "orientation", "smartphone", "tracking", "test", "task", "hand", "device", "data", "raycasting", "ray", "approach", "system", "support", "ar", "sphere", "mbo", "paper", "input", "pose", "project", "figure"], "document_vector": [26.399162, -59.319351], "paragraphs": [{"paragraph_vector": [-42.499149, 18.497377], "paragraph_keywords": ["hmd", "tracking", "interaction", "support"]}, {"paragraph_vector": [-45.061985, 29.040397], "paragraph_keywords": ["hmd", "smartphone", "approach", "camera"]}, {"paragraph_vector": [-34.735771, 21.868515], "paragraph_keywords": ["based", "tracking", "sensors", "techniques"]}, {"paragraph_vector": [-44.119895, 31.829399], "paragraph_keywords": ["tracking", "interaction", "hmd", "systems"]}, {"paragraph_vector": [-44.903011, 30.830688], "paragraph_keywords": ["hmd", "pose", "data", "input"]}, {"paragraph_vector": [-47.203334, 31.607391], "paragraph_keywords": ["tracking", "latency", "center", "smartphone"]}, {"paragraph_vector": [-47.418937, 29.814123], "paragraph_keywords": ["camera", "range", "fov", "trackcap"]}, {"paragraph_vector": [-35.059448, 19.296743], "paragraph_keywords": ["trackcap", "pointing", "spheres", "task"]}, {"paragraph_vector": [-37.968452, 18.586402], "paragraph_keywords": ["blocks", "hololens", "task", "phone"]}, {"paragraph_vector": [-27.205322, 13.378508], "paragraph_keywords": ["trackcap", "drift", "pointing", "task"]}, {"paragraph_vector": [-30.285375, 20.477724], "paragraph_keywords": ["trackcap", "experiment", "selection", "mbo"]}, {"paragraph_vector": [-33.465217, 22.52976], "paragraph_keywords": ["experiment", "manipulation", "task", "objects"]}, {"paragraph_vector": [-27.724401, 27.178228], "paragraph_keywords": ["trackcap", "mbo", "error", "tct"]}, {"paragraph_vector": [-44.926658, 29.703979], "paragraph_keywords": ["trackcap", "camera", "drift", "participants"]}, {"paragraph_vector": [-34.93494, 11.024214], "paragraph_keywords": ["camswitch", "participants", "tango", "task"]}, {"paragraph_vector": [-46.520992, 29.857015], "paragraph_keywords": ["trackcap", "motion", "camswitch", "device"]}, {"paragraph_vector": [-32.464389, 16.080888], "paragraph_keywords": ["task", "participants", "tango", "system"]}, {"paragraph_vector": [-36.206417, 23.38277], "paragraph_keywords": ["trackcap", "tango", "interaction", "tangocap"]}, {"paragraph_vector": [-46.164081, 28.631324], "paragraph_keywords": ["trackcap", "interaction", "camera", "system"]}, {"paragraph_vector": [-33.548988, 47.11819], "paragraph_keywords": ["interaction", "number", "ar", "controllers"]}, {"paragraph_vector": [-44.581367, 28.876787], "paragraph_keywords": ["trackcap", "tracking", "support", "controllers"]}, {"paragraph_vector": [26.591165, 31.460103], "paragraph_keywords": ["competence", "project", "vrvis", "hmd"]}], "content": {}, "doi": "10.1145/3290605.3300603"}, {"uri": "208", "title": "HeatCraft: Designing Playful Experiences with Ingestible Sensors via Localized Thermal Stimuli", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Zhuying Li", "Yan Wang", "Wei Wang", "Weikang Chen", "Ti Hoang", "Stefan Greuter", "Florian \u2018Floyd\u2019 Mueller"], "summary": "Ingestible sensors are pill-like sensors that people swallow mainly for medical purposes. We propose that ingestible sensors also offer unique opportunities to facilitate intriguing bodily experiences in a playful manner. To explore this, we present \u201cHeatCraft\u201d, a two-player system that translates the user\u2019s body temperature measured by an ingestible sensor to localized thermal stimuli delivered through a waist belt equipped with heating pads. We conducted a study with 16 participants. The study revealed three design themes (Integration of body and technology, Integration of internal body and outside world, and Integration of play and life) along with some open challenges. In summary, this work contributes knowledge to the future design of playful experiences with ingestible sensors.", "keywords": ["localized", "change", "body", "player", "design", "reported", "sensation", "environment", "example", "temperature", "sensor", "designing", "user", "facilitate", "activity", "help", "play", "interaction", "know", "work", "participant", "integration", "designed", "think", "world", "experience", "felt", "feedback", "stimulus", "heating", "data", "heat", "game", "technology", "feel", "designer", "study", "system", "support", "influence", "belt", "heatcraft"], "document_vector": [59.919677, -16.398485], "paragraphs": [{"paragraph_vector": [-97.67205, -23.835039], "paragraph_keywords": ["sensors", "copies", "aspects", "acm"]}, {"paragraph_vector": [-100.168273, -21.380033], "paragraph_keywords": ["sensors", "players", "user", "play"]}, {"paragraph_vector": [-98.772087, -22.179256], "paragraph_keywords": ["body", "design", "perspective", "experience"]}, {"paragraph_vector": [-103.061676, -18.30784], "paragraph_keywords": ["sensations", "body", "game", "play"]}, {"paragraph_vector": [-98.521675, -20.32817], "paragraph_keywords": ["temperature", "sensor", "feedback", "arduino"]}, {"paragraph_vector": [-98.154502, -19.217191], "paragraph_keywords": ["stimuli", "thp", "body", "temperature"]}, {"paragraph_vector": [-99.33686, -20.710565], "paragraph_keywords": ["sensor", "data", "temperature", "players"]}, {"paragraph_vector": [-103.307777, -19.465003], "paragraph_keywords": ["players", "sensor", "activities", "system"]}, {"paragraph_vector": [-103.733329, -20.236864], "paragraph_keywords": ["body", "players", "heatcraft", "experiences"]}, {"paragraph_vector": [-100.845176, -16.911378], "paragraph_keywords": ["body", "think", "sensor", "example"]}, {"paragraph_vector": [-101.569587, -18.778364], "paragraph_keywords": ["body", "sensor", "temperature", "heat"]}, {"paragraph_vector": [-99.652854, -17.811994], "paragraph_keywords": ["body", "sensor", "change", "food"]}, {"paragraph_vector": [-102.562286, -19.614517], "paragraph_keywords": ["play", "heat", "body", "heatcraft"]}, {"paragraph_vector": [-101.29055, -21.701477], "paragraph_keywords": ["environment", "example", "world", "temperature"]}, {"paragraph_vector": [-105.480743, -22.651214], "paragraph_keywords": ["food", "system", "reported", "body"]}, {"paragraph_vector": [-104.212265, -18.513032], "paragraph_keywords": ["sensor", "thought", "body", "example"]}, {"paragraph_vector": [-103.05075, -20.670261], "paragraph_keywords": ["players", "experience", "participants", "reported"]}, {"paragraph_vector": [-100.782974, -18.372146], "paragraph_keywords": ["players", "system", "integration", "theory"]}, {"paragraph_vector": [-102.211608, -21.688089], "paragraph_keywords": ["user", "play", "experiences", "players"]}, {"paragraph_vector": [-97.819862, -21.4883], "paragraph_keywords": ["systems", "system", "body", "designing"]}, {"paragraph_vector": [-98.64907, -21.350296], "paragraph_keywords": ["players", "data", "designers", "heatcraft"]}, {"paragraph_vector": [-101.050239, -21.433944], "paragraph_keywords": ["body", "players", "player", "sensor"]}, {"paragraph_vector": [-99.582298, -18.701307], "paragraph_keywords": ["k\u00f6rper", "body", "leib", "experiences"]}, {"paragraph_vector": [-103.164085, -21.81179], "paragraph_keywords": ["experiences", "players", "sensors", "data"]}, {"paragraph_vector": [-101.632446, -22.022182], "paragraph_keywords": ["design", "support", "thanks", "sensors"]}], "content": {}, "doi": "10.1145/3290605.3300408"}, {"uri": "209", "title": "Understanding Perceptions of Problematic Facebook Use", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Justin Cheng", "Moira Burke", "Elena Goetz Davis"], "summary": "While many people use social network sites to connect with friends and family, some feel that their use is problematic, seriously afecting their sleep, work, or life. Pairing a survey of 20,000 Facebook users measuring perceptions of problematic use with behavioral and demographic data, we examined Facebook activities associated with problematic use as well as the kinds of people most likely to experience it. People who feel their use is problematic are more likely to be younger, male, and going through a major life event such as a breakup. They spend more time on the platform, particularly at night, and spend proportionally more time looking at profles and less time browsing their News Feeds. They also message their friends more frequently. While they are more likely to respond to notifcations, they are also more likely to deactivate their accounts, perhaps in an efort to better manage their time. Further, they are more likely to have seen content about social media or phone addiction. Notably, people reporting problematic use rate the site as more valuable to them, highlighting the complex relationship between technology use and well-being. A better understanding of problematic Facebook use can inform the design of context-appropriate and supportive tools to help people become more in control.", "keywords": ["message", "facebook", "time", "person", "deactivation", "defned", "self", "friend", "criterion", "relationship", "medium", "fraction", "notifcations", "addiction", "sample", "associated", "work", "impact", "use", "internet", "diferences", "people", "group", "post", "control", "experience", "number", "survey", "age", "experiencing", "life", "data", "technology", "spent", "research", "include", "account", "profle", "site", "report", "p"], "document_vector": [-36.480518, 59.920051], "paragraphs": [{"paragraph_vector": [-16.322498, -49.572906], "paragraph_keywords": ["use", "facebook", "site", "relationships"]}, {"paragraph_vector": [-15.860455, -50.979892], "paragraph_keywords": ["use", "time", "copies", "people"]}, {"paragraph_vector": [-17.223678, -51.593193], "paragraph_keywords": ["use", "internet", "facebook", "impact"]}, {"paragraph_vector": [-21.607782, -51.379783], "paragraph_keywords": ["use", "internet", "defned", "facebook"]}, {"paragraph_vector": [-21.859977, -51.705177], "paragraph_keywords": ["use", "facebook", "internet", "time"]}, {"paragraph_vector": [-17.467321, -50.940128], "paragraph_keywords": ["use", "facebook", "acquaintances", "time"]}, {"paragraph_vector": [-20.702772, -51.483253], "paragraph_keywords": ["facebook", "use", "control", "people"]}, {"paragraph_vector": [-16.534219, -52.386005], "paragraph_keywords": ["facebook", "use", "survey", "addiction"]}, {"paragraph_vector": [-17.516975, -49.976005], "paragraph_keywords": ["facebook", "use", "time", "number"]}, {"paragraph_vector": [-12.522398, -59.517829], "paragraph_keywords": ["friends", "messages", "fraction", "sent"]}, {"paragraph_vector": [-15.444082, -52.160514], "paragraph_keywords": ["use", "weeks", "facebook", "associated"]}, {"paragraph_vector": [-19.515764, -50.565879], "paragraph_keywords": ["use", "facebook", "matched", "account"]}, {"paragraph_vector": [-18.765762, -52.01057], "paragraph_keywords": ["use", "p", "people", "time"]}, {"paragraph_vector": [-19.618608, -51.355682], "paragraph_keywords": ["use", "spent", "time", "facebook"]}, {"paragraph_vector": [-18.027929, -51.516117], "paragraph_keywords": ["friends", "use", "sent", "time"]}, {"paragraph_vector": [-19.159996, -51.706771], "paragraph_keywords": ["people", "use", "received", "number"]}, {"paragraph_vector": [-15.170358, -52.944133], "paragraph_keywords": ["use", "people", "time", "facebook"]}, {"paragraph_vector": [-16.76225, -50.628295], "paragraph_keywords": ["people", "use", "time", "technology"]}, {"paragraph_vector": [-17.496404, -51.303649], "paragraph_keywords": ["use", "people", "life", "experiencing"]}, {"paragraph_vector": [-16.84395, -51.163227], "paragraph_keywords": ["use", "people", "media", "platforms"]}, {"paragraph_vector": [-18.267227, -51.102058], "paragraph_keywords": ["use", "facebook", "viewing", "profle"]}, {"paragraph_vector": [-12.370261, -52.591964], "paragraph_keywords": ["people", "use", "technology", "associated"]}], "content": {}, "doi": "10.1145/3290605.3300853"}, {"uri": "210", "title": "NVGaze: An Anatomically-Informed Dataset  for Low-Latency, Near-Eye Gaze Estimation", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Joohwan Kim", "Michael Stengel", "Shalini De Mello", "Alexander Majercik"], "summary": "Quality, diversity, and size of training data are critical factors for learning-based gaze estimators. We create two datasets satisfying these criteria for near-eye gaze estimation under infrared illumination: a synthetic dataset using anatomicallyinformed eye and face models with variations in face shape, gaze direction, pupil and iris, skin tone, and external conditions (2M images at 1280x960), and a real-world dataset collected with 35 subjects (2.5M images at 640x480). Using these datasets we train neural networks performing with submillisecond latency. Our gaze estimation network achieves 2.06(\u00b10.44)\u25e6 of accuracy across a wide 30\u25e6\u00d740\u25e6 field of view on real subjects excluded from training and 0.5\u25e6 best-case accuracy (across the same FOV) when explicitly trained for one real subject. We also train a pupil localization network which achieves higher robustness than previous methods.", "keywords": ["based", "requires", "condition", "al", "trained", "training", "location", "method", "layer", "provide", "subject", "gaze", "error", "camera", "accuracy", "model", "datasets", "eye", "et", "work", "use", "resolution", "screen", "learning", "size", "rendering", "page", "intensity", "dataset", "face", "tracking", "head", "estimation", "blink", "case", "variation", "data", "approach", "image", "system", "network", "illumination", "paper", "pupil", "axis", "lighting", "center"], "document_vector": [-84.178726, -59.716846], "paragraphs": [{"paragraph_vector": [-58.696544, -3.155659], "paragraph_keywords": ["tracking", "gaze", "copies", "input"]}, {"paragraph_vector": [-61.178447, -7.40432], "paragraph_keywords": ["gaze", "training", "images", "sight"]}, {"paragraph_vector": [-62.476329, -9.696581], "paragraph_keywords": ["gaze", "camera", "eye", "images"]}, {"paragraph_vector": [-61.293029, -8.965512], "paragraph_keywords": ["eye", "pupil", "gaze", "rendering"]}, {"paragraph_vector": [-62.494529, -7.936304], "paragraph_keywords": ["pupil", "images", "ms", "ellipse"]}, {"paragraph_vector": [-63.315391, -5.510437], "paragraph_keywords": ["images", "eye", "network", "training"]}, {"paragraph_vector": [-62.865962, -9.391067], "paragraph_keywords": ["images", "eye", "gaze", "subjects"]}, {"paragraph_vector": [-62.390869, -7.033366], "paragraph_keywords": ["head", "model", "eyeball", "eye"]}, {"paragraph_vector": [-61.305091, -8.215516], "paragraph_keywords": ["pupil", "eye", "skin", "light"]}, {"paragraph_vector": [-60.701629, -9.90801], "paragraph_keywords": ["eye", "data", "gaze", "illumination"]}, {"paragraph_vector": [-60.482921, -8.87398], "paragraph_keywords": ["gaze", "pupil", "subject", "blink"]}, {"paragraph_vector": [-60.900398, -8.076152], "paragraph_keywords": ["model", "gaze", "training", "data"]}, {"paragraph_vector": [-61.338573, -8.881002], "paragraph_keywords": ["training", "subjects", "gaze", "accuracy"]}, {"paragraph_vector": [-62.913806, -9.666563], "paragraph_keywords": ["eye", "images", "training", "gaze"]}, {"paragraph_vector": [-61.434715, -8.499897], "paragraph_keywords": ["network", "images", "image", "layer"]}, {"paragraph_vector": [-62.12313, -8.757922], "paragraph_keywords": ["pupil", "estimation", "images", "image"]}, {"paragraph_vector": [-65.175071, -16.022129], "paragraph_keywords": ["network", "dataset", "case", "pupilnet"]}, {"paragraph_vector": [-61.50946, -8.992362], "paragraph_keywords": ["networks", "pupil", "gaze", "estimation"]}, {"paragraph_vector": [-61.546504, -6.628472], "paragraph_keywords": ["accuracy", "gaze", "head", "training"]}, {"paragraph_vector": [-64.277069, -11.716114], "paragraph_keywords": ["network", "gaze", "blink", "eye"]}, {"paragraph_vector": [-62.840095, -9.414692], "paragraph_keywords": ["gaze", "based", "thank", "animation"]}], "content": {}, "doi": "10.1145/3290605.3300929"}, {"uri": "211", "title": "A Field Study of Teachers Using a Curriculum-integrated Digital Game", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Zhongxiu Peddycord-Liu", "Veronica Catet\u00e9", "Jessica Vandenberg", "Tiffany Barnes", "Collin F. Lynch", "Teomara Rutherford"], "summary": "We present a new framework describing how teachers use ST Math, a curriculum-integrated, year-long educational game, in 3rd-4th grade classrooms. We combined authentic classroom observations with teacher interviews to identify teacher needs and practices. Our findings extended and contrasted with prior work on teachers\u2019 behaviors around classroom games, identifying differences likely arising from a digital platform and year-long curricular integration. We suggest practical ways that curriculum-integrated games can be designed to help teachers support effective classroom culture and practice.", "keywords": ["based", "time", "child", "al", "need", "needed", "class", "progress", "interview", "wanted", "help", "stated", "activity", "school", "learn", "et", "work", "use", "learning", "pd", "concept", "teacher", "year", "content", "curriculum", "observed", "teaching", "gameplay", "culture", "classroom", "attention", "integrated", "game", "study", "st", "student", "support", "math", "research", "format", "objective", "paper", "report", "observation", "level", "access"], "document_vector": [-144.585845, 28.280866], "paragraphs": [{"paragraph_vector": [147.195861, 17.522018], "paragraph_keywords": ["games", "classrooms", "research", "use"]}, {"paragraph_vector": [147.757202, 18.746549], "paragraph_keywords": ["math", "students", "answers", "answer"]}, {"paragraph_vector": [146.64923, 17.448825], "paragraph_keywords": ["games", "classroom", "learning", "math"]}, {"paragraph_vector": [144.66307, 15.490848], "paragraph_keywords": ["games", "teachers", "game", "teacher"]}, {"paragraph_vector": [143.224746, 18.284418], "paragraph_keywords": ["teachers", "st", "math", "teacher"]}, {"paragraph_vector": [138.088226, 14.650297], "paragraph_keywords": ["teacher", "interviews", "teachers", "observations"]}, {"paragraph_vector": [145.837783, 15.853525], "paragraph_keywords": ["coding", "activities", "teacher", "teachers"]}, {"paragraph_vector": [145.727493, 15.467523], "paragraph_keywords": ["pd", "teachers", "game", "math"]}, {"paragraph_vector": [146.59642, 15.751037], "paragraph_keywords": ["teachers", "gameplay", "students", "math"]}, {"paragraph_vector": [147.34378, 18.338212], "paragraph_keywords": ["students", "teachers", "st", "math"]}, {"paragraph_vector": [147.298522, 16.723623], "paragraph_keywords": ["students", "math", "teachers", "progress"]}, {"paragraph_vector": [145.916534, 16.43819], "paragraph_keywords": ["math", "students", "teachers", "struggle"]}, {"paragraph_vector": [145.443634, 16.08892], "paragraph_keywords": ["math", "st", "stated", "students"]}, {"paragraph_vector": [146.689392, 15.276073], "paragraph_keywords": ["teachers", "time", "math", "students"]}, {"paragraph_vector": [146.690078, 17.7117], "paragraph_keywords": ["teachers", "culture", "classroom", "teacher"]}, {"paragraph_vector": [148.327102, 17.98081], "paragraph_keywords": ["teachers", "game", "classroom", "teaching"]}, {"paragraph_vector": [146.817291, 17.458606], "paragraph_keywords": ["students", "teachers", "help", "math"]}, {"paragraph_vector": [145.991592, 17.246454], "paragraph_keywords": ["observed", "classroom", "teachers", "students"]}, {"paragraph_vector": [147.186599, 17.454822], "paragraph_keywords": ["teachers", "students", "children", "needed"]}, {"paragraph_vector": [145.32109, 17.294307], "paragraph_keywords": ["students", "math", "objectives", "teachers"]}, {"paragraph_vector": [145.967971, 17.568607], "paragraph_keywords": ["students", "math", "st", "teachers"]}, {"paragraph_vector": [145.62564, 17.901634], "paragraph_keywords": ["students", "games", "game", "features"]}, {"paragraph_vector": [146.486785, 17.63426], "paragraph_keywords": ["students", "reports", "math", "teachers"]}, {"paragraph_vector": [146.191482, 17.81373], "paragraph_keywords": ["teachers", "math", "wanted", "gameplay"]}, {"paragraph_vector": [144.736999, 18.894123], "paragraph_keywords": ["students", "wanted", "teachers", "game"]}, {"paragraph_vector": [145.442687, 16.311298], "paragraph_keywords": ["teacher", "game", "year", "games"]}], "content": {}, "doi": "10.1145/3290605.3300439"}, {"uri": "212", "title": "Exploring and Designing for Memory Impairments in Depression", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Chengcheng Qu", "Corina Sas"], "summary": "Depression is an affective disorder with distinctive autobiographical memory impairments, including negative bias, overgeneralization and reduced positivity. Several clinical therapies address these impairments, and there is an opportunity to develop new supports for treatment by considering depression-associated memory impairments within design. We report on interviews with ten experts in treating depression, with expertise in both neuropsychology and cognitive behavioral therapies. The interviews explore approaches for addressing each of these memory impairments. We found consistent use of positive memories for treating all memory impairments, the challenge of direct retrieval, and the need to support the experience of positive memories. Our contributions aim to sensitize HCI researchers to the limitations of memory technologies, broaden their awareness of memory impairments beyond episodic memory recall, and inspire them to engage with this less explored design space. Our findings open up new design opportunities for memory technologies for depression, including positive memory banks for active encoding and selective retrieval, novel cues for supporting generative retrieval, and novel interfaces to strengthen the reliving of positive memories.", "keywords": ["process", "based", "time", "mentioned", "overgeneralization", "memory", "self", "depression", "training", "design", "thing", "example", "help", "user", "intervention", "thinking", "work", "use", "participant", "people", "material", "detail", "client", "cue", "treatment", "finding", "experience", "page", "retrieved", "addressing", "cbt", "content", "impairment", "life", "practice", "suggested", "technology", "therapist", "approach", "feel", "support", "event", "address", "research", "bias", "hci", "paper", "retrieve", "retrieval"], "document_vector": [32.750377, 74.164154], "paragraphs": [{"paragraph_vector": [-148.051651, -4.493988], "paragraph_keywords": ["memory", "depression", "impairments", "work"]}, {"paragraph_vector": [-144.441757, -4.015061], "paragraph_keywords": ["memory", "depression", "work", "impairments"]}, {"paragraph_vector": [-151.851394, -12.915919], "paragraph_keywords": ["interventions", "depression", "treatment", "cbt"]}, {"paragraph_vector": [-147.47615, -6.5787], "paragraph_keywords": ["memory", "treatment", "technologies", "depression"]}, {"paragraph_vector": [-145.865463, -4.792208], "paragraph_keywords": ["memory", "memories", "cues", "self"]}, {"paragraph_vector": [-147.670761, -0.917616], "paragraph_keywords": ["memory", "impairments", "depression", "self"]}, {"paragraph_vector": [-145.009216, -2.700208], "paragraph_keywords": ["memories", "people", "memory", "bias"]}, {"paragraph_vector": [-144.824874, -1.469277], "paragraph_keywords": ["depression", "memories", "memory", "users"]}, {"paragraph_vector": [-144.347457, -1.552141], "paragraph_keywords": ["participants", "literature", "overgeneralization", "interviews"]}, {"paragraph_vector": [-145.607315, -3.321237], "paragraph_keywords": ["memories", "clients", "people", "approaches"]}, {"paragraph_vector": [-144.356719, -0.891606], "paragraph_keywords": ["memories", "interpretation", "reframe", "clients"]}, {"paragraph_vector": [-144.942092, -1.542941], "paragraph_keywords": ["memories", "memory", "clients", "details"]}, {"paragraph_vector": [-147.220001, -4.785336], "paragraph_keywords": ["clients", "things", "memories", "life"]}, {"paragraph_vector": [-142.974197, -0.593974], "paragraph_keywords": ["clients", "memory", "life", "bank"]}, {"paragraph_vector": [-145.203369, 0.902924], "paragraph_keywords": ["retrieval", "memories", "cues", "memory"]}, {"paragraph_vector": [-146.066177, -2.996502], "paragraph_keywords": ["clients", "memory", "details", "process"]}, {"paragraph_vector": [-144.436492, -0.817041], "paragraph_keywords": ["clients", "thinking", "memories", "overgeneralization"]}, {"paragraph_vector": [-146.042251, -0.839567], "paragraph_keywords": ["details", "memories", "memory", "imagine"]}, {"paragraph_vector": [-144.016036, -3.271356], "paragraph_keywords": ["memories", "memory", "clients", "model"]}, {"paragraph_vector": [-150.139129, -2.651092], "paragraph_keywords": ["clients", "materials", "cues", "time"]}, {"paragraph_vector": [-146.347351, -2.777737], "paragraph_keywords": ["training", "clients", "memory", "materials"]}, {"paragraph_vector": [-145.612518, -5.796479], "paragraph_keywords": ["memory", "users", "interventions", "materials"]}, {"paragraph_vector": [-145.376052, -3.058786], "paragraph_keywords": ["memories", "memory", "clients", "depression"]}, {"paragraph_vector": [-144.503875, -3.848043], "paragraph_keywords": ["memory", "retrieval", "memories", "depression"]}, {"paragraph_vector": [-146.058746, -5.591102], "paragraph_keywords": ["cues", "retrieval", "content", "technology"]}, {"paragraph_vector": [-146.464065, -3.919801], "paragraph_keywords": ["memory", "depression", "memories", "retrieval"]}, {"paragraph_vector": [-145.864852, -3.331031], "paragraph_keywords": ["retrieval", "supported", "ireland", "foundation"]}], "content": {}, "doi": "10.1145/3290605.3300884"}, {"uri": "213", "title": "Scaptics and Highlight-Planes:  Immersive Interaction Techniques for Finding Occluded Features in 3D Scatterplots", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Arnaud Prouzeau"], "summary": "Three-dimensional scatterplots suffer from well-known perception and usability problems. In particular, overplotting and occlusion, mainly due to density and noise, prevent users from properly perceiving the data. Thanks to accurate head and hand tracking, immersive Virtual Reality (VR) setups provide new ways to interact and navigate with 3D scatterplots. VR also supports additional sensorymodalities such as haptic feedback. Inspired by methods commonly used in Scientific Visualisation to visually explore volumes, we propose two techniques that leverage the immersive aspects of VR: first, a density-based haptic vibration technique (Scaptics) which provides feedback through the controller; and second, an adaptation of a cutting plane for 3D scatterplots (HighlightPlane). We evaluated both techniques in a controlled study with two tasks involving density (finding highand lowdensity areas). Overall, Scaptics was the most time-efficient and accurate technique, however, in some conditions, it was outperformed by Highlight-Plane.", "keywords": ["explore", "vr", "point", "visualisation", "controller", "position", "density", "information", "performance", "feature", "design", "force", "highlight", "technique", "vibration", "scatterplots", "user", "volume", "interaction", "plane", "result", "space", "participant", "use", "scatterplot", "vibrotactile", "cutting", "page", "intensity", "number", "function", "feedback", "occlusion", "task", "data", "scaptics", "study", "difference", "showed", "paper", "cluster", "value", "level", "figure"], "document_vector": [178.894165, -50.066711], "paragraphs": [{"paragraph_vector": [-82.989204, 31.928956], "paragraph_keywords": ["reality", "copies", "scatterplots", "position"]}, {"paragraph_vector": [-63.093013, 43.284744], "paragraph_keywords": ["data", "density", "techniques", "plane"]}, {"paragraph_vector": [-51.006195, 47.701625], "paragraph_keywords": ["density", "improve", "exploration", "visualisation"]}, {"paragraph_vector": [-56.579902, 47.60931], "paragraph_keywords": ["occlusion", "visualisation", "techniques", "displays"]}, {"paragraph_vector": [-70.703491, 41.053112], "paragraph_keywords": ["feedback", "vibrotactile", "users", "visualisation"]}, {"paragraph_vector": [-67.083267, 45.465255], "paragraph_keywords": ["density", "data", "feedback", "points"]}, {"paragraph_vector": [-66.227783, 45.181228], "paragraph_keywords": ["use", "data", "techniques", "feedback"]}, {"paragraph_vector": [-73.169387, 45.907634], "paragraph_keywords": ["density", "kernel", "intensity", "volume"]}, {"paragraph_vector": [-69.475288, 43.621417], "paragraph_keywords": ["density", "controller", "vibration", "intensity"]}, {"paragraph_vector": [-71.180374, 43.63927], "paragraph_keywords": ["cutting", "plane", "data", "points"]}, {"paragraph_vector": [-73.467506, 42.352474], "paragraph_keywords": ["points", "plane", "effect", "data"]}, {"paragraph_vector": [-69.7014, 35.98579], "paragraph_keywords": ["vibration", "participants", "values", "base"]}, {"paragraph_vector": [-56.705982, 44.853557], "paragraph_keywords": ["points", "task", "density", "tasks"]}, {"paragraph_vector": [-41.35466, 53.724056], "paragraph_keywords": ["participants", "tasks", "study", "density"]}, {"paragraph_vector": [-24.209615, 30.838228], "paragraph_keywords": ["participants", "cross", "confidence", "means"]}, {"paragraph_vector": [-22.84284, 44.40876], "paragraph_keywords": ["results", "figure", "highlight", "spacing"]}, {"paragraph_vector": [-35.673938, 42.60947], "paragraph_keywords": ["reported", "density", "highlight", "plane"]}, {"paragraph_vector": [-43.814109, 50.090843], "paragraph_keywords": ["participants", "plane", "density", "task"]}, {"paragraph_vector": [-57.835933, 45.506755], "paragraph_keywords": ["scaptics", "density", "participants", "clusters"]}, {"paragraph_vector": [-66.354972, 43.882369], "paragraph_keywords": ["techniques", "explore", "scatterplots", "scaptics"]}, {"paragraph_vector": [-61.231735, 45.525348], "paragraph_keywords": ["combination", "scaptics", "highlight", "explore"]}], "content": {}, "doi": "10.1145/3290605.3300267"}, {"uri": "214", "title": "The Inflatable Cat: Idiosyncratic Ideation Of Smart Objects For The Home", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Arne Berger", "William Odom"], "summary": "Research on product experience has a history in investigating the sensory and emotional qualities of interacting with objects. However, this notion has not been fully expanded to the design space of co-designing smart objects. In this paper, we report on findings from a series of co-design workshops where we used the toolkit Loaded Dice in conjunction with a card set that aimed to support participants in reflecting the sensory qualities of domestic smart objects. We synthesize and interpret findings from our study to help illustrate how the workshops supported co-designers in creatively ideating concepts for emotionally valuable smart objects that better connect personal inputs with the output of smart objects. Our work contributes a case example of how a co-design approach that emphasizes situated sensory exploration can be effective in enabling co-designers to ideate concepts of idiosyncratic smart objects that closely relate to the characteristics of their domestic living situations.", "keywords": ["resident", "explore", "based", "vocabulary", "time", "need", "object", "information", "design", "actuator", "reflect", "home", "problem", "co", "example", "sensor", "describe", "interaction", "meowing", "communication", "workshop", "work", "scenario", "space", "anger", "tool", "card", "people", "perception", "living", "way", "sense", "noise", "page", "emotion", "debtor", "property", "cat", "-", "developed", "neighbor", "data", "technology", "rent", "designer", "research", "quality", "dice", "paper", "negotiate"], "document_vector": [80.441734, 2.15285], "paragraphs": [{"paragraph_vector": [132.019226, -64.287521], "paragraph_keywords": ["objects", "copies", "systems", "acm"]}, {"paragraph_vector": [-104.082237, -57.071407], "paragraph_keywords": ["people", "design", "co", "tools"]}, {"paragraph_vector": [-96.796897, -57.270919], "paragraph_keywords": ["co", "-", "objects", "people"]}, {"paragraph_vector": [-95.754928, -47.973957], "paragraph_keywords": ["qualities", "senses", "emotion", "framework"]}, {"paragraph_vector": [-94.676666, -56.385978], "paragraph_keywords": ["design", "qualities", "cards", "co"]}, {"paragraph_vector": [-96.951461, -57.656436], "paragraph_keywords": ["design", "data", "based", "sources"]}, {"paragraph_vector": [-96.097312, -56.690799], "paragraph_keywords": ["qualities", "card", "iot", "based"]}, {"paragraph_vector": [-93.331573, -57.622039], "paragraph_keywords": ["cards", "designers", "-", "scenario"]}, {"paragraph_vector": [-99.026351, -51.693515], "paragraph_keywords": ["cube", "sensor", "cards", "input"]}, {"paragraph_vector": [-87.032966, -60.345169], "paragraph_keywords": ["design", "cards", "workshops", "scenario"]}, {"paragraph_vector": [-96.376655, -53.647048], "paragraph_keywords": ["people", "scenarios", "neighbor", "-"]}, {"paragraph_vector": [-104.966583, -60.391654], "paragraph_keywords": ["residents", "developed", "communication", "message"]}, {"paragraph_vector": [-93.080406, -51.707401], "paragraph_keywords": ["cat", "sensor", "designers", "-"]}, {"paragraph_vector": [-103.548927, -60.946529], "paragraph_keywords": ["-", "designers", "anger", "co"]}, {"paragraph_vector": [-99.425743, -60.841876], "paragraph_keywords": ["neighbor", "designers", "level", "noise"]}, {"paragraph_vector": [19.066766, -87.12677], "paragraph_keywords": ["information", "cards", "residents", "discussed"]}, {"paragraph_vector": [-86.211746, -71.933868], "paragraph_keywords": ["scenario", "designers", "-", "co"]}, {"paragraph_vector": [-94.144035, -57.083583], "paragraph_keywords": ["cat", "meowing", "shakespeare", "alfred"]}, {"paragraph_vector": [-95.704643, -56.992069], "paragraph_keywords": ["-", "co", "designers", "qualities"]}, {"paragraph_vector": [-92.362579, -58.677345], "paragraph_keywords": ["scenario", "designers", "-", "co"]}, {"paragraph_vector": [-89.622383, -57.325786], "paragraph_keywords": ["people", "-", "cat", "co"]}, {"paragraph_vector": [-95.892921, -56.38779], "paragraph_keywords": ["objects", "design", "co", "people"]}, {"paragraph_vector": [-98.058067, -59.725372], "paragraph_keywords": ["objects", "co", "qualities", "home"]}, {"paragraph_vector": [-82.216491, -59.799644], "paragraph_keywords": ["living", "housing", "co", "design"]}, {"paragraph_vector": [-95.52227, -58.525375], "paragraph_keywords": ["objects", "design", "co", "qualities"]}, {"paragraph_vector": [-97.850479, -57.773841], "paragraph_keywords": ["objects", "qualities", "design", "home"]}, {"paragraph_vector": [-86.744087, -59.783016], "paragraph_keywords": ["research", "conducting", "data", "workshops"]}], "content": {}, "doi": "10.1145/3290605.3300246"}, {"uri": "215", "title": "A Comparison of Guiding Techniques for Out-of-View Objects in Full-Coverage Displays", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Julian Petford", "Iain Carson", "Miguel A. Nacenta", "Carl Gutwin"], "summary": "Full-coverage displays can place visual content anywhere on the interior surfaces of a room (e.g., a weather display near the coat stand). In these settings, digital artefacts can be located behind the user and out of their field of view \u2014 meaning that it can be difficult to notify the user when these artefacts need attention. Although much research has been carried out on notification, little is known about how best to direct people to the necessary location in room environments. We designed five diverse attention-guiding techniques for full-coverage display rooms, and evaluated them in a study where participants completed search tasks guided by the different techniques. Our study provides new results about notification in full-coverage displays: we showed benefits of persistent visualisations that could be followed all the way to the target and that indicate distance-to-target. Our findings provide useful information for improving the usability of interactive full-coverage environments.", "keywords": ["point", "fcds", "time", "position", "information", "find", "performance", "wall", "location", "display", "design", "technique", "provide", "environment", "focus", "user", "guiding", "work", "result", "space", "participant", "people", "ceiling", "trial", "notification", "content", "head", "representation", "wedge", "task", "attention", "signal", "game", "study", "room", "flashing", "system", "target", "showed", "figure", "radar"], "document_vector": [-164.140518, -32.158554], "paragraphs": [{"paragraph_vector": [-30.245906, 37.174465], "paragraph_keywords": ["copies", "techniques", "acm", "content"]}, {"paragraph_vector": [-28.163543, 41.198459], "paragraph_keywords": ["user", "location", "techniques", "target"]}, {"paragraph_vector": [-27.777853, 38.712268], "paragraph_keywords": ["display", "notification", "work", "guiding"]}, {"paragraph_vector": [-26.86845, 38.343753], "paragraph_keywords": ["information", "user", "notification", "attention"]}, {"paragraph_vector": [-26.484872, 39.750541], "paragraph_keywords": ["information", "notifications", "element", "attention"]}, {"paragraph_vector": [-24.375705, 35.949604], "paragraph_keywords": ["location", "information", "attention", "senses"]}, {"paragraph_vector": [-32.009708, 38.809749], "paragraph_keywords": ["guiding", "user", "placement", "techniques"]}, {"paragraph_vector": [-27.441022, 29.566009], "paragraph_keywords": ["user", "target", "way", "location"]}, {"paragraph_vector": [-26.415218, 32.799751], "paragraph_keywords": ["wall", "target", "room", "radar"]}, {"paragraph_vector": [-27.376691, 34.83078], "paragraph_keywords": ["target", "technique", "performance", "techniques"]}, {"paragraph_vector": [-43.821395, 25.821517], "paragraph_keywords": ["game", "participants", "walls", "keypad"]}, {"paragraph_vector": [-20.396968, 25.940992], "paragraph_keywords": ["target", "participants", "trial", "trials"]}, {"paragraph_vector": [-29.452703, 31.599248], "paragraph_keywords": ["participants", "study", "technique", "techniques"]}, {"paragraph_vector": [-23.116413, 27.441995], "paragraph_keywords": ["target", "participants", "technique", "techniques"]}, {"paragraph_vector": [-28.535881, 28.562271], "paragraph_keywords": ["target", "showed", "wall", "techniques"]}, {"paragraph_vector": [-31.016828, 28.298025], "paragraph_keywords": ["rotation", "time", "signal", "wall"]}, {"paragraph_vector": [-30.343654, 30.274902], "paragraph_keywords": ["technique", "p", "techniques", "wedge"]}, {"paragraph_vector": [-28.70902, 29.785354], "paragraph_keywords": ["wedge", "flashing", "target", "point"]}, {"paragraph_vector": [-25.726167, 36.549884], "paragraph_keywords": ["location", "radar", "wall", "ceiling"]}, {"paragraph_vector": [-29.742757, 37.560642], "paragraph_keywords": ["techniques", "times", "require", "guiding"]}, {"paragraph_vector": [-27.560861, 37.303882], "paragraph_keywords": ["techniques", "attention", "study", "wedge"]}, {"paragraph_vector": [99.925315, 47.691135], "paragraph_keywords": ["improve", "information", "effectiveness", "designers"]}], "content": {}, "doi": "10.1145/3290605.3300688"}, {"uri": "216", "title": "Designing for Digital Playing Out", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Gavin Wood", "Thomas Dylan", "Abigail Durrant", "Pablo E. Torres", "Madeline Balaam", "John Vines", "Shawn Lawson", "Denise Downey", "Phil McGrath", "Alice Ferguson"], "summary": "We report on a design-led study in the UK that aimed to understand barriers to children (aged 5 to 14 years) \u2018playing out\u2019 in their neighbourhood and explore the potential of the Internet of Things (IoT) for supporting children\u2019s free play that extends outdoors. The study forms a design ethnography, combining observational fieldwork with design prototyping and co-creative activities across four linked workshops, where we used BBC micro:bit devices to co-create new IoT designs with the participating children. Our collective account contributes new insights about the physical and interactive features of micro:bits that shaped play, gameplay, and social interaction in the workshops, illuminating an emerging design space for supporting \u2018digital playing out\u2019 that is grounded in empirical instances. We highlight opportunities for designing for digital playing out in ways that promote social negotiation, supports varying participation, allows for integrating cultural influences, and accounts for the weaving together of placemaking and play.", "keywords": ["explore", "micro", "based", "tct", "child", "lucas", "time", "resource", "development", "connected", "design", "environment", "drew", "opportunity", "playing", "uk", "engagement", "activity", "play", "interaction", "workshop", "creating", "work", "place", "space", "use", "sam", "group", "team", "neighborhood", "created", "magnet", "iot", "page", "bbc", "field", "function", "found", "provided", "observed", "programming", "device", "computer", "played", "day", "game", "technology", "bit", "role", "researcher", "rtd", "support", "led", "ethnography", "research", "ball", "rule", "hci", "paper", "hide", "context", "community", "making"], "document_vector": [114.057342, 20.497116], "paragraphs": [{"paragraph_vector": [-134.046493, -22.375173], "paragraph_keywords": ["play", "copies", "decline", "uk"]}, {"paragraph_vector": [-134.408447, -19.52308], "paragraph_keywords": ["design", "children", "technologies", "explore"]}, {"paragraph_vector": [-135.56224, -19.828651], "paragraph_keywords": ["play", "children", "hci", "design"]}, {"paragraph_vector": [-133.946105, -22.956716], "paragraph_keywords": ["play", "design", "children", "interaction"]}, {"paragraph_vector": [-133.462371, -20.502853], "paragraph_keywords": ["micro", "children", "design", "community"]}, {"paragraph_vector": [-133.28012, -22.994506], "paragraph_keywords": ["play", "design", "playing", "children"]}, {"paragraph_vector": [-132.958755, -29.216371], "paragraph_keywords": ["children", "play", "community", "activities"]}, {"paragraph_vector": [-124.355926, -29.803024], "paragraph_keywords": ["tct", "play", "children", "team"]}, {"paragraph_vector": [-134.665817, -22.941642], "paragraph_keywords": ["children", "design", "play", "concepts"]}, {"paragraph_vector": [-126.338218, -26.913667], "paragraph_keywords": ["children", "play", "activities", "played"]}, {"paragraph_vector": [-134.828186, -19.762924], "paragraph_keywords": ["play", "children", "developed", "draw"]}, {"paragraph_vector": [-134.747375, -18.142187], "paragraph_keywords": ["children", "play", "bits", "workshop"]}, {"paragraph_vector": [-130.797164, -19.782403], "paragraph_keywords": ["play", "children", "workshop", "bits"]}, {"paragraph_vector": [-135.879745, -24.542701], "paragraph_keywords": ["play", "functions", "children", "data"]}, {"paragraph_vector": [-130.148071, -23.056819], "paragraph_keywords": ["play", "children", "played", "activity"]}, {"paragraph_vector": [-133.992706, -23.711412], "paragraph_keywords": ["estate", "tree", "play", "climbing"]}, {"paragraph_vector": [-134.617904, -21.169212], "paragraph_keywords": ["ball", "play", "children", "group"]}, {"paragraph_vector": [-135.643844, -19.778961], "paragraph_keywords": ["ball", "game", "group", "children"]}, {"paragraph_vector": [-136.420013, -19.103324], "paragraph_keywords": ["group", "children", "games", "sam"]}, {"paragraph_vector": [-137.430541, -20.33041], "paragraph_keywords": ["game", "play", "children", "role"]}, {"paragraph_vector": [-137.386672, -18.094709], "paragraph_keywords": ["game", "lucas", "dance", "group"]}, {"paragraph_vector": [-132.346038, -19.178621], "paragraph_keywords": ["children", "games", "play", "micro"]}, {"paragraph_vector": [-132.500762, -19.1914], "paragraph_keywords": ["magnet", "game", "bit", "use"]}, {"paragraph_vector": [-133.442199, -21.68296], "paragraph_keywords": ["lucas", "war", "children", "ideas"]}, {"paragraph_vector": [-133.885772, -16.158916], "paragraph_keywords": ["play", "children", "games", "functionality"]}, {"paragraph_vector": [-134.513931, -22.484066], "paragraph_keywords": ["play", "devices", "children", "games"]}, {"paragraph_vector": [-136.361862, -18.988039], "paragraph_keywords": ["play", "children", "designs", "functions"]}, {"paragraph_vector": [-133.407287, -22.339416], "paragraph_keywords": ["play", "children", "making", "devices"]}, {"paragraph_vector": [-134.245101, -22.237127], "paragraph_keywords": ["play", "children", "devices", "community"]}, {"paragraph_vector": [-135.719711, -22.36227], "paragraph_keywords": ["play", "children", "programming", "resources"]}, {"paragraph_vector": [73.849411, 32.283061], "paragraph_keywords": ["ep"]}], "content": {}, "doi": "10.1145/3290605.3300290"}, {"uri": "217", "title": "What Can We Learn from Augmented Reality (AR)? Benefits and Drawbacks of AR for Inquiry-based Learning of Physics", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Iulian Radu", "Bertrand Schneider"], "summary": "Emerging technologies such as Augmented Reality (AR), have the potential to radically transform education by making challenging concepts visible and accessible to novices. In this project, we have designed a Hololensbased system in which collaborators are exposed to an unstructured learning activity in which they learned about the invisible physics involved in audio speakers. They learned topics ranging from spatial knowledge, such as shape of magnetic fields, to abstract conceptual knowledge, such as relationships between electricity and magnetism. We compared participants\u2019 learning, attitudes and collaboration with a tangible interface through multiple experimental conditions containing varying layers of AR information. We found that educational AR representations were beneficial for learning specific knowledge and increasing participants\u2019 self-efficacy (i.e., their ability to learn concepts in physics). However, we also found that participants in conditions that did not contain AR educational content, learned some concepts better than other groups and became more curious about physics. We discuss learning and collaboration differences, as well as benefits and detriments of implementing augmented reality for unstructured learning activities.", "keywords": ["condition", "information", "ability", "electromagnetism", "electricity", "activity", "physic", "participant", "use", "hololens", "group", "edar", "phenomenon", "effect", "learning", "sig", "concept", "visualization", "page", "field", "collaboration", "understanding", "content", "augmented", "understand", "representation", "measured", "technology", "study", "student", "system", "ar", "reality", "research", "difference", "question", "paper", "knowledge", "benefit"], "document_vector": [171.44992, 4.710512], "paragraphs": [{"paragraph_vector": [-167.694091, 33.937538], "paragraph_keywords": ["copies", "reality", "learning", "concepts"]}, {"paragraph_vector": [-167.289505, 32.938049], "paragraph_keywords": ["representations", "reality", "augmented", "electromagnetism"]}, {"paragraph_vector": [-169.243606, 33.033233], "paragraph_keywords": ["ar", "learning", "content", "students"]}, {"paragraph_vector": [-168.05191, 34.098472], "paragraph_keywords": ["ar", "ability", "learning", "interface"]}, {"paragraph_vector": [-169.537948, 34.141746], "paragraph_keywords": ["phenomena", "representations", "ar", "fields"]}, {"paragraph_vector": [-162.33197, 35.48138], "paragraph_keywords": ["system", "physics", "students", "activity"]}, {"paragraph_vector": [-168.122177, 33.320663], "paragraph_keywords": ["ar", "presence", "representations", "visualizations"]}, {"paragraph_vector": [-171.468032, 33.499328], "paragraph_keywords": ["learning", "participants", "questions", "test"]}, {"paragraph_vector": [85.668861, 54.753677], "paragraph_keywords": ["question", "field", "questions", "understanding"]}, {"paragraph_vector": [99.199462, 47.196025], "paragraph_keywords": ["participants", "nested", "followed", "dimensions"]}, {"paragraph_vector": [161.380676, 40.038665], "paragraph_keywords": ["edar", "groups", "participant", "attitudes"]}, {"paragraph_vector": [-170.872467, 33.9025], "paragraph_keywords": ["edar", "groups", "ar", "learning"]}, {"paragraph_vector": [106.692161, 48.855777], "paragraph_keywords": ["sig", "groups", "edar", "collaboration"]}, {"paragraph_vector": [-167.842163, 34.410873], "paragraph_keywords": ["ar", "representations", "learning", "fields"]}, {"paragraph_vector": [-168.151535, 32.699005], "paragraph_keywords": ["ar", "representations", "learning", "field"]}, {"paragraph_vector": [-168.366821, 34.199558], "paragraph_keywords": ["engagement", "representations", "ar", "technology"]}, {"paragraph_vector": [-170.291198, 33.119159], "paragraph_keywords": ["ar", "information", "field", "student"]}, {"paragraph_vector": [-167.221359, 32.365322], "paragraph_keywords": ["ar", "participants", "research", "representations"]}], "content": {}, "doi": "10.1145/3290605.3300357"}, {"uri": "218", "title": "PinchList: Leveraging Pinch Gestures for Hierarchical List Navigation on Smartphones", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Teng Han", "Jie Liu", "Khalad Hasan", "Mingming Fan", "Junhyeok Kim", "Jiannan Li", "Xiangmin Fan", "Feng Tian", "Edward Lank", "Pourang Irani"], "summary": "Intensive exploration and navigation of hierarchical lists on smartphones can be tedious and time-consuming as it often requires users to frequently switch between multiple views. To overcome this limitation, we present PinchList, a novel interaction design that leverages pinch gestures to support seamless exploration of multi-level list items in hierarchical views. With PinchList, sub-lists are accessed with a pinch-out gesture whereas a pinch-in gesture navigates back to the previous level. Additionally, pinch and flick gestures are used to navigate lists consisting of more than two levels. We conduct a user study to refine the design parameters of PinchList such as a suitable item size, and quantitatively evaluate the target acquisition performance using pinch-in/out gestures in both scrolling and non-scrolling conditions. In a second study, we compare the performance of PinchList in a hierarchal navigation task with two commonly used touch interfaces for list browsing: pagination and expand-and-collapse interfaces. The results reveal that PinchList is significantly faster than other two interfaces in accessing items located in hierarchical list views. Finally, we demonstrate that PinchList enables a host of novel applications in list-based interaction.", "keywords": ["time", "finger", "need", "tap", "condition", "selection", "performance", "design", "layer", "technique", "touch", "user", "pinchlist", "participant", "use", "list", "screen", "size", "page", "trial", "gesture", "pinch", "task", "item", "study", "scrolling", "select", "target", "view", "paper", "input", "browsing", "figure"], "document_vector": [-179.241409, -69.507728], "paragraphs": [{"paragraph_vector": [-11.52271, 13.958351], "paragraph_keywords": ["list", "pinch", "details", "items"]}, {"paragraph_vector": [-7.883719, 13.183069], "paragraph_keywords": ["fingers", "pinch", "list", "layer"]}, {"paragraph_vector": [-9.425119, 11.619391], "paragraph_keywords": ["list", "design", "pinch", "performance"]}, {"paragraph_vector": [-11.081918, 12.338658], "paragraph_keywords": ["touch", "gestures", "input", "menu"]}, {"paragraph_vector": [-10.73634, 12.446446], "paragraph_keywords": ["scrolling", "users", "target", "fit"]}, {"paragraph_vector": [-13.964228, 12.147126], "paragraph_keywords": ["pinch", "gestures", "zoom", "size"]}, {"paragraph_vector": [-8.933789, 12.359524], "paragraph_keywords": ["list", "users", "screen", "selection"]}, {"paragraph_vector": [-23.610866, 13.326448], "paragraph_keywords": ["target", "participants", "tap", "mm"]}, {"paragraph_vector": [-30.707494, 18.749145], "paragraph_keywords": ["screen", "target", "targets", "participants"]}, {"paragraph_vector": [-27.510391, 14.162457], "paragraph_keywords": ["target", "p", "trial", "data"]}, {"paragraph_vector": [-19.98987, 13.850071], "paragraph_keywords": ["target", "pinchout", "distance", "pinchin"]}, {"paragraph_vector": [-10.40322, 12.908494], "paragraph_keywords": ["pinch", "gestures", "list", "dwell"]}, {"paragraph_vector": [-12.197644, 17.165578], "paragraph_keywords": ["pinch", "fingers", "layer", "view"]}, {"paragraph_vector": [-9.422337, 14.219749], "paragraph_keywords": ["list", "layer", "items", "layers"]}, {"paragraph_vector": [-10.169564, 15.837569], "paragraph_keywords": ["type", "set", "item", "need"]}, {"paragraph_vector": [2.841548, 45.546699], "paragraph_keywords": ["participants", "tasks", "trials", "task"]}, {"paragraph_vector": [-9.476593, 13.58954], "paragraph_keywords": ["pinchlist", "task", "gestures", "users"]}, {"paragraph_vector": [-9.94921, 13.218838], "paragraph_keywords": ["users", "fingers", "gestures", "list"]}, {"paragraph_vector": [-9.037004, 15.179514], "paragraph_keywords": ["item", "fingers", "folder", "pinch"]}, {"paragraph_vector": [-11.311127, 15.627425], "paragraph_keywords": ["fingers", "selection", "list", "item"]}, {"paragraph_vector": [-10.144451, 11.371817], "paragraph_keywords": ["users", "gestures", "list", "pinchlist"]}, {"paragraph_vector": [-9.602958, 12.996604], "paragraph_keywords": ["pinchlist", "list", "lists", "program"]}], "content": {}, "doi": "10.1145/3290605.3300803"}, {"uri": "219", "title": "A Framework for the Experience of Meaning in Human-Computer Interaction", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Elisa D. Mekler"], "summary": "The view of quality in human-computer interaction continuously develops, having in past decades included consistency, transparency, usability, and positive emotions. Recently, meaning is receiving increased interest in the user experience literature and in industry, referring to the end, purpose or significance of interaction with computers. However, the notion of meaning remains elusive and a bewildering number of senses are in use. We present a framework of meaning in interaction, based on a synthesis of psychological meaning research. The framework outlines five distinct senses of the experience of meaning: connectedness, purpose, coherence, resonance, and significance. We illustrate the usefulness of the framework by analyzing a selection of recent papers at the CHI conference and by raising a series of open research questions about the interplay of meaning, user experience, reflection, and well-being.", "keywords": ["complexity", "reflection", "process", "feeling", "consider", "time", "al", "need", "discussion", "self", "design", "component", "psychology", "analysis", "focus", "example", "help", "goal", "user", "activity", "interaction", "et", "work", "use", "people", "make", "world", "sense", "experience", "page", "understanding", "connectedness", "found", "life", "data", "feel", "study", "instance", "role", "framework", "purpose", "event", "research", "notion", "term", "quality", "meaning", "resonance", "hci", "paper", "coherence", "significance", "making"], "document_vector": [29.669965, 24.461736], "paragraphs": [{"paragraph_vector": [143.029006, -31.910589], "paragraph_keywords": ["meaning", "interaction", "copies", "work"]}, {"paragraph_vector": [146.552627, -32.110202], "paragraph_keywords": ["meaning", "interaction", "hci", "experience"]}, {"paragraph_vector": [144.024871, -31.170633], "paragraph_keywords": ["meaning", "interaction", "hci", "quality"]}, {"paragraph_vector": [144.811035, -40.260742], "paragraph_keywords": ["meaning", "experiences", "design", "found"]}, {"paragraph_vector": [142.993377, -37.632423], "paragraph_keywords": ["meaning", "concerns", "hci", "work"]}, {"paragraph_vector": [142.741333, -32.749164], "paragraph_keywords": ["meaning", "world", "experience", "interaction"]}, {"paragraph_vector": [152.724044, -31.924556], "paragraph_keywords": ["meaning", "psychology", "life", "humans"]}, {"paragraph_vector": [147.267776, -34.963565], "paragraph_keywords": ["meaning", "components", "framework", "research"]}, {"paragraph_vector": [154.812393, -30.427501], "paragraph_keywords": ["meaning", "experiences", "experience", "self"]}, {"paragraph_vector": [153.078353, -31.175195], "paragraph_keywords": ["meaning", "connectedness", "sense", "people"]}, {"paragraph_vector": [153.758682, -32.740955], "paragraph_keywords": ["purpose", "goals", "meaning", "self"]}, {"paragraph_vector": [152.111373, -30.645174], "paragraph_keywords": ["sense", "experience", "coherence", "experiences"]}, {"paragraph_vector": [152.434249, -33.41447], "paragraph_keywords": ["sense", "making", "connections", "paper"]}, {"paragraph_vector": [153.334747, -31.602807], "paragraph_keywords": ["experience", "meaning", "experiences", "life"]}, {"paragraph_vector": [154.072906, -31.40896], "paragraph_keywords": ["significance", "sense", "experiences", "resonance"]}, {"paragraph_vector": [152.261093, -32.010025], "paragraph_keywords": ["meaning", "sense", "significance", "experience"]}, {"paragraph_vector": [147.07341, -32.2928], "paragraph_keywords": ["meaning", "papers", "interaction", "understanding"]}, {"paragraph_vector": [-135.211181, -40.66941], "paragraph_keywords": ["meaning", "data", "place", "experiences"]}, {"paragraph_vector": [166.16629, -34.254112], "paragraph_keywords": ["goals", "significance", "meaning", "actions"]}, {"paragraph_vector": [163.028015, -41.83723], "paragraph_keywords": ["meaning", "sense", "users", "design"]}, {"paragraph_vector": [154.965957, -26.064216], "paragraph_keywords": ["reflection", "meaning", "sense", "data"]}, {"paragraph_vector": [146.826034, -32.717296], "paragraph_keywords": ["meaning", "hci", "papers", "framework"]}, {"paragraph_vector": [147.703323, -34.545677], "paragraph_keywords": ["meaning", "design", "making", "focus"]}, {"paragraph_vector": [147.721862, -34.292865], "paragraph_keywords": ["meaning", "experience", "scale", "framework"]}, {"paragraph_vector": [148.015762, -32.425136], "paragraph_keywords": ["meaning", "framework", "papers", "analysis"]}, {"paragraph_vector": [151.007095, -32.170227], "paragraph_keywords": ["coherence", "meaning", "making", "experiences"]}, {"paragraph_vector": [145.17691, -35.522666], "paragraph_keywords": ["meaning", "components", "satisfaction", "help"]}], "content": {}, "doi": "10.1145/3290605.3300244"}, {"uri": "220", "title": "Beyond the Patient Portal: Supporting Needs of Hospitalized Patients", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Shefali Haldar", "Sonali R. Mishra", "Maher Khelifi", "Ari H Pollack"], "summary": "Although patient portals\u2014technologies that give patients access to their health information\u2014are recognized as key to increasing patient engagement, we have a limited understanding of how these technologies should be designed to meet the needs of hospitalized patients and caregivers. Through semi-structured interviews with 30 patients and caregivers, we examine how future patient portals can best align with their needs and support engagement in their care. Our findings reveal six needs that existing patient portals do not support: (1) transitioning from home to hospital, (2) adjusting schedules and receiving status updates, (3) understanding and remembering care, (4) asking questions and flagging problems, (5) collaborating with providers and caregivers, and (6) preparing for discharge and at-home care. Based on these findings, we discuss three design implications: highlight patient-centric goals and preferences, provide dynamic information about care events, and design for situationally-impaired users. Our contributions guide future patient portals in engaging hospitalized patients and caregivers as primary stakeholders in their health care.", "keywords": ["caregiver", "based", "doctor", "time", "need", "information", "resource", "progress", "design", "feature", "discharge", "interview", "care", "wanted", "example", "help", "goal", "schedule", "engagement", "having", "know", "result", "inpatient", "work", "procedure", "participant", "use", "patient", "card", "team", "health", "page", "including", "understand", "want", "data", "technology", "study", "support", "provider", "research", "ask", "stay", "explained", "question", "paper", "portal", "meet", "hospital", "access"], "document_vector": [-85.424064, 89.901168], "paragraphs": [{"paragraph_vector": [152.49298, -9.0594], "paragraph_keywords": ["health", "care", "copies", "engagement"]}, {"paragraph_vector": [153.83287, -8.598416], "paragraph_keywords": ["portals", "health", "patients", "inpatients"]}, {"paragraph_vector": [155.454345, -9.819614], "paragraph_keywords": ["patients", "design", "health", "technologies"]}, {"paragraph_vector": [173.358596, -20.829095], "paragraph_keywords": ["patients", "care", "inpatients", "hospital"]}, {"paragraph_vector": [155.371139, -7.649531], "paragraph_keywords": ["patients", "portals", "care", "health"]}, {"paragraph_vector": [154.701599, -8.758311], "paragraph_keywords": ["cards", "patients", "interviews", "hospital"]}, {"paragraph_vector": [152.025024, -17.143508], "paragraph_keywords": ["participants", "patients", "interviews", "hospital"]}, {"paragraph_vector": [145.051956, -26.615993], "paragraph_keywords": ["hospital", "participants", "home", "research"]}, {"paragraph_vector": [160.240509, -6.874632], "paragraph_keywords": ["hospital", "information", "wanted", "help"]}, {"paragraph_vector": [161.244415, -6.071066], "paragraph_keywords": ["hospital", "time", "know", "schedule"]}, {"paragraph_vector": [162.313827, -5.645381], "paragraph_keywords": ["results", "care", "information", "status"]}, {"paragraph_vector": [158.393493, -9.293313], "paragraph_keywords": ["results", "providers", "articles", "wanted"]}, {"paragraph_vector": [158.503479, -5.886822], "paragraph_keywords": ["providers", "explanations", "conversations", "care"]}, {"paragraph_vector": [157.893081, -8.06991], "paragraph_keywords": ["questions", "providers", "care", "hospital"]}, {"paragraph_vector": [158.418304, -6.268678], "paragraph_keywords": ["nurse", "patients", "providers", "care"]}, {"paragraph_vector": [158.48381, -4.217563], "paragraph_keywords": ["portal", "information", "patients", "caregivers"]}, {"paragraph_vector": [166.695968, -18.585596], "paragraph_keywords": ["discharge", "patients", "goals", "information"]}, {"paragraph_vector": [154.646774, -9.168006], "paragraph_keywords": ["care", "portals", "goals", "health"]}, {"paragraph_vector": [153.756637, -11.598101], "paragraph_keywords": ["goals", "health", "patients", "hospital"]}, {"paragraph_vector": [153.370468, -9.788195], "paragraph_keywords": ["patients", "goals", "care", "hospital"]}, {"paragraph_vector": [157.149749, -8.266202], "paragraph_keywords": ["hospital", "care", "information", "inpatients"]}, {"paragraph_vector": [157.553436, -7.756669], "paragraph_keywords": ["impairments", "care", "hospital", "information"]}, {"paragraph_vector": [157.455749, -7.113948], "paragraph_keywords": ["patients", "information", "help", "results"]}, {"paragraph_vector": [154.473098, -8.496599], "paragraph_keywords": ["portals", "hospital", "design", "findings"]}, {"paragraph_vector": [155.586059, -8.963333], "paragraph_keywords": ["technologies", "quality", "thank", "hospital"]}], "content": {}, "doi": "10.1145/3290605.3300785"}, {"uri": "221", "title": "Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Kenneth Holstein", "Jennifer Wortman Vaughan"], "summary": "The potential for machine learning (ML) systems to amplify social inequities and unfairness is receiving increasing popular and academic attention. A surge of recent work has focused on the development of algorithmic tools to assess and mitigate such unfairness. If these tools are to have a positive impact on industry practice, however, it is crucial that their design be informed by an understanding of realworld needs. Through 35 semi-structured interviews and an anonymous survey of 267 ML practitioners, we conduct the first systematic investigation of commercial product teams\u2019 challenges and needs for support in developing fairer ML systems. We identify areas of alignment and disconnect between the challenges faced by teams in practice and the solutions proposed in the fair ML research literature. Based on these findings, we highlight directions for future ML and HCI research that will better address practitioners\u2019 needs.", "keywords": ["metric", "process", "time", "need", "training", "design", "method", "literature", "interview", "reported", "industry", "example", "help", "noted", "user", "model", "know", "product", "tool", "use", "issue", "demographic", "team", "way", "challenge", "respondent", "working", "interviewee", "theme", "automated", "page", "practitioner", "application", "survey", "search", "data", "fairness", "ml", "cf", "developing", "system", "support", "image", "research", "focused", "bias", "asked", "auditing", "question", "paper", "company", "level"], "document_vector": [-83.141258, 0.363236], "paragraphs": [{"paragraph_vector": [69.996025, 20.18996], "paragraph_keywords": ["systems", "learning", "copies", "machine"]}, {"paragraph_vector": [61.591781, 14.54988], "paragraph_keywords": ["ml", "needs", "practitioners", "fairness"]}, {"paragraph_vector": [65.977233, 15.361614], "paragraph_keywords": ["ml", "systems", "teams", "system"]}, {"paragraph_vector": [65.935935, 16.424919], "paragraph_keywords": ["systems", "ml", "biases", "fairness"]}, {"paragraph_vector": [65.218078, 15.151394], "paragraph_keywords": ["ml", "practitioners", "sector", "systems"]}, {"paragraph_vector": [66.631477, 13.282564], "paragraph_keywords": ["conducted", "asked", "team", "pms"]}, {"paragraph_vector": [61.958606, 12.451084], "paragraph_keywords": ["contacts", "teams", "products", "team"]}, {"paragraph_vector": [63.886913, 17.61568], "paragraph_keywords": ["team", "interviewees", "interviews", "asked"]}, {"paragraph_vector": [103.559333, -32.179672], "paragraph_keywords": ["survey", "interviewees", "team", "question"]}, {"paragraph_vector": [67.203926, 17.863384], "paragraph_keywords": ["respondents", "team", "survey", "themes"]}, {"paragraph_vector": [64.804122, 15.110474], "paragraph_keywords": ["interviewees", "survey", "biases", "fairness"]}, {"paragraph_vector": [67.654312, 15.87383], "paragraph_keywords": ["data", "ml", "collection", "fairness"]}, {"paragraph_vector": [64.825218, 18.621372], "paragraph_keywords": ["data", "test", "design", "set"]}, {"paragraph_vector": [64.961791, 16.751155], "paragraph_keywords": ["ml", "subpopulations", "tools", "data"]}, {"paragraph_vector": [66.38639, 17.142103], "paragraph_keywords": ["issues", "fairness", "teams", "products"]}, {"paragraph_vector": [68.012748, 16.218387], "paragraph_keywords": ["team", "knowledge", "teams", "celebrities"]}, {"paragraph_vector": [66.219337, 16.955316], "paragraph_keywords": ["fairness", "auditing", "issues", "team"]}, {"paragraph_vector": [64.586761, 17.203001], "paragraph_keywords": ["fairness", "metrics", "interviewees", "learn"]}, {"paragraph_vector": [63.798351, 15.004838], "paragraph_keywords": ["resources", "demographics", "fairness", "help"]}, {"paragraph_vector": [56.119972, 1.185059], "paragraph_keywords": ["demographics", "interviewees", "use", "ml"]}, {"paragraph_vector": [65.275085, 17.233407], "paragraph_keywords": ["fairness", "user", "issues", "system"]}, {"paragraph_vector": [64.709938, 16.114622], "paragraph_keywords": ["fairness", "auditing", "tools", "challenges"]}, {"paragraph_vector": [66.110313, 16.308368], "paragraph_keywords": ["fairness", "ml", "system", "metrics"]}, {"paragraph_vector": [64.5167, 18.44141], "paragraph_keywords": ["search", "system", "users", "cf"]}, {"paragraph_vector": [67.141189, 19.061721], "paragraph_keywords": ["data", "fairness", "issues", "teams"]}, {"paragraph_vector": [65.358566, 16.071907], "paragraph_keywords": ["fairness", "effects", "tools", "teams"]}, {"paragraph_vector": [64.58834, 16.982181], "paragraph_keywords": ["data", "fairness", "teams", "said"]}, {"paragraph_vector": [64.676544, 17.298158], "paragraph_keywords": ["fairness", "ml", "team", "system"]}, {"paragraph_vector": [64.655174, 15.519541], "paragraph_keywords": ["biases", "scoring", "ml", "teams"]}, {"paragraph_vector": [66.153388, 16.524599], "paragraph_keywords": ["fairness", "ml", "research", "tools"]}, {"paragraph_vector": [64.037834, 18.906656], "paragraph_keywords": ["research", "michael", "ml", "paper"]}], "content": {}, "doi": "10.1145/3290605.3300854"}, {"uri": "222", "title": "Transcalibur: A Weight Shifting Virtual Reality Controller for 2D Shape Rendering based on Computational Perception Model", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jotaro Shigeyama", "Takeru Hashimoto", "Shigeo Yoshida", "Takuji Narumi", "Tomohiro Tanikawa", "Michitaka Hirose"], "summary": "Humans can estimate the shape of a wielded object through the illusory feeling of the mass properties of the object obtained using their hands. Even though the shape of hand-held objects influences immersion and realism in virtual reality (VR), it is difficult to design VR controllers for rendering desired shapes according to the perceptions derived from the illusory effects of mass properties and shape perception. We propose Transcalibur, which is a hand-held VR controller \u2217These two authors equally contributed to this paper. \u2020Also with JST, PRESTO. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300241 that can render a 2D shape by changing its mass properties on a 2D planar area. We built a computational perception model using a data-driven approach from the collected data pairs of mass properties and perceived shapes. This enables Transcalibur to easily and effectively provide convincing shape perception based on complex illusory effects. Our user study showed that the system succeeded in providing the perception of various desired shapes in a virtual environment.", "keywords": ["vr", "based", "controller", "transcalibur", "perceived", "arm", "object", "mass", "mechanism", "experiment", "provide", "user", "model", "weight", "participant", "perception", "cost", "render", "joypad", "applied", "shape", "rendering", "page", "regression", "property", "feedback", "proposed", "hand", "device", "data", "height", "system", "target", "paper", "input"], "document_vector": [152.306686, -42.611606], "paragraphs": [{"paragraph_vector": [-94.010772, 19.11975], "paragraph_keywords": ["shape", "vr", "mechanism", "reality"]}, {"paragraph_vector": [-91.134086, 20.800539], "paragraph_keywords": ["shape", "object", "transcalibur", "controller"]}, {"paragraph_vector": [-96.456695, 17.931024], "paragraph_keywords": ["object", "shape", "illusion", "studies"]}, {"paragraph_vector": [-93.756507, 16.74076], "paragraph_keywords": ["vr", "users", "shape", "transcalibur"]}, {"paragraph_vector": [-93.452003, 19.82863], "paragraph_keywords": ["feedback", "vr", "force", "simulate"]}, {"paragraph_vector": [-94.640838, 19.906131], "paragraph_keywords": ["vr", "shape", "mechanisms", "users"]}, {"paragraph_vector": [-92.236518, 23.076286], "paragraph_keywords": ["shape", "object", "system", "vr"]}, {"paragraph_vector": [-89.840629, 21.768815], "paragraph_keywords": ["worm", "arms", "object", "wheel"]}, {"paragraph_vector": [-87.49562, 26.368959], "paragraph_keywords": ["motor", "shape", "model", "controller"]}, {"paragraph_vector": [-86.79219, 19.225189], "paragraph_keywords": ["controller", "shapes", "data", "perceived"]}, {"paragraph_vector": [-103.849388, 18.274848], "paragraph_keywords": ["joypad", "shape", "controller", "transcalibur"]}, {"paragraph_vector": [-90.575454, 23.580572], "paragraph_keywords": ["shape", "data", "controller", "participants"]}, {"paragraph_vector": [-89.960296, 21.850887], "paragraph_keywords": ["shape", "target", "model", "perceived"]}, {"paragraph_vector": [-88.489723, 21.54607], "paragraph_keywords": ["shapes", "transcalibur", "shape", "experiment"]}, {"paragraph_vector": [-89.155151, 21.716646], "paragraph_keywords": ["shapes", "shape", "perception", "mechanism"]}, {"paragraph_vector": [-93.14302, 18.279664], "paragraph_keywords": ["shape", "based", "vr", "design"]}], "content": {}, "doi": "10.1145/3290605.3300256"}, {"uri": "223", "title": "Detecting Perception of Smartphone Notifications using Skin Conductance Responses", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Pascal E. Fortin"], "summary": "Today\u2019s smartphone notification systems are incapable of determining whether a notification has been successfully perceived without explicit interaction from the user. If the system incorrectly assumes that a notification has not been perceived, it may repeat it redundantly, disrupting the user and others (e.g., phone ringing). Or, if it incorrectly assumes that a notification was perceived, and therefore fails to repeat it, the notification will be missed altogether (e.g., text message). Results from a laboratory study confirm, for the first time, that both vibrotactile and auditory smartphone notifications induce skin conductance responses (SCR), that the induced responses differ from that of arbitrary stimuli, and that they could be employed to predict perception of smartphone notifications after their presentation using wearable sensors.", "keywords": ["based", "perceived", "time", "phasicmax", "condition", "performance", "habituation", "following", "analysis", "escr", "user", "activity", "model", "interaction", "missed", "work", "second", "participant", "conductance", "perception", "delivery", "page", "notification", "smartphone", "observed", "stimulus", "measurement", "test", "device", "data", "study", "presentation", "system", "difference", "skin", "sweatsponse", "paper", "response"], "document_vector": [-12.684885, -63.093833], "paragraphs": [{"paragraph_vector": [3.244684, -6.527528], "paragraph_keywords": ["notifications", "copies", "acm", "interaction"]}, {"paragraph_vector": [1.031443, -5.994308], "paragraph_keywords": ["notification", "user", "perception", "system"]}, {"paragraph_vector": [1.193477, -5.866352], "paragraph_keywords": ["stimulus", "activity", "delivery", "perception"]}, {"paragraph_vector": [-0.010806, -6.027503], "paragraph_keywords": ["notifications", "notification", "stimulus", "delivery"]}, {"paragraph_vector": [1.467121, -5.945882], "paragraph_keywords": ["notification", "conductance", "response", "notifications"]}, {"paragraph_vector": [2.287777, -6.243897], "paragraph_keywords": ["participants", "notification", "measurements", "perceived"]}, {"paragraph_vector": [0.113124, -2.077328], "paragraph_keywords": ["notifications", "notification", "task", "perceived"]}, {"paragraph_vector": [-0.059531, -5.422314], "paragraph_keywords": ["conductance", "skin", "notifications", "notification"]}, {"paragraph_vector": [0.203953, -6.226713], "paragraph_keywords": ["notifications", "notification", "missed", "participants"]}, {"paragraph_vector": [0.960485, -6.464226], "paragraph_keywords": ["model", "phasicmax", "test", "regression"]}, {"paragraph_vector": [-0.255629, -6.118024], "paragraph_keywords": ["notifications", "responses", "habituation", "observed"]}, {"paragraph_vector": [1.01998, -6.728459], "paragraph_keywords": ["difference", "phasicmax", "perceived", "notifications"]}, {"paragraph_vector": [1.816763, -6.752856], "paragraph_keywords": ["perceived", "activity", "perception", "performance"]}, {"paragraph_vector": [1.629951, -6.937053], "paragraph_keywords": ["notification", "roc", "system", "perceived"]}, {"paragraph_vector": [2.047166, -7.190877], "paragraph_keywords": ["time", "notifications", "experience", "study"]}, {"paragraph_vector": [1.465623, -6.707265], "paragraph_keywords": ["sweatsponse", "measurements", "stress", "existing"]}, {"paragraph_vector": [2.083404, -6.974086], "paragraph_keywords": ["notifications", "intensity", "perception", "sweatsponse"]}, {"paragraph_vector": [171.209167, 66.738731], "paragraph_keywords": ["smashicons", "freepik", "flaticon"]}], "content": {}, "doi": "10.1145/3290605.3300551"}, {"uri": "224", "title": "Impulse Buying: Design Practices and Consumer Needs", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Carol Moser", "Sarita Y. Schoenebeck"], "summary": "E-commerce sites have an incentive to encourage impulse buying, even when not in the consumer\u2019s best interest. This study investigates what features e-commerce sites use to encourage impulse buying and what tools consumers desire to curb their online spending. We present two studies: (1) a systematic content analysis of 200 top e-commerce websites in the U.S. and (2) a survey of online impulse buyers (N=151). From Study 1, we find that e-commerce sites contain multiple features that encourage impulsive buying, including those that lower perceived risks, leverage social influence, and enhance perceived proximity to the product. Conversely, from Study 2 we find that online impulse buyers want tools that (a) encourage deliberation and avoidance, (b) enforce spending limits and postponement, (c) increase checkout effort, (d) make costs more salient, and (e) reduce product desire. These findings inform the design of \"friction\" technologies that help users make more deliberative consumer choices.", "keywords": ["based", "strategy", "time", "perceived", "like", "self", "feature", "purchase", "design", "reported", "store", "example", "help", "checkout", "spending", "user", "goal", "type", "temptation", "impulse", "saving", "shopping", "included", "sample", "purchased", "work", "product", "tool", "participant", "use", "e", "cost", "theme", "control", "page", "buyer", "number", "buying", "content", "survey", "deliberation", "-", "add", "money", "purchasing", "medium", "shown", "item", "study", "commerce", "buy", "research", "website", "influence", "site", "encourage", "behavior", "consumer", "making"], "document_vector": [-32.020023, 29.818098], "paragraphs": [{"paragraph_vector": [41.453807, -24.749757], "paragraph_keywords": ["buying", "design", "copies", "acm"]}, {"paragraph_vector": [39.659645, -20.523712], "paragraph_keywords": ["consumer", "features", "tools", "buying"]}, {"paragraph_vector": [39.494583, -21.07307], "paragraph_keywords": ["features", "product", "-", "commerce"]}, {"paragraph_vector": [37.994247, -19.633922], "paragraph_keywords": ["shopping", "store", "consumers", "product"]}, {"paragraph_vector": [38.287818, -23.480537], "paragraph_keywords": ["purchase", "product", "store", "consumer"]}, {"paragraph_vector": [39.533782, -20.634258], "paragraph_keywords": ["websites", "sites", "content", "travel"]}, {"paragraph_vector": [38.600654, -19.395738], "paragraph_keywords": ["product", "page", "features", "codebook"]}, {"paragraph_vector": [39.828731, -20.471065], "paragraph_keywords": ["websites", "features", "sample", "investment"]}, {"paragraph_vector": [38.850337, -21.094852], "paragraph_keywords": ["product", "features", "included", "websites"]}, {"paragraph_vector": [38.611457, -18.790693], "paragraph_keywords": ["product", "websites", "features", "included"]}, {"paragraph_vector": [36.132907, -20.620584], "paragraph_keywords": ["consumers", "goal", "buying", "control"]}, {"paragraph_vector": [28.357147, -18.186931], "paragraph_keywords": ["participants", "behavior", "goals", "commitment"]}, {"paragraph_vector": [28.775136, -15.639692], "paragraph_keywords": ["savings", "costs", "feel", "participants"]}, {"paragraph_vector": [39.076999, -21.745271], "paragraph_keywords": ["temptation", "reward", "survey", "consumers"]}, {"paragraph_vector": [37.324455, -21.596647], "paragraph_keywords": ["participants", "buying", "ads", "times"]}, {"paragraph_vector": [38.591339, -20.026248], "paragraph_keywords": ["participants", "scale", "tools", "buying"]}, {"paragraph_vector": [38.302177, -20.373085], "paragraph_keywords": ["items", "responses", "reported", "participants"]}, {"paragraph_vector": [37.222934, -20.125457], "paragraph_keywords": ["tool", "need", "features", "product"]}, {"paragraph_vector": [38.007968, -23.683586], "paragraph_keywords": ["purchase", "wait", "participants", "users"]}, {"paragraph_vector": [37.978851, -21.99195], "paragraph_keywords": ["time", "shopping", "participants", "product"]}, {"paragraph_vector": [38.693759, -20.785703], "paragraph_keywords": ["purchases", "item", "needs", "strategies"]}, {"paragraph_vector": [44.307411, -25.457181], "paragraph_keywords": ["participants", "shopping", "avoiding", "cited"]}, {"paragraph_vector": [44.118656, -23.7889], "paragraph_keywords": ["design", "consumer", "work", "research"]}, {"paragraph_vector": [38.353347, -22.280855], "paragraph_keywords": ["tools", "consumers", "help", "buyers"]}, {"paragraph_vector": [40.506191, -20.374021], "paragraph_keywords": ["tools", "checkout", "consumers", "reflection"]}, {"paragraph_vector": [39.03902, -22.690692], "paragraph_keywords": ["product", "users", "participants", "tools"]}, {"paragraph_vector": [38.799579, -21.857122], "paragraph_keywords": ["features", "tools", "product", "photography"]}, {"paragraph_vector": [39.417358, -22.387262], "paragraph_keywords": ["study", "features", "sites", "interventions"]}], "content": {}, "doi": "10.1145/3290605.3300249"}, {"uri": "225", "title": "Gamut: A Design Probe to Understand HowData Scientists Understand Machine Learning Models", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Fred Hohman"], "summary": "Without good models and the right tools to interpret them, data scientists risk making decisions based on hidden biases, spurious correlations, and false generalizations. This has led to a rallying cry for model interpretability. Yet the concept of interpretability remains nebulous, such that researchers and tool designers lack actionable guidelines for how to incorporate interpretability into models and accompanying tools. Through an iterative design process with expert machine learning researchers and practitioners, we designed a visual analytics system, Gamut, to explore how interactive interfaces could better support model interpretation. Using Gamut as a probe, we investigated why and how professional data scientists interpret models, and how interface affordances can support data scientists in answering questions about model interpretability. Our investigation showed that interpretability is not a monolithic concept: data scientists have different reasons to interpret models and tailor explanations for specific audiences, often balancing competing concerns of simplicity and completeness. Participants also asked to use Gamut in their work, highlighting its potential to help data scientists understand their own data. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300809 CCS CONCEPTS \u2022Human-centered computing\u2192 Empirical studies in visualization; Visualization systems and tools; \u2022 Computing methodologies\u2192 Machine learning.", "keywords": ["based", "explanation", "feature", "design", "price", "model", "user", "gamut", "comparison", "chart", "capability", "work", "participant", "use", "learning", "predicted", "shape", "visualization", "dataset", "function", "understanding", "waterfall", "understand", "probe", "value", "data", "ml", "instance", "study", "prediction", "scientist", "system", "support", "research", "interpretability", "machine", "view", "question", "interface", "gam", "figure"], "document_vector": [-139.415313, -12.972077], "paragraphs": [{"paragraph_vector": [73.091423, 69.156127], "paragraph_keywords": ["systems", "interpretability", "model", "data"]}, {"paragraph_vector": [76.022109, 66.163314], "paragraph_keywords": ["model", "models", "data", "explanations"]}, {"paragraph_vector": [76.110397, 68.315002], "paragraph_keywords": ["interpretability", "data", "model", "work"]}, {"paragraph_vector": [70.494781, 59.048381], "paragraph_keywords": ["explanations", "interpretability", "ai", "decision"]}, {"paragraph_vector": [75.665214, 64.167655], "paragraph_keywords": ["evaluation", "ml", "data", "systems"]}, {"paragraph_vector": [71.079635, 62.18452], "paragraph_keywords": ["explanation", "data", "machine", "user"]}, {"paragraph_vector": [69.389366, 63.686302], "paragraph_keywords": ["given", "prediction", "model", "price"]}, {"paragraph_vector": [86.438743, 67.872505], "paragraph_keywords": ["model", "models", "structure", "probe"]}, {"paragraph_vector": [80.55635, 70.030036], "paragraph_keywords": ["shape", "features", "feature", "target"]}, {"paragraph_vector": [79.337677, 69.302078], "paragraph_keywords": ["features", "feature", "model", "shape"]}, {"paragraph_vector": [84.818809, 72.419845], "paragraph_keywords": ["shape", "data", "feature", "instance"]}, {"paragraph_vector": [92.329299, 74.120864], "paragraph_keywords": ["instance", "chart", "values", "waterfall"]}, {"paragraph_vector": [80.087043, 71.423194], "paragraph_keywords": ["instance", "data", "shape", "charts"]}, {"paragraph_vector": [79.873535, 65.924491], "paragraph_keywords": ["participants", "data", "models", "scientists"]}, {"paragraph_vector": [73.59024, 64.128097], "paragraph_keywords": ["questions", "gamut", "model", "models"]}, {"paragraph_vector": [73.336845, 67.50679], "paragraph_keywords": ["data", "participants", "model", "features"]}, {"paragraph_vector": [70.00885, 59.773612], "paragraph_keywords": ["data", "model", "models", "participant"]}, {"paragraph_vector": [71.684532, 65.401405], "paragraph_keywords": ["explanations", "model", "explanation", "participant"]}, {"paragraph_vector": [77.522499, 66.981025], "paragraph_keywords": ["participants", "interactivity", "instance", "model"]}, {"paragraph_vector": [75.06723, 65.832992], "paragraph_keywords": ["feature", "participants", "wanted", "neighbors"]}, {"paragraph_vector": [76.914741, 65.179634], "paragraph_keywords": ["gamut", "models", "participants", "gams"]}, {"paragraph_vector": [82.66732, 66.441635], "paragraph_keywords": ["models", "charts", "explanations", "interpretability"]}, {"paragraph_vector": [73.522529, 64.014236], "paragraph_keywords": ["machine", "learning", "data", "gamut"]}], "content": {}, "doi": "10.1145/3290605.3300596"}, {"uri": "226", "title": "ForceRay: Extending Thumb Reach via Force Input Stabilizes Device Grip for Mobile Touch Input", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Christian Corsten", "Marcel Lahaye", "Jan Borchers"], "summary": "Smartphones are used predominantly one-handed, using the thumb for input. Many smartphones, however, have grown beyond 5\". Users cannot tap everywhere on these screens without destabilizing their grip. ForceRay (FR) lets users aim at an out-of-reach target by applying a force touch at a comfortable thumb location, casting a virtual ray towards the target. Varying pressure moves a cursor along the ray. When reaching the target, quickly lifting the thumb selects it. In Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proft or commercial advantage and that copies bear this notice and the full citation on the frst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specifc permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300442 a frst study, FR was 195 ms slower and had a 3% higher selection error than the best existing technique, BezelCursor (BC), but FR caused signifcantly less device movement than all other techniques, letting users maintain a steady grip and removing their concerns about device drops. A second study showed that an hour of training speeds up both BC and FR, and that both are equally fast for targets at the screen border.", "keywords": ["success", "time", "reach", ".", "selection", "training", "force", "cursor", "technique", "touchscreen", "touch", "user", "techniqe", "ui", "use", "reachability", "bc", "m", "screen", "size", "grip", "control", "compared", "fr", "motion", "om", "fig", "hand", "device", "ray", "study", "thumb", "select", "target", "swiping", "corner", "paper", "input", "center", "p"], "document_vector": [7.381013, -65.655738], "paragraphs": [{"paragraph_vector": [-36.90847, 13.734149], "paragraph_keywords": ["device", "force", "reachability", "touch"]}, {"paragraph_vector": [-30.68032, 15.012092], "paragraph_keywords": ["screen", "thumb", "force", "touch"]}, {"paragraph_vector": [-25.924808, 15.221274], "paragraph_keywords": ["screen", "thumb", "techniques", "reachability"]}, {"paragraph_vector": [-35.227497, 13.967789], "paragraph_keywords": ["thumb", "screen", "cursor", "ui"]}, {"paragraph_vector": [-39.080818, 14.518338], "paragraph_keywords": ["force", "targets", "screen", "control"]}, {"paragraph_vector": [-34.610679, 15.425483], "paragraph_keywords": ["force", "ray", "user", "thumb"]}, {"paragraph_vector": [-29.968246, 24.058727], "paragraph_keywords": ["force", "target", "cursor", "ray"]}, {"paragraph_vector": [-31.83006, 16.890628], "paragraph_keywords": ["force", "techniques", "values", "thumb"]}, {"paragraph_vector": [-36.015388, 15.205168], "paragraph_keywords": ["thumb", "line", "mm", "swiping"]}, {"paragraph_vector": [-25.987199, 23.270139], "paragraph_keywords": ["force", "touch", "ray", "users"]}, {"paragraph_vector": [-28.541599, 21.839473], "paragraph_keywords": ["targets", "target", "pt", "techniqe"]}, {"paragraph_vector": [-30.50555, 10.400932], "paragraph_keywords": ["users", "ms", "data", "techniqe"]}, {"paragraph_vector": [-26.466871, 26.124042], "paragraph_keywords": ["success", "p", "targets", "fr"]}, {"paragraph_vector": [-32.450202, 12.903543], "paragraph_keywords": ["p", "users", "grip", "bc"]}, {"paragraph_vector": [-29.6266, 15.941798], "paragraph_keywords": ["force", "users", "targets", "thumb"]}, {"paragraph_vector": [-25.053852, 24.629758], "paragraph_keywords": ["users", "target", "cursor", "m"]}, {"paragraph_vector": [-31.868707, 14.986104], "paragraph_keywords": ["training", "targets", "session", "fr"]}, {"paragraph_vector": [-30.181058, 14.901047], "paragraph_keywords": ["bc", "p", "target", "users"]}, {"paragraph_vector": [-28.381998, 15.327449], "paragraph_keywords": ["bc", "users", "sides", "user"]}, {"paragraph_vector": [-25.264902, 14.675207], "paragraph_keywords": ["targets", "device", "motion", "-"]}, {"paragraph_vector": [-31.893472, 16.280529], "paragraph_keywords": ["force", "target", "targets", "screen"]}, {"paragraph_vector": [-28.593658, 14.535079], "paragraph_keywords": ["bc", "force", "thumb", "device"]}, {"paragraph_vector": [74.534187, 34.114917], "paragraph_keywords": []}], "content": {}, "doi": "10.1145/3290605.3300718"}, {"uri": "227", "title": "Visualizing Uncertainty and Alternatives inEvent Sequence Predictions", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Shunan Guo", "Zhicheng Liu", "Fan Du", "Sana Malik", "Eunyee Koh", "Sungchul Kim", "Donghyun Kim", "Hongyuan Zha"], "summary": "Data analysts apply machine learning and statistical methods to timestamped event sequences to tackle various problems but face unique challenges when interpreting the results. Especially in event sequence prediction, it is difficult to convey uncertainty and possible alternative paths or outcomes. In this work, informed by interviewswith fivemachine learning practitioners, we iteratively designed a novel visualization for exploring event sequence predictions of multiple records where users are able to review the most probable predictions and possible alternatives alongside uncertainty information. Through a controlled study with 18 participants, we found that users are more confident in making decisions when alternative predictions are displayed and they consider the alternatives more when deciding between two options with similar top predictions.", "keywords": ["sequence", "based", "condition", "need", "information", "analyst", "design", "analysis", "interview", "email", "category", "showing", "uncertainty", "user", "activity", "model", "predict", "path", "decision", "result", "work", "participant", "people", "probability", "visualization", "page", "making", "fig", "task", "data", "study", "prediction", "alternative", "customer", "event", "marketing", "outcome", "paper", "level", "record"], "document_vector": [-137.908111, -9.272133], "paragraphs": [{"paragraph_vector": [155.89981, 77.641304], "paragraph_keywords": ["event", "copies", "events", "kim"]}, {"paragraph_vector": [154.430664, 74.397171], "paragraph_keywords": ["events", "event", "sequences", "models"]}, {"paragraph_vector": [155.489883, 75.236366], "paragraph_keywords": ["uncertainty", "predictions", "alternatives", "making"]}, {"paragraph_vector": [-110.942512, 88.552543], "paragraph_keywords": ["uncertainty", "data", "decision", "people"]}, {"paragraph_vector": [158.497711, 77.341773], "paragraph_keywords": ["records", "event", "outcomes", "sequences"]}, {"paragraph_vector": [156.452163, 74.893562], "paragraph_keywords": ["design", "practitioners", "interviews", "needs"]}, {"paragraph_vector": [156.104858, 72.978347], "paragraph_keywords": ["marketing", "analysts", "customers", "activities"]}, {"paragraph_vector": [157.601318, 73.643592], "paragraph_keywords": ["prediction", "uncertainty", "design", "models"]}, {"paragraph_vector": [158.211013, 74.290847], "paragraph_keywords": ["event", "based", "probability", "model"]}, {"paragraph_vector": [161.579147, 80.540969], "paragraph_keywords": ["paths", "design", "records", "uncertainty"]}, {"paragraph_vector": [116.802864, 79.173851], "paragraph_keywords": ["prediction", "fig", "users", "event"]}, {"paragraph_vector": [154.37564, 82.657348], "paragraph_keywords": ["prediction", "probability", "predictions", "event"]}, {"paragraph_vector": [167.457122, 83.363014], "paragraph_keywords": ["predictions", "users", "levels", "level"]}, {"paragraph_vector": [154.461181, 89.032348], "paragraph_keywords": ["uncertainty", "predictions", "users", "alternatives"]}, {"paragraph_vector": [-140.914276, 88.039733], "paragraph_keywords": ["marketing", "participants", "email", "shows"]}, {"paragraph_vector": [18.058712, 80.349845], "paragraph_keywords": ["predictions", "study", "probability", "situations"]}, {"paragraph_vector": [33.34386, 79.531387], "paragraph_keywords": ["predictions", "confidence", "conditions", "participants"]}, {"paragraph_vector": [40.818672, 87.175819], "paragraph_keywords": ["predictions", "participants", "prediction", "choices"]}, {"paragraph_vector": [-171.161773, 87.618286], "paragraph_keywords": ["predictions", "prediction", "uncertainty", "probability"]}, {"paragraph_vector": [152.034942, 77.733337], "paragraph_keywords": ["predictions", "uncertainty", "design", "needs"]}, {"paragraph_vector": [150.152038, 76.941703], "paragraph_keywords": ["predictions", "uncertainty", "domain", "experts"]}], "content": {}, "doi": "10.1145/3290605.3300731"}, {"uri": "228", "title": "TutoriVR: A Video-Based Tutorial System for Design Applications in Virtual Reality", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Balasaravanan Thoravi", "Cuong Nguyen", "Stephen DiVerdi", "Bj\u00f6rn Hartmann"], "summary": "Virtual Reality painting is a form of 3D-painting done in a Virtual Reality (VR) space. Being a relatively new kind of art form, there is a growing interest within the creative practices community to learn it. Currently, most users learn using community posted 2D-videos on the internet, which are a screencast recording of the painting process by an instructor. While such an approach may sufce for teaching 2D-software tools, these videos by themselves fail in delivering crucial details that required by the user to understand actions in a VR space. We conduct a formative study to identify challenges faced by users in learning to VR-paint using such video-based tutorials. Informed by results of this study, we develop a VR-embedded tutorial system that supplements video tutorials with 3D and contextual aids directly in the user\u2019s VR environment. An exploratory evaluation showed users were positive about the system and were able to use the proposed system to recreate painting tasks in VR.", "keywords": ["process", "vr", "based", "controller", "time", "player", "design", "provide", "help", "stroke", "user", "painting", "button", "interaction", "learn", "work", "video", "participant", "use", "create", "learning", "step", "stereo", "application", "understanding", "found", "awareness", "tutorivr", "task", "workfow", "study", "system", "tutorial", "event", "view", "instructor", "widget", "mode", "depth", "action", "figure"], "document_vector": [147.32582, -21.756309], "paragraphs": [{"paragraph_vector": [-101.658775, 21.840852], "paragraph_keywords": ["vr", "design", "reality", "copies"]}, {"paragraph_vector": [12.166979, 59.600509], "paragraph_keywords": ["vr", "design", "user", "tutorials"]}, {"paragraph_vector": [8.721474, 57.689994], "paragraph_keywords": ["vr", "video", "painting", "users"]}, {"paragraph_vector": [8.457228, 61.042034], "paragraph_keywords": ["users", "tutorials", "design", "system"]}, {"paragraph_vector": [12.786754, 56.383361], "paragraph_keywords": ["vr", "application", "recording", "video"]}, {"paragraph_vector": [5.960626, 57.899326], "paragraph_keywords": ["vr", "video", "users", "tutorials"]}, {"paragraph_vector": [7.632009, 56.327861], "paragraph_keywords": ["vr", "video", "painting", "user"]}, {"paragraph_vector": [14.324279, 55.978782], "paragraph_keywords": ["player", "video", "users", "vr"]}, {"paragraph_vector": [20.717643, 49.569095], "paragraph_keywords": ["video", "users", "button", "vr"]}, {"paragraph_vector": [7.828926, 54.679271], "paragraph_keywords": ["users", "controller", "interactions", "artifact"]}, {"paragraph_vector": [10.077027, 58.45354], "paragraph_keywords": ["video", "users", "stroke", "painting"]}, {"paragraph_vector": [8.899768, 55.458976], "paragraph_keywords": ["actions", "user", "vr", "users"]}, {"paragraph_vector": [11.77741, 53.076484], "paragraph_keywords": ["vr", "user", "events", "video"]}, {"paragraph_vector": [8.716744, 55.516529], "paragraph_keywords": ["video", "vr", "depth", "navigation"]}, {"paragraph_vector": [9.00497, 56.149185], "paragraph_keywords": ["controller", "stroke", "video", "widget"]}, {"paragraph_vector": [10.589141, 53.593502], "paragraph_keywords": ["user", "view", "video", "users"]}, {"paragraph_vector": [10.31994, 54.717357], "paragraph_keywords": ["video", "participants", "task", "vr"]}, {"paragraph_vector": [-0.531623, 55.599788], "paragraph_keywords": ["participants", "steps", "task", "system"]}, {"paragraph_vector": [-2.527169, 54.056041], "paragraph_keywords": ["users", "baseline", "system", "controller"]}, {"paragraph_vector": [5.90624, 59.277084], "paragraph_keywords": ["users", "vr", "tasks", "study"]}, {"paragraph_vector": [11.917506, 56.5158], "paragraph_keywords": ["vr", "user", "system", "application"]}], "content": {}, "doi": "10.1145/3290605.3300823"}, {"uri": "229", "title": "Integrating Multimedia Tools to Enrich Interactions in Live Streaming for Language Learning", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Dustin Freeman", "Ravin Balakrishnan"], "summary": "Online language lessons have adopted live broadcasted videos to provide more real-time interactive experiences between language teachers and learners. However, learner interactions are primarily limited to the built-in text chat in the live stream. Using text alone, learners cannot get feedback on important aspects of a language, such as speaking skills, that are afforded only by offering richer types of interactions. We present results from a 2-week in-the-wild study, in which we investigate the use of text, audio, video, image, and stickers as interaction tools for language teachers and learners in live streaming. Our language teacher explored three different teaching strategies over four live streamed English lessons, while nine students watched and interacted using multimodal tools. The findings reveal that multimodal communication yields instant feedback and increased engagement, but its use is dependent on factors such as group size, surroundings, time, and online identity.", "keywords": ["facebook", "time", "viewer", "conversation", "sticker", "interaction", "know", "communication", "learn", "work", "video", "language", "streaming", "participant", "tool", "live", "use", "people", "multimodal", "group", "pronunciation", "send", "learning", "experience", "felt", "page", "teacher", "chat", "content", "feedback", "teaching", "stream", "comment", "sending", "audience", "study", "lesson", "modality", "student", "image", "picture", "system", "text", "support", "talking", "streamer", "audio", "multimodality", "asked", "question", "multimedia", "sent", "paper"], "document_vector": [-127.019966, 34.639804], "paragraphs": [{"paragraph_vector": [101.047134, 3.437275], "paragraph_keywords": ["language", "copies", "viewers", "stream"]}, {"paragraph_vector": [100.568588, 1.895447], "paragraph_keywords": ["language", "learning", "multimedia", "comments"]}, {"paragraph_vector": [101.503936, 2.545395], "paragraph_keywords": ["learning", "language", "video", "multimodal"]}, {"paragraph_vector": [103.624099, 0.399279], "paragraph_keywords": ["language", "learning", "streaming", "audio"]}, {"paragraph_vector": [101.68885, 5.4685], "paragraph_keywords": ["communication", "streamer", "text", "game"]}, {"paragraph_vector": [58.713382, 9.245522], "paragraph_keywords": ["text", "chat", "content", "video"]}, {"paragraph_vector": [100.65628, 3.267804], "paragraph_keywords": ["streamer", "streams", "streaming", "stream"]}, {"paragraph_vector": [99.729629, 2.151887], "paragraph_keywords": ["streaming", "lessons", "study", "participants"]}, {"paragraph_vector": [122.844963, -51.146835], "paragraph_keywords": ["facebook", "video", "participant", "device"]}, {"paragraph_vector": [103.679046, 0.050393], "paragraph_keywords": ["study", "streamer", "participant", "asked"]}, {"paragraph_vector": [102.359268, -4.149234], "paragraph_keywords": ["questions", "participants", "viewers", "questionnaire"]}, {"paragraph_vector": [104.200393, 4.209825], "paragraph_keywords": ["participants", "data", "learning", "multimodal"]}, {"paragraph_vector": [109.177032, -1.466039], "paragraph_keywords": ["streamer", "text", "viewers", "pronunciation"]}, {"paragraph_vector": [97.505119, 6.119684], "paragraph_keywords": ["viewers", "video", "sent", "image"]}, {"paragraph_vector": [104.507362, -0.376412], "paragraph_keywords": ["stickers", "viewers", "picture", "wanted"]}, {"paragraph_vector": [101.584037, 1.17148], "paragraph_keywords": ["viewers", "learning", "modalities", "language"]}, {"paragraph_vector": [101.922279, 0.64994], "paragraph_keywords": ["viewers", "life", "language", "english"]}, {"paragraph_vector": [101.746559, 0.214317], "paragraph_keywords": ["learning", "viewers", "people", "sent"]}, {"paragraph_vector": [100.836555, 1.80535], "paragraph_keywords": ["viewers", "teacher", "streamer", "learn"]}, {"paragraph_vector": [100.389274, 2.354661], "paragraph_keywords": ["streamer", "viewers", "feedback", "object"]}, {"paragraph_vector": [101.628211, 4.625619], "paragraph_keywords": ["streamer", "time", "modality", "viewers"]}, {"paragraph_vector": [103.543312, -2.621142], "paragraph_keywords": ["time", "comments", "streamer", "stream"]}, {"paragraph_vector": [102.822601, 0.558361], "paragraph_keywords": ["viewers", "identity", "comments", "know"]}, {"paragraph_vector": [102.696258, 2.991133], "paragraph_keywords": ["fun", "viewers", "participants", "learning"]}, {"paragraph_vector": [101.035781, 2.358869], "paragraph_keywords": ["streamer", "talking", "conversation", "viewers"]}, {"paragraph_vector": [101.204986, 4.042054], "paragraph_keywords": ["moderators", "interactions", "audience", "learning"]}, {"paragraph_vector": [103.689857, 2.311235], "paragraph_keywords": ["stream", "comments", "streaming", "broadcasted"]}, {"paragraph_vector": [100.553985, 2.291571], "paragraph_keywords": ["learning", "interactions", "streaming", "multimodal"]}, {"paragraph_vector": [103.031486, 1.217659], "paragraph_keywords": ["viewers", "comments", "streamer", "multimodal"]}, {"paragraph_vector": [100.597663, 3.324488], "paragraph_keywords": ["study", "learning", "tools", "language"]}], "content": {}, "doi": "10.1145/3290605.3300239"}, {"uri": "230", "title": "Eye-Write: Gaze Sharing for Collaborative Writing", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Grete Helena K\u00fctt", "Kevin Lee", "Ethan Hardacre"], "summary": "Online collaborative writing is an increasingly common practice. Despite its positive effect on productivity and quality of work, it poses challenges to co-authors in remote settings because of limitations in conversational grounding and activity awareness. This paper presents Eye-Write, a novel system which allows two co-authors to see at will the location of their partner\u2019s gaze within a text editor. To investigate the effect of shared gaze on collaboration, we conducted a study on synchronous remote collaborative writing in academic settings with 20 dyads. Gaze sharing improved five aspects of perceived collaboration quality: mutual understanding, level of joint attention, flow of communication, level of negotiation, and awareness of the co-author\u2019s activity. Furthermore, dyads whose participants deactivated the gaze visualization showed a smaller degree of collaboration. Our findings offer insights for future text editors by outlining the benefits of at-will gaze sharing in collaborative writing.", "keywords": ["process", "based", "time", "condition", "information", "author", "dyad", "writing", "gaze", "co", "partner", "example", "user", "sharing", "eye", "communication", "work", "tool", "participant", "use", "line", "given", "working", "visualization", "page", "collaboration", "found", "awareness", "-", "g", "write", "task", "document", "study", "student", "support", "text", "research", "quality", "showed", "pair", "level", "p"], "document_vector": [-77.117935, -34.294139], "paragraphs": [{"paragraph_vector": [37.622737, 13.640576], "paragraph_keywords": ["writing", "copies", "computing", "systems"]}, {"paragraph_vector": [38.876926, 15.984064], "paragraph_keywords": ["writing", "gaze", "work", "awareness"]}, {"paragraph_vector": [37.309524, 15.27705], "paragraph_keywords": ["writing", "gaze", "eye", "awareness"]}, {"paragraph_vector": [38.398136, 15.829298], "paragraph_keywords": ["writing", "google", "docs", "levels"]}, {"paragraph_vector": [38.615287, 15.423734], "paragraph_keywords": ["gaze", "time", "awareness", "eye"]}, {"paragraph_vector": [38.918437, 16.283937], "paragraph_keywords": ["gaze", "participants", "respondents", "writing"]}, {"paragraph_vector": [37.55619, 15.859556], "paragraph_keywords": ["tools", "writing", "collaborators", "communication"]}, {"paragraph_vector": [38.703102, 15.617671], "paragraph_keywords": ["gaze", "-", "lines", "text"]}, {"paragraph_vector": [39.085289, 15.18857], "paragraph_keywords": ["visualization", "gaze", "found", "text"]}, {"paragraph_vector": [38.602909, 13.874653], "paragraph_keywords": ["participants", "gaze", "study", "eye"]}, {"paragraph_vector": [36.885848, 13.69467], "paragraph_keywords": ["users", "version", "participants", "article"]}, {"paragraph_vector": [36.412872, 18.238718], "paragraph_keywords": ["gaze", "visualization", "participants", "task"]}, {"paragraph_vector": [37.225494, 17.556013], "paragraph_keywords": ["collaboration", "level", "information", "task"]}, {"paragraph_vector": [38.185565, 17.977052], "paragraph_keywords": ["gaze", "collaboration", "level", "sharing"]}, {"paragraph_vector": [38.074462, 16.832509], "paragraph_keywords": ["collaboration", "gaze", "task", "levels"]}, {"paragraph_vector": [38.457351, 18.03808], "paragraph_keywords": ["p", "partner", "writing", "gaze"]}, {"paragraph_vector": [35.480823, 16.421442], "paragraph_keywords": ["gaze", "time", "visualization", "participants"]}, {"paragraph_vector": [37.700668, 16.744087], "paragraph_keywords": ["gaze", "participants", "visualization", "sharing"]}, {"paragraph_vector": [39.08953, 14.738099], "paragraph_keywords": ["gaze", "visualization", "sharing", "liked"]}, {"paragraph_vector": [37.831363, 15.578192], "paragraph_keywords": ["writing", "gaze", "participants", "collaboration"]}, {"paragraph_vector": [38.369678, 15.114115], "paragraph_keywords": ["gaze", "writing", "level", "sharing"]}, {"paragraph_vector": [37.407127, 15.854836], "paragraph_keywords": ["aspect", "importance", "developing", "accommodating"]}], "content": {}, "doi": "10.1145/3290605.3300577"}, {"uri": "231", "title": "Opportunities for Automating Email Processing: A Need-Finding Study", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Soya Park", "Amy X. Zhang", "Luke S. Murray"], "summary": "Email management consumes significant effort from senders and recipients. Some of this work might be automatable. We performed a mixed-methods need-finding study to learn: (i) what sort of automatic email handling users want, and (ii) what kinds of information and computation are needed to support that automation. Our investigation included a design workshop to identify categories of needs, a survey to better understand those categories, and a classification of existing email automation software to determine which needs have been addressed. Our results highlight the need for: a richer data model for rules, more ways to manage attention, leveraging internal and external email context, complex processing such as response aggregation, and affordances for senders. To further investigate our findings, we developed a platform for authoring small scripts over a user\u2019s inbox. Of the automations found in our studies, half are impossible in popular email clients, motivating new design directions.", "keywords": ["message", "requires", "time", "need", "information", "like", "processing", "feature", "programmer", "email", "category", "example", "sender", "wanted", "user", "workshop", "work", "management", "participant", "use", "people", "code", "client", "send", "way", "script", "automation", "existing", "content", "inbox", "survey", "write", "-", "found", "identified", "probe", "programming", "attention", "data", "said", "system", "imap", "recipient", "rule", "mode", "paper", "interface", "action", "context", "youps", "response"], "document_vector": [-61.95758, -7.724301], "paragraphs": [{"paragraph_vector": [55.753143, 2.581192], "paragraph_keywords": ["email", "work", "copies", "automation"]}, {"paragraph_vector": [52.436344, 3.268856], "paragraph_keywords": ["users", "email", "needs", "automation"]}, {"paragraph_vector": [53.952106, 1.918096], "paragraph_keywords": ["email", "scripts", "recipient", "users"]}, {"paragraph_vector": [51.953269, 4.646397], "paragraph_keywords": ["email", "users", "information", "systems"]}, {"paragraph_vector": [52.824928, 2.422731], "paragraph_keywords": ["email", "users", "messages", "clients"]}, {"paragraph_vector": [55.130344, 3.602374], "paragraph_keywords": ["email", "users", "workshop", "needs"]}, {"paragraph_vector": [55.587982, 13.487032], "paragraph_keywords": ["email", "survey", "emails", "participants"]}, {"paragraph_vector": [58.460453, 6.461501], "paragraph_keywords": ["priority", "survey", "message", "responses"]}, {"paragraph_vector": [53.87997, 1.427626], "paragraph_keywords": ["context", "message", "email", "vacation"]}, {"paragraph_vector": [53.682033, 0.967326], "paragraph_keywords": ["emails", "users", "email", "attention"]}, {"paragraph_vector": [54.404228, 2.186482], "paragraph_keywords": ["emails", "email", "recipients", "people"]}, {"paragraph_vector": [53.667011, 3.277373], "paragraph_keywords": ["email", "emails", "said", "message"]}, {"paragraph_vector": [53.395782, 1.732328], "paragraph_keywords": ["email", "code", "identify", "needs"]}, {"paragraph_vector": [80.713676, -7.749047], "paragraph_keywords": ["scripts", "email", "categories", "content"]}, {"paragraph_vector": [53.945785, 2.77062], "paragraph_keywords": ["scripts", "inbox", "email", "emails"]}, {"paragraph_vector": [53.616436, 3.448565], "paragraph_keywords": ["email", "users", "probe", "rules"]}, {"paragraph_vector": [52.492839, 1.387868], "paragraph_keywords": ["users", "youps", "email", "rules"]}, {"paragraph_vector": [50.177547, 1.787175], "paragraph_keywords": ["email", "participants", "rules", "sender"]}, {"paragraph_vector": [52.691173, 3.521225], "paragraph_keywords": ["email", "modes", "mode", "interaction"]}, {"paragraph_vector": [54.311042, 1.961522], "paragraph_keywords": ["email", "rules", "users", "interfaces"]}, {"paragraph_vector": [55.25386, 1.761302], "paragraph_keywords": ["emails", "users", "email", "context"]}, {"paragraph_vector": [53.233318, 2.984276], "paragraph_keywords": ["email", "users", "ways", "systems"]}, {"paragraph_vector": [52.27835, 1.915282], "paragraph_keywords": ["needs", "users", "email", "programmers"]}, {"paragraph_vector": [54.585212, 1.901785], "paragraph_keywords": ["programmers", "youps", "rules", "scripts"]}, {"paragraph_vector": [51.889564, 3.369663], "paragraph_keywords": ["email", "needs", "users", "clients"]}], "content": {}, "doi": "10.1145/3290605.3300597"}, {"uri": "232", "title": "Experimental Analysis of Bare Hand Mid-air Mode-Switching Techniques in Virtual Reality", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Hemant Bhaskar Surale", "Fabrice Matulic"], "summary": "We present an empirical comparison of eleven bare hand, mid-air mode-switching techniques suitable for virtual reality in two experiments. The first evaluates seven techniques spanning dominant and non-dominant hand actions. Techniques represent common classes of actions selected by a methodical examination of 56 examples of prior art. The standard \u201csubtraction method\u201d protocol is adapted for 3D interfaces, with two baseline selection methods, bare hand pinch and device controller button. A second experiment with four techniques explores more subtle dominant-hand techniques and the effect of using a dominant hand device for selection. Results provide guidance to practitioners when choosing bare hand, mid-air mode-switching techniques, and for researchers when designing new mode-switching methods in VR.", "keywords": ["vr", "controller", "time", "finger", "al", "rate", "experiment", "technique", "baseline", "error", "nd", "pointing", "user", "interaction", "et", "palm", "work", "drawing", "use", "participant", "line", "switching", "pinch", "fist", "found", "-", "block", "head", "task", "hand", "device", "switch", "sphere", "mode", "input", "action"], "document_vector": [155.781951, -49.696014], "paragraphs": [{"paragraph_vector": [-55.410579, 11.334817], "paragraph_keywords": ["mode", "copies", "hand", "vr"]}, {"paragraph_vector": [-48.27864, 9.931595], "paragraph_keywords": ["hand", "techniques", "vr", "mode"]}, {"paragraph_vector": [-46.732353, 8.910583], "paragraph_keywords": ["hand", "techniques", "et", "device"]}, {"paragraph_vector": [-44.037895, 11.388714], "paragraph_keywords": ["techniques", "mode", "et", "interaction"]}, {"paragraph_vector": [-48.762535, 4.261837], "paragraph_keywords": ["mode", "actions", "hand", "action"]}, {"paragraph_vector": [-46.698951, 9.551023], "paragraph_keywords": ["hand", "actions", "action", "pinch"]}, {"paragraph_vector": [-44.085582, 9.027291], "paragraph_keywords": ["hand", "mode", "fingers", "palm"]}, {"paragraph_vector": [-44.880008, 13.536859], "paragraph_keywords": ["pinch", "fist", "palm", "user"]}, {"paragraph_vector": [-56.452239, 13.772392], "paragraph_keywords": ["vr", "mode", "switching", "hmd"]}, {"paragraph_vector": [-33.437747, 15.014592], "paragraph_keywords": ["line", "spheres", "pair", "drawing"]}, {"paragraph_vector": [-41.458988, 10.579494], "paragraph_keywords": ["mode", "participant", "line", "hand"]}, {"paragraph_vector": [-27.563343, 15.746414], "paragraph_keywords": ["blocks", "baseline", "task", "tasks"]}, {"paragraph_vector": [-25.753047, 14.863092], "paragraph_keywords": ["line", "mode", "compound", "drawing"]}, {"paragraph_vector": [-22.805959, 19.565509], "paragraph_keywords": ["error", "mode", "time", "times"]}, {"paragraph_vector": [-41.041156, 8.387445], "paragraph_keywords": ["tests", "block", "effects", "p"]}, {"paragraph_vector": [-40.576503, 8.013021], "paragraph_keywords": ["error", "rate", "nd", "-"]}, {"paragraph_vector": [-43.848728, 6.871954], "paragraph_keywords": ["rate", "error", "mode", "fist"]}, {"paragraph_vector": [-36.846595, 10.242136], "paragraph_keywords": ["techniques", "palm", "d", "nd"]}, {"paragraph_vector": [-44.353748, 8.79352], "paragraph_keywords": ["pinch", "techniques", "hand", "experiment"]}, {"paragraph_vector": [-44.57761, 8.344217], "paragraph_keywords": ["mode", "controller", "times", "line"]}, {"paragraph_vector": [-39.368762, 9.090709], "paragraph_keywords": ["nd", "error", "ratings", "mode"]}, {"paragraph_vector": [-42.814617, 7.168337], "paragraph_keywords": ["techniques", "mode", "switching", "finger"]}, {"paragraph_vector": [-41.21455, 7.34569], "paragraph_keywords": ["pinch", "device", "switching", "trigger"]}, {"paragraph_vector": [-46.244792, 10.676012], "paragraph_keywords": ["techniques", "mode", "switching", "vr"]}], "content": {}, "doi": "10.1145/3290605.3300260"}, {"uri": "233", "title": "Failing with Style: Designing for Aesthetic Failure in Interactive Performance", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Adrian Hazzard", "Chris Greenhalgh", "Maria Kallionp\u00e4\u00e4", "Steve Benford", "Anne Veinberg", "Zubin Kanga", "Andrew McPherson"], "summary": "Failure is a common artefact of challenging experiences, a fact of life for interactive systems but also a resource for aesthetic and improvisational performance. We present a study of how three professional pianists performed an interactive piano composition that included playing hidden codes within the music so as to control their path through the piece and trigger system actions. We reveal how apparent failures to play the codes occurred for diverse reasons including mistakes in their playing, limitations of the system, but also deliberate failures as a way of controlling the system, and how these failures provoked aesthetic and improvised responses from the performers. We propose that creative and performative interfaces should be designed to enable aesthetic failures and introduce a taxonomy that compares human approaches to failure with approaches to capable systems, revealing new creative design strategies of gaming, taming, riding and serving the system.", "keywords": ["success", "consider", "strategy", "disklavier", "performance", "section", "design", "written", "performer", "fail", "playing", "example", "piano", "path", "performed", "tempo", "play", "interaction", "failing", "failed", "work", "piece", "way", "failure", "challenge", "given", "control", "page", "score", "note", "perform", "pianist", "music", "composer", "including", "form", "rehearsal", "concert", "robot", "audience", "z", "human", "played", "game", "narrative", "approach", "system", "research", "enable", "climb", "order", "hci", "paper", "level", "considered", "code"], "document_vector": [45.101142, -14.782851], "paragraphs": [{"paragraph_vector": [166.919281, 17.11403], "paragraph_keywords": ["failure", "work", "humans", "copies"]}, {"paragraph_vector": [167.981887, 15.825234], "paragraph_keywords": ["failure", "systems", "score", "humans"]}, {"paragraph_vector": [164.467849, 16.788291], "paragraph_keywords": ["performance", "failure", "music", "musicians"]}, {"paragraph_vector": [168.486785, 17.16818], "paragraph_keywords": ["failure", "game", "games", "performance"]}, {"paragraph_vector": [162.566802, 14.867197], "paragraph_keywords": ["work", "climb", "composer", "piano"]}, {"paragraph_vector": [161.351364, 15.686847], "paragraph_keywords": ["pianist", "piano", "music", "climb"]}, {"paragraph_vector": [158.504852, 14.598005], "paragraph_keywords": ["codes", "climb", "pianist", "challenge"]}, {"paragraph_vector": [160.183486, 15.01895], "paragraph_keywords": ["climb", "codes", "audience", "play"]}, {"paragraph_vector": [161.263031, 14.618844], "paragraph_keywords": ["performance", "failure", "performers", "system"]}, {"paragraph_vector": [159.343673, 11.449784], "paragraph_keywords": ["performers", "codes", "performance", "performances"]}, {"paragraph_vector": [160.135375, 15.185231], "paragraph_keywords": ["performer", "performance", "concert", "composition"]}, {"paragraph_vector": [159.666976, 14.990099], "paragraph_keywords": ["climb", "score", "tempo", "disklavier"]}, {"paragraph_vector": [160.91484, 14.621009], "paragraph_keywords": ["score", "codes", "performance", "performer"]}, {"paragraph_vector": [161.638656, 14.94058], "paragraph_keywords": ["code", "disklavier", "performance", "phrase"]}, {"paragraph_vector": [160.645233, 15.297158], "paragraph_keywords": ["disklavier", "code", "performer", "phrases"]}, {"paragraph_vector": [160.018051, 13.291109], "paragraph_keywords": ["code", "performance", "challenge", "path"]}, {"paragraph_vector": [159.778915, 14.134603], "paragraph_keywords": ["performance", "system", "path", "performer"]}, {"paragraph_vector": [166.015747, 16.193696], "paragraph_keywords": ["failure", "performer", "performance", "audience"]}, {"paragraph_vector": [165.72319, 17.465465], "paragraph_keywords": ["failure", "performance", "aesthetics", "success"]}, {"paragraph_vector": [163.956863, 13.732701], "paragraph_keywords": ["failure", "performers", "performance", "score"]}, {"paragraph_vector": [163.953643, 15.995517], "paragraph_keywords": ["score", "failure", "level", "performer"]}, {"paragraph_vector": [168.520736, 16.38005], "paragraph_keywords": ["failure", "system", "design", "control"]}, {"paragraph_vector": [171.348907, 18.88092], "paragraph_keywords": ["system", "performers", "failure", "strategies"]}, {"paragraph_vector": [165.939987, 16.630527], "paragraph_keywords": ["failure", "systems", "success", "performance"]}, {"paragraph_vector": [-134.004287, -1.411172], "paragraph_keywords": ["robots", "humans", "failure", "hri"]}, {"paragraph_vector": [-164.738449, 17.086921], "paragraph_keywords": ["failure", "language", "participants", "system"]}, {"paragraph_vector": [-177.185287, 18.355308], "paragraph_keywords": ["failure", "strategies", "systems", "enable"]}], "content": {}, "doi": "10.1145/3290605.3300500"}, {"uri": "234", "title": "Design Goals for Playful Technology to Support Physical Activity Among Wheelchair Users", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Liam Mason", "Kathrin Gerling", "Antonella De Angeli"], "summary": "Playful technology has the potential to support physical activity (PA) among wheelchair users, but little is known about design considerations for this audience, who experience significant access barriers. In this paper, we leverage the Integrated Behavioural Model (IBM) to understand wheelchair users\u2019 perspectives on PA, technology, and play. First, we present findings from an interview study with eight physically active wheelchair users. Second, we build on the interviews in a survey that received 44 responses from a broader group of wheelchair users. Results show that the anticipation of positive experiences was the strongest predictor of engagement with PA, and that accessibility concerns act as barriers both in terms of PA participation and technology use. We present four design goals emphasizing enjoyment, involving others, building knowledge and enabling flexibility to make our findings actionable for researchers and designers wishing to create accessible playful technology to support PA.", "keywords": ["based", "suggesting", "mentioned", "perceived", "time", "development", "player", "pa", "design", "reported", "analysis", "attitude", "interview", "example", "user", "activity", "facilitate", "accessibility", "play", "engagement", "result", "work", "engage", "video", "participant", "use", "people", "interest", "health", "participation", "factor", "control", "finding", "page", "number", "barrier", "survey", "data", "technology", "game", "study", "wheelchair", "ibm", "support", "research", "perspective", "question", "paper", "behavior", "knowledge", "context", "access"], "document_vector": [44.393466, -2.272986], "paragraphs": [{"paragraph_vector": [-148.290069, -25.863264], "paragraph_keywords": ["games", "wheelchair", "activity", "work"]}, {"paragraph_vector": [-151.58551, -27.190399], "paragraph_keywords": ["pa", "wheelchair", "users", "technology"]}, {"paragraph_vector": [-152.125701, -29.430395], "paragraph_keywords": ["pa", "users", "existing", "wheelchair"]}, {"paragraph_vector": [-153.740829, -25.518709], "paragraph_keywords": ["wheelchair", "participants", "users", "based"]}, {"paragraph_vector": [-156.638549, -31.794776], "paragraph_keywords": ["behavior", "ibm", "health", "perceived"]}, {"paragraph_vector": [-151.363723, -26.834449], "paragraph_keywords": ["wheelchair", "users", "pa", "study"]}, {"paragraph_vector": [-152.453857, -29.809423], "paragraph_keywords": ["ibm", "technology", "participants", "based"]}, {"paragraph_vector": [-152.224807, -28.120344], "paragraph_keywords": ["pa", "participants", "people", "family"]}, {"paragraph_vector": [-154.834381, -31.181644], "paragraph_keywords": ["participants", "pa", "wheelchair", "reported"]}, {"paragraph_vector": [-150.799484, -26.04074], "paragraph_keywords": ["participants", "mentioned", "participant", "activities"]}, {"paragraph_vector": [-153.223129, -28.464059], "paragraph_keywords": ["participants", "pa", "mentioned", "themes"]}, {"paragraph_vector": [-146.374313, -26.064659], "paragraph_keywords": ["participants", "game", "games", "mentioned"]}, {"paragraph_vector": [-149.271667, -27.859813], "paragraph_keywords": ["games", "pa", "questions", "ibm"]}, {"paragraph_vector": [-151.954269, -31.630327], "paragraph_keywords": ["survey", "wheelchair", "questions", "analysis"]}, {"paragraph_vector": [-145.615493, -22.787326], "paragraph_keywords": ["m", "pa", "participants", "games"]}, {"paragraph_vector": [-150.818237, -26.790901], "paragraph_keywords": ["ibm", "pa", "participants", "perceived"]}, {"paragraph_vector": [-151.53244, -25.780223], "paragraph_keywords": ["participant", "participants", "games", "exercise"]}, {"paragraph_vector": [-150.515884, -26.886619], "paragraph_keywords": ["pa", "results", "games", "suggesting"]}, {"paragraph_vector": [-149.344528, -25.260629], "paragraph_keywords": ["pa", "enjoyment", "games", "game"]}, {"paragraph_vector": [-150.034149, -23.968042], "paragraph_keywords": ["technology", "knowledge", "support", "users"]}, {"paragraph_vector": [-149.537597, -25.220455], "paragraph_keywords": ["pa", "example", "flexibility", "participation"]}, {"paragraph_vector": [-150.750213, -25.771795], "paragraph_keywords": ["users", "pa", "wheelchair", "technology"]}, {"paragraph_vector": [-152.373565, -27.890617], "paragraph_keywords": ["technology", "pa", "access", "ibm"]}, {"paragraph_vector": [-153.876022, -27.602848], "paragraph_keywords": ["pa", "technology", "results", "research"]}], "content": {}, "doi": "10.1145/3290605.3300538"}, {"uri": "235", "title": "Poirot: A Web Inspector for Designers", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Kesler Tanner", "Naomi Johnson", "James A. Landay"], "summary": "To better understand the issues designers face as they interact with developers and use developer tools to create websites, we conducted a formative investigation consisting of interviews, a survey, and an analysis of professional design documents. Based on insights gained from these efforts, we developed Poirot, a web inspection tool for designers that enables them to make style edits to websites using a familiar graphical interface. We compared Poirot to Chrome DevTools in a lab study with 16 design professionals. We observed common problems designers experience when using Chrome DevTools and found that when using Poirot, designers were more successful in accomplishing typical design tasks (97% to 63%). In addition, we found that Poirot had a significantly lower perceived cognitive load and was overwhelmingly preferred by the designers in our study. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for thirdparty components of this work must be honored. For all other uses, contact the owner/author(s). CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). ACM ISBN 978-1-4503-5970-2/19/05. https://doi.org/10.1145/3290605.3300758 CCS CONCEPTS \u2022Human-centered computing\u2192Graphical user interfaces;Web-based interaction; Empirical studies in HCI.", "keywords": ["html", "time", "change", "syntax", "custom", "development", "design", "style", "cs", "interview", "user", "ui", "poirot", "work", "tool", "selected", "participant", "web", "use", "investigation", "insight", "devtools", "page", "experience", "survey", "understand", "task", "study", "element", "designer", "system", "developer", "image", "research", "website", "paper", "interface", "making", "code"], "document_vector": [49.159526, 14.97202], "paragraphs": [{"paragraph_vector": [107.235343, 51.056304], "paragraph_keywords": ["tools", "developer", "designers", "web"]}, {"paragraph_vector": [110.080772, 53.449466], "paragraph_keywords": ["tools", "designers", "web", "design"]}, {"paragraph_vector": [105.592582, 54.58168], "paragraph_keywords": ["designers", "poirot", "web", "user"]}, {"paragraph_vector": [109.181922, 50.0568], "paragraph_keywords": ["designers", "users", "code", "websites"]}, {"paragraph_vector": [99.254325, 52.716232], "paragraph_keywords": ["designer", "designers", "design", "developers"]}, {"paragraph_vector": [108.874061, 54.920787], "paragraph_keywords": ["developer", "site", "designer", "issues"]}, {"paragraph_vector": [105.998207, 51.801601], "paragraph_keywords": ["design", "participants", "survey", "ui"]}, {"paragraph_vector": [105.686058, 54.780536], "paragraph_keywords": ["designers", "design", "changes", "translation"]}, {"paragraph_vector": [116.043487, 62.074649], "paragraph_keywords": ["poirot", "elements", "page", "designers"]}, {"paragraph_vector": [127.837387, 62.90158], "paragraph_keywords": ["element", "poirot", "selected", "instances"]}, {"paragraph_vector": [124.945991, 65.887008], "paragraph_keywords": ["element", "image", "user", "transfer"]}, {"paragraph_vector": [113.377029, 61.298629], "paragraph_keywords": ["design", "page", "changes", "system"]}, {"paragraph_vector": [103.09671, 51.143005], "paragraph_keywords": ["participants", "study", "devtools", "poirot"]}, {"paragraph_vector": [145.107437, 65.283233], "paragraph_keywords": ["change", "study", "changes", "showed"]}, {"paragraph_vector": [94.029258, 51.841217], "paragraph_keywords": ["task", "participants", "tasks", "design"]}, {"paragraph_vector": [97.521591, 46.900127], "paragraph_keywords": ["tasks", "tool", "participants", "task"]}, {"paragraph_vector": [93.519683, 51.758228], "paragraph_keywords": ["tasks", "participants", "spent", "time"]}, {"paragraph_vector": [95.82077, 52.793987], "paragraph_keywords": ["poirot", "load", "perceived", "rated"]}, {"paragraph_vector": [100.230751, 53.414947], "paragraph_keywords": ["task", "participants", "design", "tool"]}, {"paragraph_vector": [103.363563, 54.835014], "paragraph_keywords": ["poirot", "css", "design", "syntax"]}, {"paragraph_vector": [105.792083, 53.180809], "paragraph_keywords": ["poirot", "designers", "support", "changes"]}, {"paragraph_vector": [104.015785, 57.30746], "paragraph_keywords": ["designers", "poirot", "web", "design"]}], "content": {}, "doi": "10.1145/3290605.3300517"}, {"uri": "236", "title": "Guidelines for Human-AI Interaction", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Saleema Amershi", "Dan Weld", "Mihaela Vorvoreanu", "Adam Fourney", "Besmira Nushi", "Penny Collisson", "Jina Suh", "Shamsi Iqbal", "Paul N. Bennett", "Kori Inkpen", "Jaime Teevan", "Ruth Kikin-Gil"], "summary": "Advances in artifcial intelligence (AI) frame opportunities and challenges for user interface design. Principles for humanAI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of guidelines for human-AI interaction design.", "keywords": ["based", "time", "set", "explanation", "design", "feature", "specifc", "reported", "expert", "example", "violation", "user", "interaction", "work", "product", "evaluation", "show", "participant", "use", "usability", "people", "recommendation", "list", "infused", "tested", "applied", "identify", "issue", "team", "ai", "page", "experience", "voice", "application", "variety", "understand", "proposed", "search", "phase", "study", "instance", "designer", "system", "research", "evaluator", "hci", "paper", "apply", "behavior", "guideline", "action"], "document_vector": [19.448226, -13.556523], "paragraphs": [{"paragraph_vector": [69.238906, 41.209102], "paragraph_keywords": ["ai", "systems", "recognition", "computing"]}, {"paragraph_vector": [67.03408, 41.436149], "paragraph_keywords": ["systems", "work", "user", "ai"]}, {"paragraph_vector": [70.759948, 41.966148], "paragraph_keywords": ["ai", "guidelines", "design", "systems"]}, {"paragraph_vector": [71.838691, 40.822879], "paragraph_keywords": ["design", "ai", "systems", "interaction"]}, {"paragraph_vector": [72.620635, 41.317798], "paragraph_keywords": ["systems", "work", "variety", "ai"]}, {"paragraph_vector": [84.642982, 46.336311], "paragraph_keywords": ["guidelines", "design", "ai", "phase"]}, {"paragraph_vector": [70.551628, 40.564548], "paragraph_keywords": ["guidelines", "feature", "design", "products"]}, {"paragraph_vector": [79.596961, 45.095932], "paragraph_keywords": ["guideline", "guidelines", "allow", "applications"]}, {"paragraph_vector": [80.050689, 48.451934], "paragraph_keywords": ["guidelines", "participants", "study", "user"]}, {"paragraph_vector": [77.141197, 45.331901], "paragraph_keywords": ["products", "based", "study", "selected"]}, {"paragraph_vector": [70.02256, 46.34613], "paragraph_keywords": ["participants", "product", "experience", "usability"]}, {"paragraph_vector": [116.342262, 26.317678], "paragraph_keywords": ["participants", "guideline", "metrics", "experience"]}, {"paragraph_vector": [88.435585, 53.265979], "paragraph_keywords": ["guideline", "applications", "participants", "violations"]}, {"paragraph_vector": [-108.370925, -59.319221], "paragraph_keywords": ["guidelines", "tested", "guideline", "product"]}, {"paragraph_vector": [75.796104, 40.242095], "paragraph_keywords": ["product", "violations", "guideline", "shows"]}, {"paragraph_vector": [73.649581, 35.000438], "paragraph_keywords": ["user", "products", "guideline", "explanations"]}, {"paragraph_vector": [80.666465, 8.237816], "paragraph_keywords": ["participants", "product", "voice", "reported"]}, {"paragraph_vector": [84.453964, 16.305376], "paragraph_keywords": ["guidelines", "user", "guideline", "phrased"]}, {"paragraph_vector": [94.41471, 54.582801], "paragraph_keywords": ["guideline", "guidelines", "feedback", "time"]}, {"paragraph_vector": [87.295692, 49.001331], "paragraph_keywords": ["guidelines", "experts", "participants", "distinguish"]}, {"paragraph_vector": [69.962364, 40.876647], "paragraph_keywords": ["guidelines", "systems", "ai", "design"]}, {"paragraph_vector": [69.30397, 41.039699], "paragraph_keywords": ["guidelines", "designers", "model", "ai"]}, {"paragraph_vector": [70.234176, 42.138008], "paragraph_keywords": ["ai", "guidelines", "design", "contributions"]}], "content": {}, "doi": "10.1145/3290605.3300715"}, {"uri": "237", "title": "Estimating Touch Force with Barometric Pressure Sensors", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Philip Quinn"], "summary": "Finger pressure offers a new dimension for touch interaction, where input is defined by its spatial position and orthogonal force. However, the limited availability and complexity of integrated force-sensing hardware in mobile devices is a barrier to exploring this design space. This paper presents a synthesis of two features in recent mobile devices \u2013 a barometric sensor (pressure altimeter) and ingress protection \u2013 to sense a user\u2019s touch force. When a user applies force to a device\u2019s display, it flexes inward and causes an increase in atmospheric pressure within the sealed chassis. This increase in pressure can be sensed by the device\u2019s internal barometer. However, this change is uncontrolled and requires a calibration model to map atmospheric pressure to touch force. This paper derives such a model and demonstrates its viability on four commercially-available devices (including two with dedicated force sensors). The results show this method is sensitive to forces of less than 1N, and is comparable to dedicated force sensors.", "keywords": ["\u03bb", "change", "dust", "sensing", "barometric", "location", "display", "force", "component", "sensor", "touch", "user", "gas", "contact", "tracking", "pressure", "device", "flow", "decay", "input", "barometer", "figure"], "document_vector": [59.71276, -61.973625], "paragraphs": [{"paragraph_vector": [-49.242485, 13.214979], "paragraph_keywords": ["force", "touch", "pressure", "copies"]}, {"paragraph_vector": [-53.98394, 12.206003], "paragraph_keywords": ["sensing", "force", "sensor", "forces"]}, {"paragraph_vector": [-50.952045, 14.376966], "paragraph_keywords": ["device", "sensors", "force", "pressure"]}, {"paragraph_vector": [-67.403182, -2.10456], "paragraph_keywords": ["pressure", "device", "force", "touch"]}, {"paragraph_vector": [-54.04243, 14.200276], "paragraph_keywords": ["pressure", "gas", "device", "p"]}, {"paragraph_vector": [-53.470458, 14.861869], "paragraph_keywords": ["touch", "device", "pressure", "force"]}, {"paragraph_vector": [-52.956306, 16.581275], "paragraph_keywords": ["force", "pressure", "location", "\u03bb"]}, {"paragraph_vector": [-49.92144, 14.063092], "paragraph_keywords": ["force", "input", "touch", "pressure"]}, {"paragraph_vector": [-54.295154, 13.452629], "paragraph_keywords": ["pressure", "force", "device", "devices"]}, {"paragraph_vector": [-52.86502, 14.462214], "paragraph_keywords": ["pressure", "forces", "device", "force"]}], "content": {}, "doi": "10.1145/3290605.3300461"}, {"uri": "238", "title": "Editing Spatial Layouts through Tactile Templates for People with Visual Impairments", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jingyi Li", "Son Kim", "Joshua A. Miele", "Maneesh Agrawala", "Sean Follmer"], "summary": "Spatial layout is a key component in graphic design. While people who are blind or visually impaired (BVI) can use screen readers or magnifiers to access digital content, these tools fail to fully communicate the content\u2019s graphic design information. Through semi-structured interviews and contextual inquiries, we identify the lack of this information and feedback as major challenges in understanding and editing layouts. Guided by these insights and a co-design process with a blind hobbyist web developer, we developed an interactive, multimodal authoring tool that lets blind people understand spatial relationships between elements and modify layout templates. Our tool automatically generates tactile print-outs of a web page\u2019s layout, which users overlay on top of a tablet that runs our self-voicing digital design tool. We conclude with design considerations grounded in user feedback for improving the accessibility of spatially encoded information and developing tools for BVI authors.", "keywords": ["tablet", "ben", "html", "vision", "information", "author", "design", "sheet", "figure", "user", "creating", "work", "tool", "web", "participant", "people", "container", "screen", "pixel", "reader", "menu", "template", "page", "slide", "understanding", "content", "feedback", "understand", "access", "edit", "representation", "layout", "edits", "editing", "researcher", "tactile", "element", "image", "text", "graphic", "website", "structure", "paper", "padding", "level", "bvi"], "document_vector": [-173.694137, -62.123577], "paragraphs": [{"paragraph_vector": [-138.895034, 50.945243], "paragraph_keywords": ["work", "design", "bvi", "people"]}, {"paragraph_vector": [-142.984619, 49.573589], "paragraph_keywords": ["page", "text", "bvi", "screen"]}, {"paragraph_vector": [-138.281494, 51.757328], "paragraph_keywords": ["tool", "graphics", "bvi", "people"]}, {"paragraph_vector": [-130.270187, 51.691318], "paragraph_keywords": ["design", "researchers", "layout", "sheets"]}, {"paragraph_vector": [-131.008224, 52.681262], "paragraph_keywords": ["users", "design", "tactile", "tools"]}, {"paragraph_vector": [-138.315887, 46.502063], "paragraph_keywords": ["participants", "content", "inquiries", "code"]}, {"paragraph_vector": [167.459655, 65.481086], "paragraph_keywords": ["participants", "layouts", "default", "templates"]}, {"paragraph_vector": [-165.594299, 62.862541], "paragraph_keywords": ["page", "screen", "content", "layouts"]}, {"paragraph_vector": [-158.463104, 57.733749], "paragraph_keywords": ["design", "screen", "collaborators", "participants"]}, {"paragraph_vector": [-141.324172, 49.222164], "paragraph_keywords": ["bvi", "layout", "content", "elements"]}, {"paragraph_vector": [-144.592254, 53.267047], "paragraph_keywords": ["web", "tool", "layout", "page"]}, {"paragraph_vector": [-138.799453, 52.319984], "paragraph_keywords": ["sheets", "tactile", "layout", "layouts"]}, {"paragraph_vector": [179.471405, 65.843048], "paragraph_keywords": ["layout", "ben", "information", "file"]}, {"paragraph_vector": [-145.721801, 64.670532], "paragraph_keywords": ["ben", "layout", "wants", "tactile"]}, {"paragraph_vector": [-142.249359, 56.380523], "paragraph_keywords": ["sheets", "container", "padding", "text"]}, {"paragraph_vector": [-129.89302, 56.444042], "paragraph_keywords": ["tool", "feedback", "tactile", "sheets"]}, {"paragraph_vector": [151.037628, 67.604019], "paragraph_keywords": ["participants", "elements", "layout", "editing"]}, {"paragraph_vector": [-141.142929, 49.932327], "paragraph_keywords": ["tactile", "elements", "users", "tools"]}, {"paragraph_vector": [-142.895736, 52.898517], "paragraph_keywords": ["elements", "layout", "web", "tactile"]}, {"paragraph_vector": [-142.424865, 54.242], "paragraph_keywords": ["tool", "design", "users", "level"]}, {"paragraph_vector": [-140.621841, 53.335811], "paragraph_keywords": ["insights", "accessibility", "oriented", "jennifer"]}], "content": {}, "doi": "10.1145/3290605.3300720"}, {"uri": "239", "title": "AILA: Attentive Interactive Labeling Assistant for Document Classification through Attention-based Deep Neural Networks", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Minsuk Choi", "Cheonbok Park", "Soyoung Yang", "Yonggyu Kim", "Jaegul Choo", "Sungsoo (Ray) Hong"], "summary": "Document labeling is a critical step in building various machine learning applications. However, the step can be timeconsuming and arduous, requiring a significant amount of human effort. To support an efficient document labeling environment, we present a system called Attentive Interactive Labeling Assistant (AILA). At its core, AILA uses Interactive Attention Module (IAM), a novel module that visually highlights words in a document that labelers may pay attention to when labeling a document. IAM utilizes attention-based Deep Neural Networks, which not only support a prediction of which words to highlight, but also enable labelers to indicate words that should be assigned high attention weights while labeling to improve the future quality of word prediction. We evaluated the labeling efficiency and accuracy by comparing the conditions with and without IAM in our study. The results showed that the participants\u2019 labeling efficiency increased significantly under the condition with IAM than under the condition without IAM, while the two conditions maintained roughly the same labeling accuracy.", "keywords": ["based", "vector", "time", "perceived", "labeling", "information", "embedding", "training", "improve", "design", "classification", "model", "labeler", "accuracy", "user", "labelers", "present", "ui", "result", "word", "weight", "work", "participant", "show", "learning", "iam", "score", "labeled", "fig", "module", "task", "document", "attention", "data", "study", "ml", "aila", "prediction", "system", "presented", "text", "input", "label"], "document_vector": [-99.761032, -66.29541], "paragraphs": [{"paragraph_vector": [152.469314, 62.534172], "paragraph_keywords": ["labeling", "copies", "labeled", "attention"]}, {"paragraph_vector": [152.262313, 63.043498], "paragraph_keywords": ["labeling", "documents", "model", "labelers"]}, {"paragraph_vector": [153.693481, 59.515815], "paragraph_keywords": ["iam", "labeling", "classification", "models"]}, {"paragraph_vector": [153.175567, 62.686172], "paragraph_keywords": ["labeling", "attention", "humans", "word"]}, {"paragraph_vector": [152.291885, 62.016376], "paragraph_keywords": ["attention", "words", "model", "labelers"]}, {"paragraph_vector": [156.689682, 62.941184], "paragraph_keywords": ["attention", "iam", "vector", "input"]}, {"paragraph_vector": [152.339904, 62.481224], "paragraph_keywords": ["attention", "loss", "iam", "classification"]}, {"paragraph_vector": [154.316909, 59.991878], "paragraph_keywords": ["attention", "words", "iam", "documents"]}, {"paragraph_vector": [154.681259, 62.796245], "paragraph_keywords": ["words", "document", "proportions", "shows"]}, {"paragraph_vector": [151.9635, 61.644046], "paragraph_keywords": ["aila", "accuracy", "documents", "inputs"]}, {"paragraph_vector": [149.888031, 59.861011], "paragraph_keywords": ["labeler", "document", "predicted", "labelers"]}, {"paragraph_vector": [152.789794, 61.715122], "paragraph_keywords": ["data", "attention", "word", "learning"]}, {"paragraph_vector": [152.809234, 60.103797], "paragraph_keywords": ["document", "documents", "labeling", "score"]}, {"paragraph_vector": [152.288055, 61.262348], "paragraph_keywords": ["documents", "type", "document", "score"]}, {"paragraph_vector": [157.071975, 62.612789], "paragraph_keywords": ["documents", "document", "view", "model"]}, {"paragraph_vector": [152.751174, 61.43861], "paragraph_keywords": ["model", "documents", "prediction", "document"]}, {"paragraph_vector": [153.380065, 60.732955], "paragraph_keywords": ["iam", "labeling", "study", "labelers"]}, {"paragraph_vector": [150.710891, 61.689304], "paragraph_keywords": ["participants", "aila", "documents", "effect"]}, {"paragraph_vector": [148.797256, 62.488193], "paragraph_keywords": ["participants", "aila", "labeling", "documents"]}, {"paragraph_vector": [153.215621, 61.066184], "paragraph_keywords": ["participants", "aila", "labeling", "effort"]}, {"paragraph_vector": [154.861923, 60.139411], "paragraph_keywords": ["labeling", "model", "document", "design"]}, {"paragraph_vector": [152.880401, 60.959362], "paragraph_keywords": ["ml", "attention", "labeling", "model"]}], "content": {}, "doi": "10.1145/3290605.3300238"}, {"uri": "240", "title": "Evaluating the Impact of Pseudo-Colour and Coordinate System on the Detection of Medication-induced ECG Changes", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Alaa Alahmadi", "Alan Davies", "Jennifer Royle", "Markel Vigo", "Caroline Jay"], "summary": "The electrocardiogram (ECG), a graphical representation of the heart\u2019s electrical activity, is used for detecting cardiac pathologies. Certain medications can produce a complication known as \u2018long QT syndrome\u2019, shown on the ECG as an increased gap between two parts of the waveform. Selfmonitoring for this could be lifesaving, as the syndrome can result in sudden death, but detecting it on the ECG is difficult. Here we evaluate whether using pseudo-colour to highlight wave length and changing the coordinate system can support lay people in identifying increases in the QT interval. The results show that introducing colour significantly improves accuracy, and that whilst it is easier to detect a difference without colour with Cartesian coordinates, the greatest accuracy is achieved when Polar coordinates are combined with colour. The results show that applying simple visualisation techniques has the potential to improve ECG interpretation accuracy, and support people in monitoring their own ECG.", "keywords": ["lead", "visualisation", "coordinate", "time", "condition", "change", "ecg", "interpretation", "method", "rate", "technique", "interval", "baseline", "figure", "wave", "eye", "qt", "participant", "people", "increase", "detection", "colouring", "heart", "page", "pseudo", "-", "t", "shown", "data", "lqts", "study", "system", "colour", "value", "morphology"], "document_vector": [89.527832, 50.247459], "paragraphs": [{"paragraph_vector": [-4.222304, 41.481803], "paragraph_keywords": ["ecg", "copies", "acm", "induced"]}, {"paragraph_vector": [-1.63899, 39.479], "paragraph_keywords": ["people", "ecg", "qt", "increases"]}, {"paragraph_vector": [-5.09925, 39.826736], "paragraph_keywords": ["ecg", "wave", "data", "methods"]}, {"paragraph_vector": [0.572932, 38.999027], "paragraph_keywords": ["ecg", "heart", "t", "visualisation"]}, {"paragraph_vector": [-4.453159, 39.213687], "paragraph_keywords": ["data", "properties", "ecg", "colour"]}, {"paragraph_vector": [-3.00805, 41.067539], "paragraph_keywords": ["qt", "interval", "data", "ecg"]}, {"paragraph_vector": [-1.281483, 38.72298], "paragraph_keywords": ["ecg", "r", "interval", "ecgs"]}, {"paragraph_vector": [0.401449, 37.906906], "paragraph_keywords": ["participants", "wave", "morphology", "ecg"]}, {"paragraph_vector": [-1.31159, 38.104709], "paragraph_keywords": ["qt", "ecg", "interval", "condition"]}, {"paragraph_vector": [-2.250461, 37.989238], "paragraph_keywords": ["interval", "qt", "ecg", "t"]}, {"paragraph_vector": [-0.001861, 39.380943], "paragraph_keywords": ["reaction", "jnd", "-", "time"]}, {"paragraph_vector": [0.151432, 39.250831], "paragraph_keywords": ["t", "wave", "reaction", "morphology"]}, {"paragraph_vector": [-2.910674, 38.192737], "paragraph_keywords": ["qt", "interval", "p", "stimulus"]}, {"paragraph_vector": [-0.835115, 39.197608], "paragraph_keywords": ["interval", "qt", "ecg", "people"]}, {"paragraph_vector": [-1.529494, 37.66856], "paragraph_keywords": ["data", "interval", "colour", "increased"]}, {"paragraph_vector": [-3.399805, 41.524765], "paragraph_keywords": ["techniques", "ecg", "visualisation", "monitoring"]}, {"paragraph_vector": [-179.495849, 86.336883], "paragraph_keywords": ["team", "dgitalecmt", "arabia", "college"]}], "content": {}, "doi": "10.1145/3290605.3300347"}, {"uri": "241", "title": "Swire: Sketch-based User Interface Retrieval", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Forrest Huang", "John F. Canny", "Jefrey Nichols"], "summary": "Sketches and real-world user interface examples are frequently used in multiple stages of the user interface design process. Unfortunately, fnding relevant user interface examples, especially in large-scale datasets, is a highly challenging task because user interfaces have aesthetic and functional properties that are only indirectly refected by their corresponding pixel data and meta-data. This paper introduces Swire, a sketch-based neural-network-driven technique for retrieving user interfaces. We collect the frst large-scale user interface sketch dataset from the development of Swire that researchers can use to develop new sketch-based data-driven design interfaces and applications. Swire achieves high performance for querying user interfaces: for a known validation task it retrieves the most relevant example as within the top-10 results for over 60% of queries. With this technique, \u2217Work done as an intern and student researcher at Google LLC. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proft or commercial advantage and that copies bear this notice and the full citation on the frst page. Copyrights for thirdparty components of this work must be honored. For all other uses, contact the owner/author(s). for the frst time designers can accurately retrieve relevant user interface examples with free-form sketches natural to their design workfows. We demonstrate several novel applications driven by Swire that could greatly augment the user interface design process.", "keywords": ["based", "swire", "trained", "information", "sketch", "embedding", "training", "design", "feature", "screenshot", "example", "model", "user", "interaction", "ui", "result", "use", "learning", "page", "dataset", "screenshots", "match", "query", "data", "designer", "image", "network", "paper", "interface", "edge", "retrieve", "retrieval"], "document_vector": [122.476165, -65.020011], "paragraphs": [{"paragraph_vector": [10.840259, 51.539295], "paragraph_keywords": ["examples", "design", "retrieval", "information"]}, {"paragraph_vector": [13.05814, 51.479991], "paragraph_keywords": ["ui", "sketches", "sketch", "based"]}, {"paragraph_vector": [10.487282, 51.52943], "paragraph_keywords": ["designers", "based", "rico", "ui"]}, {"paragraph_vector": [9.81285, 51.985057], "paragraph_keywords": ["image", "sketch", "images", "edge"]}, {"paragraph_vector": [11.597534, 50.848896], "paragraph_keywords": ["designers", "dataset", "sketches", "ui"]}, {"paragraph_vector": [12.10799, 50.928482], "paragraph_keywords": ["sketches", "sketch", "image", "network"]}, {"paragraph_vector": [10.268421, 52.068252], "paragraph_keywords": ["sketches", "network", "layers", "based"]}, {"paragraph_vector": [11.644811, 52.456233], "paragraph_keywords": ["network", "training", "pairs", "sketch"]}, {"paragraph_vector": [8.810186, 51.824752], "paragraph_keywords": ["sketch", "image", "screenshots", "edge"]}, {"paragraph_vector": [10.574741, 52.172069], "paragraph_keywords": ["swire", "example", "bow", "based"]}, {"paragraph_vector": [8.765892, 52.170227], "paragraph_keywords": ["results", "designers", "design", "parts"]}, {"paragraph_vector": [9.445574, 50.250164], "paragraph_keywords": ["results", "swire", "ui", "embedding"]}, {"paragraph_vector": [9.691519, 51.638671], "paragraph_keywords": ["swire", "sketches", "design", "example"]}, {"paragraph_vector": [8.409259, 51.939735], "paragraph_keywords": ["swire", "examples", "ui", "example"]}, {"paragraph_vector": [9.116909, 51.01435], "paragraph_keywords": ["ui", "information", "design", "swire"]}, {"paragraph_vector": [11.403579, 50.348899], "paragraph_keywords": ["designers", "sketches", "dataset", "swire"]}], "content": {}, "doi": "10.1145/3290605.3300855"}, {"uri": "242", "title": "empty", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": [], "summary": "This paper tracks a debate that occurred, first, within the field of Ubiquitous Computing but quickly spread to CHI and beyond, in which design scholars argued that seamlessness had long been an implicit and privileged design virtue, often at the expense of seamfulness. Seamless design emphasizes clarity, simplicity, ease of use, and consistency to facilitate technological interaction. Seamful design emphasizes configurability, user appropriation, and revelation of complexity, ambiguity or inconsistency. Here we review these literatures together and argue that, rather than rival approaches, seamful and seamless design are complements, each emphasizing different aspects of downstream user agency. Ultimately, we situate this debate within the larger, perennial discussion about the strategic revelation and concealment of human and technological operations and therein the role of design.", "keywords": ["based", "virtue", "breakdown", "time", "information", "enabling", "allow", "design", "literature", "formulation", "focus", "example", "ideal", "power", "designing", "seamfulness", "user", "uncertainty", "review", "interaction", "taken", "cast", "debate", "work", "tool", "space", "use", "weiser", "agency", "way", "world", "seamlessness", "concept", "computing", "theme", "advocate", "connectivity", "page", "working", "understanding", "found", "revelation", "appropriation", "transformation", "invisibility", "task", "attention", "data", "technology", "study", "researcher", "infrastructure", "designer", "sought", "system", "network", "research", "focused", "paper", "revealing", "seeking", "context", "seam", "making"], "document_vector": [52.04306, 17.394035], "paragraphs": [{"paragraph_vector": [93.975509, -4.930519], "paragraph_keywords": ["computing", "technology", "arrangement", "circles"]}, {"paragraph_vector": [98.361282, -7.507224], "paragraph_keywords": ["design", "seamlessness", "seamfulness", "tool"]}, {"paragraph_vector": [97.710289, -7.76936], "paragraph_keywords": ["design", "agency", "users", "concepts"]}, {"paragraph_vector": [96.096168, -9.725234], "paragraph_keywords": ["design", "seamfulness", "found", "concept"]}, {"paragraph_vector": [98.65245, -7.073725], "paragraph_keywords": ["literature", "design", "review", "agency"]}, {"paragraph_vector": [97.602432, -7.25381], "paragraph_keywords": ["design", "decisions", "seamlessness", "definitions"]}, {"paragraph_vector": [96.323417, -9.137783], "paragraph_keywords": ["attention", "technology", "computers", "design"]}, {"paragraph_vector": [97.453437, -6.519503], "paragraph_keywords": ["design", "seams", "seamlessness", "heuristics"]}, {"paragraph_vector": [96.367134, -5.74963], "paragraph_keywords": ["seamfulness", "design", "seamlessness", "error"]}, {"paragraph_vector": [98.501724, -12.742924], "paragraph_keywords": ["users", "network", "variation", "connectivity"]}, {"paragraph_vector": [97.613822, -9.219015], "paragraph_keywords": ["design", "uncertainty", "seams", "resource"]}, {"paragraph_vector": [-139.59172, -51.781654], "paragraph_keywords": ["seams", "applications", "gap", "based"]}, {"paragraph_vector": [-138.031692, -51.320549], "paragraph_keywords": ["time", "design", "data", "space"]}, {"paragraph_vector": [111.78675, -15.599127], "paragraph_keywords": ["formulations", "invisibility", "hand", "bounded"]}, {"paragraph_vector": [99.061363, -10.586126], "paragraph_keywords": ["design", "infrastructure", "bell", "world"]}, {"paragraph_vector": [86.430511, -71.815826], "paragraph_keywords": ["power", "facility", "infrastructure", "vertesi"]}, {"paragraph_vector": [91.689521, -64.901863], "paragraph_keywords": ["infrastructure", "marvin", "city", "sts"]}, {"paragraph_vector": [88.958831, -70.875358], "paragraph_keywords": ["infrastructure", "communication", "vision", "wealth"]}, {"paragraph_vector": [99.384277, -13.030529], "paragraph_keywords": ["design", "seams", "visibility", "question"]}, {"paragraph_vector": [97.636856, -8.240841], "paragraph_keywords": ["data", "design", "users", "systems"]}, {"paragraph_vector": [94.446159, -7.945463], "paragraph_keywords": ["data", "breakdown", "interoperability", "tools"]}, {"paragraph_vector": [97.794593, -9.162344], "paragraph_keywords": ["user", "seams", "understanding", "developers"]}, {"paragraph_vector": [108.741806, -13.867549], "paragraph_keywords": ["delegation", "literature", "working", "embodied"]}, {"paragraph_vector": [93.036613, -7.509963], "paragraph_keywords": ["data", "transformations", "understanding", "seeking"]}, {"paragraph_vector": [97.263061, -8.005507], "paragraph_keywords": ["design", "seamlessness", "debate", "understanding"]}, {"paragraph_vector": [100.469039, -5.887785], "paragraph_keywords": ["design", "weiser", "example", "taken"]}, {"paragraph_vector": [-158.295883, 86.619178], "paragraph_keywords": ["design", "user", "use", "seam"]}], "content": {}, "doi": "10.1145/3290605.3300645"}, {"uri": "243", "title": "Upside and Downside Risk in Online Security for Older Adults with Mild Cognitive Impairment", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Helena M. Mentis"], "summary": "Older adults are rapidly increasing their use of online services such as banking, social media, and email \u2014 services that come with subtle and serious security and privacy risks. Older adults with mild cognitive impairment (MCI) are particularly vulnerable to these risks because MCI can reduce their ability to recognize scams such as email phishing, follow recommended password guidelines, and consider the implications of sharing personal information. Older adults with MCI often cope with their impairments with the help of caregivers, including partners, children, and professional health personnel, when using and managing online services. Yet, this too carries security and privacy risks: sharing personal information with caregivers can create issues of agency, autonomy, and even risk embarrassment and information leakage; caregivers also do not always act in their charges\u2019 best interest. Through a series of interviews conducted in the US, we identify a spectrum of safeguarding strategies used and consider them through the lens of \u2018upside and downside risk\u2019 where there are tradeoffs between reduced privacy and maintaining older adults\u2019 autonomy and access to online services.", "keywords": ["caregiver", "mci", "facebook", "time", "population", "need", "person", "information", "wife", "cyber", "care", "safety", "interview", "provide", "email", "example", "user", "activity", "interaction", "taken", "shared", "risk", "decision", "engage", "work", "participant", "use", "internet", "people", "patient", "concern", "security", "step", "page", "experience", "impairment", "autonomy", "life", "password", "family", "member", "data", "technology", "approach", "instance", "dementia", "said", "support", "system", "decline", "adult", "research", "recipient", "paper", "privacy", "aging", "access", "making"], "document_vector": [-32.302947, 46.502872], "paragraphs": [{"paragraph_vector": [20.146709, -79.654602], "paragraph_keywords": ["systems", "copies", "acm", "computing"]}, {"paragraph_vector": [23.807519, -70.996337], "paragraph_keywords": ["caregivers", "dementia", "impairment", "care"]}, {"paragraph_vector": [25.024909, -72.207992], "paragraph_keywords": ["disease", "functioning", "making", "decline"]}, {"paragraph_vector": [26.383199, -71.308891], "paragraph_keywords": ["adults", "privacy", "scams", "settings"]}, {"paragraph_vector": [21.111316, -71.243293], "paragraph_keywords": ["mci", "caregivers", "information", "phishing"]}, {"paragraph_vector": [-163.397399, -86.840011], "paragraph_keywords": ["person", "mci", "technology", "provide"]}, {"paragraph_vector": [-170.925842, -33.413932], "paragraph_keywords": ["risk", "safety", "autonomy", "fall"]}, {"paragraph_vector": [26.366041, -70.193893], "paragraph_keywords": ["person", "mci", "interview", "interviews"]}, {"paragraph_vector": [125.682624, -83.72528], "paragraph_keywords": ["care", "recipient", "caregiver", "participants"]}, {"paragraph_vector": [112.022117, -42.540386], "paragraph_keywords": ["individual", "research", "consent", "participants"]}, {"paragraph_vector": [50.734081, -67.041946], "paragraph_keywords": ["video", "interviews", "participants", "security"]}, {"paragraph_vector": [51.948051, -69.09291], "paragraph_keywords": ["themes", "technology", "author", "data"]}, {"paragraph_vector": [-117.742179, -64.130432], "paragraph_keywords": ["found", "mci", "internet", "shoes"]}, {"paragraph_vector": [-141.353302, -28.263422], "paragraph_keywords": ["family", "facebook", "access", "games"]}, {"paragraph_vector": [3.717209, -70.381843], "paragraph_keywords": ["security", "scam", "credit", "internet"]}, {"paragraph_vector": [5.353894, -51.966819], "paragraph_keywords": ["time", "mci", "facebook", "likes"]}, {"paragraph_vector": [-31.589574, -81.643562], "paragraph_keywords": ["said", "incident", "staples", "event"]}, {"paragraph_vector": [22.694635, -67.241371], "paragraph_keywords": ["taken", "risk", "autonomy", "steps"]}, {"paragraph_vector": [125.972442, -85.214584], "paragraph_keywords": ["wife", "facebook", "email", "mci"]}, {"paragraph_vector": [16.354871, -80.233352], "paragraph_keywords": ["engage", "mci", "check", "work"]}, {"paragraph_vector": [-31.203535, -82.300582], "paragraph_keywords": ["mci", "person", "planning", "risk"]}, {"paragraph_vector": [24.676931, -71.143081], "paragraph_keywords": ["access", "passwords", "monitored", "regards"]}, {"paragraph_vector": [-156.93074, -84.10363], "paragraph_keywords": ["prevent", "health", "concerns", "things"]}, {"paragraph_vector": [-169.18724, -43.21104], "paragraph_keywords": ["risk", "autonomy", "taken", "action"]}, {"paragraph_vector": [49.14204, -74.549636], "paragraph_keywords": ["person", "support", "allow", "children"]}, {"paragraph_vector": [23.035249, -66.000503], "paragraph_keywords": ["caregiver", "risk", "care", "posts"]}, {"paragraph_vector": [28.048639, -62.624256], "paragraph_keywords": ["access", "systems", "service", "use"]}, {"paragraph_vector": [11.779089, -54.129802], "paragraph_keywords": ["systems", "privacy", "users", "facebook"]}], "content": {}, "doi": "10.1145/3290605.3300653"}, {"uri": "244", "title": "Effects of Locomotion and Visual Overview on Spatial Memory when Interacting with Wall Displays", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Yvonne Jansen", "Jonas Schjerlund"], "summary": "Wall displays support people in interacting with large information spaces in two ways: On the one hand, the physical space in front of such displays enables them to navigate information spaces physically. On the other hand, the visual overview of the information space on the display may promote the formation of spatial memory; from studies of Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300521 desktop computers we know this can boost performance. However, it remains unclear how the benefits of locomotion and overviews relate and whether one is more important than the other. We study this question through a wall display adaptation of the classic Data Mountain system to separate the effects of locomotion and visual overview. Our findings suggest that overview improves recall and that the combination of overview and locomotion outperforms all other combinations of factors.", "keywords": ["condition", "time", "information", "performance", "wall", "memory", "location", "display", "recall", "cursor", "experiment", "interaction", "plane", "work", "space", "movement", "participant", "use", "people", "effect", "page", "locomotion", "found", "peephole", "measure", "task", "item", "data", "phase", "study", "colleague", "mountain", "overview", "research", "difference", "view", "paper", "figure"], "document_vector": [-165.401611, -25.918342], "paragraphs": [{"paragraph_vector": [-25.043573, 37.982913], "paragraph_keywords": ["display", "menu", "displays", "wall"]}, {"paragraph_vector": [-23.01769, 37.761081], "paragraph_keywords": ["memory", "display", "wall", "displays"]}, {"paragraph_vector": [-23.594923, 37.119808], "paragraph_keywords": ["memory", "overview", "document", "study"]}, {"paragraph_vector": [-24.002872, 34.984825], "paragraph_keywords": ["environments", "display", "navigation", "locomotion"]}, {"paragraph_vector": [-23.609918, 35.282676], "paragraph_keywords": ["memory", "wall", "displays", "participants"]}, {"paragraph_vector": [-25.034971, 35.404079], "paragraph_keywords": ["overview", "wall", "effects", "display"]}, {"paragraph_vector": [-23.623733, 37.638385], "paragraph_keywords": ["information", "overview", "wall", "data"]}, {"paragraph_vector": [-25.474012, 39.03807], "paragraph_keywords": ["display", "locomotion", "view", "study"]}, {"paragraph_vector": [-22.23719, 37.068363], "paragraph_keywords": ["item", "cursor", "view", "items"]}, {"paragraph_vector": [-24.219579, 36.754268], "paragraph_keywords": ["mountain", "items", "cursor", "data"]}, {"paragraph_vector": [-20.965612, 38.577194], "paragraph_keywords": ["items", "participants", "experiment", "placing"]}, {"paragraph_vector": [-21.19996, 36.634769], "paragraph_keywords": ["participants", "data", "phase", "items"]}, {"paragraph_vector": [-21.119806, 35.951488], "paragraph_keywords": ["measures", "effect", "figure", "distance"]}, {"paragraph_vector": [-22.786376, 33.226119], "paragraph_keywords": ["effect", "items", "condition", "factor"]}, {"paragraph_vector": [-21.383714, 40.529853], "paragraph_keywords": ["time", "spent", "measures", "effect"]}, {"paragraph_vector": [-19.112434, 37.946029], "paragraph_keywords": ["participants", "conditions", "analysis", "figure"]}, {"paragraph_vector": [-23.048202, 35.634418], "paragraph_keywords": ["overview", "condition", "locomotion", "recall"]}, {"paragraph_vector": [-23.230852, 36.008453], "paragraph_keywords": ["locomotion", "overview", "conditions", "movement"]}, {"paragraph_vector": [-22.370887, 37.249515], "paragraph_keywords": ["work", "locomotion", "data", "mountain"]}, {"paragraph_vector": [-22.67387, 37.439392], "paragraph_keywords": ["overview", "locomotion", "research", "combination"]}], "content": {}, "doi": "10.1145/3290605.3300523"}, {"uri": "245", "title": "\u201cIt Broadens My Mind\u201d: Empowering People with Cognitive Disabilities through Computing Education", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Varsha Koushik", "Shaun K. Kane"], "summary": "Computer science education is widely viewed as a path to empowerment for young people, potentially leading to higher education, careers, and development of computational thinking skills. However, few resources exist for people with cognitive disabilities to learn computer science. In this paper, we document our observations of a successful program in which young adults with cognitive disabilities are trained in computing concepts. Through field observations and interviews, we identify instructional strategies used by this group, accessibility challenges encountered by this group, and how instructors and students leverage peer learning to support technical education. Our findings lead to guidelines for developing tools and curricula to support young adults with cognitive disabilities in learning computer science.", "keywords": ["population", "teach", "scratch", "information", "ability", "class", "provide", "problem", "example", "help", "accessibility", "work", "tool", "use", "helped", "people", "group", "learning", "challenge", "sally", "including", "teaching", "science", "programming", "member", "practice", "computer", "technology", "disability", "skill", "student", "monty", "support", "mark", "club", "research", "focused", "session", "tutorial", "program", "staff", "project", "code"], "document_vector": [-146.059646, 25.42284], "paragraphs": [{"paragraph_vector": [111.952392, 28.308229], "paragraph_keywords": ["computer", "science", "population", "education"]}, {"paragraph_vector": [110.5904, 30.896408], "paragraph_keywords": ["disabilities", "challenges", "group", "computer"]}, {"paragraph_vector": [107.517715, 32.733142], "paragraph_keywords": ["programming", "tools", "practices", "research"]}, {"paragraph_vector": [107.529388, 32.187873], "paragraph_keywords": ["skills", "program", "disabilities", "computer"]}, {"paragraph_vector": [108.344932, 31.638181], "paragraph_keywords": ["club", "code", "members", "research"]}, {"paragraph_vector": [113.394783, 31.101791], "paragraph_keywords": ["sessions", "class", "participants", "sally"]}, {"paragraph_vector": [110.57772, 31.876665], "paragraph_keywords": ["sally", "code", "club", "interviews"]}, {"paragraph_vector": [105.6044, 31.454816], "paragraph_keywords": ["sally", "club", "members", "code"]}, {"paragraph_vector": [106.935752, 32.792758], "paragraph_keywords": ["sally", "club", "members", "code"]}, {"paragraph_vector": [103.501846, 33.979423], "paragraph_keywords": ["sally", "scratch", "pages", "students"]}, {"paragraph_vector": [98.830917, 35.952022], "paragraph_keywords": ["code", "members", "program", "scratch"]}, {"paragraph_vector": [105.230216, 36.682445], "paragraph_keywords": ["members", "problem", "code", "sally"]}, {"paragraph_vector": [102.630142, 35.598793], "paragraph_keywords": ["members", "code", "sally", "tutorials"]}, {"paragraph_vector": [105.258834, 33.778667], "paragraph_keywords": ["mouse", "members", "code", "member"]}, {"paragraph_vector": [107.755012, 32.326938], "paragraph_keywords": ["mentors", "role", "sally", "work"]}, {"paragraph_vector": [105.151733, 32.046463], "paragraph_keywords": ["project", "members", "sally", "working"]}, {"paragraph_vector": [108.332603, 31.963092], "paragraph_keywords": ["code", "members", "club", "job"]}, {"paragraph_vector": [108.415214, 29.756311], "paragraph_keywords": ["club", "code", "peers", "program"]}, {"paragraph_vector": [107.705291, 33.244506], "paragraph_keywords": ["code", "club", "members", "skills"]}, {"paragraph_vector": [105.965324, 31.944118], "paragraph_keywords": ["code", "help", "club", "support"]}, {"paragraph_vector": [106.19577, 33.200546], "paragraph_keywords": ["members", "provide", "code", "club"]}, {"paragraph_vector": [108.030845, 32.695072], "paragraph_keywords": ["science", "computer", "individuals", "support"]}], "content": {}, "doi": "10.1145/3290605.3300544"}, {"uri": "246", "title": "Towards Understanding the Design of Positive Pre-sleep Through a Neurofeedback Artistic Experience", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Nathan Arthur Semertzidis"], "summary": "Poor sleep has been acknowledged as an increasingly prevalent global health concern, however, how to design for promoting sleep is relatively underexplored. We propose neurofeedback technology may potentially facilitate restfulness and sleep onset, and we explore this through the creation and study of \u201cInter-Dream\u201d, a novel multisensory interactive artistic experience driven by neurofeedback. Twelve participants individually rested, augmented by Inter-Dream. Results demonstrated: statistically significant decreases in pre-sleep cognitive arousal (p = .01), negative emotion (p = .008), and negative affect (p = .004). EEG readings were also indicative of restorative restfulness and cognitive stillness, while interview responses described experiences of mindfulness and playful self-exploration. Taken together, our work highlights neurofeedback as a potential pathway for future research in the promotion of sleep, while also suggesting strategies for designing towards this within the context of pre-sleep. CCS CONCEPTS \u2022 Human-centered computing \u2192 Ubiquitous and mobile computing design and evaluation methods \u2022 Human-centered computing \u2192 Interaction design", "keywords": ["expression", "vr", "time", ".", "imagery", "mind", "self", "design", "component", "focus", "power", "eeg", "bed", "exploration", "activity", "user", "thought", "designing", "sleep", "participant", "use", "agency", "onset", "demonstrated", "art", "health", "considering", "factor", "state", "experience", "emotion", "page", "finding", "control", "neurofeedback", "dream", "form", "-", "arousal", "light", "scale", "response", "driven", "data", "affect", "brain", "technology", "study", "approach", "computer", "stressor", "system", "research", "notion", "journal", "paper", "context", "pre"], "document_vector": [62.299854, -1.597015], "paragraphs": [{"paragraph_vector": [-95.626716, -36.253192], "paragraph_keywords": ["sleep", "user", "designing", "expression"]}, {"paragraph_vector": [-100.168113, -34.561557], "paragraph_keywords": ["sleep", "stressors", "affectivity", "sleepers"]}, {"paragraph_vector": [-99.62432, -34.656139], "paragraph_keywords": ["sleep", "technology", "onset", "pre"]}, {"paragraph_vector": [-97.899719, -34.548507], "paragraph_keywords": ["approach", "sleep", "topic", "emotion"]}, {"paragraph_vector": [-97.162048, -35.411716], "paragraph_keywords": ["activity", "neurofeedback", "ability", "self"]}, {"paragraph_vector": [-97.158279, -34.827388], "paragraph_keywords": ["factors", "artefact", "approach", "research"]}, {"paragraph_vector": [-95.8385, -36.374717], "paragraph_keywords": ["participant", "bed", "artists", "position"]}, {"paragraph_vector": [-96.55809, -35.887302], "paragraph_keywords": ["activity", "imagery", "time", "eeg"]}, {"paragraph_vector": [-97.686363, -35.340873], "paragraph_keywords": ["participants", "study", "participant", "states"]}, {"paragraph_vector": [-96.122833, -34.578155], "paragraph_keywords": ["participants", "eeg", "participant", "time"]}, {"paragraph_vector": [-99.613059, -38.697204], "paragraph_keywords": ["arousal", "scale", "participants", "symptom"]}, {"paragraph_vector": [-96.380668, -38.944545], "paragraph_keywords": ["scale", "data", "power", "states"]}, {"paragraph_vector": [-96.628395, -41.22171], "paragraph_keywords": ["data", "arousal", "scores", "t"]}, {"paragraph_vector": [-94.060249, -38.133422], "paragraph_keywords": ["affect", "power", "dream", "participants"]}, {"paragraph_vector": [-102.036972, -37.280002], "paragraph_keywords": ["participants", "system", "bit", "things"]}, {"paragraph_vector": [-101.733551, -34.394065], "paragraph_keywords": ["mind", "participant", "mindfulness", "experience"]}, {"paragraph_vector": [-96.670158, -37.372116], "paragraph_keywords": ["participants", "participant", "agency", "activity"]}, {"paragraph_vector": [-96.788261, -37.397041], "paragraph_keywords": ["system", "arousal", "decrease", "participants"]}, {"paragraph_vector": [-98.237258, -35.374179], "paragraph_keywords": ["sleep", "alpha", "system", "activity"]}, {"paragraph_vector": [-97.513008, -36.154392], "paragraph_keywords": ["system", "exploration", "neurofeedback", "components"]}, {"paragraph_vector": [-95.708518, -34.755992], "paragraph_keywords": ["neurofeedback", "users", "system", "expression"]}, {"paragraph_vector": [-96.795158, -34.641693], "paragraph_keywords": ["sleep", "system", "research", "neurofeedback"]}, {"paragraph_vector": [-100.112846, -33.789356], "paragraph_keywords": ["sleep", "potential", "research", "neurofeedback"]}, {"paragraph_vector": [-100.392539, -35.626644], "paragraph_keywords": ["sleep", ".", "journal", "health"]}, {"paragraph_vector": [-98.54071, -36.472404], "paragraph_keywords": ["sleep", "research", ".", "dreams"]}, {"paragraph_vector": [-99.480888, -35.873889], "paragraph_keywords": ["sleep", "eeg", "use", "therapy"]}, {"paragraph_vector": [-97.978698, -34.54293], "paragraph_keywords": ["journal", "conference", "interaction", "health"]}], "content": {}, "doi": "10.1145/3290605.3300809"}, {"uri": "247", "title": "Does It Feel Real? Using Tangibles with Different Fidelities to Build and Explore Scenes in Virtual Reality", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Thomas Muender", "Anke V. Reinschluessel", "Sean Drewes", "Dirk Wenig", "Tanja D\u00f6ring", "Rainer Malaka"], "summary": "Professionals in domains like film, theater, or architecture often rely on physical models to visualize spaces. With virtual reality (VR) new tools are available providing immersive experiences with correct perceptions of depth and scale. However, these lack the tangibility of physical models. Using tangible objects in VR can close this gap but creates the challenges of producing suitable objects and interacting with them with only the virtual objects visible. This work addresses these challenges by evaluating tangibles with three haptic fidelities: equal disc-shaped tangibles for all virtual objects, Lego-built tangibles, and 3D-printed tangibles resembling the virtual shapes. We present results from a comparative study on immersion, performance, and intuitive interaction and interviews with domain experts. The results show that 3D-printed objects perform best, but Lego offers a good trade-off between fast creation of tangibles and sufficient fidelity. The experts rate our approach as useful and would use all three versions.", "keywords": ["process", "fidelity", "planning", "vr", "time", "mentioned", "object", "ability", "scene", "design", "expert", "prop", "user", "model", "workflow", "interaction", "production", "work", "result", "participant", "use", "effect", "domain", "page", "tracking", "tangibles", "answer", "table", "study", "system", "reality", "animation", "plan", "research", "printed", "paper", "previs", "lego", "film", "figure"], "document_vector": [138.669769, -37.021499], "paragraphs": [{"paragraph_vector": [-97.082649, 23.113031], "paragraph_keywords": ["product", "planning", "copies", "work"]}, {"paragraph_vector": [-100.796066, 34.427646], "paragraph_keywords": ["vr", "object", "models", "previs"]}, {"paragraph_vector": [-99.028228, 30.450601], "paragraph_keywords": ["tangibles", "objects", "lego", "vr"]}, {"paragraph_vector": [-100.767921, 29.977201], "paragraph_keywords": ["interaction", "user", "interfaces", "world"]}, {"paragraph_vector": [-97.31034, 17.216407], "paragraph_keywords": ["objects", "props", "feedback", "found"]}, {"paragraph_vector": [-96.610511, 21.114543], "paragraph_keywords": ["vr", "objects", "shapes", "work"]}, {"paragraph_vector": [-57.17926, 29.876537], "paragraph_keywords": ["user", "tracking", "table", "headset"]}, {"paragraph_vector": [-101.833473, 34.738418], "paragraph_keywords": ["tangibles", "objects", "lego", "fidelities"]}, {"paragraph_vector": [-103.616317, 30.372859], "paragraph_keywords": ["objects", "table", "scene", "rate"]}, {"paragraph_vector": [-102.736305, 33.98632], "paragraph_keywords": ["participants", "objects", "tangibles", "conditions"]}, {"paragraph_vector": [-87.243309, 25.463371], "paragraph_keywords": ["questionnaire", "questions", "conducted", "score"]}, {"paragraph_vector": [-111.061408, 39.924423], "paragraph_keywords": ["system", "director", "results", "plan"]}, {"paragraph_vector": [-85.473945, 24.327421], "paragraph_keywords": ["objects", "accuracy", "figure", "effect"]}, {"paragraph_vector": [-111.791351, 34.995029], "paragraph_keywords": ["process", "participants", "answers", "system"]}, {"paragraph_vector": [-101.972793, 43.760902], "paragraph_keywords": ["use", "mentioned", "stage", "process"]}, {"paragraph_vector": [-106.979026, 31.157882], "paragraph_keywords": ["participants", "time", "tangibles", "planning"]}, {"paragraph_vector": [-100.421249, 34.234706], "paragraph_keywords": ["tangibles", "participants", "objects", "lego"]}, {"paragraph_vector": [-100.12107, 33.958946], "paragraph_keywords": ["fidelity", "system", "objects", "tangibles"]}, {"paragraph_vector": [-102.009452, 32.201099], "paragraph_keywords": ["tangibles", "vr", "hand", "lego"]}, {"paragraph_vector": [-100.413414, 35.79557], "paragraph_keywords": ["tangibles", "research", "process", "production"]}], "content": {}, "doi": "10.1145/3290605.3300250"}, {"uri": "248", "title": "HistoryTracker: Minimizing Human Interactions in Baseball Game Annotation", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jorge Piazentin Ono", "Arvi Gjoka", "Justin Salamon", "Carlos Dietrich", "Claudio T. Silva"], "summary": "The sport data tracking systems available today are based on specialized hardware (high-definition cameras, speed radars, RFID) to detect and track targets on the field. While effective, implementing and maintaining these systems pose a number of challenges, including high cost and need for close human monitoring. On the other hand, the sports analytics community has been exploring human computation and crowdsourcing in order to produce tracking data that is trustworthy, cheaper and more accessible. However, state-of-theart methods require a large number of users to perform the annotation, or put too much burden into a single user. We propose HistoryTracker, a methodology that facilitates the creation of tracking data for baseball games bywarm-starting the annotation process using a vast collection of historical data. We show that HistoryTracker helps users to produce tracking data in a fast and reliable way.", "keywords": ["caught", "process", "based", "position", "time", "information", "set", "baseball", "trajectory", "player", "analysis", "annotation", "annotating", "user", "play", "historytracker", "work", "video", "use", "basketball", "team", "sport", "base", "number", "tracking", "inning", "annotated", "query", "data", "game", "approach", "starting", "system", "batter", "event", "ball", "order", "paper", "question", "cluster", "action", "figure", "baseman"], "document_vector": [-5.83174, -11.551553], "paragraphs": [{"paragraph_vector": [-124.525253, -17.267368], "paragraph_keywords": ["data", "tracking", "copies", "sports"]}, {"paragraph_vector": [-142.26622, 11.309382], "paragraph_keywords": ["data", "annotation", "tracking", "systems"]}, {"paragraph_vector": [-141.245147, 10.479329], "paragraph_keywords": ["tracking", "plays", "baseball", "methodology"]}, {"paragraph_vector": [-141.2919, 9.946915], "paragraph_keywords": ["tracking", "data", "basketball", "sports"]}, {"paragraph_vector": [-142.084854, 9.139491], "paragraph_keywords": ["data", "tracking", "annotation", "game"]}, {"paragraph_vector": [-141.901702, 10.613002], "paragraph_keywords": ["sports", "system", "based", "annotation"]}, {"paragraph_vector": [-134.626892, 8.595438], "paragraph_keywords": ["bases", "ball", "pitcher", "teams"]}, {"paragraph_vector": [-144.584152, 11.597876], "paragraph_keywords": ["batter", "user", "ball", "events"]}, {"paragraph_vector": [-140.499191, 11.818894], "paragraph_keywords": ["actions", "play", "plays", "trajectory"]}, {"paragraph_vector": [-143.339981, 13.294537], "paragraph_keywords": ["plays", "play", "events", "questions"]}, {"paragraph_vector": [-143.425018, 14.928552], "paragraph_keywords": ["query", "cluster", "play", "user"]}, {"paragraph_vector": [-140.514053, 12.563071], "paragraph_keywords": ["event", "batting", "time", "signal"]}, {"paragraph_vector": [-141.281265, 11.51827], "paragraph_keywords": ["trajectory", "video", "user", "player"]}, {"paragraph_vector": [-144.173919, 12.625821], "paragraph_keywords": ["users", "plays", "annotation", "historytracker"]}, {"paragraph_vector": [-139.80484, 12.207218], "paragraph_keywords": ["ball", "baseman", "inning", "base"]}, {"paragraph_vector": [-140.65158, 11.354195], "paragraph_keywords": ["error", "play", "ball", "baseman"]}, {"paragraph_vector": [-140.376159, 13.203409], "paragraph_keywords": ["historytracker", "users", "annotations", "time"]}, {"paragraph_vector": [-140.733367, 9.531599], "paragraph_keywords": ["data", "use", "tracking", "image"]}, {"paragraph_vector": [-142.810531, 10.37857], "paragraph_keywords": ["research", "project", "nyu", "system"]}], "content": {}, "doi": "10.1145/3290605.3300830"}, {"uri": "249", "title": "i\u2019sFree: Eyes-Free Gesture Typing via a Touch-Enabled Remote Control", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Suwen Zhu", "Jingjie Zheng", "Shumin Zhai"], "summary": "Entering text without having to pay attention to the keyboard is compelling but challenging due to the lack of visual guidance. We propose i\u2019sFree to enable eyes-free gesture typing on a distant display from a touch-enabled remote control. i\u2019sFree does not display the keyboard or gesture trace but decodes gestures drawn on the remote control into text according to an invisible and shifting Qwerty layout. i\u2019sFree decodes gestures similar to a general gesture typing decoder, but learns from the instantaneous and historical input gestures to dynamically adjust the keyboard location. We designed it based on the understanding of how users perform eyes-free gesture typing. Our evaluation shows eyes-free gesture typing is feasible: reducing visual guidance on the distant display hardly affects the typing speed. Results also show that the i\u2019sFree gesture decoding algorithm is effective, enabling an input speed of 23 WPM, 46% faster than the baseline eyes-free condition built on a general gesture decoder. Finally, i\u2019sFree is easy to learn: participants reached 22 WPM in the first ten minutes, even though 40% of them were first-time gesture typing users. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300678 CCS CONCEPTS \u2022 Human-centered computing \u2192 Interaction devices; Interaction techniques.", "keywords": ["decoding", "based", "position", "condition", "finger", "location", "display", "method", "following", "speed", "component", "baseline", "tv", "experiment", "mm", "entry", "touch", "keyboard", "user", "eye", "word", "participant", "y", "control", "algorithm", "android", "score", "touchpad", "gesture", "phrase", "device", "study", "qwerty", "text", "typing", "showed", "u", "input", "figure"], "document_vector": [-46.417324, -68.637603], "paragraphs": [{"paragraph_vector": [-34.49818, -16.394586], "paragraph_keywords": ["eyes", "input", "users", "attention"]}, {"paragraph_vector": [-35.459632, -14.238033], "paragraph_keywords": ["gesture", "typing", "keyboard", "eyes"]}, {"paragraph_vector": [-32.120494, -17.054697], "paragraph_keywords": ["typing", "text", "input", "entry"]}, {"paragraph_vector": [-33.398918, -13.212965], "paragraph_keywords": ["users", "gesture", "typing", "al"]}, {"paragraph_vector": [-34.404335, -12.544418], "paragraph_keywords": ["participants", "gesture", "typing", "tv"]}, {"paragraph_vector": [-33.347816, -13.279237], "paragraph_keywords": ["u", "positions", "points", "template"]}, {"paragraph_vector": [-35.203769, -11.96547], "paragraph_keywords": ["keyboard", "positions", "variance", "y"]}, {"paragraph_vector": [-31.474412, -11.955477], "paragraph_keywords": ["keyboard", "gesture", "decoding", "yt"]}, {"paragraph_vector": [-33.866786, -16.287441], "paragraph_keywords": ["keyboard", "gesture", "location", "score"]}, {"paragraph_vector": [-30.890649, -17.190057], "paragraph_keywords": ["keyboard", "gesture", "u", "score"]}, {"paragraph_vector": [-31.785911, -15.644862], "paragraph_keywords": ["keyboard", "gesture", "row", "estimation"]}, {"paragraph_vector": [-32.909984, -14.173994], "paragraph_keywords": ["location", "keyboard", "gesture", "figure"]}, {"paragraph_vector": [-30.80199, -16.343549], "paragraph_keywords": ["keyboard", "gesture", "input", "qwerty"]}, {"paragraph_vector": [-34.031898, -15.255056], "paragraph_keywords": ["gesture", "word", "study", "input"]}, {"paragraph_vector": [-32.964275, -14.266863], "paragraph_keywords": ["gesture", "keyboard", "participants", "typing"]}, {"paragraph_vector": [-32.243068, -13.064162], "paragraph_keywords": ["participants", "t", "block", "speed"]}, {"paragraph_vector": [-31.75777, -15.5593], "paragraph_keywords": ["s", "p", "error", "word"]}, {"paragraph_vector": [-28.902296, 8.945261], "paragraph_keywords": ["keyboard", "measures", "backspace", "trial"]}, {"paragraph_vector": [-33.004936, -15.405744], "paragraph_keywords": ["baseline", "eyes", "keyboard", "gesture"]}, {"paragraph_vector": [-35.813137, -13.463591], "paragraph_keywords": ["gesture", "typing", "eyes", "text"]}], "content": {}, "doi": "10.1145/3290605.3300291"}, {"uri": "250", "title": "Investigating the Effect of Orientation and Visual Style on Touchscreen Slider Performance", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Ashley Colley", "Sven Mayer"], "summary": "Sliders are one of the most fundamental components used in touchscreen user interfaces (UIs). When entering data using a slider, errors occur due e.g. to visual perception, resulting in inputs not matching what is intended by the user. However, it is unclear if the errors occur uniformly across the full range of the slider or if there are systematic offsets. We conducted a study to assess the errors occurring when entering values with horizontal and vertical sliders as well as two common visual styles. Our results reveal significant effects of slider orientation and style on the precision of the entered values. Furthermore, we identify systematic offsets that depend on the visual style and the target value. As the errors are partially systematic, they can be compensated to improve users\u2019 precision. Our findings provide UI designers with data to optimize user experiences in the wide variety of application areas where slider based touchscreen input is used. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300419 CCS CONCEPTS \u2022Human-centered computing\u2192Human computer interaction (HCI).", "keywords": ["based", "position", "al", "set", "press", "slider", "style", "touchscreen", "bar", "error", "touch", "user", "interaction", "et", "work", "participant", "use", "effect", "screen", "range", "orientation", "trial", "application", "found", "scale", "track", "data", "study", "thumb", "target", "input", "area", "value"], "document_vector": [-24.707765, -87.528518], "paragraphs": [{"paragraph_vector": [-18.395364, 20.26301], "paragraph_keywords": ["slider", "sliders", "scale", "interface"]}, {"paragraph_vector": [-18.018342, 16.49596], "paragraph_keywords": ["slider", "users", "sliders", "thumb"]}, {"paragraph_vector": [-16.287595, 23.364349], "paragraph_keywords": ["sliders", "slider", "track", "thumb"]}, {"paragraph_vector": [-21.250864, 19.911643], "paragraph_keywords": ["sliders", "interaction", "work", "input"]}, {"paragraph_vector": [-16.971155, 24.204313], "paragraph_keywords": ["slider", "et", "track", "use"]}, {"paragraph_vector": [-17.301578, 20.115648], "paragraph_keywords": ["sliders", "slider", "interaction", "track"]}, {"paragraph_vector": [-17.103946, 18.526939], "paragraph_keywords": ["slider", "orientation", "sliders", "track"]}, {"paragraph_vector": [-21.410722, 28.294881], "paragraph_keywords": ["value", "trials", "set", "entered"]}, {"paragraph_vector": [-18.746686, 16.772077], "paragraph_keywords": ["participants", "value", "trials", "hand"]}, {"paragraph_vector": [-19.689428, 36.95079], "paragraph_keywords": ["target", "error", "effect", "direction"]}, {"paragraph_vector": [-20.078838, 20.722299], "paragraph_keywords": ["thumb", "number", "slider", "bar"]}, {"paragraph_vector": [-26.908124, 13.372504], "paragraph_keywords": ["target", "thumb", "slider", "error"]}, {"paragraph_vector": [-18.844831, 26.303401], "paragraph_keywords": ["thumb", "slider", "range", "bar"]}, {"paragraph_vector": [-19.599168, 17.87335], "paragraph_keywords": ["slider", "work", "use", "bar"]}, {"paragraph_vector": [-19.342931, 21.315414], "paragraph_keywords": ["research", "orientation", "slider", "input"]}], "content": {}, "doi": "10.1145/3290605.3300776"}, {"uri": "251", "title": "Behavioural Biometrics in VR", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Ken Pfeuffer", "Matthias J Geiger", "Sarah Prange", "Lukas Mecke", "Daniel Buschek", "Florian Alt"], "summary": "Every person is unique, with individual behavioural characteristics: how one moves, coordinates, and uses their body. In this paper we investigate body motion as behavioural biometrics for virtual reality. In particular, we look into which behaviour is suitable to identify a user. This is valuable in situations wheremultiple people use a virtual reality environment in parallel, for example in the context of authentication or to adapt the VR environment to users\u2019 preferences. We present a user study (N=22) where people perform controlled VR tasks (pointing, grabbing, walking, typing), monitoring their head, hand, and eye motion data over two sessions. These body segments can be arbitrarily combined into body relations, and we found that these movements and their combination lead to characteristic behavioural patterns. We present an extensive analysis of which motion/relation is useful to identify users in which tasks using classification methods. Our findings are beneficial for researchers and practitioners alike who aim to build novel adaptive and secure user interfaces in virtual reality.", "keywords": ["vr", "position", "based", "time", "relation", "set", "body", "behaviour", "feature", "pointing", "example", "user", "accuracy", "eye", "work", "result", "movement", "use", "identify", "authentication", "biometrics", "walking", "page", "motion", "head", "task", "hand", "distance", "data", "study", "system", "identification", "target", "figure"], "document_vector": [-11.125488, -52.772991], "paragraphs": [{"paragraph_vector": [-61.033611, 12.491381], "paragraph_keywords": ["motion", "body", "biometrics", "copies"]}, {"paragraph_vector": [-61.745838, 14.272901], "paragraph_keywords": ["body", "motion", "user", "movements"]}, {"paragraph_vector": [-60.327594, 13.997391], "paragraph_keywords": ["body", "user", "users", "motion"]}, {"paragraph_vector": [-58.908023, 12.601477], "paragraph_keywords": ["body", "motion", "features", "users"]}, {"paragraph_vector": [-59.316734, 10.566264], "paragraph_keywords": ["body", "position", "types", "motion"]}, {"paragraph_vector": [-60.593441, 12.255692], "paragraph_keywords": ["body", "hand", "example", "users"]}, {"paragraph_vector": [-59.089328, 3.54162], "paragraph_keywords": ["user", "target", "eye", "space"]}, {"paragraph_vector": [-56.399955, 10.053958], "paragraph_keywords": ["target", "vr", "user", "tasks"]}, {"paragraph_vector": [-41.297679, 12.529351], "paragraph_keywords": ["user", "typing", "users", "m"]}, {"paragraph_vector": [-35.843448, -5.297943], "paragraph_keywords": ["study", "eye", "user", "controllers"]}, {"paragraph_vector": [-25.738473, -10.357751], "paragraph_keywords": ["task", "users", "target", "relations"]}, {"paragraph_vector": [-60.180274, 4.32117], "paragraph_keywords": ["task", "motion", "device", "targets"]}, {"paragraph_vector": [-58.448669, 10.701665], "paragraph_keywords": ["feature", "target", "angle", "sets"]}, {"paragraph_vector": [-63.021247, 16.293943], "paragraph_keywords": ["users", "user", "identify", "classification"]}, {"paragraph_vector": [-56.953083, 10.346379], "paragraph_keywords": ["feature", "features", "relations", "head"]}, {"paragraph_vector": [-58.24451, 11.809421], "paragraph_keywords": ["feature", "head", "user", "set"]}, {"paragraph_vector": [-58.404788, 13.834915], "paragraph_keywords": ["body", "features", "hand", "users"]}, {"paragraph_vector": [-60.059558, 11.094511], "paragraph_keywords": ["example", "features", "user", "tasks"]}, {"paragraph_vector": [-61.468955, 12.250761], "paragraph_keywords": ["users", "features", "relations", "user"]}, {"paragraph_vector": [-60.994518, 12.873107], "paragraph_keywords": ["user", "research", "exploit", "realtime"]}], "content": {}, "doi": "10.1145/3290605.3300846"}, {"uri": "252", "title": "VizML: A Machine Learning Approach to Visualization Recommendation (Main)", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Kevin Hu", "Michiel A. Bakker", "Stephen Li", "Tim Kraska"], "summary": "Visualization recommender systems aim to lower the barrier to exploring basic visualizations by automatically generating results for analysts to search and select, rather than manually specify. Here, we demonstrate a novel machine learningbased approach to visualization recommendation that learns visualization design choices from a large corpus of datasets and associated visualizations. First, we identify fve key design choices made by analysts while creating visualizations, such as selecting a visualization type and choosing to encode a column along the Xor Y-axis. We train models to predict these design choices using one million dataset-visualization pairs collected from a popular online visualization platform. Neural networks predict these design choices with high accuracy compared to baseline models. We report and interpret feature importances from one of these baseline models. To Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proft or commercial advantage and that copies bear this notice and the full citation on the frst page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specifc permission and/or a fee. Request permissions from permissions@acm.org. evaluate the generalizability and uncertainty of our approach, we benchmark with a crowdsourced test set, and show that the performance of our model is comparable to human performance when predicting consensus visualization type, and exceeds that of other visualization recommender systems.", "keywords": ["based", "recommender", "trained", "set", "performance", "class", "feature", "design", "model", "type", "datasets", "user", "accuracy", "result", "vizml", "train", "use", "recommendation", "learning", "y", "visualization", "number", "dataset", "c", "property", "test", "deepeye", "task", "data", "system", "choice", "mark", "machine", "rule", "paper", "consensus", "corpus", "column", "value", "level"], "document_vector": [-146.446166, -13.406443], "paragraphs": [{"paragraph_vector": [-33.68077, 88.617538], "paragraph_keywords": ["visualization", "data", "visualizations", "generate"]}, {"paragraph_vector": [-55.522914, 78.430999], "paragraph_keywords": ["models", "visualization", "choices", "design"]}, {"paragraph_vector": [-47.586132, 77.127388], "paragraph_keywords": ["position", "data", "visualization", "color"]}, {"paragraph_vector": [-53.133991, 77.854202], "paragraph_keywords": ["design", "choices", "visualization", "visualizations"]}, {"paragraph_vector": [-65.641151, 78.372848], "paragraph_keywords": ["systems", "data", "visualization", "rules"]}, {"paragraph_vector": [-56.243366, 78.151306], "paragraph_keywords": ["visualizations", "datasets", "model", "vizml"]}, {"paragraph_vector": [-58.875434, 79.496582], "paragraph_keywords": ["features", "column", "visualization", "systems"]}, {"paragraph_vector": [-51.226268, 77.678466], "paragraph_keywords": ["column", "features", "columns", "number"]}, {"paragraph_vector": [-46.670269, 76.997291], "paragraph_keywords": ["visualization", "use", "removed", "values"]}, {"paragraph_vector": [-56.98587, 74.406898], "paragraph_keywords": ["class", "column", "type", "types"]}, {"paragraph_vector": [54.996761, 76.406135], "paragraph_keywords": ["sets", "model", "rate", "test"]}, {"paragraph_vector": [-31.124448, 88.653976], "paragraph_keywords": ["feature", "column", "number", "based"]}, {"paragraph_vector": [-55.339099, 79.241516], "paragraph_keywords": ["column", "type", "properties", "importance"]}, {"paragraph_vector": [-33.906639, 79.690246], "paragraph_keywords": ["based", "features", "systems", "design"]}, {"paragraph_vector": [17.120834, 67.659439], "paragraph_keywords": ["score", "choice", "visualization", "c"]}, {"paragraph_vector": [-7.020708, 79.939712], "paragraph_keywords": ["deepeye", "based", "predictors", "data"]}, {"paragraph_vector": [-52.134502, 75.797836], "paragraph_keywords": ["cars", "scores", "class", "consensus"]}, {"paragraph_vector": [-54.996044, 77.546684], "paragraph_keywords": ["design", "recommenders", "vizml", "error"]}, {"paragraph_vector": [-42.881023, 77.935089], "paragraph_keywords": ["visualization", "data", "tasks", "based"]}, {"paragraph_vector": [-71.930549, 85.029678], "paragraph_keywords": ["visualization", "models", "learning", "benchmark"]}], "content": {}, "doi": "10.1145/3290605.3300529"}, {"uri": "253", "title": "Vistribute: Distributing Interactive Visualizations in Dynamic Multi-Device Setups", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Tom Horak", "Andreas Mathisen", "Clemens N. Klokmose"], "summary": "WepresentVistribute, a framework for the automatic distribution of visualizations and UI components across multiple heterogeneous devices. Our framework consists of three parts: (i) a design space considering properties and relationships of interactive visualizations, devices, and user preferences in multi-display environments; (ii) specific heuristics incorporating these dimensions for guiding the distribution for a given interface and device ensemble; and (iii) a web-based implementation instantiating these heuristics to automatically generate a distribution as well as providing interaction mechanisms for user-defined adaptations. In contrast to existing UI distribution systems, we are able to infer all required information by analyzing the visualizations and devices without Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland, UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300846 relying on additional input provided by users or programmers. In a qualitative study, we let experts create their own distributions and rate both other manual distributions and our automatic ones. We found that all distributions provided comparable quality, hence validating our framework.", "keywords": ["based", "point", "time", "al", "change", "information", "heuristic", "distribution", "allow", "display", "design", "component", "analysis", "provide", "example", "relationship", "user", "aspect", "type", "surface", "interaction", "et", "implementation", "space", "participant", "distributed", "screen", "size", "connectivity", "visualization", "page", "existing", "vistribute", "setup", "property", "similarity", "layout", "device", "task", "data", "instance", "framework", "system", "research", "view", "paper", "interface", "input", "preference", "considered"], "document_vector": [-156.38031, -11.092298], "paragraphs": [{"paragraph_vector": [-14.958411, 61.982852], "paragraph_keywords": ["devices", "tumor", "device", "tablet"]}, {"paragraph_vector": [-16.038316, 63.134258], "paragraph_keywords": ["visualization", "distribution", "framework", "heuristics"]}, {"paragraph_vector": [-19.228734, 62.263927], "paragraph_keywords": ["interaction", "device", "display", "data"]}, {"paragraph_vector": [-19.483051, 55.078155], "paragraph_keywords": ["interface", "devices", "frameworks", "challenges"]}, {"paragraph_vector": [-14.679959, 64.366302], "paragraph_keywords": ["distribution", "interface", "framework", "et"]}, {"paragraph_vector": [-21.37224, 66.608741], "paragraph_keywords": ["properties", "relationships", "data", "visualizations"]}, {"paragraph_vector": [-24.337202, 64.043479], "paragraph_keywords": ["views", "data", "properties", "view"]}, {"paragraph_vector": [-22.925485, 66.2117], "paragraph_keywords": ["data", "views", "similarity", "connectivity"]}, {"paragraph_vector": [-20.683311, 62.081207], "paragraph_keywords": ["preferences", "device", "user", "visualization"]}, {"paragraph_vector": [-12.362835, 60.407238], "paragraph_keywords": ["device", "devices", "display", "dimensions"]}, {"paragraph_vector": [-19.64113, 63.874176], "paragraph_keywords": ["views", "heuristics", "similarity", "distribution"]}, {"paragraph_vector": [-24.303445, 65.529335], "paragraph_keywords": ["view", "similarity", "input", "data"]}, {"paragraph_vector": [-20.288412, 63.095298], "paragraph_keywords": ["space", "data", "view", "points"]}, {"paragraph_vector": [-18.821369, 62.523586], "paragraph_keywords": ["device", "user", "distribution", "views"]}, {"paragraph_vector": [-20.94094, 63.304931], "paragraph_keywords": ["data", "properties", "visualization", "distribution"]}, {"paragraph_vector": [-19.681383, 62.657623], "paragraph_keywords": ["data", "device", "properties", "resolution"]}, {"paragraph_vector": [-21.747274, 60.719978], "paragraph_keywords": ["views", "surface", "view", "space"]}, {"paragraph_vector": [-19.814125, 64.520683], "paragraph_keywords": ["views", "surfaces", "user", "distribution"]}, {"paragraph_vector": [-18.257305, 59.844181], "paragraph_keywords": ["distribution", "views", "crime", "bc"]}, {"paragraph_vector": [-20.039573, 63.147319], "paragraph_keywords": ["participants", "distributions", "views", "figure"]}, {"paragraph_vector": [-21.682472, 63.734634], "paragraph_keywords": ["participants", "views", "distributions", "observed"]}, {"paragraph_vector": [-20.033737, 61.866809], "paragraph_keywords": ["device", "distribution", "provide", "research"]}, {"paragraph_vector": [-16.728771, 64.107482], "paragraph_keywords": ["distribution", "heuristics", "algorithm", "layouts"]}, {"paragraph_vector": [-17.480997, 63.559181], "paragraph_keywords": ["visualization", "views", "distribution", "set"]}, {"paragraph_vector": [-22.098974, 74.360694], "paragraph_keywords": ["layouts", "findings", "da", "feedback"]}], "content": {}, "doi": "10.1145/3290605.3300327"}, {"uri": "254", "title": "SottoVoce: An Ultrasound Imaging-Based Silent Speech Interaction Using Deep Neural Networks", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Naoki Kimura"], "summary": "The availability of digital devices operated by voice is expanding rapidly. However, the applications of voice interfaces are still restricted. For example, speaking in public places becomes an annoyance to the surrounding people, and secret information should not be uttered. Environmental noise may reduce the accuracy of speech recognition. To address these limitations, a system to detect a user\u2019s unvoiced utterance is proposed. From internal information observed by an ultrasonic imaging sensor attached to the underside of the jaw, our proposed system recognizes the utterance contents without the user\u2019s uttering voice. Our proposed deep neural network model is used to obtain acoustic features from a sequence of ultrasound images. We confirmed that audio signals generated by our system can control the existing smart speakers. We also observed that a user can adjust their oral movement to learn and improve the accuracy of their voice recognition. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300376 CCS CONCEPTS \u2022Computingmethodologies\u2192Neural networks; \u2022Humancentered computing \u2192 Interface design prototyping; Mobile devices; Sound-based input / output; \u2022 Social and professional topics\u2192 People with disabilities;", "keywords": ["sequence", "based", "vector", "time", "speech", "information", "cavity", "training", "user", "command", "interaction", "ultrasound", "video", "movement", "tongue", "voice", "ai", "sound", "recognition", "scale", "device", "computer", "image", "system", "network", "research", "input", "alexa", "imaging", "figure"], "document_vector": [-73.858604, -46.053192], "paragraphs": [{"paragraph_vector": [-45.234119, -30.613658], "paragraph_keywords": ["speech", "interaction", "systems", "interface"]}, {"paragraph_vector": [-45.82442, -28.672838], "paragraph_keywords": ["user", "imaging", "camera", "gesture"]}, {"paragraph_vector": [-43.720409, -31.811819], "paragraph_keywords": ["networks", "speech", "imaging", "voice"]}, {"paragraph_vector": [-43.82085, -32.141845], "paragraph_keywords": ["speech", "ultrasound", "applications", "example"]}, {"paragraph_vector": [-45.386394, -30.053035], "paragraph_keywords": ["interaction", "speech", "tongue", "recognition"]}, {"paragraph_vector": [-42.748126, -30.52106], "paragraph_keywords": ["system", "voice", "speech", "user"]}, {"paragraph_vector": [-42.289943, -29.962707], "paragraph_keywords": ["images", "sound", "vectors", "delay"]}, {"paragraph_vector": [-42.450855, -29.444486], "paragraph_keywords": ["network", "sequence", "size", "vectors"]}, {"paragraph_vector": [-42.642826, -31.862319], "paragraph_keywords": ["network", "input", "speech", "speaker"]}, {"paragraph_vector": [-41.198825, -31.75144], "paragraph_keywords": ["network", "networks", "training", "scale"]}, {"paragraph_vector": [-41.073223, -28.923015], "paragraph_keywords": ["commands", "network", "speech", "recognition"]}, {"paragraph_vector": [-44.213733, -28.717746], "paragraph_keywords": ["voice", "sound", "level", "generated"]}, {"paragraph_vector": [-42.802848, -28.753536], "paragraph_keywords": ["voice", "ai", "learn", "research"]}, {"paragraph_vector": [-43.67337, -29.830316], "paragraph_keywords": ["voice", "networks", "user", "loop"]}], "content": {}, "doi": "10.1145/3290605.3300910"}, {"uri": "255", "title": "ALAP: Accessible LaTeX Based Mathematical Document Authoring and Presentation", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Ahtsham Manzoor", "Safa Arooj", "Shaban Zulfiqar", "Asim Karim"], "summary": "Assistive technologies such as screen readers and text editors have been used in past to improve the accessibility and authoring of scientific and mathematical documents. However, most screens readers fail to narrate complex mathematical notations and expressions as they skip symbols and necessary information required for the accurate narration of mathematical content. This study aims at evaluating a new Accessible LaTeX Based Mathematical Document Authoring and Presentation (ALAP) tool, which assist people with visual impairments in reading and writing mathematical documents. ALAP includes features like, assistive debugging, Math Mode for reading and writing mathematical notations, and automatic generation of an accessible PDF document. These features aim to improve the LaTeX debugging experience and make it simple for blind users to author mathematical content by narrating it in natural language through the use of integrated text to speech (TTS) engine. We evaluated ALAP by conducting a study with 18 visually impaired LaTeX users. The results showed that users preferred ALAP over another comparable LaTeX based authoring tool and were relatively more comfortable in completing the tasks while using ALAP. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05...$15.00 https://doi.org/10.1145/3290605.3300734", "keywords": ["process", "based", "time", "speech", "narration", "feature", "source", "error", "nvda", "debugging", "user", "accessibility", "result", "work", "tool", "participant", "latex", "use", "line", "screen", "equation", "reader", "page", "output", "existing", "pdf", "content", "task", "document", "narrating", "editing", "texlipse", "system", "jaw", "support", "math", "text", "mode", "editor", "alap", "tt", "code"], "document_vector": [-166.612228, -61.054302], "paragraphs": [{"paragraph_vector": [-153.162628, 53.362026], "paragraph_keywords": ["latex", "tools", "support", "editing"]}, {"paragraph_vector": [-155.785232, 54.922645], "paragraph_keywords": ["latex", "following", "speech", "based"]}, {"paragraph_vector": [-151.973815, 53.741825], "paragraph_keywords": ["tool", "users", "support", "work"]}, {"paragraph_vector": [-157.290771, 61.160045], "paragraph_keywords": ["user", "latex", "editing", "document"]}, {"paragraph_vector": [-153.32138, 55.77135], "paragraph_keywords": ["latex", "error", "debugging", "line"]}, {"paragraph_vector": [-163.569259, 65.24681], "paragraph_keywords": ["line", "errors", "narrating", "jaws"]}, {"paragraph_vector": [-158.453704, 60.472724], "paragraph_keywords": ["tts", "latex", "system", "documents"]}, {"paragraph_vector": [-170.428237, 66.297149], "paragraph_keywords": ["errors", "error", "verbosity", "build"]}, {"paragraph_vector": [-152.292266, 57.415679], "paragraph_keywords": ["pdf", "output", "tts", "keys"]}, {"paragraph_vector": [-169.461624, 66.10437], "paragraph_keywords": ["expression", "rule", "numerator", "end"]}, {"paragraph_vector": [-156.503433, 61.098205], "paragraph_keywords": ["latex", "participants", "screen", "pdf"]}, {"paragraph_vector": [102.766792, 45.775455], "paragraph_keywords": ["participants", "alap", "experiment", "day"]}, {"paragraph_vector": [-164.871643, 64.127426], "paragraph_keywords": ["alap", "task", "tasks", "pdf"]}, {"paragraph_vector": [177.71553, 71.803337], "paragraph_keywords": ["task", "user", "time", "participants"]}, {"paragraph_vector": [-170.837356, 67.525352], "paragraph_keywords": ["alap", "participants", "time", "texlipse"]}, {"paragraph_vector": [-171.857299, 65.40303], "paragraph_keywords": ["participants", "alap", "task", "errors"]}, {"paragraph_vector": [-171.976776, 66.234802], "paragraph_keywords": ["errors", "participants", "alap", "err"]}, {"paragraph_vector": [-168.220352, 64.656654], "paragraph_keywords": ["alap", "texlipse", "participants", "pdf"]}, {"paragraph_vector": [-166.724365, 63.799465], "paragraph_keywords": ["participants", "system", "debugging", "alap"]}, {"paragraph_vector": [-162.414916, 63.875488], "paragraph_keywords": ["system", "participants", "error", "help"]}, {"paragraph_vector": [-160.136016, 59.365318], "paragraph_keywords": ["users", "latex", "editor", "speech"]}, {"paragraph_vector": [-151.519714, 55.165824], "paragraph_keywords": ["system", "latex", "results", "users"]}, {"paragraph_vector": [-152.079345, 54.3544], "paragraph_keywords": ["alap", "based", "authoring", "documents"]}], "content": {}, "doi": "10.1145/3290605.3300778"}, {"uri": "256", "title": "Practitioners Teaching Data Science in Industry and Academia: Expectations, Workflows, and Challenges", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Sean Kross", "Philip J. Guo"], "summary": "Data science has been growing in prominence across both academia and industry, but there is still little formal consensus about how to teach it. Many people who currently teach data science are practitioners such as computational researchers in academia or data scientists in industry. To understand how these practitioner-instructors pass their knowledge onto novices and how that contrasts with teachingmore traditional forms of programming, we interviewed 20 data scientists who teach in settings ranging from small-group workshops to large online courses. We found that: 1) they must empathize with a diverse array of student backgrounds and expectations, 2) they teach technical workflows that integrate authentic practices surrounding code, data, and communication, 3) they face challenges involving authenticity versus abstraction in software setup, finding and curating pedagogically-relevant datasets, and acclimating students to live with uncertainty in data analysis. These findings can point the way toward better tools for data science education and help bring data literacy to more people around the world.", "keywords": ["library", "based", "mentioned", "teach", "need", "time", "scratch", "class", "design", "analysis", "environment", "industry", "example", "user", "workflow", "datasets", "learn", "workshop", "work", "tool", "language", "participant", "use", "web", "people", "statistic", "learning", "challenge", "computing", "finding", "page", "dataset", "practitioner", "teaching", "write", "science", "programming", "computer", "data", "want", "study", "researcher", "scientist", "setting", "student", "skill", "system", "research", "course", "instructor", "end", "r", "coding", "software", "background", "taught", "community", "code"], "document_vector": [-145.296875, 22.559896], "paragraphs": [{"paragraph_vector": [114.293136, 20.862092], "paragraph_keywords": ["data", "science", "copies", "code"]}, {"paragraph_vector": [110.636436, 26.023706], "paragraph_keywords": ["science", "end", "data", "programming"]}, {"paragraph_vector": [108.085578, 29.104274], "paragraph_keywords": ["data", "science", "programming", "end"]}, {"paragraph_vector": [106.663604, 32.851932], "paragraph_keywords": ["data", "science", "taught", "software"]}, {"paragraph_vector": [107.676612, 28.594249], "paragraph_keywords": ["data", "science", "teach", "schools"]}, {"paragraph_vector": [109.608612, 27.424209], "paragraph_keywords": ["programming", "data", "studied", "scratch"]}, {"paragraph_vector": [114.177795, 17.297161], "paragraph_keywords": ["teach", "participants", "person", "scientists"]}, {"paragraph_vector": [104.584991, 24.857654], "paragraph_keywords": ["data", "teach", "science", "instructors"]}, {"paragraph_vector": [108.430198, 24.453115], "paragraph_keywords": ["data", "science", "source", "student"]}, {"paragraph_vector": [108.880119, 28.013301], "paragraph_keywords": ["backgrounds", "students", "courses", "teaches"]}, {"paragraph_vector": [105.23941, 28.323268], "paragraph_keywords": ["data", "students", "learn", "programming"]}, {"paragraph_vector": [102.050186, 30.195615], "paragraph_keywords": ["students", "data", "tools", "tool"]}, {"paragraph_vector": [97.402374, 30.838706], "paragraph_keywords": ["data", "libraries", "frame", "r"]}, {"paragraph_vector": [99.474464, 30.689167], "paragraph_keywords": ["data", "communication", "files", "science"]}, {"paragraph_vector": [105.414024, 32.374874], "paragraph_keywords": ["students", "data", "science", "programming"]}, {"paragraph_vector": [102.52182, 24.665153], "paragraph_keywords": ["data", "students", "materials", "science"]}, {"paragraph_vector": [108.644149, 26.07052], "paragraph_keywords": ["instructors", "students", "data", "practice"]}, {"paragraph_vector": [105.142204, 26.349943], "paragraph_keywords": ["students", "computers", "environment", "setup"]}, {"paragraph_vector": [106.380416, 26.415431], "paragraph_keywords": ["students", "computing", "web", "environment"]}, {"paragraph_vector": [106.143005, 26.525014], "paragraph_keywords": ["data", "students", "teaching", "applications"]}, {"paragraph_vector": [106.034767, 25.435571], "paragraph_keywords": ["data", "students", "repositories", "datasets"]}, {"paragraph_vector": [104.583869, 23.677253], "paragraph_keywords": ["data", "students", "teach", "dataset"]}, {"paragraph_vector": [114.157104, 15.982841], "paragraph_keywords": ["data", "instructors", "courses", "date"]}, {"paragraph_vector": [100.985, 31.0323], "paragraph_keywords": ["data", "tools", "science", "statistics"]}, {"paragraph_vector": [102.649879, 26.932559], "paragraph_keywords": ["data", "datasets", "language", "science"]}, {"paragraph_vector": [59.463603, 67.251052], "paragraph_keywords": ["data", "dataset", "search", "system"]}, {"paragraph_vector": [67.518043, 67.843078], "paragraph_keywords": ["data", "dataset", "students", "style"]}, {"paragraph_vector": [113.752662, 19.691356], "paragraph_keywords": ["programming", "design", "data", "science"]}], "content": {}, "doi": "10.1145/3290605.3300741"}, {"uri": "257", "title": "Beyond Tutoring: Opportunities for Intergenerational Mentorship at a Community Level", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Ye Yuan", "Svetlana Yarosh"], "summary": "Community intergenerational mentorship offers an opportunity to address older adults\u2019 social isolation while providing valuable one-on-one or small group learning experiences for elementary school students. Current organizations that support this kind of engagement focus on in-person visits that place the burden of logistics and transportation on the older adult. However, as older adults become less independent while aging, coming to schools in person becomes more challenging. We present a qualitative analysis of current intergenerational mentorship practices to understand opportunities for technology to expand access to this experience. We highlight elements critical for building successful mentorship: the importance of relationship building between older adults and children during mentoring activities, the skills mentors acquired to carry out mentoring activities, and support needed from teachers and schools. We contribute a rich description of current intergenerational mentorship practices and provide insights for opportunities for novel HCI technologies in this context.", "keywords": ["reading", "based", "mentoring", "child", "time", "connection", "mentor", "class", "interview", "opportunity", "book", "relationship", "help", "example", "mentorship", "activity", "school", "story", "communication", "work", "read", "working", "page", "experience", "teacher", "provided", "volunteer", "volunteering", "family", "technology", "student", "support", "system", "math", "adult", "session", "program", "paper", "question", "context", "community"], "document_vector": [-177.508834, 46.972694], "paragraphs": [{"paragraph_vector": [145.699508, -2.801254], "paragraph_keywords": ["programs", "program", "mentoring", "copies"]}, {"paragraph_vector": [145.647186, -6.274217], "paragraph_keywords": ["adults", "mentorship", "paper", "systems"]}, {"paragraph_vector": [143.394653, -43.017951], "paragraph_keywords": ["adults", "technologies", "community", "connectedness"]}, {"paragraph_vector": [144.89685, -21.503599], "paragraph_keywords": ["children", "family", "members", "support"]}, {"paragraph_vector": [146.215835, -6.018986], "paragraph_keywords": ["mentors", "robots", "mentoring", "technologies"]}, {"paragraph_vector": [144.835876, -5.015849], "paragraph_keywords": ["volunteers", "students", "schools", "school"]}, {"paragraph_vector": [143.086547, -5.755497], "paragraph_keywords": ["volunteers", "observation", "teacher", "participants"]}, {"paragraph_vector": [142.612762, -10.601657], "paragraph_keywords": ["codes", "volunteering", "mentoring", "interview"]}, {"paragraph_vector": [145.359039, -3.843876], "paragraph_keywords": ["students", "story", "book", "volunteers"]}, {"paragraph_vector": [147.335281, 1.873577], "paragraph_keywords": ["students", "volunteers", "strategies", "working"]}, {"paragraph_vector": [143.997665, -3.963439], "paragraph_keywords": ["students", "volunteers", "read", "progress"]}, {"paragraph_vector": [146.716491, -6.579171], "paragraph_keywords": ["students", "volunteers", "mentoring", "reading"]}, {"paragraph_vector": [-163.134674, -11.75859], "paragraph_keywords": ["students", "volunteers", "volunteer", "group"]}, {"paragraph_vector": [147.110031, -4.3898], "paragraph_keywords": ["volunteers", "mentoring", "said", "skills"]}, {"paragraph_vector": [144.666488, -4.794517], "paragraph_keywords": ["mentoring", "volunteers", "program", "mentors"]}, {"paragraph_vector": [146.373046, -1.512519], "paragraph_keywords": ["students", "volunteers", "teachers", "mentoring"]}, {"paragraph_vector": [145.929138, -2.237087], "paragraph_keywords": ["students", "volunteers", "teachers", "mentoring"]}, {"paragraph_vector": [145.908416, -2.652547], "paragraph_keywords": ["volunteers", "time", "needs", "class"]}, {"paragraph_vector": [143.758605, -4.113184], "paragraph_keywords": ["mentoring", "students", "programs", "program"]}, {"paragraph_vector": [147.505737, -6.514838], "paragraph_keywords": ["mentoring", "volunteers", "activity", "students"]}, {"paragraph_vector": [145.714218, -4.271549], "paragraph_keywords": ["mentoring", "volunteers", "students", "connections"]}, {"paragraph_vector": [171.014373, -0.703462], "paragraph_keywords": ["mentoring", "teachers", "facilitating", "communication"]}, {"paragraph_vector": [145.540283, -5.975935], "paragraph_keywords": ["mentoring", "programs", "support", "community"]}, {"paragraph_vector": [-113.377754, -79.89138], "paragraph_keywords": ["support", "schools", "work", "like"]}], "content": {}, "doi": "10.1145/3290605.3300358"}, {"uri": "258", "title": "Techies Against Facebook: Understanding Negative Sentiment Toward Facebook via User Generated Content", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Abu Saleh Md Noman", "Sanchari Das", "Sameer Patil"], "summary": "Researchers have recognized the need to pay attention to negative aspects and non-use of social media services to uncover usage barriers and surface shortcomings of these systems. We contribute to these eforts by analyzing comments on posts related to Facebook on two blogs with a technically savvy readership: Slashdot and Schneier on Security. Our analysis indicates that technically savvy individuals exhibit notably large negative sentiment toward Facebook with nearly 45% of the 3,000 reader comments we coded expressing such views. Qualitative coding revealed Privacy and Security, User Experience, and Personal Disposition as key factors underlying the negative views. Our fndings suggest that negative sentiment is an explicit higher level factor driving non-use practices. Further, we confrm several non-use practices reported in the literature and identify additional aspects connected to recent technological and societal developments. Our results demonstrate that analysis of user generated content can be useful for surfacing usage practices on a large scale.", "keywords": ["facebook", "population", "mentioned", "expressed", "time", "information", "generated", "source", "reported", "slashdot", "specifc", "provide", "help", "medium", "user", "aspect", "news", "sample", "associated", "work", "impact", "use", "non", "people", "insight", "post", "issue", "concern", "service", "sentiment", "given", "theme", "related", "security", "factor", "experience", "page", "number", "content", "found", "-", "comment", "coder", "family", "practice", "data", "advertising", "technology", "study", "commenters", "research", "view", "term", "platform", "coding", "schneier", "individual", "account", "paper", "site", "privacy", "fndings", "pertaining"], "document_vector": [-43.958099, 41.746677], "paragraphs": [{"paragraph_vector": [106.376434, -62.654895], "paragraph_keywords": ["computing", "copies", "use", "acm"]}, {"paragraph_vector": [9.324841, -51.132701], "paragraph_keywords": ["media", "views", "services", "facebook"]}, {"paragraph_vector": [15.248752, -48.051609], "paragraph_keywords": ["security", "facebook", "posts", "research"]}, {"paragraph_vector": [8.84534, -52.051074], "paragraph_keywords": ["use", "user", "-", "sentiment"]}, {"paragraph_vector": [88.376663, -41.257183], "paragraph_keywords": ["use", "-", "researchers", "studies"]}, {"paragraph_vector": [-1.96822, -52.284027], "paragraph_keywords": ["facebook", "specifc", "use", "non"]}, {"paragraph_vector": [10.059252, -51.942813], "paragraph_keywords": ["facebook", "use", "privacy", "benefts"]}, {"paragraph_vector": [12.161763, -47.616214], "paragraph_keywords": ["facebook", "user", "comments", "contribute"]}, {"paragraph_vector": [18.483381, -48.017879], "paragraph_keywords": ["slashdot", "comments", "security", "facebook"]}, {"paragraph_vector": [14.574829, -46.82315], "paragraph_keywords": ["posts", "slashdot", "content", "comments"]}, {"paragraph_vector": [12.717317, -47.291587], "paragraph_keywords": ["comments", "slashdot", "coding", "agreement"]}, {"paragraph_vector": [7.569421, -46.523479], "paragraph_keywords": ["coders", "facebook", "sentiment", "coding"]}, {"paragraph_vector": [7.907984, -47.928272], "paragraph_keywords": ["security", "facebook", "privacy", "coding"]}, {"paragraph_vector": [10.923545, -49.954925], "paragraph_keywords": ["facebook", "privacy", "account", "use"]}, {"paragraph_vector": [9.443546, -50.469165], "paragraph_keywords": ["facebook", "user", "people", "experience"]}, {"paragraph_vector": [6.067816, -50.976959], "paragraph_keywords": ["facebook", "users", "people", "designed"]}, {"paragraph_vector": [7.454169, -48.818248], "paragraph_keywords": ["facebook", "people", "issues", "advertising"]}, {"paragraph_vector": [0.893312, -50.350444], "paragraph_keywords": ["facebook", "media", "family", "people"]}, {"paragraph_vector": [5.439437, -50.222209], "paragraph_keywords": ["facebook", "people", "media", "options"]}, {"paragraph_vector": [6.51898, -51.404788], "paragraph_keywords": ["facebook", "content", "observed", "talk"]}, {"paragraph_vector": [18.980627, -53.274993], "paragraph_keywords": ["facebook", "data", "commenters", "content"]}, {"paragraph_vector": [9.531307, -51.185783], "paragraph_keywords": ["facebook", "accounts", "people", "content"]}, {"paragraph_vector": [-1.439376, -55.44297], "paragraph_keywords": ["facebook", "use", "employers", "years"]}, {"paragraph_vector": [6.546878, -50.150947], "paragraph_keywords": ["facebook", "privacy", "sample", "user"]}, {"paragraph_vector": [8.425905, -51.007125], "paragraph_keywords": ["use", "user", "reported", "-"]}, {"paragraph_vector": [-6.017517, -52.053272], "paragraph_keywords": ["use", "facebook", "privacy", "factors"]}, {"paragraph_vector": [8.635375, -48.495361], "paragraph_keywords": ["sentiment", "use", "fndings", "-"]}, {"paragraph_vector": [8.756126, -48.752685], "paragraph_keywords": ["use", "facebook", "data", "comments"]}, {"paragraph_vector": [10.535069, -44.860176], "paragraph_keywords": ["comments", "sites", "facebook", "fndings"]}, {"paragraph_vector": [9.018477, -50.436515], "paragraph_keywords": ["views", "help", "population", "paper"]}], "content": {}, "doi": "10.1145/3290605.3300892"}, {"uri": "259", "title": "GameViews: Understanding and Supporting Data-driven Sports Storytelling", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Qiyu Zhi", "Suwen Lin", "Poorna Talkad Sukumar", "Ronald Metoyer"], "summary": "Various stakeholders in the sports domain rely on the analysis and presentation of sports data to derive insights. In particular, sportswriters construct game stories using statistical information; fans share their viewpoints based on the real-time stats while watching the game. In this paper, we explore how these stakeholders construct data-driven sports stories. We began by observing a sportswriter, then analyzed published sports stories, and characterized 1500 fan comments about particular sporting events. We found that their story needs were similar in some respects while quite different in others. Based on the findings, we implemented two exploratory prototypes: GameViews-Writers for sportswriters to quickly extract key game information and GameViews-Fans to support a real-time data-driven gameviewing experience for fans. We report insights from two user studies conducted with four professional sportswriters and eight sports fans, respectively. We discuss the results of these studies and present several avenues for future work.", "keywords": ["explore", "point", "time", "information", "find", "gameviews", "player", "design", "analysis", "box", "example", "medium", "user", "play", "story", "included", "chart", "fan", "video", "participant", "use", "basketball", "designed", "recap", "team", "sport", "shot", "run", "espn", "visualization", "page", "score", "stats", "sportswriter", "comment", "writer", "table", "data", "game", "study", "support", "event", "prototype", "paper", "interface"], "document_vector": [-5.486665, -4.903219], "paragraphs": [{"paragraph_vector": [-147.990432, 16.361377], "paragraph_keywords": ["sports", "data", "copies", "fans"]}, {"paragraph_vector": [-145.257781, 15.568214], "paragraph_keywords": ["game", "data", "sports", "sportswriters"]}, {"paragraph_vector": [-147.110046, 15.837043], "paragraph_keywords": ["data", "sports", "visualizations", "visualization"]}, {"paragraph_vector": [-146.997055, 15.171659], "paragraph_keywords": ["fans", "data", "game", "sports"]}, {"paragraph_vector": [-144.214645, 9.81221], "paragraph_keywords": ["game", "sports", "stories", "basketball"]}, {"paragraph_vector": [-142.464126, 9.006486], "paragraph_keywords": ["stories", "basketball", "game", "categories"]}, {"paragraph_vector": [-143.627426, 7.915574], "paragraph_keywords": ["fans", "points", "team", "scored"]}, {"paragraph_vector": [-144.695175, 3.281444], "paragraph_keywords": ["comments", "game", "themes", "player"]}, {"paragraph_vector": [-141.601486, 5.716845], "paragraph_keywords": ["game", "comments", "fans", "examples"]}, {"paragraph_vector": [-143.480255, 8.117939], "paragraph_keywords": ["game", "fans", "example", "sportswriters"]}, {"paragraph_vector": [-145.685516, 10.425125], "paragraph_keywords": ["game", "fans", "comments", "sportswriters"]}, {"paragraph_vector": [-143.42575, 12.307649], "paragraph_keywords": ["game", "fans", "shows", "designed"]}, {"paragraph_vector": [-143.36856, 13.940243], "paragraph_keywords": ["game", "blazers", "run", "chart"]}, {"paragraph_vector": [-143.144165, 10.449037], "paragraph_keywords": ["chart", "game", "player", "time"]}, {"paragraph_vector": [-143.255203, 9.690189], "paragraph_keywords": ["chart", "table", "shot", "player"]}, {"paragraph_vector": [-142.746246, 10.795546], "paragraph_keywords": ["game", "score", "fans", "events"]}, {"paragraph_vector": [-144.342102, 8.44434], "paragraph_keywords": ["game", "play", "player", "comments"]}, {"paragraph_vector": [-144.611404, 12.285588], "paragraph_keywords": ["writers", "gameviews", "stories", "basketball"]}, {"paragraph_vector": [-161.476531, 37.479557], "paragraph_keywords": ["writers", "participants", "gameviews", "study"]}, {"paragraph_vector": [-146.256774, 13.299202], "paragraph_keywords": ["game", "participants", "interactions", "chart"]}, {"paragraph_vector": [-142.551284, 4.744021], "paragraph_keywords": ["participants", "game", "prototype", "study"]}, {"paragraph_vector": [-144.539306, 8.565467], "paragraph_keywords": ["comments", "fans", "participants", "play"]}, {"paragraph_vector": [-145.72142, 9.58415], "paragraph_keywords": ["comments", "participants", "game", "stats"]}, {"paragraph_vector": [-145.783721, 13.960502], "paragraph_keywords": ["video", "game", "participants", "replay"]}, {"paragraph_vector": [-144.79013, 15.319567], "paragraph_keywords": ["data", "design", "visualization", "fans"]}, {"paragraph_vector": [-147.267456, 16.336399], "paragraph_keywords": ["game", "authoring", "participants", "story"]}], "content": {}, "doi": "10.1145/3290605.3300334"}, {"uri": "260", "title": "Defending My Castle: A Co-Design Study of Privacy Mechanisms for Smart Homes", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Yaxing Yao"], "summary": "Home is a person\u2019s castle, a private and protected space. Internet-connected devices such as locks, cameras, and speakers mightmake a home \u201csmarter\u201d but also raise privacy issues because these devices may constantly and inconspicuously collect, infer or even share information about people in the home. To explore user-centered privacy designs for smart homes, we conducted a co-design study in which we worked closely with diverse groups of participants in creating new designs. This study helps fill the gap in the literature between studying users\u2019 privacy concerns and designing privacy tools only by experts. Our participants\u2019 privacy designs often relied on simple strategies, such as data localization, disconnection from the Internet, and a private mode. From these designs, we identified six key design factors: data transparency and control, security, safety, usability and user experience, system intelligence, and system modality. We discuss how these factors can guide design for smart home privacy.", "keywords": ["based", "lock", "consider", "al", "toy", "information", "mechanism", "design", "app", "home", "safety", "co", "camera", "user", "et", "risk", "work", "participant", "use", "internet", "people", "concern", "designed", "collection", "authentication", "security", "control", "voice", "page", "factor", "-", "proposed", "car", "device", "data", "study", "instance", "considered", "system", "network", "session", "mode", "question", "privacy", "manufacturer", "context", "access"], "document_vector": [70.278266, 45.884765], "paragraphs": [{"paragraph_vector": [56.506175, -83.139404], "paragraph_keywords": ["privacy", "home", "copies", "data"]}, {"paragraph_vector": [-17.591054, -87.234527], "paragraph_keywords": ["privacy", "home", "design", "risks"]}, {"paragraph_vector": [-4.745579, -81.96894], "paragraph_keywords": ["privacy", "data", "concerns", "al"]}, {"paragraph_vector": [-23.427417, -86.430442], "paragraph_keywords": ["users", "privacy", "home", "et"]}, {"paragraph_vector": [-139.177612, -86.277976], "paragraph_keywords": ["participants", "home", "study", "session"]}, {"paragraph_vector": [-66.213478, -85.195716], "paragraph_keywords": ["home", "participants", "devices", "question"]}, {"paragraph_vector": [143.659896, -86.660377], "paragraph_keywords": ["participants", "home", "scenario", "privacy"]}, {"paragraph_vector": [102.691299, -36.09262], "paragraph_keywords": ["participants", "prototypes", "session", "codebook"]}, {"paragraph_vector": [-86.699806, -85.939117], "paragraph_keywords": ["home", "codes", "privacy", "devices"]}, {"paragraph_vector": [-120.621902, -86.845832], "paragraph_keywords": ["car", "data", "transparency", "home"]}, {"paragraph_vector": [-35.010784, -84.620468], "paragraph_keywords": ["data", "fingerprint", "home", "lock"]}, {"paragraph_vector": [49.459049, -89.278625], "paragraph_keywords": ["data", "internet", "lock", "security"]}, {"paragraph_vector": [-72.477401, -82.539619], "paragraph_keywords": ["authentication", "voice", "data", "users"]}, {"paragraph_vector": [-0.509874, -85.744194], "paragraph_keywords": ["access", "home", "mode", "data"]}, {"paragraph_vector": [24.974578, -84.444137], "paragraph_keywords": ["home", "data", "notify", "app"]}, {"paragraph_vector": [-61.099571, -83.728218], "paragraph_keywords": ["people", "users", "privacy", "design"]}, {"paragraph_vector": [-40.125534, -86.714981], "paragraph_keywords": ["toys", "privacy", "participants", "designs"]}, {"paragraph_vector": [-62.38961, -84.52275], "paragraph_keywords": ["data", "usb", "design", "plug"]}, {"paragraph_vector": [-38.973011, -85.552909], "paragraph_keywords": ["privacy", "designs", "home", "app"]}, {"paragraph_vector": [1.570369, -84.952201], "paragraph_keywords": ["home", "privacy", "data", "design"]}, {"paragraph_vector": [7.405023, -84.067932], "paragraph_keywords": ["data", "internet", "devices", "home"]}, {"paragraph_vector": [-39.653186, -86.334053], "paragraph_keywords": ["privacy", "user", "designs", "safety"]}, {"paragraph_vector": [-15.959609, -85.36235], "paragraph_keywords": ["privacy", "user", "device", "data"]}, {"paragraph_vector": [-5.542726, -85.724914], "paragraph_keywords": ["participants", "privacy", "designs", "homes"]}, {"paragraph_vector": [-27.385524, -86.655448], "paragraph_keywords": ["designs", "users", "privacy", "design"]}, {"paragraph_vector": [10.014163, -86.122711], "paragraph_keywords": ["privacy", "dym", "thank", "bryan"]}], "content": {}, "doi": "10.1145/3290605.3300851"}, {"uri": "261", "title": "CanMobile Augmented Reality Stimulate a Honeypot Efect? Observations from Santa\u2019s Lil Helper", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Hasan Shahid Ferdous", "Frank Vetere"], "summary": "In HCI, the honeypot efect describes a form of audience engagement in which a person\u2019s interaction with a technology stimulates passers-by to observe, approach and engage in an interaction themselves. In this paper we explore the potential for honeypot efects to arise in the use of mobile augmented reality (AR) applications in urban spaces. We present an observational study of Santa\u2019s Lil Helper, a mobile AR game that created a Christmas-themed treasure hunt in a metropolitan area. Our study supports a consideration of three factors that may impede the honeypot efect: the presence of people in relation to the game and its interactive components; the visibility of gameplay in urban space; and the extent to which the game permits a shared experience. We consider how these factors can inform the design of future AR experiences that are capable of stimulating honeypot efects in public space.", "keywords": ["melbourne", "marker", "efect", "location", "player", "display", "stimulate", "opportunity", "playing", "example", "user", "engagement", "interaction", "shared", "passersby", "work", "space", "slh", "use", "people", "group", "way", "participation", "experience", "page", "presence", "application", "content", "found", "observed", "understand", "audience", "attention", "device", "technology", "game", "study", "honeypot", "system", "ar", "deployed", "potential", "site", "paper", "street", "observation", "city", "figure", "efects"], "document_vector": [143.324539, 7.909741], "paragraphs": [{"paragraph_vector": [-119.715072, -36.598167], "paragraph_keywords": ["use", "users", "copies", "engagement"]}, {"paragraph_vector": [-118.093498, -36.796089], "paragraph_keywords": ["efect", "honeypot", "ar", "use"]}, {"paragraph_vector": [-119.210739, -35.304496], "paragraph_keywords": ["efect", "people", "honeypot", "technology"]}, {"paragraph_vector": [-121.375679, -38.555431], "paragraph_keywords": ["displays", "honeypot", "efect", "users"]}, {"paragraph_vector": [-121.053573, -38.280235], "paragraph_keywords": ["technology", "honeypot", "efect", "passersby"]}, {"paragraph_vector": [-120.551193, -35.463218], "paragraph_keywords": ["players", "ar", "games", "game"]}, {"paragraph_vector": [-118.57006, -36.101963], "paragraph_keywords": ["honeypot", "ar", "efect", "technologies"]}, {"paragraph_vector": [-119.939727, -34.565135], "paragraph_keywords": ["game", "ar", "city", "locations"]}, {"paragraph_vector": [-129.999984, -24.900289], "paragraph_keywords": ["figure", "marker", "location", "user"]}, {"paragraph_vector": [-122.931777, -35.195747], "paragraph_keywords": ["laneways", "game", "city", "situated"]}, {"paragraph_vector": [-122.170989, -36.120944], "paragraph_keywords": ["slh", "users", "game", "ar"]}, {"paragraph_vector": [-133.840866, -45.596294], "paragraph_keywords": ["observations", "interviews", "users", "feld"]}, {"paragraph_vector": [-120.668754, -37.06808], "paragraph_keywords": ["people", "slh", "playing", "users"]}, {"paragraph_vector": [-119.298103, -38.046684], "paragraph_keywords": ["people", "technology", "honeypot", "efect"]}, {"paragraph_vector": [-121.033561, -38.662342], "paragraph_keywords": ["people", "honeypot", "location", "efect"]}, {"paragraph_vector": [-120.440925, -35.563838], "paragraph_keywords": ["honeypot", "users", "efect", "visibility"]}, {"paragraph_vector": [-123.071128, -34.919422], "paragraph_keywords": ["markers", "game", "objects", "interest"]}, {"paragraph_vector": [-127.738883, -22.704114], "paragraph_keywords": ["device", "slh", "people", "ar"]}, {"paragraph_vector": [-119.305175, -37.792182], "paragraph_keywords": ["users", "manipulations", "efects", "honeypot"]}, {"paragraph_vector": [-120.143951, -37.260589], "paragraph_keywords": ["people", "use", "slh", "activity"]}, {"paragraph_vector": [-119.042732, -38.050827], "paragraph_keywords": ["group", "device", "users", "involved"]}, {"paragraph_vector": [-120.950569, -36.839412], "paragraph_keywords": ["ar", "people", "shared", "honeypot"]}, {"paragraph_vector": [-119.913078, -36.753334], "paragraph_keywords": ["ar", "honeypot", "efect", "people"]}, {"paragraph_vector": [-120.616325, -35.854965], "paragraph_keywords": ["ar", "efect", "honeypot", "interactions"]}, {"paragraph_vector": [-121.105476, -35.705581], "paragraph_keywords": ["users", "ar", "experience", "game"]}, {"paragraph_vector": [-122.33303, -33.979587], "paragraph_keywords": ["ar", "use", "honeypot", "uptake"]}], "content": {}, "doi": "10.1145/3290605.3300637"}, {"uri": "262", "title": "Pictorial System Usability Scale (P-SUS): Developing", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Juergen Baumgartnerab", "Naomi Freia", "Mascha Kleinkea", "Juergen Sauera", "Andreas Sondereggerc"], "summary": "We have developed a pictorial multi-item scale, called PSUS (Pictorial System Usability Scale), which aims to measure the perceived usability of mobile devices. The scale is based on the established verbal usability questionnaire SUS (System Usability Scale). A usercentred design process was employed to develop and refine its 10 pictorial items. The scale was tested in a first validation study (N=60) using student participants. Psychometric properties (convergent validity, criterionrelated validity, sensitivity, and reliability), as well as the motivation to fill in the scale were assessed. The results indicated satisfactory convergent validity for about twothirds of the items. Furthermore, strong correlations were obtained for the sum scores between verbal and pictorial SUS, and the pictorial scale was perceived as more motivating than the verbal questionnaire. The P-SUS represents a first attempt to provide a pictorial usability scale for the evaluation of (mobile) devices.", "keywords": ["sus", "point", "time", "development", "questionnaire", "interpretation", "design", "validity", "user", "result", "participant", "usability", "e", "page", "experience", "obtained", "developed", "test", "scale", "version", "item", "data", "regard", "study", "element", "reliability", "system", "order", "r", "prototype", "motivation", "instrument", "p"], "document_vector": [8.509981, 15.373403], "paragraphs": [{"paragraph_vector": [115.499404, -11.246223], "paragraph_keywords": ["usability", "user", "interaction", "concept"]}, {"paragraph_vector": [6.048064, 43.068225], "paragraph_keywords": ["usability", "scale", "instrument", "system"]}, {"paragraph_vector": [11.29358, 44.212844], "paragraph_keywords": ["participants", "survey", "response", "usability"]}, {"paragraph_vector": [5.302582, 43.110107], "paragraph_keywords": ["items", "usability", "emotion", "way"]}, {"paragraph_vector": [6.728367, 41.015792], "paragraph_keywords": ["sus", "applied", "usability", "scales"]}, {"paragraph_vector": [99.187858, 47.106742], "paragraph_keywords": ["design", "items", "e", "students"]}, {"paragraph_vector": [103.518775, 54.357978], "paragraph_keywords": ["item", "test", "items", "design"]}, {"paragraph_vector": [7.598189, 39.471542], "paragraph_keywords": ["scale", "elements", "items", "developed"]}, {"paragraph_vector": [9.636833, 41.008827], "paragraph_keywords": ["items", "participants", "usability", "developed"]}, {"paragraph_vector": [9.150084, 40.552898], "paragraph_keywords": ["questionnaire", "validity", "usability", "sus"]}, {"paragraph_vector": [5.511535, 39.945636], "paragraph_keywords": ["questionnaire", "prototype", "participants", "subscale"]}, {"paragraph_vector": [7.590326, 44.075584], "paragraph_keywords": ["r", "data", "sum", "tests"]}, {"paragraph_vector": [5.503305, 41.833545], "paragraph_keywords": ["p", "sus", "revealed", "item"]}, {"paragraph_vector": [9.712687, 42.462852], "paragraph_keywords": ["sus", "time", "effects", "p"]}, {"paragraph_vector": [5.343043, 41.704483], "paragraph_keywords": ["participants", "questionnaires", "scales", "questionnaire"]}, {"paragraph_vector": [2.719611, 41.112728], "paragraph_keywords": ["items", "order", "sus", "scale"]}, {"paragraph_vector": [7.337296, 42.866039], "paragraph_keywords": ["scale", "results", "development", "design"]}], "content": {}, "doi": "10.1145/3290605.3300311"}, {"uri": "263", "title": "Kyub: A 3D Editor for Modeling Sturdy Laser-Cut Objects", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Patrick Baudisch", "Arthur Silber", "Yannis Kommana", "Milan Gruner", "Ludwig Wall", "Kevin Reuss", "Lukas Heilman", "Robert Kovacs", "Daniel Rechlitz", "Thijs Roumen"], "summary": "We present an interactive editing system for laser cutting called kyub. Kyub allows users to create models efficiently in 3D, which it then unfolds into the 2D plates laser cutters expect. Unlike earlier systems, such as FlatFitFab, kyub affords construction based on closed box structures, which allows users to turn very thin material, such as 4mm plywood, into objects capable of withstanding large forces, such as chairs users can actually sit on. To afford such sturdy construction, every kyub project begins with a simple finger-joint \u201cboxel\u201d\u2014a structure we found to be capable of withstanding over 500kg of load. Users then extend their model by attaching additional boxels. Boxels merge automatically, resulting in larger, yet equally strong structures. While the concept of stacking boxels allows kyub to offer the strong affordance and ease of use of a voxel-based editor, boxels are not confined to a grid and readily combine with kuyb\u2019s various geometry deformation tools. In our technical evaluation, objects built with kyub withstood hundreds of kilograms of loads. In our user study, non-engineers rated the learnability of kyub 6.1/7. CCS CONCEPTS \u2022 Human-centered computing~Human computer interaction", "keywords": ["based", "boxel", "time", "object", "cut", "design", "boxels", "box", "example", "user", "model", "allows", "construction", "tool", "show", "participant", "use", "create", "material", "kyub", "joint", "shape", "cutting", "page", "laser", "c", "part", "add", "test", "shown", "plate", "geometry", "end", "grid", "structure", "editor", "figure", "making"], "document_vector": [94.660209, -39.567527], "paragraphs": [{"paragraph_vector": [-105.654106, 51.382362], "paragraph_keywords": ["acm", "laser", "copies", "objects"]}, {"paragraph_vector": [-101.769317, 53.750923], "paragraph_keywords": ["structures", "objects", "kyub", "users"]}, {"paragraph_vector": [-104.313621, 53.004535], "paragraph_keywords": ["user", "boxel", "plates", "kyub"]}, {"paragraph_vector": [-89.018341, 58.264385], "paragraph_keywords": ["grid", "boxel", "kyub", "boxels"]}, {"paragraph_vector": [-104.115371, 49.912464], "paragraph_keywords": ["parts", "kyub", "allows", "boxel"]}, {"paragraph_vector": [-98.818496, 52.658283], "paragraph_keywords": ["plates", "figure", "design", "boxel"]}, {"paragraph_vector": [-102.953689, 53.097587], "paragraph_keywords": ["kyub", "objects", "cells", "users"]}, {"paragraph_vector": [-100.917686, 54.507503], "paragraph_keywords": ["based", "structures", "construction", "kyub"]}, {"paragraph_vector": [-104.996208, 51.22591], "paragraph_keywords": ["users", "laser", "allows", "models"]}, {"paragraph_vector": [-98.422683, 54.145927], "paragraph_keywords": ["objects", "boxels", "test", "plates"]}, {"paragraph_vector": [-100.266532, 51.639545], "paragraph_keywords": ["participants", "object", "test", "kyub"]}, {"paragraph_vector": [-102.550811, 54.138401], "paragraph_keywords": ["participants", "models", "kyub", "designs"]}, {"paragraph_vector": [-106.177627, 54.077148], "paragraph_keywords": ["grid", "kyub", "mouse", "base"]}, {"paragraph_vector": [-98.061561, 55.535259], "paragraph_keywords": ["grid", "kyub", "end", "candidates"]}, {"paragraph_vector": [-7.615325, 9.772561], "paragraph_keywords": ["integrate", "kyub", "plate", "evaluation"]}], "content": {}, "doi": "10.1145/3290605.3300726"}, {"uri": "264", "title": "Spaces and Traces: Implications of Smart Technology in Public Housing", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Sandjar Kozubaev", "Fernando Rochaix"], "summary": "Smart home technologies are beginning to become more widespread and common, even as their deployment and implementation remain complex and spread across different competing commercial ecosystems. Looking beyond the middle-class, single-family home often at the center of the smart home narrative, we report on a series of participatory design workshops held with residents and building managers to better understand the role of smart home technologies in the context of public housing in the U.S. The design workshops enabled us to gather insight into the specific challenges and opportunities of deploying smart home technologies in a setting where issues of privacy, data collection and ownership, and autonomy collide with diverse living arrangements, where income, age, and the consequences of monitoring and data aggregation setup an expanding collection of design implications in the ecosystems of smart home technologies.", "keywords": ["resident", "housing", "need", "information", "set", "discussion", "community", "design", "home", "atlanta", "environment", "provide", "boundary", "income", "sensor", "workshop", "capability", "work", "building", "space", "participant", "use", "people", "concern", "living", "service", "issue", "way", "health", "agency", "control", "page", "property", "monitoring", "tracking", "providing", "life", "case", "family", "practice", "device", "data", "technology", "support", "system", "research", "surveillance", "hci", "paper", "privacy", "staff", "value", "context", "access"], "document_vector": [87.547271, 50.201011], "paragraphs": [{"paragraph_vector": [59.959087, -81.454864], "paragraph_keywords": ["copies", "building", "acm", "work"]}, {"paragraph_vector": [80.163497, -86.494369], "paragraph_keywords": ["housing", "technologies", "design", "residents"]}, {"paragraph_vector": [144.258316, -87.629829], "paragraph_keywords": ["home", "housing", "systems", "income"]}, {"paragraph_vector": [-85.072952, -58.895542], "paragraph_keywords": ["home", "objects", "values", "way"]}, {"paragraph_vector": [-73.148178, -83.409873], "paragraph_keywords": ["housing", "home", "technologies", "policy"]}, {"paragraph_vector": [50.713314, -87.054374], "paragraph_keywords": ["housing", "health", "technologies", "data"]}, {"paragraph_vector": [-34.363132, -89.457595], "paragraph_keywords": ["housing", "residents", "home", "projects"]}, {"paragraph_vector": [29.630807, -86.907707], "paragraph_keywords": ["housing", "income", "technologies", "families"]}, {"paragraph_vector": [-91.425964, -85.068939], "paragraph_keywords": ["workshops", "participants", "technologies", "housing"]}, {"paragraph_vector": [57.813201, -82.823524], "paragraph_keywords": ["participants", "sensors", "housing", "technologies"]}, {"paragraph_vector": [-107.73001, -59.383548], "paragraph_keywords": ["participants", "technologies", "game", "devices"]}, {"paragraph_vector": [139.338973, -82.637519], "paragraph_keywords": ["participants", "technologies", "use", "technology"]}, {"paragraph_vector": [89.093902, -84.911575], "paragraph_keywords": ["residents", "technologies", "workshop", "property"]}, {"paragraph_vector": [57.469638, -88.026], "paragraph_keywords": ["technologies", "participants", "discussion", "staff"]}, {"paragraph_vector": [75.861106, -87.657234], "paragraph_keywords": ["technologies", "health", "housing", "tracking"]}, {"paragraph_vector": [38.416759, -88.171661], "paragraph_keywords": ["way", "tracking", "health", "workshop"]}, {"paragraph_vector": [-76.473739, -87.957115], "paragraph_keywords": ["residents", "technologies", "building", "track"]}, {"paragraph_vector": [85.467994, -88.255241], "paragraph_keywords": ["participants", "housing", "recording", "surveillance"]}, {"paragraph_vector": [-37.009628, -83.922851], "paragraph_keywords": ["technologies", "people", "speaker", "talking"]}, {"paragraph_vector": [-153.873947, -65.965881], "paragraph_keywords": ["workshop", "technologies", "residents", "transit"]}, {"paragraph_vector": [17.381221, -89.113395], "paragraph_keywords": ["access", "home", "housing", "tv"]}, {"paragraph_vector": [104.11174, -88.944343], "paragraph_keywords": ["residents", "tracking", "use", "access"]}, {"paragraph_vector": [93.586853, -85.10379], "paragraph_keywords": ["housing", "data", "ownership", "residents"]}, {"paragraph_vector": [-64.712608, -85.942016], "paragraph_keywords": ["privacy", "housing", "technologies", "technology"]}, {"paragraph_vector": [108.014068, -89.402664], "paragraph_keywords": ["technologies", "services", "use", "technology"]}, {"paragraph_vector": [162.142608, -88.95684], "paragraph_keywords": ["technologies", "data", "systems", "participation"]}, {"paragraph_vector": [56.673042, -89.096557], "paragraph_keywords": ["concerns", "residents", "housing", "data"]}], "content": {}, "doi": "10.1145/3290605.3300453"}, {"uri": "265", "title": "Autonomous Distributed Energy Systems: Problematising the Invisible through Design, Drama and Deliberation", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Larissa Pschetz"], "summary": "Technologies such as blockchains, smart contracts and programmable batteries facilitate emerging models of energy distribution, trade and consumption, and generate a considerable number of opportunities for energy markets. However, these developments complicate relationships between stakeholders, disrupting traditional notions of value, control and ownership. Discussing these issues with the public is particularly challenging as energy consumption habits often obscure the competing values and interests that shape Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300617 stakeholders\u2019 relationships. To make such difficult discussions more approachable and examine the missing relational aspect of autonomous energy systems, we combined the design of speculative hairdryers with performance and deliberation. This integrated method of inquiry makes visible the competing values and interests, eliciting people\u2019s wishes to negotiate these terms. We argue that the complexity of mediated energy distribution and its convoluted stakeholder relationships requires more sophisticated methods of inquiry to engage people in debates concerning distributed energy systems.", "keywords": ["process", "supply", "based", "time", "sketch", "discussion", "design", "trade", "problem", "relationship", "power", "price", "model", "electricity", "user", "going", "know", "hairdryer", "exercise", "engage", "work", "participant", "use", "people", "market", "distributed", "issue", "designed", "way", "think", "energy", "actor", "control", "experience", "page", "according", "improvisation", "exchange", "deliberation", "drama", "demand", "stakeholder", "money", "device", "data", "transparency", "technology", "role", "system", "choice", "buy", "support", "term", "gigbliss", "order", "transaction", "grid", "question", "paper", "critique", "value", "hairdryers", "level", "negotiate", "access"], "document_vector": [72.017372, 41.870632], "paragraphs": [{"paragraph_vector": [89.355003, -54.581508], "paragraph_keywords": ["energy", "systems", "design", "relationships"]}, {"paragraph_vector": [96.721359, -52.09967], "paragraph_keywords": ["energy", "people", "design", "distributed"]}, {"paragraph_vector": [74.307685, -56.508892], "paragraph_keywords": ["energy", "transactions", "distributed", "support"]}, {"paragraph_vector": [76.518539, -59.719768], "paragraph_keywords": ["energy", "systems", "distributed", "storage"]}, {"paragraph_vector": [81.378776, -55.643501], "paragraph_keywords": ["energy", "design", "model", "systems"]}, {"paragraph_vector": [93.838348, -50.583885], "paragraph_keywords": ["issues", "participants", "critique", "hairdryers"]}, {"paragraph_vector": [71.508827, -63.024772], "paragraph_keywords": ["energy", "device", "scenario", "systems"]}, {"paragraph_vector": [77.395561, -57.63734], "paragraph_keywords": ["energy", "device", "gigbliss", "costs"]}, {"paragraph_vector": [91.853195, -44.591148], "paragraph_keywords": ["design", "questions", "hairdryers", "hci"]}, {"paragraph_vector": [98.717796, -49.615673], "paragraph_keywords": ["participants", "discussion", "design", "hairdryers"]}, {"paragraph_vector": [99.005584, -46.243888], "paragraph_keywords": ["hairdryer", "anna", "sketch", "sarah"]}, {"paragraph_vector": [75.10054, -59.622657], "paragraph_keywords": ["device", "hairdryer", "energy", "says"]}, {"paragraph_vector": [106.554801, -50.55865], "paragraph_keywords": ["design", "performance", "uses", "technologies"]}, {"paragraph_vector": [99.783531, -45.883342], "paragraph_keywords": ["experience", "deliberation", "participants", "process"]}, {"paragraph_vector": [97.664909, -46.04174], "paragraph_keywords": ["participants", "technology", "exercise", "actors"]}, {"paragraph_vector": [84.711441, -58.904926], "paragraph_keywords": ["know", "data", "technology", "use"]}, {"paragraph_vector": [93.509979, -48.517257], "paragraph_keywords": ["participants", "technologies", "terms", "technology"]}, {"paragraph_vector": [106.363388, -56.388153], "paragraph_keywords": ["price", "control", "use", "access"]}, {"paragraph_vector": [30.181768, -30.148036], "paragraph_keywords": ["stocks", "buy", "energy", "phone"]}, {"paragraph_vector": [75.946098, -62.323223], "paragraph_keywords": ["energy", "functionality", "hairdryer", "participants"]}, {"paragraph_vector": [78.048568, -56.972721], "paragraph_keywords": ["trade", "energy", "work", "participants"]}, {"paragraph_vector": [79.461997, -73.976654], "paragraph_keywords": ["time", "hairdryer", "use", "morning"]}, {"paragraph_vector": [76.411506, -65.695976], "paragraph_keywords": ["energy", "gives", "think", "decided"]}, {"paragraph_vector": [90.611183, -51.787723], "paragraph_keywords": ["technologies", "participants", "people", "drama"]}, {"paragraph_vector": [90.980674, -48.969692], "paragraph_keywords": ["deliberation", "design", "participants", "people"]}, {"paragraph_vector": [81.513305, -57.724849], "paragraph_keywords": ["control", "people", "participants", "energy"]}, {"paragraph_vector": [87.201927, -56.789066], "paragraph_keywords": ["access", "participants", "design", "control"]}, {"paragraph_vector": [96.156089, -46.511257], "paragraph_keywords": ["participants", "design", "experience", "deliberation"]}, {"paragraph_vector": [92.943664, -47.819049], "paragraph_keywords": ["project", "research", "participants", "experience"]}], "content": {}, "doi": "10.1145/3290605.3300626"}, {"uri": "266", "title": "Power Struggles and Disciplined Designers \u2013 A Nexus Analytic Inquiry on Cross-Disciplinary Research and Design", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Netta Iivari"], "summary": "Design is at the heart of Human Computer Interaction research and practice. In the research community, there has emerged an increasing interest in understanding and conceptualizing our research practice, particularly such entailing design. However, reflective discussion around the associated challenges and practicalities is yet limited. Moreover, so far there is limited discussion on the crossdisciplinary nature of our research and design practices: although cross-disciplinarity has been brought up as an ideal and a necessity, its practicalities and complexities remain yet poorly explored. This study examines a crossdisciplinary research project with a number of researcherdesigners representing different disciplines acting as \u2018designers\u2019, while having a divergent understanding of it and of who has authority to do it. The study relies on nexus analysis as a sensitizing device and shows how various discourses, epistemologies and histories shape cross-disciplinary research and design. Critical reflection around our research practice entailing design is called for.", "keywords": ["process", "reflection", "based", "time", "need", "body", "requirement", "design", "feature", "analysis", "method", "seen", "bear", "user", "interaction", "tutor", "involved", "shared", "expertise", "work", "place", "inspired", "participant", "people", "world", "specialist", "created", "page", "application", "variety", "including", "science", "authority", "practice", "document", "discipline", "study", "designer", "researcher", "nexus", "shaping", "research", "discourse", "hci", "software", "paper", "assumption", "knowledge", "project", "action", "making"], "document_vector": [42.754402, 23.150775], "paragraphs": [{"paragraph_vector": [108.841064, -23.341871], "paragraph_keywords": ["design", "research", "copies", "practice"]}, {"paragraph_vector": [102.701828, -20.695949], "paragraph_keywords": ["research", "design", "hci", "disciplines"]}, {"paragraph_vector": [108.808364, -20.090343], "paragraph_keywords": ["research", "design", "variety", "discourses"]}, {"paragraph_vector": [106.690673, -20.290433], "paragraph_keywords": ["design", "research", "discipline", "knowledge"]}, {"paragraph_vector": [106.67942, -21.846303], "paragraph_keywords": ["design", "research", "reflection", "view"]}, {"paragraph_vector": [106.77861, -21.613168], "paragraph_keywords": ["disciplines", "design", "work", "expertise"]}, {"paragraph_vector": [103.839973, -20.587423], "paragraph_keywords": ["research", "analysis", "design", "variety"]}, {"paragraph_vector": [120.780387, -35.296001], "paragraph_keywords": ["action", "people", "concept", "analysis"]}, {"paragraph_vector": [123.29412, -29.188436], "paragraph_keywords": ["action", "study", "research", "time"]}, {"paragraph_vector": [114.736732, -27.491317], "paragraph_keywords": ["world", "research", "project", "representations"]}, {"paragraph_vector": [112.776573, -17.736227], "paragraph_keywords": ["project", "analysis", "based", "utilized"]}, {"paragraph_vector": [115.837898, -8.544123], "paragraph_keywords": ["feature", "tutor", "project", "design"]}, {"paragraph_vector": [115.440765, -6.527235], "paragraph_keywords": ["science", "specialists", "requirements", "design"]}, {"paragraph_vector": [115.352218, -9.085252], "paragraph_keywords": ["specialists", "tutor", "science", "design"]}, {"paragraph_vector": [114.66455, -9.03283], "paragraph_keywords": ["specialists", "hci", "design", "usability"]}, {"paragraph_vector": [112.095703, -5.35645], "paragraph_keywords": ["specialists", "hci", "work", "design"]}, {"paragraph_vector": [-132.805099, 0.002581], "paragraph_keywords": ["users", "tutor", "game", "use"]}, {"paragraph_vector": [100.573944, 53.305992], "paragraph_keywords": ["specialists", "users", "tried", "video"]}, {"paragraph_vector": [120.975868, -7.180235], "paragraph_keywords": ["design", "action", "process", "designs"]}, {"paragraph_vector": [115.872047, -7.050871], "paragraph_keywords": ["design", "specialists", "science", "hci"]}, {"paragraph_vector": [114.074066, -7.587916], "paragraph_keywords": ["design", "specialists", "hci", "project"]}, {"paragraph_vector": [109.951499, -12.061216], "paragraph_keywords": ["design", "research", "hci", "practice"]}, {"paragraph_vector": [115.709213, -7.948277], "paragraph_keywords": ["design", "specialists", "hci", "designers"]}, {"paragraph_vector": [115.429039, -8.803452], "paragraph_keywords": ["design", "specialists", "science", "data"]}, {"paragraph_vector": [107.430221, -20.732189], "paragraph_keywords": ["design", "practice", "research", "practices"]}, {"paragraph_vector": [105.264526, -19.862733], "paragraph_keywords": ["research", "design", "participants", "researcher"]}, {"paragraph_vector": [110.782722, -20.387332], "paragraph_keywords": ["design", "people", "projects", "discourses"]}, {"paragraph_vector": [108.882835, -16.365262], "paragraph_keywords": ["design", "project", "research", "reflection"]}], "content": {}, "doi": "10.1145/3290605.3300508"}, {"uri": "267", "title": "Supporting Coping with Parkinson\u2019s Disease Through Self-Tracking", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Sonali R. Mishra", "Predrag Klasnja"], "summary": "Self-tracking can help people understand their medical condition and the factors that influence their symptoms. However, it is unclear how tracking technologies should be tailored to help people cope with the progression of a degenerative disease. To understand how smartphone apps and other tracking technologies can support people in coping with an incurable illness, we interviewed both people with Parkinson\u2019s Disease (n=17) and care partners (n=6) who help people with Parkinson\u2019s manage their lives. We describe how symptom trackers can help people identify and solve problems to improve their quality of life, the role symptom trackers can play in helping people combat their own tendencies towards avoidance and denial, and the complex role of care partners in defining and tracking ambiguous symptoms. Our findings yield insights that can guide the design of tracking technologies to help people with Parkinson\u2019s Disease accept and plan for their condition.", "keywords": ["metric", "explore", "clinician", "strategy", "pwp", "time", "progression", "condition", "need", "change", "needed", "self", "care", "problem", "disease", "partner", "wanted", "help", "user", "pain", "know", "work", "tool", "participant", "tremor", "use", "people", "designed", "pd", "health", "sense", "finding", "page", "felt", "c", "found", "variety", "understand", "tracking", "life", "track", "data", "technology", "researcher", "symptom", "instance", "system", "support", "decline", "term", "paper", "coping", "context", "medication"], "document_vector": [-4.824967, 80.265045], "paragraphs": [{"paragraph_vector": [167.250274, -28.47759], "paragraph_keywords": ["pd", "symptoms", "copies", "people"]}, {"paragraph_vector": [177.6082, -20.201093], "paragraph_keywords": ["strategies", "coping", "pd", "quality"]}, {"paragraph_vector": [-178.390441, -22.572114], "paragraph_keywords": ["pwp", "tracking", "pd", "care"]}, {"paragraph_vector": [-173.559356, -23.232547], "paragraph_keywords": ["symptoms", "pwp", "tracking", "manage"]}, {"paragraph_vector": [-177.881561, -28.777204], "paragraph_keywords": ["people", "tracking", "self", "systems"]}, {"paragraph_vector": [-177.434814, -26.223217], "paragraph_keywords": ["pwp", "technologies", "self", "help"]}, {"paragraph_vector": [-176.86, -23.356248], "paragraph_keywords": ["people", "pwp", "participants", "care"]}, {"paragraph_vector": [140.849945, -36.761726], "paragraph_keywords": ["participants", "care", "pwp", "partners"]}, {"paragraph_vector": [-177.659011, -20.993274], "paragraph_keywords": ["tracking", "storyboards", "data", "participants"]}, {"paragraph_vector": [-179.471847, -24.015171], "paragraph_keywords": ["symptoms", "participants", "tracking", "pwp"]}, {"paragraph_vector": [-177.961395, -23.905347], "paragraph_keywords": ["tracking", "symptoms", "data", "participants"]}, {"paragraph_vector": [-178.746292, -24.37659], "paragraph_keywords": ["help", "participants", "term", "problem"]}, {"paragraph_vector": [-175.826904, -26.96529], "paragraph_keywords": ["medication", "tracking", "visits", "wanted"]}, {"paragraph_vector": [-179.154739, -25.885421], "paragraph_keywords": ["data", "symptoms", "participants", "measure"]}, {"paragraph_vector": [-177.977951, -26.181585], "paragraph_keywords": ["data", "symptoms", "tracking", "coping"]}, {"paragraph_vector": [-174.889953, -25.986268], "paragraph_keywords": ["tremor", "tracking", "participants", "data"]}, {"paragraph_vector": [-177.886734, -23.997228], "paragraph_keywords": ["symptoms", "concern", "experienced", "sense"]}, {"paragraph_vector": [-176.165664, -24.102058], "paragraph_keywords": ["accept", "spouse", "wanted", "tremor"]}, {"paragraph_vector": [-175.348815, -25.125522], "paragraph_keywords": ["care", "symptoms", "participants", "partners"]}, {"paragraph_vector": [-173.71875, -24.830928], "paragraph_keywords": ["symptoms", "participants", "partners", "pd"]}, {"paragraph_vector": [-176.976562, -25.460262], "paragraph_keywords": ["symptoms", "care", "symptom", "pd"]}, {"paragraph_vector": [-177.79039, -24.165967], "paragraph_keywords": ["care", "symptoms", "tracking", "symptom"]}, {"paragraph_vector": [-177.832092, -23.114767], "paragraph_keywords": ["self", "care", "tracking", "strategies"]}, {"paragraph_vector": [-179.640426, -24.307174], "paragraph_keywords": ["tracking", "self", "systems", "track"]}, {"paragraph_vector": [-178.217544, -23.405153], "paragraph_keywords": ["tracking", "self", "systems", "progression"]}, {"paragraph_vector": [-178.678451, -24.164875], "paragraph_keywords": ["users", "data", "pwp", "pd"]}, {"paragraph_vector": [-179.314773, -24.353778], "paragraph_keywords": ["symptoms", "users", "self", "help"]}, {"paragraph_vector": [-177.085739, -22.921451], "paragraph_keywords": ["care", "partners", "self", "data"]}, {"paragraph_vector": [-178.402725, -22.896734], "paragraph_keywords": ["symptoms", "pwp", "partners", "care"]}, {"paragraph_vector": [-177.971908, -23.732898], "paragraph_keywords": ["pwp", "self", "tracking", "partners"]}, {"paragraph_vector": [-179.378677, -22.443748], "paragraph_keywords": ["partners", "help", "pd", "care"]}], "content": {}, "doi": "10.1145/3290605.3300388"}, {"uri": "268", "title": "To Repeat or Not to Repeat? Redesigning Repeating Auditory Alarms Based on EEG Analysis", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Yi-Chen Lee"], "summary": "Auditory alarms that repeatedly interrupt users until they react are common, especially in the context of alarms. However, when an alarm repeats, our brains habituate to it and perceive it less and less, with reductions in both perception and attention-shifting: a phenomenon known as the repetition-suppression effect (RS). To retain users\u2019 perception and attention, this paper proposes and tests the use of pitchand intensity-modulated alarms. Its experimental findings suggest that the proposed modulated alarms can reduce RS, albeit in different patterns, depending on whether pitch or intensity is the focus of the modulation. Specifically, pitch-modulated alarms were found to reduce RS more when the number of repetitions was small, while intensity-modulated alarms reduced it more as the number of repetitions increased. Based on these results, we make several recommendations for the design of improved repeating alarms, based on which modulation approach should be adopted in various situations.", "keywords": ["time", "design", "mmn", "habituation", "method", "analysis", "experiment", "deviant", "eeg", "user", "isolated", "elicited", "result", "participant", "effect", "m", "auditory", "intensity", "modulated", "sound", "stimulus", "amplitude", "attention", "brain", "study", "repetition", "pitch", "alarm", "modulation", "research", "session", "r", "background", "paper", "repeating", "figure"], "document_vector": [-14.974411, -39.099494], "paragraphs": [{"paragraph_vector": [13.185462, -5.098761], "paragraph_keywords": ["alarms", "copies", "users", "acm"]}, {"paragraph_vector": [13.516716, -7.814228], "paragraph_keywords": ["alarms", "alarm", "auditory", "rs"]}, {"paragraph_vector": [4.84048, -5.425422], "paragraph_keywords": ["users", "eeg", "auditory", "effects"]}, {"paragraph_vector": [0.691175, -2.188141], "paragraph_keywords": ["mmn", "eeg", "erp", "method"]}, {"paragraph_vector": [11.787524, -4.517955], "paragraph_keywords": ["rs", "sounds", "sound", "habituation"]}, {"paragraph_vector": [11.82591, -6.96785], "paragraph_keywords": ["studies", "mmn", "participants", "sound"]}, {"paragraph_vector": [13.007585, -7.593209], "paragraph_keywords": ["intensity", "pitch", "alarms", "db"]}, {"paragraph_vector": [12.533858, -7.429988], "paragraph_keywords": ["session", "trials", "auditory", "ms"]}, {"paragraph_vector": [2.586138, -1.638741], "paragraph_keywords": ["ica", "eeg", "ms", "mmn"]}, {"paragraph_vector": [11.998815, -5.146046], "paragraph_keywords": ["mmn", "sessions", "elicited", "alarms"]}, {"paragraph_vector": [12.785146, -5.7428], "paragraph_keywords": ["amplitude", "alarms", "amplitudes", "mmn"]}, {"paragraph_vector": [12.691888, -7.357547], "paragraph_keywords": ["alarm", "figure", "effect", "amplitudes"]}, {"paragraph_vector": [11.909967, -5.759008], "paragraph_keywords": ["alarms", "latency", "effect", "repeating"]}, {"paragraph_vector": [11.15059, -7.173521], "paragraph_keywords": ["alarms", "effect", "participants", "sound"]}, {"paragraph_vector": [12.440384, -6.055767], "paragraph_keywords": ["effect", "background", "study", "participants"]}, {"paragraph_vector": [13.500037, -7.43341], "paragraph_keywords": ["alarms", "modulated", "auditory", "effect"]}, {"paragraph_vector": [10.054236, -7.237356], "paragraph_keywords": ["alarms", "auditory", "modulated", "design"]}, {"paragraph_vector": [11.581004, -8.163483], "paragraph_keywords": ["alarms", "effect", "modulated", "include"]}, {"paragraph_vector": [12.223351, -6.335921], "paragraph_keywords": ["alarms", "modulated", "research", "rs"]}], "content": {}, "doi": "10.1145/3290605.3300877"}, {"uri": "269", "title": "Analyzing Value Discovery in Design Decisions Through Ethicography", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Shruthi Sai Chivukula", "Colin M. Gray"], "summary": "HCI scholarship is increasingly concerned with the ethical impact of socio-technical systems. Current theoreticallydriven approaches that engage with ethics generally prescribe only abstract approaches by which designers might consider values in the design process. However, there is little guidance on methods that promote value discovery, which might lead to more specific examples of relevant values in specific design contexts. In this paper, we elaborate a method for value discovery, identifying how values impact the designer\u2019s decision making. We demonstrate the use of this method, called Ethicography, in describing value discovery and use throughout the design process. We present analysis of design activity by user experience (UX) design students in two lab protocol conditions, describing specific human values that designers considered for each task, and visualizing the interplay of these values. We identify opportunities for further research, using the Ethicograph method to illustrate value discovery and translation into design solutions.", "keywords": ["process", "based", "vsd", "time", "brand", "need", "information", "design", "method", "analysis", "store", "provide", "user", "decision", "work", "product", "engage", "impact", "participant", "use", "group", "increase", "identify", "page", "experience", "existing", "form", "identified", "provided", "task", "practice", "protocol", "solution", "designer", "approach", "ethic", "donation", "address", "discovery", "focused", "website", "hci", "paper", "value", "considered", "making"], "document_vector": [44.934421, 28.781507], "paragraphs": [{"paragraph_vector": [110.876197, -25.490398], "paragraph_keywords": ["design", "value", "values", "copies"]}, {"paragraph_vector": [104.530632, -22.09984], "paragraph_keywords": ["design", "value", "values", "discovery"]}, {"paragraph_vector": [106.771972, -22.339614], "paragraph_keywords": ["work", "design", "ethics", "values"]}, {"paragraph_vector": [104.695884, -25.82998], "paragraph_keywords": ["design", "values", "value", "vsd"]}, {"paragraph_vector": [104.805992, -20.117895], "paragraph_keywords": ["design", "values", "hci", "practice"]}, {"paragraph_vector": [103.434043, -21.240076], "paragraph_keywords": ["design", "participants", "protocol", "task"]}, {"paragraph_vector": [71.076843, -22.592079], "paragraph_keywords": ["participants", "charity", "design", "task"]}, {"paragraph_vector": [108.971389, 43.713912], "paragraph_keywords": ["participants", "design", "analysis", "solutions"]}, {"paragraph_vector": [102.904891, -23.333429], "paragraph_keywords": ["design", "value", "values", "decisions"]}, {"paragraph_vector": [106.307952, -20.912349], "paragraph_keywords": ["values", "design", "protocol", "speech"]}, {"paragraph_vector": [77.924041, -23.644113], "paragraph_keywords": ["information", "participants", "user", "value"]}, {"paragraph_vector": [75.617988, -29.961723], "paragraph_keywords": ["information", "user", "donate", "users"]}, {"paragraph_vector": [76.549217, -27.578449], "paragraph_keywords": ["button", "groups", "form", "participants"]}, {"paragraph_vector": [105.757461, 57.220172], "paragraph_keywords": ["form", "user", "mentioned", "page"]}, {"paragraph_vector": [77.501869, -23.584316], "paragraph_keywords": ["value", "design", "group", "user"]}, {"paragraph_vector": [78.747711, -26.216482], "paragraph_keywords": ["design", "users", "group", "security"]}, {"paragraph_vector": [73.076789, -20.296504], "paragraph_keywords": ["brand", "store", "page", "solutions"]}, {"paragraph_vector": [45.119022, -22.31879], "paragraph_keywords": ["store", "brand", "information", "group"]}, {"paragraph_vector": [77.723442, -21.992729], "paragraph_keywords": ["information", "brand", "participants", "user"]}, {"paragraph_vector": [77.867835, -19.093673], "paragraph_keywords": ["brand", "page", "users", "store"]}, {"paragraph_vector": [79.089271, -22.911384], "paragraph_keywords": ["participants", "users", "group", "buy"]}, {"paragraph_vector": [97.748321, -23.117204], "paragraph_keywords": ["design", "participants", "interplay", "value"]}, {"paragraph_vector": [103.806556, -24.593654], "paragraph_keywords": ["values", "design", "users", "designers"]}, {"paragraph_vector": [106.483894, -21.187122], "paragraph_keywords": ["design", "ethics", "value", "values"]}, {"paragraph_vector": [112.680999, -13.865453], "paragraph_keywords": ["design", "practice", "values", "value"]}, {"paragraph_vector": [122.466545, -39.704467], "paragraph_keywords": ["ethics", "thank", "like", "rhea"]}], "content": {}, "doi": "10.1145/3290605.3300245"}, {"uri": "270", "title": "Designing User Interface Elements to Improve the Quality and Civility of Discourse in Online Commenting Behaviors", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Joseph Seering"], "summary": "Ensuring high-quality, civil social interactions remains a vexing challenge in many online spaces. In the present work, we introduce a novel approach to address this problem: using psychologically \u201cembedded\u201d CAPTCHAs containing stimuli intended to prime positive emotions and mindsets. An exploratory randomized experiment (N = 454 Mechanical Turk workers) tested the impact of eight new CAPTCHA designs implemented on a simulated, politically charged comment thread. Results revealed that the two interventions that were the most successful at activating positive affect also significantly increased the positivity of tone and analytical complexity of argumentation in participants\u2019 responses. A focused follow-up experiment (N = 120 Mechanical Turk workers) revealed that exposure to CAPTCHAs featuring image sets previously validated to evoke low-arousal positive emotions significantly increased the positivity of sentiment and the levels of complexity and social connectedness in participants\u2019 posts. We offer several explanations for these results and discuss the practical and ethical implications of designing interfaces to influence discourse in online forums. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300836 CCS CONCEPTS \u2022Human-centered computing\u2192 Empirical studies in HCI;", "keywords": ["complexity", "process", "condition", "change", "time", "set", "self", "intended", "design", "literature", "reported", "user", "commenting", "interaction", "intervention", "captchas", "work", "result", "impact", "persuasion", "participant", "use", "drawing", "designed", "post", "effect", "sentiment", "utilizing", "control", "state", "page", "number", "tone", "content", "found", "including", "comment", "task", "affect", "study", "approach", "researcher", "priming", "image", "text", "research", "influence", "paper", "interface", "site", "captcha", "behavior", "utilized", "level", "response"], "document_vector": [-70.679321, 46.763156], "paragraphs": [{"paragraph_vector": [37.461769, -37.650127], "paragraph_keywords": ["comment", "sites", "behaviors", "harassment"]}, {"paragraph_vector": [38.767051, -38.405948], "paragraph_keywords": ["interventions", "study", "users", "work"]}, {"paragraph_vector": [39.822368, -41.626838], "paragraph_keywords": ["design", "approaches", "detection", "behaviors"]}, {"paragraph_vector": [93.973381, -71.966194], "paragraph_keywords": ["content", "users", "impact", "approach"]}, {"paragraph_vector": [38.085971, -29.969413], "paragraph_keywords": ["change", "users", "work", "persuasion"]}, {"paragraph_vector": [39.823524, -35.294887], "paragraph_keywords": ["priming", "stimulus", "techniques", "presented"]}, {"paragraph_vector": [34.378025, -39.211692], "paragraph_keywords": ["priming", "self", "study", "task"]}, {"paragraph_vector": [31.926919, -39.570075], "paragraph_keywords": ["users", "captchas", "process", "content"]}, {"paragraph_vector": [39.109909, -35.50175], "paragraph_keywords": ["users", "comment", "captchas", "process"]}, {"paragraph_vector": [35.84103, -39.021617], "paragraph_keywords": ["comments", "post", "users", "blog"]}, {"paragraph_vector": [42.048019, 4.636056], "paragraph_keywords": ["text", "wick", "interventions", "reporting"]}, {"paragraph_vector": [34.590412, -36.959182], "paragraph_keywords": ["captcha", "users", "version", "figure"]}, {"paragraph_vector": [31.317407, -30.311149], "paragraph_keywords": ["captcha", "participants", "comment", "study"]}, {"paragraph_vector": [35.491737, -35.860916], "paragraph_keywords": ["comment", "participants", "comments", "options"]}, {"paragraph_vector": [40.06607, -39.673751], "paragraph_keywords": ["think", "captcha", "sentiment", "pay"]}, {"paragraph_vector": [39.220436, -40.363777], "paragraph_keywords": ["tone", "captcha", "comments", "rating"]}, {"paragraph_vector": [32.394165, -34.452938], "paragraph_keywords": ["participants", "affect", "fish", "results"]}, {"paragraph_vector": [34.755195, -37.082145], "paragraph_keywords": ["affect", "self", "captchas", "states"]}, {"paragraph_vector": [32.650669, -36.808151], "paragraph_keywords": ["image", "study", "images", "condition"]}, {"paragraph_vector": [35.884624, -36.888935], "paragraph_keywords": ["participants", "captcha", "condition", "control"]}, {"paragraph_vector": [38.465332, -38.330718], "paragraph_keywords": ["priming", "interventions", "participants", "arousal"]}, {"paragraph_vector": [36.873538, -36.894176], "paragraph_keywords": ["priming", "behaviors", "work", "use"]}, {"paragraph_vector": [36.900226, -38.319713], "paragraph_keywords": ["participants", "persuasion", "design", "questions"]}, {"paragraph_vector": [40.626907, -30.991436], "paragraph_keywords": ["research", "design", "thank", "believe"]}], "content": {}, "doi": "10.1145/3290605.3300506"}, {"uri": "271", "title": "Lost in Style: Gaze-driven Adaptive Aid for VR Navigation", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Rawan Alghofaili", "George Mason", "Haikun Huang", "Yasuhito Sawahata"], "summary": "A key challenge for virtual reality level designers is striking a balance between maintaining the immersiveness of VR and providing users with on-screen aids after designing a virtual experience. These aids are often necessary for wayfnding in virtual environments with complex paths. We introduce a novel adaptive aid that maintains the effectiveness of traditional aids, while equipping designers and users with the controls of how often help is displayed. Our adaptive aid uses gaze patterns in predicting user\u2019s need for navigation aid in VR and displays mini-maps or arrows accordingly. Using a dataset of gaze angle sequences of users navigating a VR environment and markers of when users requested aid, we trained an LSTM to classify user\u2019s gaze sequences as needing navigation help and display an aid. We validated the efcacy of the adaptive aid for wayfnding compared to other commonly-used wayfnding aids. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for proft or commercial advantage and that copies bear this notice and the full citation on the frst page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specifc permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland Uk \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300578 CCS CONCEPTS \u2022 Human-centered computing \u2192 Virtual reality.", "keywords": ["sequence", "navigation", "vr", "point", "time", "al", "need", "set", "classifer", "scene", "training", "environment", "subject", "gaze", "help", "user", "accuracy", "model", "frustration", "eye", "sample", "et", "participant", "compared", "-", "tracking", "head", "task", "shown", "data", "study", "approach", "starting", "map", "pattern", "aid", "navigating", "reality", "arrow", "mini", "city", "level", "figure"], "document_vector": [-152.717803, -41.153114], "paragraphs": [{"paragraph_vector": [-61.868282, -2.065703], "paragraph_keywords": ["vr", "tracking", "reality", "eye"]}, {"paragraph_vector": [-59.294952, -0.172107], "paragraph_keywords": ["gaze", "navigation", "analyzed", "aids"]}, {"paragraph_vector": [-101.247062, 28.213794], "paragraph_keywords": ["vr", "navigation", "ar", "players"]}, {"paragraph_vector": [-61.568172, 0.233114], "paragraph_keywords": ["gaze", "navigation", "eye", "classifer"]}, {"paragraph_vector": [-58.317703, 1.568308], "paragraph_keywords": ["participant", "fruit", "shown", "city"]}, {"paragraph_vector": [-58.151153, -0.667323], "paragraph_keywords": ["gaze", "participant", "angle", "session"]}, {"paragraph_vector": [-58.126338, -0.647297], "paragraph_keywords": ["sequences", "gaze", "samples", "window"]}, {"paragraph_vector": [-59.843982, -1.504835], "paragraph_keywords": ["network", "training", "data", "validation"]}, {"paragraph_vector": [-58.166275, -4.033537], "paragraph_keywords": ["navigation", "aid", "model", "samples"]}, {"paragraph_vector": [-59.120086, 0.267989], "paragraph_keywords": ["aid", "user", "navigation", "gaze"]}, {"paragraph_vector": [-61.029056, 8.0623], "paragraph_keywords": ["starting", "scene", "task", "tasks"]}, {"paragraph_vector": [-58.160362, 10.547255], "paragraph_keywords": ["participants", "aid", "point", "task"]}, {"paragraph_vector": [-56.473552, 1.852226], "paragraph_keywords": ["frustration", "navigation", "reported", "aid"]}, {"paragraph_vector": [-56.27568, 5.910352], "paragraph_keywords": ["participants", "map", "arrow", "aid"]}, {"paragraph_vector": [-58.216266, 2.079766], "paragraph_keywords": ["arrow", "aid", "gaze", "participants"]}, {"paragraph_vector": [-58.173435, 0.002936], "paragraph_keywords": ["participants", "navigation", "vr", "scene"]}, {"paragraph_vector": [-60.552322, -1.061671], "paragraph_keywords": ["users", "eye", "fove", "navigation"]}, {"paragraph_vector": [-57.739635, 1.009215], "paragraph_keywords": ["subjects", "aid", "navigation", "users"]}, {"paragraph_vector": [-58.435577, -1.459189], "paragraph_keywords": ["navigation", "user", "aid", "help"]}], "content": {}, "doi": "10.1145/3290605.3300329"}, {"uri": "272", "title": "Unintended Consonances: Methods to Understand Robot Motor Sound Perception", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Dylan Moore", "Ingunn Berget", "Tobias Dahl", "Paula Varela", "Wendy Ju", "Tormod N\u00e6s"], "summary": "Recent research suggests that a robot\u2019s motors make sounds that can influence users\u2019 perception of the robot\u2019s characteristics. To more deeply understand users\u2019 associations with specific sonic characteristics, we adapted methods from sensory science including Check All That Apply (CATA) questions and Polarized Sensory Positioning (PSP) to tease out small differences in motor sounds in an online survey. These methods are straightforward for untrained people to do in an online setting, mathematically rigorous, and can explore a variety of subtle auditory and perceptual stimuli. We describe how to use these methods, interpret the results with several intuitive visual representations, and show that the results align with a previous study of the same dataset. We close by discussing benefits and limitations of applying these methods to study subtle phenomena in the HCI community.", "keywords": ["set", "design", "method", "analysis", "mfa", "describe", "user", "comparison", "interaction", "sample", "work", "word", "space", "motor", "participant", "cata", "use", "product", "result", "applied", "analyzed", "consumer", "page", "sound", "survey", "understand", "science", "robot", "table", "data", "study", "variable", "reference", "characteristic", "psp", "difference", "quality", "hci", "evaluate", "paper", "context", "figure"], "document_vector": [13.697576, -46.383041], "paragraphs": [{"paragraph_vector": [-83.032546, -12.888898], "paragraph_keywords": ["sound", "interaction", "systems", "design"]}, {"paragraph_vector": [-82.161705, -11.039371], "paragraph_keywords": ["sound", "hci", "science", "methods"]}, {"paragraph_vector": [-88.991287, -14.248531], "paragraph_keywords": ["sounds", "sound", "motor", "robot"]}, {"paragraph_vector": [-82.537483, -11.55826], "paragraph_keywords": ["sound", "sounds", "car", "neighbor"]}, {"paragraph_vector": [26.491363, -22.503463], "paragraph_keywords": ["based", "consumers", "attributes", "products"]}, {"paragraph_vector": [-80.529487, -10.622927], "paragraph_keywords": ["sounds", "survey", "methods", "psp"]}, {"paragraph_vector": [-76.878318, -9.113734], "paragraph_keywords": ["sounds", "participants", "variables", "sound"]}, {"paragraph_vector": [-79.696464, -9.842823], "paragraph_keywords": ["sound", "sounds", "participant", "questions"]}, {"paragraph_vector": [-76.967651, -10.148686], "paragraph_keywords": ["data", "mfa", "words", "package"]}, {"paragraph_vector": [-79.662399, -10.020162], "paragraph_keywords": ["sound", "participants", "data", "cata"]}, {"paragraph_vector": [-78.707183, -11.669654], "paragraph_keywords": ["sound", "participants", "data", "survey"]}, {"paragraph_vector": [-78.833679, -11.081998], "paragraph_keywords": ["sounds", "sound", "words", "figure"]}, {"paragraph_vector": [-78.571624, -12.807913], "paragraph_keywords": ["methods", "dimension", "variables", "psp"]}, {"paragraph_vector": [-79.783203, -9.809881], "paragraph_keywords": ["sound", "sounds", "data", "fit"]}, {"paragraph_vector": [-77.171051, -13.19358], "paragraph_keywords": ["cata", "methods", "data", "study"]}, {"paragraph_vector": [-79.446632, -11.587583], "paragraph_keywords": ["design", "samples", "psp", "user"]}, {"paragraph_vector": [-78.711418, -10.49665], "paragraph_keywords": ["data", "samples", "cata", "sounds"]}, {"paragraph_vector": [-80.114868, -10.729444], "paragraph_keywords": ["sounds", "methods", "design", "sound"]}, {"paragraph_vector": [-79.919723, -10.557965], "paragraph_keywords": ["methods", "help", "motor", "distinctions"]}], "content": {}, "doi": "10.1145/3290605.3300496"}, {"uri": "273", "title": "Continuous Evaluation of Video Lectures from Real-Time Difficulty Self-Report", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Namrata Srivastava", "Jason M. Lodge", "Sarah Erfani"], "summary": "With the increased reach and impact of video lectures, it is crucial to understand how they are experienced. Whereas previous studies typically present questionnaires at the end of the lecture, they fail to capture students\u2019 experience in enough granularity. In this paper we propose recording the lecture difficulty in real-time with a physical slider, enabling continuous and fine-grained analysis of the learning experience. We evaluated our approach in a study with 100 participants viewing two variants of two short lectures. We demonstrate that our approach helps us paint a more complete picture of the learning experience. Our analysis has design implications for instructors, providing them with a method that helps them compare their expectations with students\u2019 beliefs about the lectures and to better understand the specific effects of different instructional design decisions.", "keywords": ["based", "point", "time", "slider", "design", "analysis", "experiment", "neuroscience", "learner", "work", "video", "participant", "use", "identify", "learning", "compared", "page", "difficulty", "slide", "series", "segment", "found", "version", "answer", "data", "study", "student", "animation", "text", "research", "term", "instructor", "paper", "question", "rating", "lecture", "level"], "document_vector": [-128.01802, 34.470336], "paragraphs": [{"paragraph_vector": [21.106597, -0.347704], "paragraph_keywords": ["video", "learning", "lectures", "copies"]}, {"paragraph_vector": [18.486362, -1.364611], "paragraph_keywords": ["lecture", "time", "reactions", "use"]}, {"paragraph_vector": [19.262283, -2.274113], "paragraph_keywords": ["video", "time", "lecture", "ratings"]}, {"paragraph_vector": [21.218233, 0.218532], "paragraph_keywords": ["lecture", "students", "video", "level"]}, {"paragraph_vector": [17.964513, -1.276467], "paragraph_keywords": ["students", "video", "measuring", "level"]}, {"paragraph_vector": [20.335578, -1.690896], "paragraph_keywords": ["video", "participants", "lectures", "neuroscience"]}, {"paragraph_vector": [20.612361, -1.341149], "paragraph_keywords": ["participants", "text", "slider", "slide"]}, {"paragraph_vector": [-79.557487, -12.638449], "paragraph_keywords": ["lecture", "participants", "asked", "answer"]}, {"paragraph_vector": [20.494047, -1.502472], "paragraph_keywords": ["lecture", "video", "questionnaire", "procedure"]}, {"paragraph_vector": [20.499792, -0.067632], "paragraph_keywords": ["lecture", "difficulty", "participants", "design"]}, {"paragraph_vector": [19.202398, -1.019973], "paragraph_keywords": ["difficulty", "slide", "effort", "ratings"]}, {"paragraph_vector": [21.04169, -1.865688], "paragraph_keywords": ["difficulty", "segment", "questions", "ratings"]}, {"paragraph_vector": [20.097942, -1.149999], "paragraph_keywords": ["difficulty", "participants", "instructor", "lecture"]}, {"paragraph_vector": [18.448444, -2.495616], "paragraph_keywords": ["lecture", "terms", "correlation", "slides"]}, {"paragraph_vector": [20.249826, -1.303488], "paragraph_keywords": ["ratings", "difficulty", "video", "points"]}, {"paragraph_vector": [19.454437, -1.879498], "paragraph_keywords": ["lecture", "lectures", "compared", "participants"]}, {"paragraph_vector": [20.175226, -1.313173], "paragraph_keywords": ["difficulty", "lecture", "ratings", "found"]}, {"paragraph_vector": [19.575126, -0.13383], "paragraph_keywords": ["difficulty", "based", "examples", "explanation"]}, {"paragraph_vector": [19.489549, -1.683868], "paragraph_keywords": ["study", "difficulty", "students", "sample"]}, {"paragraph_vector": [18.5102, -0.297441], "paragraph_keywords": ["data", "participants", "difficulty", "research"]}], "content": {}, "doi": "10.1145/3290605.3300630"}, {"uri": "274", "title": "Text Entry Throughput Towards Unifying Speed and Accuracy in a Single Performance Metric", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Mingrui \u201cRay\u201d Zhang", "Shumin Zhai", "Jacob O. Wobbrock"], "summary": "Human-computer input performance inherently involves speedaccuracy tradeoffs\u2014the faster users act, the more inaccurate those actions are. Therefore, comparing speeds and accuracies separately can result in ambiguous outcomes: Does a fast but inaccurate technique perform better or worse overall than a slow but accurate one? For pointing, speed and accuracy has been unified for over 60 years as throughput (bits/s) (Crossman 1957, Welford 1968), but to date, no similar metric has been established for text entry. In this paper, we introduce a text entry methodindependent throughput metric based on Shannon information theory (1948). To explore the practical usability of the metric, we conducted an experiment in which 16 participants typed with a laptop keyboard using different cognitive sets, i.e., speed-accuracy biases. Our results show that as a performance metric, text entry throughput remains relatively stable under different speedaccuracy conditions. We also evaluated a smartphone keyboard with 12 participants, finding that throughput varied least compared to other text entry metrics. This work allows researchers to characterize text entry performance with a single unified measure of input efficiency.", "keywords": ["metric", "throughput", "point", "condition", "time", "insertion", "information", "ea", "set", "performance", "source", "speed", "rate", "method", "experiment", "error", "example", "entry", "accuracy", "keyboard", "type", "work", "word", "participant", "use", "probability", "adjwpm", "character", "measure", "phrase", "string", "text", "typing", "transmission", "paper", "ef", "p", "laptop"], "document_vector": [-61.638038, -51.498592], "paragraphs": [{"paragraph_vector": [-16.111507, -7.196033], "paragraph_keywords": ["entry", "speed", "text", "methods"]}, {"paragraph_vector": [-12.177896, -8.929449], "paragraph_keywords": ["text", "information", "entry", "input"]}, {"paragraph_vector": [-14.060472, -3.988943], "paragraph_keywords": ["accuracy", "speed", "text", "pointing"]}, {"paragraph_vector": [-17.346374, -3.392312], "paragraph_keywords": ["throughput", "speed", "adjwpm", "accuracy"]}, {"paragraph_vector": [-14.425196, -6.739462], "paragraph_keywords": ["throughput", "entry", "characters", "time"]}, {"paragraph_vector": [-14.201489, -7.673976], "paragraph_keywords": ["text", "entry", "metric", "message"]}, {"paragraph_vector": [-12.939593, -7.556162], "paragraph_keywords": ["information", "source", "transmission", "channel"]}, {"paragraph_vector": [-13.108362, -8.511727], "paragraph_keywords": ["errors", "symbol", "text", "character"]}, {"paragraph_vector": [-12.95023, -7.191273], "paragraph_keywords": ["character", "source", "information", "errors"]}, {"paragraph_vector": [-11.539149, -7.430125], "paragraph_keywords": ["character", "transmission", "probabilities", "information"]}, {"paragraph_vector": [-11.929562, -6.634557], "paragraph_keywords": ["insertion", "probability", "substitution", "character"]}, {"paragraph_vector": [-12.887729, -8.027542], "paragraph_keywords": ["entry", "character", "east", "characters"]}, {"paragraph_vector": [-14.569586, -10.04329], "paragraph_keywords": ["throughput", "participants", "entry", "laptop"]}, {"paragraph_vector": [-18.06545, -6.987856], "paragraph_keywords": ["phrase", "keyboard", "laptop", "entry"]}, {"paragraph_vector": [-18.2646, 0.696406], "paragraph_keywords": ["participants", "condition", "phrases", "sets"]}, {"paragraph_vector": [-18.337396, -6.633649], "paragraph_keywords": ["participants", "points", "phrase", "condition"]}, {"paragraph_vector": [-18.228424, -6.766633], "paragraph_keywords": ["condition", "points", "score", "table"]}, {"paragraph_vector": [-17.507953, -5.442695], "paragraph_keywords": ["speed", "ef", "throughput", "participants"]}, {"paragraph_vector": [-16.587034, -4.267621], "paragraph_keywords": ["throughput", "speed", "adjwpm", "showed"]}, {"paragraph_vector": [-17.671377, -0.038494], "paragraph_keywords": ["conditions", "speed", "throughput", "data"]}, {"paragraph_vector": [-18.696596, -9.844339], "paragraph_keywords": ["conditions", "difference", "speed", "condition"]}, {"paragraph_vector": [-16.84159, -8.011088], "paragraph_keywords": ["throughput", "performance", "condition", "word"]}, {"paragraph_vector": [-14.958863, -6.932238], "paragraph_keywords": ["throughput", "error", "entry", "text"]}, {"paragraph_vector": [-13.7056, -6.554767], "paragraph_keywords": ["throughput", "speed", "accuracy", "work"]}], "content": {}, "doi": "10.1145/3290605.3300621"}, {"uri": "275", "title": "Brick: Toward A Model for Designing Synchronous Colocated Augmented Reality Games", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Po Bhattacharyya", "Radha Nath"], "summary": "Augmented reality (AR) games have been growing in popularity in recent years. However, current AR games ofer limited opportunities for a synchronous multiplayer experience. This paper introduces a model for designing AR experiences in which players inhabit a shared, real-time augmented environment and can engage in synchronous and collaborative interactions with other players. We explored the development of this model through the creation of Brick, a two-player mobile AR game at the room scale. We refned Brick over multiple rounds of iteration, and we used our playtests to investigate a range of issues involved in designing sharedworld AR games. Our fndings suggest that there are fve major categories of interactions in a shared-world AR system: single-player, intrapersonal, multiplayer, interpersonal, and environmental. We believe that this model can support the development of collaborative AR games and new forms of social gameplay.", "keywords": ["process", "based", "time", "involve", "object", "playtests", "player", "design", "opportunity", "example", "designing", "model", "user", "interaction", "shared", "work", "pick", "movement", "create", "proximity", "screen", "world", "state", "experience", "page", "augmented", "gameplay", "scale", "multiplayer", "game", "room", "pattern", "ar", "reality", "brick", "include", "paper"], "document_vector": [144.660949, -8.339784], "paragraphs": [{"paragraph_vector": [-123.498344, -13.331742], "paragraph_keywords": ["games", "players", "copies", "work"]}, {"paragraph_vector": [-123.235137, -21.853359], "paragraph_keywords": ["ar", "shared", "interactions", "world"]}, {"paragraph_vector": [-125.727798, -23.843746], "paragraph_keywords": ["games", "ar", "devices", "players"]}, {"paragraph_vector": [-121.523307, -18.925241], "paragraph_keywords": ["ar", "design", "user", "games"]}, {"paragraph_vector": [-123.319664, -18.182062], "paragraph_keywords": ["game", "players", "design", "ar"]}, {"paragraph_vector": [-127.394409, -12.445114], "paragraph_keywords": ["bricks", "players", "game", "brick"]}, {"paragraph_vector": [-125.271652, -21.478403], "paragraph_keywords": ["game", "brick", "participants", "fdelity"]}, {"paragraph_vector": [-125.639839, -14.515169], "paragraph_keywords": ["interactions", "model", "quotes", "player"]}, {"paragraph_vector": [-122.577049, -13.078764], "paragraph_keywords": ["players", "interaction", "pick", "bricks"]}, {"paragraph_vector": [-124.283294, -14.158687], "paragraph_keywords": ["players", "bricks", "brick", "interactions"]}, {"paragraph_vector": [-122.870635, -13.723548], "paragraph_keywords": ["players", "interactions", "game", "multiplayer"]}, {"paragraph_vector": [-126.677459, -11.306766], "paragraph_keywords": ["players", "game", "player", "brick"]}, {"paragraph_vector": [-125.37606, -14.450118], "paragraph_keywords": ["pattern", "players", "room", "bricks"]}, {"paragraph_vector": [-125.002021, -11.129434], "paragraph_keywords": ["players", "bricks", "brick", "ar"]}, {"paragraph_vector": [-124.382446, -13.353632], "paragraph_keywords": ["players", "proximity", "interaction", "ar"]}, {"paragraph_vector": [-123.236419, -16.386669], "paragraph_keywords": ["players", "interactions", "fatigue", "ar"]}, {"paragraph_vector": [-124.070755, -13.78345], "paragraph_keywords": ["players", "ar", "shared", "world"]}, {"paragraph_vector": [176.184616, 14.538008], "paragraph_keywords": ["brick", "time", "openness", "feedback"]}], "content": {}, "doi": "10.1145/3290605.3300564"}, {"uri": "276", "title": "Modeling the Engagement-Disengagement Cycle of Compulsive Phone Use", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jonathan A. Tran", "Katherine S. Yang", "Katie Davis", "Alexis Hiniker"], "summary": "Many smartphone users engage in compulsive and habitual phone checking they fnd frustrating, yet our understanding of how this phenomenon is experienced is limited. We conducted a semi-structured interview, a think-aloud phoneuse demonstration, and a sketching exercise with 39 smartphone users (ages 14\u201364) to probe their experiences with compulsive phone checking. Their insights revealed a small taxonomy of common triggers that lead up to instances of compulsive phone use and a second set that end compulsive phone use sessions. Though participants expressed frustration with their lack of self-control, they also reported that the activities they engage in during these sessions can be meaningful, which they defned as transcending the current instance of use. Participants said they periodically refect on their compulsive use and delete apps that drive compulsive checking without providing sufcient meaning. We use these fndings to create a descriptive model of the cycle of compulsive checking, and we call on designers to craft experiences that meet users\u2019 defnition of meaningfulness rather than creating lock-out mechanisms to help them police their own use.", "keywords": ["lead", "time", "change", "fnd", "need", "moment", "phone", "self", "design", "app", "specifc", "habit", "thing", "medium", "user", "activity", "school", "addiction", "apps", "work", "engage", "use", "participant", "people", "investment", "way", "think", "sense", "experience", "page", "felt", "college", "life", "usage", "check", "described", "checking", "pattern", "said", "adult", "session", "meaning", "explained", "asked", "paper", "saying", "behavior"], "document_vector": [-18.843101, 68.709915], "paragraphs": [{"paragraph_vector": [-116.728988, -63.089366], "paragraph_keywords": ["users", "checking", "phone", "phones"]}, {"paragraph_vector": [-121.869575, -61.657154], "paragraph_keywords": ["use", "phone", "users", "participants"]}, {"paragraph_vector": [-20.886192, -52.365901], "paragraph_keywords": ["addiction", "colleagues", "activities", "use"]}, {"paragraph_vector": [-128.583755, -60.606697], "paragraph_keywords": ["users", "use", "design", "patterns"]}, {"paragraph_vector": [-122.983261, -61.314853], "paragraph_keywords": ["use", "design", "patterns", "people"]}, {"paragraph_vector": [5.655871, -82.293678], "paragraph_keywords": ["participants", "college", "adults", "adolescents"]}, {"paragraph_vector": [-125.920997, -70.476074], "paragraph_keywords": ["phone", "use", "participants", "asked"]}, {"paragraph_vector": [-177.646224, -68.355926], "paragraph_keywords": ["asked", "change", "app", "participant"]}, {"paragraph_vector": [-122.643898, -64.672172], "paragraph_keywords": ["phone", "time", "participants", "themes"]}, {"paragraph_vector": [-122.449989, -65.932258], "paragraph_keywords": ["phone", "check", "participants", "things"]}, {"paragraph_vector": [-121.353118, -63.674221], "paragraph_keywords": ["phone", "participants", "check", "checking"]}, {"paragraph_vector": [-124.626541, -62.849063], "paragraph_keywords": ["phone", "check", "sessions", "participants"]}, {"paragraph_vector": [-173.203933, -63.70169], "paragraph_keywords": ["minutes", "time", "things", "phone"]}, {"paragraph_vector": [-124.199707, -63.731292], "paragraph_keywords": ["explained", "checking", "phone", "participants"]}, {"paragraph_vector": [-123.267288, -64.177047], "paragraph_keywords": ["checking", "day", "time", "told"]}, {"paragraph_vector": [-122.050109, -61.78115], "paragraph_keywords": ["youtube", "time", "participant", "deleted"]}, {"paragraph_vector": [-122.614189, -63.494697], "paragraph_keywords": ["time", "app", "use", "stopped"]}, {"paragraph_vector": [-120.482826, -60.930461], "paragraph_keywords": ["use", "apps", "people", "app"]}, {"paragraph_vector": [-120.851615, -63.095306], "paragraph_keywords": ["use", "participants", "phone", "apps"]}, {"paragraph_vector": [-123.192169, -63.413669], "paragraph_keywords": ["phone", "participants", "use", "phones"]}, {"paragraph_vector": [-124.998664, -61.680248], "paragraph_keywords": ["use", "self", "participants", "meaning"]}, {"paragraph_vector": [-122.679687, -63.034408], "paragraph_keywords": ["tools", "lock", "use", "self"]}, {"paragraph_vector": [149.958053, -55.302864], "paragraph_keywords": ["use", "users", "usage", "time"]}, {"paragraph_vector": [-121.878463, -63.444358], "paragraph_keywords": ["phone", "use", "checking", "fndings"]}, {"paragraph_vector": [-118.687538, -62.980709], "paragraph_keywords": ["phone", "use", "factor", "investment"]}], "content": {}, "doi": "10.1145/3290605.3300324"}, {"uri": "277", "title": "Long-Term Value of Social Robots through the Eyes of Expert Users", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Dmitry Dereshev", "David Kirk"], "summary": "Socially-enabled digital technologies have attracted academic interest for decades, with recent commercial examples of Siri and Alexa, capturing public attention. However, despite ubiquitous visions of a robotic future, very few fully-fledged social robots are currently available to consumers. To improve their designs, studies of their long-term use are particularly valuable, but are currently unavailable. To address this gap, we report on interviews with four long-term users of Pepper a social robot introduced in 2014. Our thematic analysis elicited insights across three kinds of value Pepper brought to its users: utilitarian functionality; the community that formed around Pepper; and a personal value of affection. We focus on two contributions those values bring to social robot design: social robots as social proxies, alleviating disabilities or acting akin to social media profiles; and robot nurturing as a design construct, going beyond purely utilitarian or hedonistic perspectives on robots.", "keywords": ["ipas", "time", "acceptance", "perceived", "information", "development", "behaviour", "expectation", "allow", "design", "companion", "interview", "care", "example", "user", "interaction", "communication", "work", "participant", "use", "people", "explored", "perception", "pleo", "given", "related", "personification", "voice", "page", "existing", "year", "pointed", "nurturing", "university", "form", "providing", "kind", "robot", "life", "task", "pepper", "device", "novelty", "study", "owner", "pattern", "framework", "research", "difference", "term", "question", "highlighted", "value", "month"], "document_vector": [91.579139, -7.477205], "paragraphs": [{"paragraph_vector": [-134.674133, -1.967266], "paragraph_keywords": ["robots", "copies", "acm", "research"]}, {"paragraph_vector": [-134.933944, -2.635007], "paragraph_keywords": ["robot", "use", "acceptance", "frameworks"]}, {"paragraph_vector": [-138.079101, -2.414767], "paragraph_keywords": ["pepper", "robots", "robot", "users"]}, {"paragraph_vector": [-136.784988, -1.414731], "paragraph_keywords": ["pepper", "robot", "participants", "robots"]}, {"paragraph_vector": [-134.987167, -0.960824], "paragraph_keywords": ["use", "personification", "companion", "ipas"]}, {"paragraph_vector": [-133.209457, -0.121447], "paragraph_keywords": ["ipas", "studies", "use", "users"]}, {"paragraph_vector": [-134.343597, -1.510934], "paragraph_keywords": ["robots", "robot", "differences", "explored"]}, {"paragraph_vector": [-136.50296, -3.388131], "paragraph_keywords": ["robot", "robots", "gestures", "people"]}, {"paragraph_vector": [-136.421493, -1.780891], "paragraph_keywords": ["robot", "robots", "time", "explore"]}, {"paragraph_vector": [119.019676, -45.609466], "paragraph_keywords": ["participants", "pepper", "university", "interview"]}, {"paragraph_vector": [123.455314, -44.988853], "paragraph_keywords": ["pepper", "value", "participants", "analysis"]}, {"paragraph_vector": [-135.290832, -3.007642], "paragraph_keywords": ["pepper", "participants", "people", "apps"]}, {"paragraph_vector": [-134.601425, -6.069953], "paragraph_keywords": ["pepper", "participants", "time", "value"]}, {"paragraph_vector": [-134.668777, -3.874312], "paragraph_keywords": ["pepper", "people", "participants", "time"]}, {"paragraph_vector": [-135.054931, -3.063759], "paragraph_keywords": ["pepper", "participants", "recording", "parents"]}, {"paragraph_vector": [-135.674804, -3.942791], "paragraph_keywords": ["pepper", "participants", "time", "sense"]}, {"paragraph_vector": [-134.93489, -0.589336], "paragraph_keywords": ["pepper", "robot", "attachment", "time"]}, {"paragraph_vector": [-134.00711, -1.414669], "paragraph_keywords": ["robots", "people", "pepper", "telepresence"]}, {"paragraph_vector": [-135.684143, -0.541361], "paragraph_keywords": ["robots", "robot", "participants", "owners"]}, {"paragraph_vector": [-136.915252, -2.315975], "paragraph_keywords": ["robot", "robots", "users", "work"]}, {"paragraph_vector": [-137.099792, -2.100039], "paragraph_keywords": ["robots", "pepper", "study", "proxies"]}, {"paragraph_vector": [-137.492553, -2.80902], "paragraph_keywords": ["designers", "developed", "approaches", "nurtured"]}], "content": {}, "doi": "10.1145/3290605.3300469"}, {"uri": "278", "title": "The Magic Machine Workshops", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Kristina Andersen", "Ron Wakkary"], "summary": "New technologies emerge into an increasingly complex everyday life. How can we engage users further into material practices that explore ideas and notions of these new things? This paper proposes a set of qualities for short, intense, workshop-like experiences, created to generate strong individual commitments, and expose underlying personal desires as drivers for ideas. By making use of open-ended making to engage participants in the imagination of new things, we aim to allow a broad range of knowledge to materialise, focused on the making of work that is about technology, rather than of technology.", "keywords": ["process", "facilitator", "strategy", "time", "vision", "moment", "set", "performance", "selection", "self", "design", "technique", "provide", "opportunity", "focus", "thing", "user", "facilitate", "workshop", "work", "engage", "space", "language", "participant", "use", "create", "word", "material", "concern", "group", "way", "challenge", "idea", "sense", "step", "experience", "page", "existing", "form", "-", "embodied", "attention", "hand", "technology", "aim", "research", "machine", "outcome", "built", "paper", "knowledge", "context", "figure", "making"], "document_vector": [81.380187, 17.123975], "paragraphs": [{"paragraph_vector": [117.518753, -38.776603], "paragraph_keywords": ["design", "copies", "participants", "research"]}, {"paragraph_vector": [130.086654, 0.947307], "paragraph_keywords": ["outcomes", "design", "participants", "visions"]}, {"paragraph_vector": [139.098373, 3.525616], "paragraph_keywords": ["participants", "workshops", "workshop", "user"]}, {"paragraph_vector": [136.961227, 2.953362], "paragraph_keywords": ["design", "participants", "approaches", "use"]}, {"paragraph_vector": [136.788299, 7.812643], "paragraph_keywords": ["strategies", "workshop", "point", "design"]}, {"paragraph_vector": [136.789566, 3.860153], "paragraph_keywords": ["material", "making", "machines", "steps"]}, {"paragraph_vector": [141.883621, 8.938949], "paragraph_keywords": ["workshop", "paper", "introduction", "participants"]}, {"paragraph_vector": [124.070251, -11.580677], "paragraph_keywords": ["participants", "drawing", "provides", "prompt"]}, {"paragraph_vector": [146.529403, 10.823495], "paragraph_keywords": ["materials", "selection", "drawing", "provided"]}, {"paragraph_vector": [111.255935, -2.7397], "paragraph_keywords": ["workshop", "design", "participants", "participant"]}, {"paragraph_vector": [136.383544, 9.092191], "paragraph_keywords": ["moment", "process", "ideas", "participants"]}, {"paragraph_vector": [117.526481, -11.774771], "paragraph_keywords": ["participants", "work", "machine", "prototypes"]}, {"paragraph_vector": [139.023437, 10.215206], "paragraph_keywords": ["set", "making", "effect", "language"]}, {"paragraph_vector": [119.828071, -1.096621], "paragraph_keywords": ["questions", "machine", "object", "participant"]}, {"paragraph_vector": [127.485839, 3.633704], "paragraph_keywords": ["workshop", "participants", "machine", "process"]}, {"paragraph_vector": [127.02272, -9.880218], "paragraph_keywords": ["participants", "technology", "workshops", "space"]}, {"paragraph_vector": [-134.752792, 0.474117], "paragraph_keywords": ["robot", "magic", "technology", "machine"]}, {"paragraph_vector": [147.640808, 7.221251], "paragraph_keywords": ["materials", "material", "form", "participant"]}, {"paragraph_vector": [120.824623, 3.059585], "paragraph_keywords": ["time", "participant", "participants", "materials"]}, {"paragraph_vector": [124.533554, -6.171053], "paragraph_keywords": ["design", "taking", "process", "work"]}, {"paragraph_vector": [134.452301, 3.481589], "paragraph_keywords": ["design", "knowledge", "participants", "frame"]}, {"paragraph_vector": [133.763977, 5.321589], "paragraph_keywords": ["outcomes", "workshops", "process", "making"]}, {"paragraph_vector": [107.917419, -14.266699], "paragraph_keywords": ["participants", "design", "experience", "workshops"]}, {"paragraph_vector": [137.445144, 3.46422], "paragraph_keywords": ["participants", "design", "content", "making"]}], "content": {}, "doi": "10.1145/3290605.3300521"}, {"uri": "279", "title": "Discovering Alternative Treatments for Opioid Use Recovery Using Social Media", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Stevie Chancellor"], "summary": "Opioid use disorder (OUD) poses substantial risks to personal well-being and public health. In online communities, users support those seeking recovery, in part by promoting clinically grounded treatments. However, some communities also promote clinically unverified OUD treatments, such as unregulated and untested drugs. Little research exists on which alternative treatments people use, whether these treatments are effective for recovery, or if they cause negative side effects. We provide the first large-scale social media study of clinically unverified, alternative treatments in OUD recovery on Reddit, partnering with an addiction research scientist. We adopt transfer learning across 63 subreddits to precisely identify posts related to opioid recovery. Then, we quantitatively discover potential alternative treatments and contextualize their effectiveness. Our work benefits health research and practice by identifying undiscovered recovery strategies.We also discuss the impacts to online communities dealing with stigmatized behavior and research ethics.", "keywords": ["transfer", "clinician", "stigmatizing", "al", "reddit", "heroin", "analysis", "substance", "embeddings", "stigma", "kratom", "medium", "user", "model", "intervention", "addiction", "et", "risk", "work", "word", "use", "withdrawal", "post", "identify", "subreddit", "opioids", "health", "learning", "classifier", "insight", "treatment", "imodium", "related", "page", "dataset", "subreddits", "labeled", "recovery", "identified", "including", "drug", "abuse", "data", "researcher", "symptom", "approach", "study", "at", "support", "oud", "research", "r", "individual", "paper", "behavior", "harm", "community"], "document_vector": [-70.875175, 66.535179], "paragraphs": [{"paragraph_vector": [65.380546, -20.461202], "paragraph_keywords": ["recovery", "use", "opioids", "copies"]}, {"paragraph_vector": [63.210334, -16.979654], "paragraph_keywords": ["use", "oud", "recovery", "ats"]}, {"paragraph_vector": [64.231552, -19.331966], "paragraph_keywords": ["ats", "recovery", "oud", "use"]}, {"paragraph_vector": [63.250106, -18.553768], "paragraph_keywords": ["cause", "opioids", "users", "use"]}, {"paragraph_vector": [64.457229, -16.803421], "paragraph_keywords": ["ats", "kratom", "studies", "recovery"]}, {"paragraph_vector": [65.668449, -15.704647], "paragraph_keywords": ["use", "drug", "abuse", "al"]}, {"paragraph_vector": [62.895782, -14.254528], "paragraph_keywords": ["recovery", "use", "support", "ats"]}, {"paragraph_vector": [64.275917, -14.454393], "paragraph_keywords": ["subreddit", "subreddits", "recovery", "related"]}, {"paragraph_vector": [66.488098, -17.591051], "paragraph_keywords": ["posts", "recovery", "data", "r"]}, {"paragraph_vector": [64.190246, -17.056835], "paragraph_keywords": ["posts", "r", "drug", "recovery"]}, {"paragraph_vector": [66.429725, -15.271736], "paragraph_keywords": ["recovery", "ats", "learning", "embeddings"]}, {"paragraph_vector": [65.103858, -16.50988], "paragraph_keywords": ["recovery", "model", "use", "transfer"]}, {"paragraph_vector": [64.523773, -16.910108], "paragraph_keywords": ["recovery", "classifier", "posts", "correlated"]}, {"paragraph_vector": [68.236747, -15.670912], "paragraph_keywords": ["recovery", "oud", "opioids", "identified"]}, {"paragraph_vector": [64.955299, -17.485258], "paragraph_keywords": ["drugs", "recovery", "use", "benzodiazepines"]}, {"paragraph_vector": [65.635543, -17.561216], "paragraph_keywords": ["kratom", "withdrawal", "recovery", "imodium"]}, {"paragraph_vector": [67.001205, -19.358869], "paragraph_keywords": ["imodium", "withdrawal", "users", "oud"]}, {"paragraph_vector": [66.583435, -16.456617], "paragraph_keywords": ["clinicians", "recovery", "oud", "ats"]}, {"paragraph_vector": [63.439945, -16.42513], "paragraph_keywords": ["recovery", "ats", "patients", "stigma"]}, {"paragraph_vector": [63.961704, -17.207775], "paragraph_keywords": ["communities", "behaviors", "recovery", "stigmatizing"]}, {"paragraph_vector": [64.497772, -16.695325], "paragraph_keywords": ["interventions", "intervention", "oud", "behaviors"]}, {"paragraph_vector": [63.890258, -18.642095], "paragraph_keywords": ["data", "research", "recovery", "work"]}, {"paragraph_vector": [60.918613, -26.054851], "paragraph_keywords": ["identify", "data", "ats", "risks"]}, {"paragraph_vector": [63.537063, -18.201002], "paragraph_keywords": ["work", "recovery", "use", "ats"]}, {"paragraph_vector": [63.653491, -18.06258], "paragraph_keywords": ["recovery", "researchers", "learning", "use"]}], "content": {}, "doi": "10.1145/3290605.3300643"}, {"uri": "280", "title": "Older People Inventing their Personal Internet of Things with the IoT Un-Kit Experience", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Aloha Hufana Ambe", "Margot Brereton", "Alessandro Soro", "Min Zhen Chai", "Laurie Buys", "Paul Roe"], "summary": "We introduce the IoT Un-Kit Experience, a co-design approach that engages people in exploring, designing and generating personally meaningful IoT applications and that also serves as a means to explore IoT kit design through in-home workshops. Un-Kit represents a seemingly uncompleted set of sensors, actuators and media elements that have a decontextualized appearance unfinished state, undefined purpose and unboxed form. The approach emphasises users contemplating and experiencing the IoT elements in their familiar space through detailed and layered conversation with researchers; rather than focusing on connecting up the kit itself, thus their ideas are not constrained by the kit or their competence with it. We illustrate the approach through in-home workshops with older adults, envisioned users of IoT who have had limited voice in its conception. The Un-kit approach supported participants to lead the process and to imagine new artfully integrated designs, with personally legible interactions and aesthetic qualities that fit their desire. We offer insights for a more situated and responsive approach to design of the IoT and its constituent kits.", "keywords": ["process", "explore", "time", "al", "need", "object", "design", "component", "actuator", "home", "conversation", "environment", "garden", "focus", "wanted", "relationship", "sensor", "co", "medium", "user", "interaction", "workshop", "et", "work", "participant", "use", "card", "people", "detail", "team", "way", "idea", "iot", "experience", "page", "found", "sound", "form", "fig", "ann", "family", "bird", "want", "connect", "moisture", "technology", "approach", "element", "passion", "un", "routine", "support", "val", "kit", "research", "quality", "order", "prototype", "paper", "daughter", "context", "community", "making"], "document_vector": [75.343383, 6.357306], "paragraphs": [{"paragraph_vector": [-112.077995, -53.18843], "paragraph_keywords": ["elements", "people", "copies", "approach"]}, {"paragraph_vector": [-115.589416, -56.524318], "paragraph_keywords": ["people", "design", "kit", "create"]}, {"paragraph_vector": [-110.284118, -55.195003], "paragraph_keywords": ["design", "toolkits", "approach", "kits"]}, {"paragraph_vector": [-106.950019, -53.151256], "paragraph_keywords": ["data", "users", "toolkit", "kit"]}, {"paragraph_vector": [-99.382904, 49.032066], "paragraph_keywords": ["components", "approach", "learning", "skills"]}, {"paragraph_vector": [-112.19432, -56.955005], "paragraph_keywords": ["design", "people", "technology", "technologies"]}, {"paragraph_vector": [-108.205253, -54.772003], "paragraph_keywords": ["technology", "people", "needs", "al"]}, {"paragraph_vector": [-110.877899, -55.66119], "paragraph_keywords": ["elements", "un", "approach", "person"]}, {"paragraph_vector": [-109.71566, -51.647838], "paragraph_keywords": ["sensors", "programming", "bluetooth", "types"]}, {"paragraph_vector": [-80.214508, -60.061893], "paragraph_keywords": ["ann", "participants", "detail", "child"]}, {"paragraph_vector": [-69.770744, -63.749382], "paragraph_keywords": ["val", "ann", "home", "facebook"]}, {"paragraph_vector": [-98.172851, -47.95771], "paragraph_keywords": ["participant", "cards", "participants", "showing"]}, {"paragraph_vector": [-117.387161, -54.721664], "paragraph_keywords": ["participant", "prototype", "design", "team"]}, {"paragraph_vector": [-111.413314, -60.250579], "paragraph_keywords": ["elements", "people", "themes", "objects"]}, {"paragraph_vector": [-103.311843, -58.064773], "paragraph_keywords": ["environment", "relationships", "objects", "qualities"]}, {"paragraph_vector": [-106.196578, -56.415622], "paragraph_keywords": ["prototype", "garden", "way", "cooking"]}, {"paragraph_vector": [-99.363998, -51.824935], "paragraph_keywords": ["val", "scarecrow", "know", "motion"]}, {"paragraph_vector": [-96.969581, -63.108482], "paragraph_keywords": ["ann", "people", "want", "time"]}, {"paragraph_vector": [-87.649848, -39.608142], "paragraph_keywords": ["daughter", "birds", "ann", "community"]}, {"paragraph_vector": [-98.631546, -59.365024], "paragraph_keywords": ["ann", "fig", "family", "relationships"]}, {"paragraph_vector": [-95.241065, -49.079235], "paragraph_keywords": ["sound", "wanted", "moisture", "sensor"]}, {"paragraph_vector": [-100.826774, -50.672954], "paragraph_keywords": ["elements", "design", "participant", "kit"]}, {"paragraph_vector": [-102.969932, -53.533023], "paragraph_keywords": ["cards", "people", "details", "iot"]}, {"paragraph_vector": [-99.952941, -61.679584], "paragraph_keywords": ["home", "participants", "design", "ideas"]}, {"paragraph_vector": [-107.101753, -57.385112], "paragraph_keywords": ["design", "ideas", "elements", "designs"]}, {"paragraph_vector": [-108.024475, -56.230243], "paragraph_keywords": ["kits", "kit", "un", "people"]}, {"paragraph_vector": [-106.667007, -57.036216], "paragraph_keywords": ["kit", "components", "un", "kits"]}, {"paragraph_vector": [-110.868125, -53.71651], "paragraph_keywords": ["users", "people", "kit", "use"]}, {"paragraph_vector": [-105.254676, -56.025348], "paragraph_keywords": ["iot", "design", "people", "elements"]}], "content": {}, "doi": "10.1145/3290605.3300904"}, {"uri": "281", "title": "Understanding Personal Productivity", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Young-Ho Kim", "Eun Kyoung Choe", "Bongshin Lee", "Jinwook Seo"], "summary": "Productivity tracking tools often determine productivity based on the time interacting with work-related applications. To deconstruct productivity\u2019s diverse and nebulous nature, we investigate how knowledge workers conceptualize personal productivity and delimit productive tasks in both work and non-work contexts. We report a 2-week diary study followed by a semi-structured interview with 24 knowledge workers. Participants captured productive activities and provided the rationale for why the activities were assessed to be productive. They reported a wide range of productive activities beyond typical desk-bound work\u2014ranging from having a personal conversation with dad to getting a haircut. We found six themes that characterize the productivity assessment\u2014work product, time management, worker\u2019s state, attitude toward work, impact & benefit, and compound task\u2014and identified how participants interleaved multiple facets when assessing their productivity. We discuss how these findings could inform the design of a comprehensive productivity tracking system that covers a wide range of productive activities.", "keywords": ["capture", "time", "perceived", "worker", "self", "design", "reported", "duration", "app", "category", "example", "entry", "having", "activity", "hour", "included", "work", "tool", "evaluation", "participant", "use", "people", "captured", "related", "factor", "automated", "page", "output", "number", "productivity", "identified", "tracking", "task", "efficiency", "device", "diary", "data", "study", "approach", "journal", "paper", "job", "behavior", "knowledge", "level", "context", "considered", "making", "benefit"], "document_vector": [-33.47076, -9.093318], "paragraphs": [{"paragraph_vector": [121.480949, -24.299306], "paragraph_keywords": ["productivity", "tracking", "workers", "copies"]}, {"paragraph_vector": [122.971656, -21.545776], "paragraph_keywords": ["productivity", "work", "activities", "knowledge"]}, {"paragraph_vector": [123.321601, -22.214302], "paragraph_keywords": ["productivity", "work", "knowledge", "workers"]}, {"paragraph_vector": [124.78421, -22.959688], "paragraph_keywords": ["productivity", "people", "work", "task"]}, {"paragraph_vector": [123.918128, -25.026313], "paragraph_keywords": ["data", "study", "people", "tracking"]}, {"paragraph_vector": [121.605041, -26.784494], "paragraph_keywords": ["participants", "productivity", "capture", "study"]}, {"paragraph_vector": [123.542846, -25.847459], "paragraph_keywords": ["participants", "journal", "entries", "productivity"]}, {"paragraph_vector": [120.128601, -20.135961], "paragraph_keywords": ["entries", "task", "productivity", "coded"]}, {"paragraph_vector": [123.92086, -23.367033], "paragraph_keywords": ["entries", "productivity", "activities", "participants"]}, {"paragraph_vector": [121.463462, -18.861652], "paragraph_keywords": ["output", "progress", "participants", "making"]}, {"paragraph_vector": [126.184234, -22.557401], "paragraph_keywords": ["participants", "time", "tasks", "counseling"]}, {"paragraph_vector": [124.058883, -23.376493], "paragraph_keywords": ["participants", "task", "condition", "productivity"]}, {"paragraph_vector": [124.58216, -8.300395], "paragraph_keywords": ["career", "participants", "benefit", "decision"]}, {"paragraph_vector": [140.520507, -25.226936], "paragraph_keywords": ["activities", "participants", "task", "tasks"]}, {"paragraph_vector": [104.16259, -10.481979], "paragraph_keywords": ["participants", "task", "categories", "design"]}, {"paragraph_vector": [124.162322, -23.65125], "paragraph_keywords": ["productivity", "activities", "people", "tools"]}, {"paragraph_vector": [125.585716, -21.830444], "paragraph_keywords": ["work", "activities", "related", "productivity"]}, {"paragraph_vector": [124.604072, -21.897243], "paragraph_keywords": ["productivity", "tasks", "participants", "relationship"]}, {"paragraph_vector": [124.163436, -22.996133], "paragraph_keywords": ["tracking", "automated", "tracker", "capture"]}, {"paragraph_vector": [123.348953, -23.421033], "paragraph_keywords": ["productivity", "work", "data", "participants"]}, {"paragraph_vector": [72.438049, 30.252033], "paragraph_keywords": ["nsf", "award", "gift", "erb"]}], "content": {}, "doi": "10.1145/3290605.3300383"}, {"uri": "282", "title": "Dynamic Network Plaid", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Alexandra Lee", "Daniel Archambault"], "summary": "Network data that changes over time can be very useful for studying a wide range of important phenomena, from how social network connections change to epidemiology. However, it is challenging to analyze, especially if it has many actors, connections or if the covered timespan is large with rapidly changing links (e.g., months of changes with changes at second resolution). In these analyses one would often like to comparemany periods of time to others, without having to look at the full timeline. To support this kind of analysis we designed and implemented a technique and system to visualize this dynamic data. The Dynamic Network Plaid (DNP) is designed for large displays and based on user-generated interactive timeslicing on the dynamic graph attributes and on linked provenance-preserving representations. We present the technique, interface and the design/evaluation with a group of public health researchers investigating non-suicidal self-harm picture sharing in Instagram.", "keywords": ["timeslice", "based", "time", "information", "node", "grade", "timeline", "analyst", "self", "display", "feature", "design", "analysis", "timeslices", "user", "activity", "wound", "interaction", "work", "space", "participant", "use", "group", "screen", "dnp", "graph", "way", "provenance", "actor", "link", "visualization", "page", "number", "dataset", "representation", "vignette", "data", "researcher", "element", "approach", "support", "system", "network", "event", "image", "row", "compare", "interface", "harm", "figure"], "document_vector": [-119.871917, 59.708194], "paragraphs": [{"paragraph_vector": [-137.371612, 86.408996], "paragraph_keywords": ["time", "copies", "computing", "user"]}, {"paragraph_vector": [-166.951065, 86.466491], "paragraph_keywords": ["time", "dataset", "space", "visualization"]}, {"paragraph_vector": [-149.367477, 87.062759], "paragraph_keywords": ["time", "graph", "space", "graphs"]}, {"paragraph_vector": [-172.092071, 85.165672], "paragraph_keywords": ["time", "visualization", "user", "based"]}, {"paragraph_vector": [-65.90184, 83.079505], "paragraph_keywords": ["displays", "visualization", "time", "user"]}, {"paragraph_vector": [60.544406, -20.967763], "paragraph_keywords": ["harm", "self", "dataset", "data"]}, {"paragraph_vector": [33.859962, 89.211494], "paragraph_keywords": ["data", "time", "analysis", "network"]}, {"paragraph_vector": [176.515594, 83.626907], "paragraph_keywords": ["data", "challenges", "support", "analysis"]}, {"paragraph_vector": [173.89772, 83.880004], "paragraph_keywords": ["researchers", "observation", "data", "use"]}, {"paragraph_vector": [-123.748847, 82.039886], "paragraph_keywords": ["rows", "time", "interface", "data"]}, {"paragraph_vector": [-162.846084, 84.661193], "paragraph_keywords": ["timeline", "node", "slice", "timeslices"]}, {"paragraph_vector": [155.802566, 83.61061], "paragraph_keywords": ["timeslice", "vignettes", "vignette", "node"]}, {"paragraph_vector": [-176.421691, 85.499092], "paragraph_keywords": ["rows", "time", "figure", "nodes"]}, {"paragraph_vector": [-171.684112, 82.026428], "paragraph_keywords": ["node", "vignettes", "nodes", "selected"]}, {"paragraph_vector": [172.421188, 86.950416], "paragraph_keywords": ["node", "nodes", "way", "data"]}, {"paragraph_vector": [148.272018, 68.242019], "paragraph_keywords": ["dataset", "dnp", "elements", "data"]}, {"paragraph_vector": [166.093551, 81.629211], "paragraph_keywords": ["interface", "participants", "session", "research"]}, {"paragraph_vector": [178.537811, 85.261032], "paragraph_keywords": ["peak", "activity", "timelines", "data"]}, {"paragraph_vector": [158.622238, 84.626045], "paragraph_keywords": ["vignette", "analysts", "image", "answers"]}, {"paragraph_vector": [-174.299438, 86.468994], "paragraph_keywords": ["actor", "time", "features", "session"]}, {"paragraph_vector": [161.281433, 85.347297], "paragraph_keywords": ["analysts", "vignette", "activity", "clusters"]}, {"paragraph_vector": [-175.087036, 85.780975], "paragraph_keywords": ["analysts", "dnp", "procedures", "workflows"]}, {"paragraph_vector": [-175.284118, 85.372322], "paragraph_keywords": ["provenance", "analysis", "researchers", "interaction"]}, {"paragraph_vector": [178.287948, 85.387298], "paragraph_keywords": ["dnp", "data", "display", "visualizations"]}, {"paragraph_vector": [-95.806861, 86.652809], "paragraph_keywords": ["dnp", "user", "node", "visualization"]}, {"paragraph_vector": [176.160934, 87.191818], "paragraph_keywords": ["potential", "interaction", "techniques", "university"]}], "content": {}, "doi": "10.1145/3290605.3300476"}, {"uri": "283", "title": "May AI?", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Janin Koch", "Andr\u00e9s Lucero", "Lena Hegemann", "Antti Oulasvirta"], "summary": "Design ideation is a prime creative activity in design. However, it is challenging to support computationally due to its quickly evolving and exploratory nature. The paper presents cooperative contextual bandits (CCB) as a machine-learning method for interactive ideation support. A CCB can learn to propose domain-relevant contributions and adapt their exploration/exploitation strategy. We developed a CCB for an interactive design ideation tool that 1) suggests inspirational and situationally relevant materials (\u201cmay AI?\u201d); 2) explores and exploits inspirational materials with the designer; and 3) explains its suggestions to aid reflection. The application case of digital mood board design is presented, wherein visual inspirational materials are collected and curated in collages. In a controlled study, 14 of 16 professional designers preferred the CCB-augmented tool. The CCB approach holds promise for ideation activities wherein adaptive and steerable support is welcome but designers must retain full outcome control.", "keywords": ["process", "based", "strategy", "time", "vector", "perceived", "condition", "association", "ability", "slice", "design", "feature", "suggestion", "exploitation", "help", "user", "exploration", "added", "ccb", "bandit", "work", "result", "tool", "space", "use", "participant", "probability", "learning", "related", "idea", "ai", "page", "algorithm", "agent", "feedback", "fig", "described", "task", "search", "approach", "designer", "ideation", "color", "image", "system", "support", "presented", "adapt", "mood", "asked", "paper", "panel", "board", "context"], "document_vector": [39.101818, -6.421236], "paragraphs": [{"paragraph_vector": [131.564392, 51.62807], "paragraph_keywords": ["design", "support", "learning", "copies"]}, {"paragraph_vector": [133.137771, 53.459644], "paragraph_keywords": ["designers", "board", "making", "mood"]}, {"paragraph_vector": [132.448257, 52.100025], "paragraph_keywords": ["designer", "support", "system", "mood"]}, {"paragraph_vector": [137.164749, 49.388492], "paragraph_keywords": ["user", "time", "drawing", "approach"]}, {"paragraph_vector": [141.129501, 60.024936], "paragraph_keywords": ["tool", "finding", "canvas", "users"]}, {"paragraph_vector": [136.15982, 53.575798], "paragraph_keywords": ["panel", "images", "image", "search"]}, {"paragraph_vector": [136.327301, 53.94852], "paragraph_keywords": ["image", "features", "board", "mood"]}, {"paragraph_vector": [143.917327, 42.796932], "paragraph_keywords": ["bandit", "arm", "lever", "algorithm"]}, {"paragraph_vector": [128.294418, 53.027622], "paragraph_keywords": ["agents", "strategy", "suggestion", "context"]}, {"paragraph_vector": [121.816093, 56.360168], "paragraph_keywords": ["suggestion", "strategy", "agent", "agents"]}, {"paragraph_vector": [134.049774, 55.071678], "paragraph_keywords": ["strategy", "space", "color", "agent"]}, {"paragraph_vector": [134.082199, 54.463108], "paragraph_keywords": ["ai", "feature", "probability", "strategy"]}, {"paragraph_vector": [134.756835, 54.546657], "paragraph_keywords": ["image", "designer", "prompt", "contrast"]}, {"paragraph_vector": [135.486343, 51.822608], "paragraph_keywords": ["mood", "time", "boards", "suggestions"]}, {"paragraph_vector": [132.587249, 54.990455], "paragraph_keywords": ["ai", "design", "use", "tool"]}, {"paragraph_vector": [136.867004, 52.471286], "paragraph_keywords": ["tool", "interview", "ability", "ccb"]}, {"paragraph_vector": [131.950744, 50.976238], "paragraph_keywords": ["ai", "condition", "effect", "mood"]}, {"paragraph_vector": [136.552947, 55.479347], "paragraph_keywords": ["tool", "ai", "system", "image"]}, {"paragraph_vector": [132.521133, 52.918323], "paragraph_keywords": ["system", "ai", "suggestions", "following"]}, {"paragraph_vector": [138.298416, 49.344097], "paragraph_keywords": ["ai", "images", "teenager", "suggest"]}, {"paragraph_vector": [143.261322, 48.44997], "paragraph_keywords": ["suggestions", "think", "participants", "bit"]}, {"paragraph_vector": [141.789505, 53.158542], "paragraph_keywords": ["suggestions", "ccb", "ability", "reflect"]}, {"paragraph_vector": [135.518997, 53.355155], "paragraph_keywords": ["system", "ideation", "participants", "designer"]}, {"paragraph_vector": [137.828643, 48.233177], "paragraph_keywords": ["design", "ccb", "choreography", "music"]}, {"paragraph_vector": [141.857757, 46.565135], "paragraph_keywords": ["research", "european", "work", "grant"]}], "content": {}, "doi": "10.1145/3290605.3300614"}, {"uri": "284", "title": "Virtual Hubs", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jandy Luik"], "summary": "We have recently seen the emergence of new platforms that aim to provide remotely located entrepreneurs and startup companies with support analogous to that found within traditional incubation or acceleration spaces. This paper offers an understanding of these \u2018virtual hubs\u2019, and the inherently socio-technical interactions that occur between their members. Our study analyzes a sample of existing virtual hubs in two stages. First, we contribute broader insight into the current landscape of virtual hubs by documenting and categorizing 25 hubs regarding their form, support offered and a selection of further qualities. Second, we contribute detailed insight into the operation and experience of such hubs, from an analysis of 10 semi-structured interviews with organizers and participants of virtual hubs. We conclude by analyzing our findings in terms of relational aspects of non-virtual hubs from the literature and remediation theory, and propose opportunities for advancing the design of such platforms.", "keywords": ["process", "based", "remediation", "time", "person", "set", "incubator", "organizer", "interview", "stage", "provide", "opportunity", "example", "mentorship", "incubation", "model", "activity", "aspect", "included", "sample", "work", "tool", "space", "participant", "service", "way", "range", "challenge", "participation", "finding", "experience", "page", "hub", "found", "form", "business", "including", "acceleration", "developed", "study", "offer", "startup", "support", "platform", "program", "paper", "company", "knowledge", "access"], "document_vector": [144.385345, 56.158214], "paragraphs": [{"paragraph_vector": [-21.586194, -47.198417], "paragraph_keywords": ["copies", "incubation", "systems", "acm"]}, {"paragraph_vector": [-23.594442, -46.821659], "paragraph_keywords": ["hubs", "platforms", "participants", "support"]}, {"paragraph_vector": [-20.158264, -45.030525], "paragraph_keywords": ["incubation", "platforms", "incubators", "hubs"]}, {"paragraph_vector": [-22.385145, -46.780769], "paragraph_keywords": ["hubs", "support", "incubators", "incubation"]}, {"paragraph_vector": [-25.13726, -45.964405], "paragraph_keywords": ["media", "remediation", "hubs", "business"]}, {"paragraph_vector": [-22.701559, -45.294857], "paragraph_keywords": ["hubs", "stage", "support", "hub"]}, {"paragraph_vector": [-19.505504, -47.795936], "paragraph_keywords": ["hub", "hubs", "accelerator", "incubator"]}, {"paragraph_vector": [-23.635316, -45.634407], "paragraph_keywords": ["hubs", "interviews", "participants", "data"]}, {"paragraph_vector": [-23.013248, -45.390865], "paragraph_keywords": ["support", "hubs", "participants", "tools"]}, {"paragraph_vector": [-25.959131, -45.299564], "paragraph_keywords": ["hubs", "participants", "mentors", "included"]}, {"paragraph_vector": [-25.973928, -45.648326], "paragraph_keywords": ["time", "hubs", "interviews", "potential"]}, {"paragraph_vector": [-23.466444, -46.0802], "paragraph_keywords": ["hubs", "stage", "person", "way"]}, {"paragraph_vector": [-22.12886, -46.262855], "paragraph_keywords": ["model", "platform", "business", "strategies"]}, {"paragraph_vector": [-22.164249, -44.682929], "paragraph_keywords": ["program", "person", "combination", "user"]}, {"paragraph_vector": [86.130455, 9.483848], "paragraph_keywords": ["participants", "mentor", "time", "hub"]}, {"paragraph_vector": [-22.064229, -46.67612], "paragraph_keywords": ["process", "video", "hubs", "platforms"]}, {"paragraph_vector": [-20.740772, -48.005935], "paragraph_keywords": ["platform", "offer", "hubs", "entrepreneurs"]}, {"paragraph_vector": [-23.664484, -45.263065], "paragraph_keywords": ["hubs", "participants", "model", "seen"]}, {"paragraph_vector": [-22.389598, -46.432357], "paragraph_keywords": ["model", "hubs", "business", "service"]}, {"paragraph_vector": [-25.895696, -47.743434], "paragraph_keywords": ["hubs", "activities", "events", "person"]}, {"paragraph_vector": [-96.678718, -63.887542], "paragraph_keywords": ["hubs", "participants", "sharing", "interactions"]}, {"paragraph_vector": [-22.424455, -44.873077], "paragraph_keywords": ["incubation", "form", "challenges", "hubs"]}, {"paragraph_vector": [-24.049674, -44.472293], "paragraph_keywords": ["incubation", "hubs", "experience", "process"]}, {"paragraph_vector": [-22.751913, -45.065639], "paragraph_keywords": ["hubs", "incubation", "analysis", "participants"]}, {"paragraph_vector": [-21.141302, -46.461143], "paragraph_keywords": ["hubs", "participants", "incubation", "remediation"]}], "content": {}, "doi": "10.1145/3290605.3300417"}, {"uri": "285", "title": "\u201cWhat\u2019s Happening at that Hip?\u201d: Evaluating an On-body Projection based Augmented Reality System for Physiotherapy Classroom", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Hasan Shahid Ferdous", "Zaher Joukhadar", "Martin N Reinoso", "Frank Vetere", "David Kelly", "Louisa Remedios"], "summary": "We present two studies to discuss the design, usability analysis, and educational outcome resulting from our system Augmented Body in physiotherapy classroom. We build on prioruser-centricdesignwork that investigatesexisting teaching methods and discuss opportunities for intervention. We present the design and implementation of a hybrid system for physiotherapy education combining an on-body projection based virtual anatomy supplemented by pen-based tablets to create real-time annotations. We conducted a usability evaluation of this system, comparing with projection only and traditional teaching conditions. Finally, we focus on a comparative study to evaluate learning outcome among students in actual classroom settings. Our studies showed increased usage of visual representation techniques in students\u2019 note taking behavior and statistically significant improvement in some learning aspects. We discuss challenges for designing augmented reality systems for education, including minimizing attention split, addressing text-entry issues, and digital annotations on a moving physical body.", "keywords": ["tablet", "based", "condition", "information", "body", "class", "design", "muscle", "analysis", "annotation", "user", "model", "performed", "projection", "video", "movement", "use", "drawing", "participant", "usability", "load", "group", "issue", "learning", "visualization", "page", "compared", "score", "teacher", "note", "augmented", "content", "understanding", "teaching", "tracking", "motion", "developed", "test", "classroom", "volunteer", "data", "technology", "study", "testing", "student", "system", "ar", "pen", "outcome", "showed", "paper", "interface", "anatomy", "physiotherapy", "figure"], "document_vector": [171.618591, 4.820983], "paragraphs": [{"paragraph_vector": [-136.211502, 29.288143], "paragraph_keywords": ["systems", "information", "copies", "acm"]}, {"paragraph_vector": [-136.258453, 29.700769], "paragraph_keywords": ["ar", "based", "systems", "interactions"]}, {"paragraph_vector": [-136.848434, 30.019384], "paragraph_keywords": ["ar", "usability", "students", "based"]}, {"paragraph_vector": [-134.454238, 28.830533], "paragraph_keywords": ["interface", "system", "pen", "vr"]}, {"paragraph_vector": [-134.799316, 28.85642], "paragraph_keywords": ["annotations", "tablet", "annotation", "ar"]}, {"paragraph_vector": [-137.956954, 27.908279], "paragraph_keywords": ["study", "body", "sensor", "tracking"]}, {"paragraph_vector": [-132.702468, 28.494132], "paragraph_keywords": ["students", "body", "projection", "annotations"]}, {"paragraph_vector": [-132.306259, 26.395637], "paragraph_keywords": ["students", "paper", "projection", "teacher"]}, {"paragraph_vector": [-135.650085, 29.153793], "paragraph_keywords": ["test", "dimensions", "conditions", "effort"]}, {"paragraph_vector": [-135.02272, 28.518447], "paragraph_keywords": ["condition", "projection", "abbreviations", "compared"]}, {"paragraph_vector": [-123.728164, 31.647769], "paragraph_keywords": ["students", "body", "condition", "projection"]}, {"paragraph_vector": [-132.777221, 27.734287], "paragraph_keywords": ["muscle", "students", "teacher", "feature"]}, {"paragraph_vector": [-132.477447, 27.387546], "paragraph_keywords": ["interface", "students", "body", "projection"]}, {"paragraph_vector": [-134.998321, 29.026149], "paragraph_keywords": ["study", "students", "figure", "volunteer"]}, {"paragraph_vector": [-133.940368, 28.422033], "paragraph_keywords": ["students", "study", "teaching", "outcome"]}, {"paragraph_vector": [-137.420822, 30.71997], "paragraph_keywords": ["students", "test", "analysis", "annotation"]}, {"paragraph_vector": [-147.780105, 33.078479], "paragraph_keywords": ["mrt", "test", "students", "group"]}, {"paragraph_vector": [-135.583526, 28.190353], "paragraph_keywords": ["body", "projection", "test", "helped"]}, {"paragraph_vector": [-133.372009, 28.661212], "paragraph_keywords": ["body", "teacher", "use", "drawing"]}, {"paragraph_vector": [-133.639099, 27.989681], "paragraph_keywords": ["students", "movements", "videos", "muscles"]}, {"paragraph_vector": [-133.806289, 27.336702], "paragraph_keywords": ["muscle", "body", "students", "example"]}, {"paragraph_vector": [-136.484954, 29.320627], "paragraph_keywords": ["system", "projection", "body", "students"]}, {"paragraph_vector": [-136.443084, 28.739391], "paragraph_keywords": ["body", "tablet", "annotation", "students"]}, {"paragraph_vector": [-136.447006, 28.614809], "paragraph_keywords": ["study", "pen", "based", "projection"]}, {"paragraph_vector": [-136.384033, 30.389402], "paragraph_keywords": ["students", "projection", "learning", "body"]}, {"paragraph_vector": [-136.987884, 30.885835], "paragraph_keywords": ["learning", "contribution", "team", "optitrack"]}], "content": {}, "doi": "10.1145/3290605.3300432"}, {"uri": "286", "title": "An Exploration of Speech-Based Productivity Support in the Car", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Nikolas Martelaro", "Jaime Teevan", "Shamsi T. Iqbal"], "summary": "In-car intelligent assistants ofer the opportunity to help drivers productively use previously unclaimed time during their commute. However, engaging in secondary tasks can reduce attention on driving and thus may afect road safety. Any interface used while driving, even if speech-based, cannot consider non-driving tasks in isolation of driving\u2014alerts for safer driving and timing of the non-driving tasks are crucial to maintaining safety. In this work, we explore experiences with a speech-based assistant that attempts to help drivers safely complete complex productivity tasks. Via a controlled simulator study, we look at how level of support and road context alerts from the assistant infuence a driver\u2019s ability to drive safely while writing a document or creating slides via speech. Our results suggest ways to support speech-based productivity interactions and how speech-based road context alerts may infuence driver behavior.", "keywords": ["based", "time", "condition", "speech", "information", "performance", "safety", "writing", "drive", "assistant", "help", "headway", "road", "work", "result", "participant", "page", "felt", "productivity", "complete", "task", "car", "document", "distance", "attention", "study", "presentation", "microtasks", "support", "system", "lane", "event", "session", "driver", "question", "driving", "level", "context"], "document_vector": [-103.391845, -42.832241], "paragraphs": [{"paragraph_vector": [7.412795, 17.960168], "paragraph_keywords": ["driving", "drivers", "work", "copies"]}, {"paragraph_vector": [6.594213, 15.848996], "paragraph_keywords": ["driving", "drivers", "tasks", "speech"]}, {"paragraph_vector": [4.778869, 10.530856], "paragraph_keywords": ["drivers", "support", "driving", "task"]}, {"paragraph_vector": [7.821974, 14.587623], "paragraph_keywords": ["speech", "tasks", "systems", "driving"]}, {"paragraph_vector": [7.188811, 16.458168], "paragraph_keywords": ["task", "driving", "tasks", "drivers"]}, {"paragraph_vector": [6.110501, 13.88847], "paragraph_keywords": ["driving", "task", "support", "productivity"]}, {"paragraph_vector": [2.315543, 12.33848], "paragraph_keywords": ["car", "driver", "mph", "driving"]}, {"paragraph_vector": [3.717443, 11.869581], "paragraph_keywords": ["driver", "task", "events", "driving"]}, {"paragraph_vector": [3.249103, 11.343096], "paragraph_keywords": ["task", "presentation", "tasks", "participants"]}, {"paragraph_vector": [3.938011, 14.301458], "paragraph_keywords": ["completed", "task", "driver", "driving"]}, {"paragraph_vector": [3.707747, 10.875057], "paragraph_keywords": ["headway", "time", "distance", "crowdworkers"]}, {"paragraph_vector": [4.142749, 12.026334], "paragraph_keywords": ["road", "productivity", "driver", "participants"]}, {"paragraph_vector": [3.746739, 11.434177], "paragraph_keywords": ["driving", "drivers", "headway", "support"]}, {"paragraph_vector": [2.696334, 12.452682], "paragraph_keywords": ["drivers", "position", "lane", "support"]}, {"paragraph_vector": [3.868509, 11.056603], "paragraph_keywords": ["braking", "driving", "task", "drivers"]}, {"paragraph_vector": [1.678913, 11.383026], "paragraph_keywords": ["task", "session", "word", "count"]}, {"paragraph_vector": [2.523607, 11.327196], "paragraph_keywords": ["task", "driving", "felt", "drivers"]}, {"paragraph_vector": [3.3994, 11.332735], "paragraph_keywords": ["task", "support", "drivers", "session"]}, {"paragraph_vector": [4.387822, 12.321849], "paragraph_keywords": ["drivers", "preferred", "writing", "order"]}, {"paragraph_vector": [6.935394, 14.965811], "paragraph_keywords": ["support", "task", "thinking", "driving"]}, {"paragraph_vector": [3.734611, 11.787926], "paragraph_keywords": ["support", "task", "context", "productivity"]}, {"paragraph_vector": [4.800469, 10.346946], "paragraph_keywords": ["productivity", "task", "driving", "scenario"]}, {"paragraph_vector": [6.69005, 13.616533], "paragraph_keywords": ["drivers", "work", "load", "driving"]}, {"paragraph_vector": [2.344743, 10.312631], "paragraph_keywords": ["context", "support", "help", "drivers"]}], "content": {}, "doi": "10.1145/3290605.3300660"}, {"uri": "287", "title": "\u201cOccupational Therapy is Making\u201d: Clinical Rapid Prototyping and Digital Fabrication", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Megan Hofmann", "Kristin Williams", "Toni Kaplan", "Gabriella Hann", "Scott E. Hudson", "Stephanie Valencia"], "summary": "Consumer-fabrication technologies potentially improve the efectiveness and adoption of assistive technology (AT) by engaging AT users in AT creation. However, little is known about the role of clinicians in this revolution. We investigate clinical AT fabrication by working as expert fabricators for clinicians over a four-month period. We observed and codesigned AT with four occupational therapists at two clinics: a free clinic for uninsured clients, and a Veteran\u2019s Afairs Hospital. We fnd that existing fabrication processes, particularly with respect to rapid prototyping, do not align with clinical practice and its do-no-harm ethos. We recommend software solutions that would integrate into client care by: amplifying clinicians\u2019 expertise, revealing appropriate fabrication opportunities, and supporting adaptable fabrication.", "keywords": ["process", "transfer", "clinician", "time", "resource", "design", "ron", "splint", "pain", "ft", "expertise", "lorelai", "work", "tool", "diy", "use", "material", "clinic", "client", "maker", "pipe", "grip", "printing", "page", "prototyping", "existing", "cad", "dfo", "-", "therapy", "jon", "case", "practice", "device", "technology", "study", "researcher", "va", "pattern", "knife", "sara", "thumb", "support", "carbon", "julie", "ots", "research", "printed", "iteration", "fabrication", "board", "consumer", "access"], "document_vector": [77.782112, -26.791925], "paragraphs": [{"paragraph_vector": [25.433212, 39.697837], "paragraph_keywords": ["copies", "people", "acm", "work"]}, {"paragraph_vector": [25.272943, 35.821498], "paragraph_keywords": ["clinicians", "design", "ots", "fabrication"]}, {"paragraph_vector": [26.880229, 34.812473], "paragraph_keywords": ["design", "tools", "clinicians", "diy"]}, {"paragraph_vector": [26.610616, 36.03281], "paragraph_keywords": ["user", "tools", "fabrication", "clinicians"]}, {"paragraph_vector": [26.201379, 34.833908], "paragraph_keywords": ["fabrication", "tools", "benefts", "setting"]}, {"paragraph_vector": [26.682777, 34.772026], "paragraph_keywords": ["clinic", "ots", "design", "fabrication"]}, {"paragraph_vector": [24.624801, 34.524555], "paragraph_keywords": ["clinic", "julie", "design", "aford"]}, {"paragraph_vector": [27.214454, 35.215892], "paragraph_keywords": ["design", "resources", "fabrication", "clinic"]}, {"paragraph_vector": [23.57509, 34.167537], "paragraph_keywords": ["clinic", "client", "maker", "design"]}, {"paragraph_vector": [25.788162, 33.929355], "paragraph_keywords": ["splint", "ron", "thumb", "julie"]}, {"paragraph_vector": [25.961696, 34.385749], "paragraph_keywords": ["splint", "ron", "julie", "pain"]}, {"paragraph_vector": [26.006551, 33.405044], "paragraph_keywords": ["pattern", "splint", "patterns", "printed"]}, {"paragraph_vector": [24.790103, 32.337539], "paragraph_keywords": ["julie", "pattern", "software", "sara"]}, {"paragraph_vector": [24.780427, 34.759117], "paragraph_keywords": ["design", "splint", "maker", "julie"]}, {"paragraph_vector": [22.497425, 35.62569], "paragraph_keywords": ["jon", "lorelai", "grip", "knife"]}, {"paragraph_vector": [-79.889732, 56.731868], "paragraph_keywords": ["jon", "grip", "lorelai", "va"]}, {"paragraph_vector": [24.043704, 34.962848], "paragraph_keywords": ["design", "board", "tsa", "jon"]}, {"paragraph_vector": [-161.263427, -35.570854], "paragraph_keywords": ["carbon", "device", "fber", "pipes"]}, {"paragraph_vector": [24.172376, 32.12572], "paragraph_keywords": ["fabrication", "board", "transfer", "consumer"]}, {"paragraph_vector": [26.92732, 35.262489], "paragraph_keywords": ["design", "ots", "existing", "risks"]}, {"paragraph_vector": [25.049076, 33.902717], "paragraph_keywords": ["clinic", "fabrication", "designs", "clinicians"]}, {"paragraph_vector": [27.73645, 35.302169], "paragraph_keywords": ["design", "prototyping", "clinicians", "process"]}, {"paragraph_vector": [26.336679, 35.142726], "paragraph_keywords": ["clinicians", "materials", "researchers", "fabrication"]}, {"paragraph_vector": [25.579874, 35.675003], "paragraph_keywords": ["fabrication", "resources", "research", "dfo"]}, {"paragraph_vector": [68.282104, -18.243846], "paragraph_keywords": ["like", "clinicians", "fellowship", "nsf"]}], "content": {}, "doi": "10.1145/3290605.3300728"}, {"uri": "288", "title": "Critter: Augmenting Creative Work with Dynamic Checklists, Automated Quality Assurance, and Contextual Reviewer Feedback", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Aditya Bharadwaj"], "summary": "Checklists and guidelines have played an increasingly important role in complex tasks ranging from the cockpit to the operating theater. Their role in creative tasks like design is less explored. In a needfinding study with expert web designers, we identified designers\u2019 challenges in adhering to a checklist of design guidelines. We built Critter, which addressed these challenges with three components: Dynamic Checklists that progressively disclose guideline complexity with a self-pruning hierarchical view, AutoQA to automate common quality assurance checks, and guideline-specific feedback provided by a reviewer to highlight mistakes as they appear. In an observational study, we found that the more engaged a designer waswith Critter, the fewermistakes they made in following design guidelines. Designers rated the AutoQA and contextual feedback experience highly, and provided feedback on the tradeoffs of the hierarchical Dynamic Checklists. We additionally found that a majority of designers rated the AutoQA experience as excellent and felt that it increased the quality of their work. Finally, we discuss broader implications for supporting complex creative tasks.", "keywords": ["process", "based", "checker", "time", "self", "design", "assurance", "error", "expert", "example", "user", "allows", "work", "read", "use", "web", "mistake", "participant", "todos", "identify", "critter", "checklist", "automated", "experience", "page", "autoqa", "feedback", "reviewer", "provided", "task", "item", "study", "approach", "designer", "guideline", "customer", "system", "ensure", "quality", "website", "structure", "paper", "area", "project", "figure"], "document_vector": [21.278707, -10.931837], "paragraphs": [{"paragraph_vector": [106.196128, 49.179134], "paragraph_keywords": ["work", "quality", "copies", "design"]}, {"paragraph_vector": [100.587715, 52.46249], "paragraph_keywords": ["checklists", "design", "guidelines", "quality"]}, {"paragraph_vector": [103.6175, 48.227672], "paragraph_keywords": ["checklists", "guidelines", "checklist", "autoqa"]}, {"paragraph_vector": [102.442977, 49.941028], "paragraph_keywords": ["designers", "feedback", "website", "guidelines"]}, {"paragraph_vector": [102.068923, 49.770984], "paragraph_keywords": ["guidelines", "checklists", "checklist", "customer"]}, {"paragraph_vector": [102.277389, 50.125087], "paragraph_keywords": ["guidelines", "design", "designers", "approach"]}, {"paragraph_vector": [102.161552, 52.414119], "paragraph_keywords": ["design", "designers", "feedback", "work"]}, {"paragraph_vector": [106.544731, 52.305122], "paragraph_keywords": ["designers", "customer", "use", "checklists"]}, {"paragraph_vector": [104.09822, 48.599727], "paragraph_keywords": ["project", "designers", "feedback", "details"]}, {"paragraph_vector": [107.924224, 53.523616], "paragraph_keywords": ["todos", "checklist", "website", "page"]}, {"paragraph_vector": [104.291534, 52.406837], "paragraph_keywords": ["checkers", "autoqa", "feedback", "ensure"]}, {"paragraph_vector": [103.21817, 51.526153], "paragraph_keywords": ["feedback", "critter", "design", "designers"]}, {"paragraph_vector": [106.904785, 53.214889], "paragraph_keywords": ["designers", "checklist", "critter", "survey"]}, {"paragraph_vector": [103.888275, 53.475627], "paragraph_keywords": ["guidelines", "design", "designers", "quality"]}, {"paragraph_vector": [101.855331, 51.675296], "paragraph_keywords": ["designers", "mistakes", "items", "website"]}, {"paragraph_vector": [102.968086, 51.860122], "paragraph_keywords": ["items", "designers", "checklist", "functionality"]}, {"paragraph_vector": [99.912361, 51.176036], "paragraph_keywords": ["participants", "checklist", "designers", "recommendations"]}, {"paragraph_vector": [100.297523, 50.802753], "paragraph_keywords": ["items", "checklist", "designers", "read"]}, {"paragraph_vector": [105.185188, 52.589191], "paragraph_keywords": ["felt", "checklist", "autoqa", "helped"]}, {"paragraph_vector": [101.797485, 51.753898], "paragraph_keywords": ["work", "designers", "critter", "mistakes"]}, {"paragraph_vector": [102.700752, 50.463809], "paragraph_keywords": ["autoqa", "feedback", "errors", "self"]}, {"paragraph_vector": [107.406784, 51.063667], "paragraph_keywords": ["checklist", "guidelines", "experts", "programming"]}, {"paragraph_vector": [105.40892, 51.57418], "paragraph_keywords": ["code", "review", "aspects", "guide"]}], "content": {}, "doi": "10.1145/3290605.3300873"}, {"uri": "289", "title": "Patient Perspectives on Self-Management Technologies for Chronic Fatigue Syndrome", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Tabby Davies", "Simon L. Jones"], "summary": "Chronic Fatigue Syndrome (CFS) is a debilitatingmedical condition that is characterized by a range of physical, cognitive and social impairments. This paper investigates CFS patients\u2019 perspectives on the potential for technological support for self-management of their symptoms.We report findings from three studies in which people living with CFS 1) prioritized symptoms that they would like technologies to address, 2) articulated their current approaches to self-management alongside challenges they face, and 3) reflected on their experiences with three commercial smartphone apps related to symptom management. We contribute an understanding of the specific needs of the ME/CFS population and the ways in which they currently engage in self-management using technology. The paper ends by describing five high-level design recommendations for ME/CFS self-management technologies.", "keywords": ["condition", "time", "need", "reminder", "self", "design", "reported", "app", "feature", "avoid", "provide", "care", "disease", "help", "goal", "power", "user", "activity", "ups", "mindfulness", "apps", "work", "management", "sleep", "participant", "use", "patient", "people", "result", "pem", "way", "health", "energy", "related", "given", "lack", "page", "monitor", "number", "understanding", "found", "provided", "including", "tracking", "track", "task", "practice", "device", "described", "data", "day", "technology", "study", "cf", "symptom", "approach", "manage", "support", "research", "term", "paper", "fatigue", "pacing", "response"], "document_vector": [13.250253, 74.986763], "paragraphs": [{"paragraph_vector": [177.506347, -32.690551], "paragraph_keywords": ["self", "management", "copies", "hci"]}, {"paragraph_vector": [-174.523574, -34.750984], "paragraph_keywords": ["cfs", "symptoms", "patients", "support"]}, {"paragraph_vector": [-174.498794, -34.093902], "paragraph_keywords": ["symptoms", "cfs", "tiredness", "including"]}, {"paragraph_vector": [-171.803375, -31.95795], "paragraph_keywords": ["cfs", "activity", "patients", "self"]}, {"paragraph_vector": [-172.737243, -36.170703], "paragraph_keywords": ["cfs", "study", "self", "energy"]}, {"paragraph_vector": [152.892623, -50.598407], "paragraph_keywords": ["research", "participants", "people", "studies"]}, {"paragraph_vector": [-174.926849, -30.804841], "paragraph_keywords": ["participants", "research", "reminders", "cfs"]}, {"paragraph_vector": [-178.207366, -32.407588], "paragraph_keywords": ["symptoms", "cfs", "participants", "self"]}, {"paragraph_vector": [-178.710174, -29.437089], "paragraph_keywords": ["cfs", "self", "support", "agreement"]}, {"paragraph_vector": [169.915283, -44.961296], "paragraph_keywords": ["participants", "management", "data", "self"]}, {"paragraph_vector": [-170.534347, -30.578838], "paragraph_keywords": ["activity", "energy", "day", "steps"]}, {"paragraph_vector": [-173.949691, -31.34233], "paragraph_keywords": ["activity", "need", "monitor", "results"]}, {"paragraph_vector": [-176.684906, -33.107143], "paragraph_keywords": ["self", "habits", "app", "things"]}, {"paragraph_vector": [-174.607009, -32.428112], "paragraph_keywords": ["activity", "cfs", "issues", "devices"]}, {"paragraph_vector": [-172.471374, -32.073047], "paragraph_keywords": ["participants", "fatigue", "energy", "track"]}, {"paragraph_vector": [-175.693191, -30.250614], "paragraph_keywords": ["participants", "self", "pacing", "management"]}, {"paragraph_vector": [-178.828155, -31.47373], "paragraph_keywords": ["apps", "self", "management", "app"]}, {"paragraph_vector": [-174.751098, -32.226451], "paragraph_keywords": ["fatigue", "users", "management", "self"]}, {"paragraph_vector": [-176.156555, -33.726539], "paragraph_keywords": ["participants", "cfs", "mindfulness", "feedback"]}, {"paragraph_vector": [-171.740798, -34.467788], "paragraph_keywords": ["fatigue", "data", "liked", "activities"]}, {"paragraph_vector": [-173.3246, -34.461303], "paragraph_keywords": ["ups", "goals", "participants", "app"]}, {"paragraph_vector": [-171.079742, -35.411273], "paragraph_keywords": ["app", "use", "cfs", "sb"]}, {"paragraph_vector": [-171.921737, -32.365909], "paragraph_keywords": ["activity", "cfs", "self", "people"]}, {"paragraph_vector": [-170.973617, -35.436363], "paragraph_keywords": ["cfs", "fatigue", "self", "mechanisms"]}, {"paragraph_vector": [-173.925933, -34.074726], "paragraph_keywords": ["cfs", "people", "symptoms", "technologies"]}, {"paragraph_vector": [-175.428222, -32.197391], "paragraph_keywords": ["people", "cfs", "design", "self"]}, {"paragraph_vector": [169.298263, -20.778812], "paragraph_keywords": ["design", "patients", "support", "caregivers"]}], "content": {}, "doi": "10.1145/3290605.3300541"}, {"uri": "290", "title": "Examining Augmented Virtuality Impairment Simulation for Mobile App Accessibility Design", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Kenny Tsu", "Wei Choo", "Rajesh Krishna Balan", "Youngki Lee"], "summary": "With mobile apps rapidly permeating all aspects of daily living with use by all segments of the population, it is crucial to support the evaluation of app usability for specific impaired users to improve app accessibility. In this work, we examine the effects of using our augmented virtuality impairment simulation system\u2013Empath-D\u2013to support experienced designerdevelopers to redesign a mockup of commonly used mobile application for cataract-impaired users, comparing this with existing tools that aid designing for accessibility. We show that the use of augmented virtuality for assessing usability supports enhanced usability challenge identification, finding more defects and doing so more accurately than with existing methods. Through our user interviews, we also show that augmented virtuality impairment simulation supports realistic interaction and evaluation to provide a concrete understanding over the usability challenges that impaired users face, and complements the existing guidelines-based approaches meant for general accessibility.", "keywords": ["google", "vr", "virtuality", "change", "phone", "design", "app", "problem", "instagram", "user", "accessibility", "wcag", "interaction", "ui", "apps", "tool", "empath", "participant", "use", "web", "usability", "cataract", "issue", "post", "challenge", "scanner", "page", "content", "provided", "impairment", "task", "d", "support", "developer", "text", "paper", "spacing", "guideline", "letter", "figure"], "document_vector": [156.750518, -47.032623], "paragraphs": [{"paragraph_vector": [-142.406692, 41.49974], "paragraph_keywords": ["app", "copies", "computing", "population"]}, {"paragraph_vector": [-145.234649, 39.495048], "paragraph_keywords": ["d", "empath", "app", "developers"]}, {"paragraph_vector": [-146.653503, 41.406044], "paragraph_keywords": ["accessibility", "web", "design", "tools"]}, {"paragraph_vector": [-145.822692, 44.434799], "paragraph_keywords": ["impairment", "design", "users", "simulate"]}, {"paragraph_vector": [-143.299346, 40.014747], "paragraph_keywords": ["phone", "d", "virtuality", "vr"]}, {"paragraph_vector": [-142.594802, 46.295562], "paragraph_keywords": ["participants", "instagram", "usability", "use"]}, {"paragraph_vector": [-148.157989, 43.780162], "paragraph_keywords": ["participants", "use", "study", "users"]}, {"paragraph_vector": [-143.204818, 44.386112], "paragraph_keywords": ["users", "html", "participants", "mockup"]}, {"paragraph_vector": [-145.541931, 46.747856], "paragraph_keywords": ["participants", "design", "task", "tools"]}, {"paragraph_vector": [-143.566741, 45.881595], "paragraph_keywords": ["users", "text", "post", "spacing"]}, {"paragraph_vector": [-143.296798, 44.712978], "paragraph_keywords": ["usability", "changes", "challenges", "d"]}, {"paragraph_vector": [-143.698669, 44.968357], "paragraph_keywords": ["text", "participants", "ui", "size"]}, {"paragraph_vector": [-146.604598, 45.925472], "paragraph_keywords": ["users", "buttons", "problems", "design"]}, {"paragraph_vector": [-142.878128, 44.180221], "paragraph_keywords": ["accessibility", "wcag", "found", "issues"]}, {"paragraph_vector": [-146.131973, 44.434181], "paragraph_keywords": ["users", "accessibility", "problems", "guidelines"]}, {"paragraph_vector": [-146.509902, 39.756633], "paragraph_keywords": ["empath", "d", "users", "interaction"]}, {"paragraph_vector": [-146.705413, 42.31599], "paragraph_keywords": ["users", "accessibility", "developers", "guidelines"]}], "content": {}, "doi": "10.1145/3290605.3300282"}, {"uri": "291", "title": "Gamified Ads: Bridging the Gap Between User Enjoyment and the Effectiveness of Online Ads", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Maximilian Altmeyer", "Kathrin Dernbecher", "Vladislav Hnatovskiy", "Marc Schubhan", "Pascal Lessel", "Antonio Kr\u00fcger"], "summary": "While the use of ad blockers prevents negative impacts of advertising on user experience, it poses a serious threat to the business model of commercial web services and freely available content on the web. As an alternative, we investigate the user enjoyment and the advertising effectiveness of playfully deactivating online ads. We created eight game concepts, performed a pre-study assessing the users\u2019 perception of them (N=50) and implemented three well-perceived ones. In a lab study (N=72), we found that these game concepts are more enjoyable than deactivating ads without game elements. Additionally, one game concept was even preferred over using an ad blocker. Notably, playfully deactivating ads was shown to have a positive impact on users\u2019 brand and product memory, enhancing the advertising effectiveness. Thus, our results indicate that playfully deactivating ads is a promising way of bridging the gap between user enjoyment and effective advertising. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300412 CCS CONCEPTS \u2022Human-centered computing\u2192 Empirical studies in HCI;", "keywords": ["based", "perceived", "ad", "brand", "condition", "memory", "following", "interactivity", "enjoyment", "deactivate", "user", "news", "interaction", "effectiveness", "product", "participant", "web", "perception", "effect", "concept", "page", "experience", "monster", "deactivating", "found", "content", "recognition", "shown", "advertising", "game", "study", "approach", "website", "paper"], "document_vector": [6.535614, 12.893393], "paragraphs": [{"paragraph_vector": [173.04425, 39.171478], "paragraph_keywords": ["ads", "users", "user", "banner"]}, {"paragraph_vector": [-170.711791, 33.417858], "paragraph_keywords": ["ad", "ads", "users", "game"]}, {"paragraph_vector": [-172.152969, 34.349113], "paragraph_keywords": ["ads", "user", "perceived", "game"]}, {"paragraph_vector": [-171.023574, 32.543128], "paragraph_keywords": ["ad", "ads", "users", "user"]}, {"paragraph_vector": [-172.264862, 32.524795], "paragraph_keywords": ["interactivity", "product", "ads", "effects"]}, {"paragraph_vector": [-174.442993, 34.070426], "paragraph_keywords": ["game", "ads", "product", "games"]}, {"paragraph_vector": [-169.958496, 33.523124], "paragraph_keywords": ["ads", "game", "deactivating", "user"]}, {"paragraph_vector": [-177.665039, 33.265254], "paragraph_keywords": ["ad", "character", "participants", "game"]}, {"paragraph_vector": [179.805831, 38.708267], "paragraph_keywords": ["study", "game", "participants", "storyboards"]}, {"paragraph_vector": [-172.937957, 33.850536], "paragraph_keywords": ["game", "participants", "concepts", "idea"]}, {"paragraph_vector": [-172.841903, 33.649768], "paragraph_keywords": ["ad", "game", "news", "website"]}, {"paragraph_vector": [-167.948822, 33.551769], "paragraph_keywords": ["ad", "monster", "game", "pieces"]}, {"paragraph_vector": [-172.137283, 34.631198], "paragraph_keywords": ["ads", "ad", "news", "effects"]}, {"paragraph_vector": [170.845672, 38.056503], "paragraph_keywords": ["ad", "ads", "participants", "effects"]}, {"paragraph_vector": [171.741165, 34.894573], "paragraph_keywords": ["ad", "participants", "article", "task"]}, {"paragraph_vector": [-174.950531, 37.746368], "paragraph_keywords": ["participants", "brand", "ads", "word"]}, {"paragraph_vector": [-146.542892, 20.365976], "paragraph_keywords": ["game", "participants", "baseline", "concepts"]}, {"paragraph_vector": [-173.364669, 33.449344], "paragraph_keywords": ["conditions", "number", "monster", "tetris"]}, {"paragraph_vector": [-171.226654, 34.773773], "paragraph_keywords": ["concept", "news", "ads", "monster"]}, {"paragraph_vector": [-172.029495, 33.728946], "paragraph_keywords": ["ads", "ad", "effect", "game"]}, {"paragraph_vector": [-171.34169, 33.731868], "paragraph_keywords": ["ads", "approach", "ad", "research"]}], "content": {}, "doi": "10.1145/3290605.3300487"}, {"uri": "292", "title": "How to Design Voice Based Navigation for  How-To Videos", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Minsuk Chang", "Anh Truong", "Oliver Wang", "Maneesh Agrawala"], "summary": "When watching how-to videos related to physical tasks, users\u2019 hands are often occupied by the task, making voice input a natural fit. To better understand the design space of voice interactions for how-to video navigation, we conducted three think-aloud studies using: 1) a traditional video interface, 2) a research probe providing a voice controlled video interface, and 3) a wizard-of-oz interface. From the studies, we distill seven navigation objectives and their underlying intents: pace control pause, content alignment pause, video control pause, reference jump, replay jump, skip jump, and peek jump. Our analysis found that users\u2019 navigation objectives and intents affect the choice of referent type and referencing approach in command utterances. Based on our findings, we recommend to 1) support conversational strategies like sequence expansions and command queues, 2) allow users to identify and refine their navigation objectives explicitly, and 3) support the seven interaction intents.", "keywords": ["navigation", "based", "point", "pause", "time", "makeup", "design", "analysis", "wizard", "intent", "experiment", "jump", "user", "type", "command", "interaction", "play", "work", "video", "second", "participant", "use", "control", "voice", "step", "page", "understanding", "content", "observed", "understand", "task", "study", "tutorial", "research", "target", "interface", "skip", "stop"], "document_vector": [-33.298637, -26.530937], "paragraphs": [{"paragraph_vector": [42.835659, 37.349426], "paragraph_keywords": ["video", "videos", "copies", "acm"]}, {"paragraph_vector": [37.884117, 42.479148], "paragraph_keywords": ["video", "videos", "viewers", "navigation"]}, {"paragraph_vector": [42.029155, 38.470546], "paragraph_keywords": ["navigation", "voice", "video", "videos"]}, {"paragraph_vector": [38.166004, 38.834461], "paragraph_keywords": ["users", "video", "browsing", "tutorials"]}, {"paragraph_vector": [44.401199, 39.169086], "paragraph_keywords": ["users", "voice", "user", "video"]}, {"paragraph_vector": [43.566917, 37.21405], "paragraph_keywords": ["user", "voice", "commands", "users"]}, {"paragraph_vector": [44.413928, 37.483367], "paragraph_keywords": ["study", "user", "voice", "users"]}, {"paragraph_vector": [45.999706, 32.85054], "paragraph_keywords": ["video", "participants", "song", "makeup"]}, {"paragraph_vector": [42.716117, 34.375328], "paragraph_keywords": ["video", "pause", "user", "pauses"]}, {"paragraph_vector": [43.101947, 37.174137], "paragraph_keywords": ["jump", "pauses", "video", "user"]}, {"paragraph_vector": [44.284755, 35.810501], "paragraph_keywords": ["skip", "user", "video", "jump"]}, {"paragraph_vector": [47.040172, 34.36922], "paragraph_keywords": ["participants", "probe", "research", "voice"]}, {"paragraph_vector": [46.280502, 37.685184], "paragraph_keywords": ["stop", "command", "pauses", "video"]}, {"paragraph_vector": [43.810253, 37.035156], "paragraph_keywords": ["jumps", "position", "skip", "users"]}, {"paragraph_vector": [42.530513, 38.595855], "paragraph_keywords": ["users", "voice", "stop", "video"]}, {"paragraph_vector": [45.207313, 37.278911], "paragraph_keywords": ["video", "users", "user", "sessions"]}, {"paragraph_vector": [47.488586, 38.349967], "paragraph_keywords": ["command", "users", "wizard", "navigate"]}, {"paragraph_vector": [42.957038, 39.01221], "paragraph_keywords": ["users", "pause", "user", "commands"]}, {"paragraph_vector": [37.290531, 39.917373], "paragraph_keywords": ["voice", "video", "user", "users"]}, {"paragraph_vector": [42.872371, 38.177722], "paragraph_keywords": ["users", "voice", "video", "references"]}, {"paragraph_vector": [51.105636, 41.798206], "paragraph_keywords": ["participants", "commands", "sequence", "command"]}, {"paragraph_vector": [43.132793, 37.203437], "paragraph_keywords": ["voice", "design", "interactions", "wizard"]}, {"paragraph_vector": [45.070907, 37.81287], "paragraph_keywords": ["voice", "user", "videos", "analysis"]}, {"paragraph_vector": [44.77919, 38.214687], "paragraph_keywords": ["voice", "navigation", "thank", "systems"]}], "content": {}, "doi": "10.1145/3290605.3300515"}, {"uri": "293", "title": "Understanding Metamaterial Mechanisms", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Alexandra Ion", "David Lindlbauer", "Philipp Herholz", "Marc Alexa", "Patrick Baudisch"], "summary": "In this paper, we establish the underlying foundations of mechanisms that are composed of cell structures\u2014known as metamaterial mechanisms. Such metamaterial mechanisms were previously shown to implement complete mechanisms in the cell structure of a 3D printed material, without the need for assembly. However, their design is highly challenging. A mechanism consists of many cells that are interconnected and impose constraints on each other. This leads to unobvious and non-linear behavior of the mechanism, which impedes user design. In this work, we investigate the underlying topological constraints of such cell structures and their influence on the resulting mechanism. Based on these findings, we contribute a computational design tool that automatically creates a metamaterial mechanism from userdefined motion paths. This tool is only feasible because our novel abstract representation of the global constraints highly reduces the search space of possible cell arrangements. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300877 CCS CONCEPTS \u2022 Human-centered computing \u2192 Interactive systems and tools; \u2022 Hardware\u2192 Emerging technologies.", "keywords": ["position", "defined", "object", "find", "allow", "dof", "mechanism", "component", "example", "simulation", "path", "user", "optimization", "type", "work", "space", "tool", "use", "resolution", "desired", "material", "graph", "metamaterials", "algorithm", "output", "number", "anchor", "motion", "transformation", "configuration", "cell", "researcher", "approach", "grid", "constraint", "paper", "input", "edge", "figure"], "document_vector": [89.36145, -35.262535], "paragraphs": [{"paragraph_vector": [-108.295173, 51.196472], "paragraph_keywords": ["objects", "researchers", "structures", "arranged"]}, {"paragraph_vector": [-116.845558, 60.600532], "paragraph_keywords": ["cells", "mechanisms", "constraints", "example"]}, {"paragraph_vector": [-117.527412, 60.519565], "paragraph_keywords": ["cell", "space", "mechanisms", "figure"]}, {"paragraph_vector": [-119.036437, 58.736064], "paragraph_keywords": ["objects", "cells", "mechanisms", "researchers"]}, {"paragraph_vector": [-93.113739, 54.975414], "paragraph_keywords": ["mechanisms", "researchers", "tools", "objects"]}, {"paragraph_vector": [-114.802032, 59.82331], "paragraph_keywords": ["mechanisms", "cells", "draw", "properties"]}, {"paragraph_vector": [-118.4197, 61.325241], "paragraph_keywords": ["mechanisms", "edge", "constraints", "mechanism"]}, {"paragraph_vector": [-123.152053, 64.611045], "paragraph_keywords": ["cell", "graph", "edges", "cells"]}, {"paragraph_vector": [-115.942565, 61.560173], "paragraph_keywords": ["edges", "cell", "edge", "component"]}, {"paragraph_vector": [-120.03199, 61.742172], "paragraph_keywords": ["grid", "edges", "configurations", "mechanisms"]}, {"paragraph_vector": [-116.745933, 61.22343], "paragraph_keywords": ["cell", "cells", "state", "edges"]}, {"paragraph_vector": [-116.256576, 60.482997], "paragraph_keywords": ["handle", "configuration", "position", "problem"]}, {"paragraph_vector": [-118.212783, 60.667602], "paragraph_keywords": ["cell", "mechanism", "input", "algorithm"]}, {"paragraph_vector": [-113.383682, 60.142265], "paragraph_keywords": ["anchors", "path", "paths", "mechanism"]}, {"paragraph_vector": [-117.461311, 61.391738], "paragraph_keywords": ["cell", "pi", "paths", "configuration"]}, {"paragraph_vector": [-116.480171, 61.150566], "paragraph_keywords": ["dof", "configuration", "number", "chosen"]}, {"paragraph_vector": [-118.036628, 61.133666], "paragraph_keywords": ["resolution", "cell", "optimization", "error"]}, {"paragraph_vector": [-115.636146, 62.255172], "paragraph_keywords": ["editor", "algorithm", "cells", "tool"]}, {"paragraph_vector": [-108.099548, 54.104427], "paragraph_keywords": ["mechanisms", "examples", "work", "motion"]}, {"paragraph_vector": [-119.192398, 60.473243], "paragraph_keywords": ["mechanisms", "cell", "input", "output"]}, {"paragraph_vector": [-117.804855, 60.88475], "paragraph_keywords": ["constraints", "editor", "cells", "work"]}, {"paragraph_vector": [-118.179969, 61.067169], "paragraph_keywords": ["cells", "metamaterials", "components", "mechanisms"]}, {"paragraph_vector": [-27.597438, 77.10437], "paragraph_keywords": ["z", "y", "n", "s"]}], "content": {}, "doi": "10.1145/3290605.3300795"}, {"uri": "294", "title": "Inalienability: Understanding Digital Gifts", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Jocelyn Spence"], "summary": "This paper takes on one of the rarely articulated yet important questions pertaining to digital media objects: how do HCI and design researchers understand \u2018gifting\u2019 when the object can just as easily be \u2018shared\u2019? This question has often been implied and occasionally answered, though only partially. We propose the concept of \u2018inalienability\u2019, taken from the gifting literature, as a useful theory for clarifying what design researchers mean by gifting in a digital context. We apply \u2018inalienability\u2019 to three papers from the ACMDigital Library and one ongoing project, spanning nearly two decades of HCI and design research, that combine \u2018gifting and \u2018sharing\u2019 in their frameworks. In this way we show how applying the concept of \u2018inalienability\u2019 can clarify behaviours that mark gifting as a unique activity, frame research questions around gifting and sharing, outline specific next steps for gifting research, and suggest design strategies in this area.", "keywords": ["process", "connection", "al", "relation", "object", "person", "mind", "believe", "giving", "design", "literature", "mechanism", "seen", "takei", "relationship", "example", "medium", "project", "sharing", "shared", "et", "work", "video", "use", "participant", "people", "gift", "museum", "file", "given", "way", "sense", "concept", "experience", "page", "gifting", "exchange", "understanding", "found", "including", "effort", "case", "value", "practice", "reciprocity", "researcher", "study", "technology", "colleague", "economy", "research", "term", "meaning", "giver", "hci", "receiver", "paper", "inalienability"], "document_vector": [76.084236, 19.387529], "paragraphs": [{"paragraph_vector": [-167.748596, 3.840147], "paragraph_keywords": ["gifting", "work", "gift", "copies"]}, {"paragraph_vector": [-166.908584, 4.024719], "paragraph_keywords": ["gifting", "design", "literature", "inalienability"]}, {"paragraph_vector": [-166.815536, 6.629633], "paragraph_keywords": ["gifting", "design", "hci", "inalienability"]}, {"paragraph_vector": [-166.175781, 5.566834], "paragraph_keywords": ["gifting", "sharing", "work", "research"]}, {"paragraph_vector": [-165.225936, 4.029582], "paragraph_keywords": ["gifting", "sharing", "practices", "work"]}, {"paragraph_vector": [-164.665069, 4.955764], "paragraph_keywords": ["gift", "gifts", "design", "technologies"]}, {"paragraph_vector": [-165.264816, 3.851697], "paragraph_keywords": ["gifting", "sharing", "reciprocity", "link"]}, {"paragraph_vector": [-166.873168, 5.159953], "paragraph_keywords": ["gifting", "reciprocity", "work", "gift"]}, {"paragraph_vector": [-166.20108, 5.000611], "paragraph_keywords": ["gifting", "object", "literature", "receiver"]}, {"paragraph_vector": [-165.986206, 6.020161], "paragraph_keywords": ["objects", "inalienability", "value", "family"]}, {"paragraph_vector": [-164.424346, 1.970251], "paragraph_keywords": ["gifts", "gift", "giver", "mauss"]}, {"paragraph_vector": [-167.316101, 5.117749], "paragraph_keywords": ["giver", "gifting", "inalienability", "mauss"]}, {"paragraph_vector": [-165.530838, 4.261857], "paragraph_keywords": ["gift", "gifting", "effort", "giver"]}, {"paragraph_vector": [-167.512405, 1.814386], "paragraph_keywords": ["inalienability", "excitement", "meaning", "gift"]}, {"paragraph_vector": [-149.581451, -74.165458], "paragraph_keywords": ["video", "takei", "relationship", "gifts"]}, {"paragraph_vector": [-167.90895, 5.718082], "paragraph_keywords": ["video", "work", "inalienability", "gift"]}, {"paragraph_vector": [-166.766738, 5.295382], "paragraph_keywords": ["giver", "ownership", "gifting", "gift"]}, {"paragraph_vector": [-167.642379, 5.084677], "paragraph_keywords": ["gifting", "sharing", "giver", "file"]}, {"paragraph_vector": [-165.268112, 4.366318], "paragraph_keywords": ["gifting", "inalienability", "media", "object"]}, {"paragraph_vector": [-165.001251, 2.722426], "paragraph_keywords": ["gift", "gifting", "experience", "inalienability"]}, {"paragraph_vector": [-163.980102, 2.783605], "paragraph_keywords": ["receiver", "objects", "gifting", "sharing"]}, {"paragraph_vector": [-167.231307, 4.660822], "paragraph_keywords": ["design", "inalienability", "gift", "gifting"]}, {"paragraph_vector": [-166.665634, 3.216632], "paragraph_keywords": ["inalienability", "things", "process", "objects"]}, {"paragraph_vector": [-164.627059, 4.593511], "paragraph_keywords": ["gifting", "inalienability", "gift", "design"]}, {"paragraph_vector": [-165.701797, 2.468876], "paragraph_keywords": ["giver", "gifting", "gifts", "gift"]}, {"paragraph_vector": [-167.119796, 6.79713], "paragraph_keywords": ["gifting", "inalienability", "literature", "effort"]}, {"paragraph_vector": [-166.463195, 4.532654], "paragraph_keywords": ["inalienability", "design", "research", "concept"]}], "content": {}, "doi": "10.1145/3290605.3300322"}, {"uri": "295", "title": "Development of a Checklist for the Prevention of Intradialytic Hypotension in Hemodialysis Care: Design Considerations Based on Activity Theory", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Pei-Yi Kuo", "Rajiv Saran", "Marissa Argentina", "Michael Heung", "Jennifer L Bragg-Gresham", "Dinesh Chatoth", "Brenda Gillespie", "Sarah Krein", "Rebecca Wingard", "Kai Zheng", "Tiffany C. Veinot"], "summary": "Hemodialysis is life-saving therapy for end-stage renal disease; yet, 20% of hemodialysis sessions are complicated by intradialytic hypotension (\u201cIDH\u201d). There is a need for approaches to preventing IDH that account for their implementation contexts. Using Activity Theory, we outline the design of a digital diagnostic checklist to identify patients at risk of IDH. Checklists were chosen a priori as an outcome due to prior evidence of effectiveness. Drawing on individual interviews with 20 clinicians and three focus groups with 17 patients, we describe four activity systems within hemodialysis care. We then outline a novel design process that includes co-design activities with clinicians, and four rapid-cycle iterations that progressively incorporated activity system elements into checklist design. We contribute a new type of checklist design to HCI: one that supports diagnostic thinking rather than consistent task completion. We further broaden checklist design by including a formal role for patients in checklist completion.", "keywords": ["process", "removal", "based", "clinician", "time", "bp", "change", "object", "information", "evidence", "design", "committee", "care", "focus", "technician", "goal", "activity", "assessment", "hd", "included", "risk", "tool", "participant", "use", "patient", "people", "identify", "idh", "treatment", "related", "checklist", "page", "nurse", "feedback", "physician", "task", "fluid", "attention", "data", "symptom", "said", "system", "focused", "session", "rule", "prototype", "paper", "healthcare", "prevention", "round", "action"], "document_vector": [89.284927, 89.86737], "paragraphs": [{"paragraph_vector": [158.52774, -5.703165], "paragraph_keywords": ["hd", "idh", "copies", "condition"]}, {"paragraph_vector": [159.982192, 6.284244], "paragraph_keywords": ["checklists", "tasks", "hd", "care"]}, {"paragraph_vector": [160.700073, 1.426336], "paragraph_keywords": ["design", "activity", "people", "process"]}, {"paragraph_vector": [157.524887, 3.685436], "paragraph_keywords": ["activity", "design", "system", "activities"]}, {"paragraph_vector": [160.432327, 5.061188], "paragraph_keywords": ["checklists", "checklist", "patients", "healthcare"]}, {"paragraph_vector": [162.471298, 0.507019], "paragraph_keywords": ["design", "checklist", "evidence", "patients"]}, {"paragraph_vector": [158.171691, 1.211703], "paragraph_keywords": ["hd", "participants", "groups", "coding"]}, {"paragraph_vector": [161.359695, 0.887064], "paragraph_keywords": ["design", "participants", "activity", "systems"]}, {"paragraph_vector": [161.393035, -2.306099], "paragraph_keywords": ["patients", "technicians", "nurse", "weights"]}, {"paragraph_vector": [161.477416, -3.375987], "paragraph_keywords": ["patients", "assessment", "rules", "patient"]}, {"paragraph_vector": [164.193771, 4.053994], "paragraph_keywords": ["nurse", "activity", "patients", "session"]}, {"paragraph_vector": [170.257461, -16.817245], "paragraph_keywords": ["patient", "bp", "patients", "symptoms"]}, {"paragraph_vector": [162.966796, -3.657036], "paragraph_keywords": ["patient", "bps", "nurse", "patients"]}, {"paragraph_vector": [162.41098, -0.509136], "paragraph_keywords": ["checklist", "activity", "nurse", "tools"]}, {"paragraph_vector": [161.54454, -1.340883], "paragraph_keywords": ["design", "checklist", "idh", "round"]}, {"paragraph_vector": [160.744003, 1.331341], "paragraph_keywords": ["checklist", "design", "activity", "items"]}, {"paragraph_vector": [160.709899, 4.024057], "paragraph_keywords": ["checklist", "patient", "tool", "design"]}, {"paragraph_vector": [160.865524, 2.423196], "paragraph_keywords": ["checklist", "risk", "patient", "idh"]}, {"paragraph_vector": [161.283615, 1.446737], "paragraph_keywords": ["checklist", "questions", "data", "issues"]}, {"paragraph_vector": [161.266418, -0.101032], "paragraph_keywords": ["checklist", "patients", "symptoms", "goal"]}, {"paragraph_vector": [162.823303, 1.478477], "paragraph_keywords": ["checklist", "nurses", "prototype", "bp"]}, {"paragraph_vector": [162.253479, -0.500106], "paragraph_keywords": ["checklist", "design", "activity", "clinicians"]}, {"paragraph_vector": [161.0018, 2.425593], "paragraph_keywords": ["checklist", "design", "activity", "system"]}, {"paragraph_vector": [158.775741, 0.90653], "paragraph_keywords": ["checklist", "clinicians", "patients", "attention"]}, {"paragraph_vector": [160.87416, 1.156543], "paragraph_keywords": ["checklist", "design", "hd", "activity"]}], "content": {}, "doi": "10.1145/3290605.3300569"}, {"uri": "296", "title": "\u201cThey Don\u2019t Leave Us Alone Anywhere We Go\u201d: Gender and Digital Abuse in South Asia", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Nithya Sambasivan", "Amna Batool", "Laura Sanely Gayt\u00e1n-Lugo", "Elie Bursztein", "Elizabeth Churchill", "Sunny Consolvo", "Nova Ahmed", "Tara Matthews", "Kurt Thomas", "David Nemer"], "summary": "South Asia faces one of the largest gender gaps online globally, and online safety is one of the main barriers to genderequitable Internet access [GSMA, 2015]. To better understand the gendered risks and coping practices online in South Asia, we present a qualitative study of the online abuse experiences and coping practices of 199 people who identified as women and 6 NGO staff from India, Pakistan, and Bangladesh, using a feminist analysis. We found that a majority of our participants regularly contended with online abuse, experiencing three major abuse types: cyberstalking, impersonation, and personal content leakages. Consequences of abuse included emotional harm, reputation damage, and physical and sexual violence. Participants coped through informal channels rather than through technological protections or law enforcement. Altogether, our findings point to opportunities for designs, policies, and algorithms to improve women\u2019s safety online in South Asia.", "keywords": ["police", "identity", "based", "relation", "south", "phone", "threat", "reported", "cyberstalking", "interview", "safety", "stranger", "porn", "focus", "example", "gender", "woman", "medium", "pakistan", "india", "user", "type", "help", "included", "work", "result", "space", "participant", "internet", "use", "group", "victim", "contact", "reputation", "created", "page", "college", "bangladesh", "content", "provided", "profile", "ngo", "abuser", "-", "incident", "member", "family", "abuse", "described", "data", "technology", "study", "reporting", "support", "system", "research", "impersonation", "platform", "paper", "coping", "photo", "asia", "violence", "context", "community"], "document_vector": [-48.61288, 45.782749], "paragraphs": [{"paragraph_vector": [93.205093, -45.315895], "paragraph_keywords": ["copies", "india", "media", "asia"]}, {"paragraph_vector": [50.334342, -53.701847], "paragraph_keywords": ["abuse", "women", "internet", "-"]}, {"paragraph_vector": [51.148174, -52.978752], "paragraph_keywords": ["abuse", "participants", "reported", "consequences"]}, {"paragraph_vector": [49.988109, -54.982383], "paragraph_keywords": ["abuse", "person", "cyberstalking", "impersonation"]}, {"paragraph_vector": [52.761135, -55.540317], "paragraph_keywords": ["abuse", "victims", "self", "platforms"]}, {"paragraph_vector": [50.815536, -56.1208], "paragraph_keywords": ["women", "abuse", "violence", "include"]}, {"paragraph_vector": [54.360893, -54.835983], "paragraph_keywords": ["women", "abuse", "india", "safety"]}, {"paragraph_vector": [58.231758, -53.82854], "paragraph_keywords": ["members", "participants", "rights", "women"]}, {"paragraph_vector": [72.366485, -53.913269], "paragraph_keywords": ["participants", "authors", "india", "recruitment"]}, {"paragraph_vector": [60.118141, -55.683704], "paragraph_keywords": ["abuse", "coping", "categories", "participants"]}, {"paragraph_vector": [64.068069, -53.798385], "paragraph_keywords": ["participants", "study", "google", "working"]}, {"paragraph_vector": [67.57489, -56.791629], "paragraph_keywords": ["participants", "women", "provided", "included"]}, {"paragraph_vector": [59.479564, -55.500701], "paragraph_keywords": ["abuse", "participants", "disabilities", "results"]}, {"paragraph_vector": [48.278285, -55.470046], "paragraph_keywords": ["reported", "abuse", "cyberstalking", "participants"]}, {"paragraph_vector": [49.930255, -54.967269], "paragraph_keywords": ["reported", "participants", "friend", "got"]}, {"paragraph_vector": [45.149112, -54.372062], "paragraph_keywords": ["participants", "reported", "abusers", "taxi"]}, {"paragraph_vector": [48.057357, -56.417591], "paragraph_keywords": ["participants", "mariyam", "family", "community"]}, {"paragraph_vector": [48.357883, -55.303703], "paragraph_keywords": ["content", "participants", "participant", "described"]}, {"paragraph_vector": [58.645355, -55.558719], "paragraph_keywords": ["women", "photos", "reported", "students"]}, {"paragraph_vector": [54.234321, -53.522399], "paragraph_keywords": ["abuse", "participants", "women", "content"]}, {"paragraph_vector": [52.009616, -53.595417], "paragraph_keywords": ["participants", "reported", "relations", "threats"]}, {"paragraph_vector": [55.233242, -53.377933], "paragraph_keywords": ["participants", "abuse", "support", "reported"]}, {"paragraph_vector": [55.025901, -53.66389], "paragraph_keywords": ["abuse", "described", "ngos", "participants"]}, {"paragraph_vector": [49.701847, -55.163452], "paragraph_keywords": ["abuse", "participants", "ngo", "reporting"]}, {"paragraph_vector": [49.272594, -55.3311], "paragraph_keywords": ["participants", "profile", "abuse", "reported"]}, {"paragraph_vector": [51.530487, -54.618366], "paragraph_keywords": ["abuse", "need", "women", "gender"]}, {"paragraph_vector": [53.303417, -53.360504], "paragraph_keywords": ["abuse", "participants", "internet", "paper"]}, {"paragraph_vector": [57.835353, -53.372028], "paragraph_keywords": ["abuse", "systems", "ngos", "communities"]}, {"paragraph_vector": [55.380752, -54.543266], "paragraph_keywords": ["abuse", "women", "participants", "technology"]}, {"paragraph_vector": [71.736091, 32.75082], "paragraph_keywords": ["syeda", "salman", "khalid", "sarwar"]}], "content": {}, "doi": "10.1145/3290605.3300859"}, {"uri": "297", "title": "Should I Agree? Delegating Consent Decisions Beyond the Individual", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Bettina Nissen", "Mateusz Mikusz", "Victoria Neumann", "Rory Gianni", "Sarah Clinch"], "summary": "Obtaining meaningful user consent is increasingly problematic in a world of numerous, heterogeneous digital services. Current approaches (e.g. agreeing to Terms and Conditions) are rooted in the idea of individual control despite growing evidence that users do not (or cannot) exercise such control in informed ways. We consider an alternative approach whereby users can opt to delegate consent decisions to an ecosystem of third-parties including friends, experts, groups and AI entities. We present the results of a study that used a technology probe at a large festival to explore initial public responses to this reframing \u2013 focusing on when and to whomusers would delegate such decisions. The results reveal substantial public interest in delegating consent and identify differing preferences depending on the privacy context, highlighting the need for alternative decision mechanisms beyond the current focus on individual choice.", "keywords": ["importance", "reading", "based", "time", "information", "set", "delegation", "questionnaire", "self", "design", "friend", "visitor", "user", "trust", "interaction", "trustball", "decision", "delegate", "result", "scenario", "read", "participant", "use", "people", "captured", "health", "control", "ai", "page", "including", "audience", "member", "practice", "crowd", "data", "technology", "study", "game", "approach", "system", "choice", "research", "ball", "hci", "paper", "question", "privacy", "consent", "option", "making", "response"], "document_vector": [-38.576705, 33.895671], "paragraphs": [{"paragraph_vector": [86.03865, -55.561683], "paragraph_keywords": ["consent", "data", "technology", "users"]}, {"paragraph_vector": [80.896789, -57.523166], "paragraph_keywords": ["consent", "privacy", "data", "control"]}, {"paragraph_vector": [82.672775, -56.521278], "paragraph_keywords": ["privacy", "consent", "decisions", "users"]}, {"paragraph_vector": [80.651191, -53.325244], "paragraph_keywords": ["consent", "users", "individuals", "privacy"]}, {"paragraph_vector": [101.590072, -57.643146], "paragraph_keywords": ["audiences", "data", "hci", "design"]}, {"paragraph_vector": [87.197402, -56.512664], "paragraph_keywords": ["consent", "user", "research", "app"]}, {"paragraph_vector": [132.677474, -52.117958], "paragraph_keywords": ["ball", "participants", "data", "screen"]}, {"paragraph_vector": [86.737548, -58.218235], "paragraph_keywords": ["privacy", "participants", "scenarios", "consent"]}, {"paragraph_vector": [-111.787704, -56.58749], "paragraph_keywords": ["visitors", "exhibition", "festival", "event"]}, {"paragraph_vector": [131.968307, -59.190402], "paragraph_keywords": ["participants", "reading", "trustball", "responses"]}, {"paragraph_vector": [154.233016, -47.254127], "paragraph_keywords": ["members", "groups", "options", "guidance"]}, {"paragraph_vector": [124.809669, -58.815177], "paragraph_keywords": ["participants", "delegate", "delegation", "data"]}, {"paragraph_vector": [136.504928, -67.827102], "paragraph_keywords": ["delegation", "participants", "option", "age"]}, {"paragraph_vector": [157.436431, -75.642608], "paragraph_keywords": ["participants", "reading", "times", "time"]}, {"paragraph_vector": [91.39801, -56.273544], "paragraph_keywords": ["data", "participants", "read", "consent"]}, {"paragraph_vector": [125.644798, -58.374118], "paragraph_keywords": ["participants", "decisions", "options", "friends"]}, {"paragraph_vector": [93.837165, -54.262126], "paragraph_keywords": ["trust", "participants", "consent", "delegation"]}, {"paragraph_vector": [100.328742, -55.282379], "paragraph_keywords": ["delegation", "participants", "control", "trust"]}, {"paragraph_vector": [125.246681, -58.162567], "paragraph_keywords": ["data", "participants", "captured", "study"]}, {"paragraph_vector": [85.402168, -58.009845], "paragraph_keywords": ["consent", "systems", "delegation", "scenarios"]}, {"paragraph_vector": [84.885574, -56.506713], "paragraph_keywords": ["consent", "data", "control", "users"]}], "content": {}, "doi": "10.1145/3290605.3300916"}, {"uri": "298", "title": "Cross-Device Taxonomy:  Survey, Opportunities and Challenges of  Interactions Spanning Across Multiple Devices", "timestamp": "2019", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Frederik Brudy", "Christian Holz", "Steven Houben"], "summary": "Designing interfaces or applications that move beyond the bounds of a single device screen enables new ways to engage with digital content. Research addressing the opportunities and challenges of interactions with multiple devices in concert is of continued focus in HCI research. To inform the future research agenda of this field, we contribute an analysis and taxonomy of a corpus of 510 papers in the crossdevice computing domain. For both new and experienced researchers in the field we provide: an overview, historic trends and unified terminology of cross-device research; discussion of major and under-explored application areas; mapping of enabling technologies; synthesis of key interaction techniques spanning across multiple devices; and review of common evaluation strategies. We close with a discussion of open issues. Our taxonomy aims to create a unified terminology and common understanding for researchers in order to facilitate and stimulate future cross-device research. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. CHI 2019, May 4\u20139, 2019, Glasgow, Scotland UK \u00a9 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-5970-2/19/05. . . $15.00 https://doi.org/10.1145/3290605.3300792 CCS CONCEPTS \u2022Human-centered computing\u2192HCI theory, concepts andmodels;Ubiquitous andmobile computing systems and tools; Interaction paradigms; Ubiquitous and mobile computing design and evaluation methods.", "keywords": ["time", "information", "display", "design", "analysis", "technique", "category", "focus", "example", "user", "interaction", "work", "evaluation", "space", "use", "people", "distributed", "challenge", "computing", "page", "field", "dataset", "application", "gesture", "content", "survey", "terminology", "tracking", "-", "including", "motion", "scale", "configuration", "device", "table", "data", "technology", "researcher", "study", "lab", "system", "support", "research", "term", "include", "tagging", "taxonomy", "paper", "interface", "area"], "document_vector": [58.576137, 3.481712], "paragraphs": [{"paragraph_vector": [-11.496678, 52.045398], "paragraph_keywords": ["computing", "device", "interaction", "research"]}, {"paragraph_vector": [-15.355993, 53.123405], "paragraph_keywords": ["research", "device", "taxonomy", "systems"]}, {"paragraph_vector": [-8.201729, 51.935306], "paragraph_keywords": ["papers", "tagging", "tags", "search"]}, {"paragraph_vector": [-9.20576, 52.696655], "paragraph_keywords": ["papers", "references", "time", "analysis"]}, {"paragraph_vector": [-11.33904, 52.701736], "paragraph_keywords": ["work", "device", "research", "area"]}, {"paragraph_vector": [-14.243201, 52.676902], "paragraph_keywords": ["research", "work", "terms", "devices"]}, {"paragraph_vector": [-13.095661, 51.68975], "paragraph_keywords": ["use", "device", "terms", "research"]}, {"paragraph_vector": [-14.576671, 50.873718], "paragraph_keywords": ["scale", "devices", "dimension", "research"]}, {"paragraph_vector": [-12.553304, 51.618618], "paragraph_keywords": ["research", "application", "work", "computing"]}, {"paragraph_vector": [-12.724417, 54.066986], "paragraph_keywords": ["devices", "tracking", "including", "interaction"]}, {"paragraph_vector": [-26.613212, 46.069179], "paragraph_keywords": ["tracking", "systems", "devices", "sensors"]}, {"paragraph_vector": [-19.828357, 50.260803], "paragraph_keywords": ["tracking", "interaction", "device", "techniques"]}, {"paragraph_vector": [-23.083259, 49.773334], "paragraph_keywords": ["techniques", "devices", "device", "configuration"]}, {"paragraph_vector": [-25.071205, 49.332321], "paragraph_keywords": ["interaction", "device", "content", "techniques"]}, {"paragraph_vector": [-25.153228, 50.30751], "paragraph_keywords": ["device", "techniques", "devices", "content"]}, {"paragraph_vector": [-18.723878, 53.492485], "paragraph_keywords": ["devices", "users", "device", "overview"]}, {"paragraph_vector": [-11.570927, 51.727016], "paragraph_keywords": ["evaluation", "device", "systems", "world"]}, {"paragraph_vector": [-11.098021, 48.402908], "paragraph_keywords": ["studies", "design", "research", "work"]}, {"paragraph_vector": [-14.614689, 50.324817], "paragraph_keywords": ["evaluation", "gestures", "device", "interaction"]}, {"paragraph_vector": [-15.296821, 51.567298], "paragraph_keywords": ["device", "challenges", "interaction", "work"]}, {"paragraph_vector": [-17.307533, 51.420433], "paragraph_keywords": ["device", "interaction", "users", "people"]}, {"paragraph_vector": [-13.10997, 51.150886], "paragraph_keywords": ["device", "use", "interactions", "users"]}, {"paragraph_vector": [-15.165904, 51.312831], "paragraph_keywords": ["device", "devices", "standards", "support"]}, {"paragraph_vector": [-13.221467, 52.051887], "paragraph_keywords": ["research", "community", "paper", "devices"]}], "content": {}, "doi": "10.1145/3290605.3300502"}]