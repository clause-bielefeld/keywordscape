export const eurovis_2021_proceedings_corpus = [{"uri": "0", "title": "A Deeper Understanding of Visualization\u2013Text Interplay in Geographic Data-driven Stories", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Shahid Latif", "Siming Chen", "Fabian Beck"], "summary": "Data-driven stories comprise of visualizations and a textual narrative. The two representations coexist and complement each other. Although existing research has explored the design strategies and structure of such stories, it remains an open research question how the two representations play together on a detailed level and how they are linked with each other. In this paper, we aim at understanding the fine-grained interplay of text and visualizations in geographic data-driven stories. We focus on geographic content as it often includes complex spatiotemporal data presented as versatile visualizations and rich textual descriptions. We conduct a qualitative empirical study on 22 stories collected from a variety of news media outlets; 10 of the stories report the COVID-19 pandemic, the others cover diverse topics. We investigate the role of every sentence and visualization within the narrative to reveal how they reference each other and interact. Moreover, we explore the positioning and sequence of various parts of the narrative to find patterns that further consolidate the stories. Drawing from the findings, we discuss study implications with respect to best practices and possibilities to automate the report generation.", "keywords": ["observed", "respect", "way", "narrative", "provide", "content", "annotation", "text", "finding", "space", "data", "describe", "example", "result", "region", "coding", "time", "instance", "sentence", "quote", "practice", "research", "information", "interplay", "study", "plot", "al", "insight", "collection", "comparison", "role", "author", "linking", "use", "support", "authoring", "analysis", "overview", "figure", "code", "reporting", "design", "map", "driven", "county", "story", "include", "entity", "level", "category", "reader", "visualization"], "document_vector": [-51.500614, -44.568347], "paragraphs": [{"paragraph_vector": [1.550902, -28.167554], "paragraph_keywords": ["data", "stories", "visualizations", "visualization"]}, {"paragraph_vector": [-1.932856, -29.232995], "paragraph_keywords": ["stories", "data", "visualization", "narrative"]}, {"paragraph_vector": [-4.388595, -26.519769], "paragraph_keywords": ["data", "stories", "authoring", "design"]}, {"paragraph_vector": [-10.303791, -23.960079], "paragraph_keywords": ["visualizations", "text", "al", "et"]}, {"paragraph_vector": [-1.705795, -29.285369], "paragraph_keywords": ["visualization", "text", "stories", "data"]}, {"paragraph_vector": [-0.701942, -31.196792], "paragraph_keywords": ["collection", "stories", "codes", "code"]}, {"paragraph_vector": [-4.307186, -24.175346], "paragraph_keywords": ["text", "categories", "visualization", "story"]}, {"paragraph_vector": [1.055727, -30.813018], "paragraph_keywords": ["time", "stories", "location", "identifiers"]}, {"paragraph_vector": [50.302619, -63.186122], "paragraph_keywords": ["values", "locations", "outlier", "outliers"]}, {"paragraph_vector": [45.648101, -65.095764], "paragraph_keywords": ["reporting", "instance", "insights", "survey"]}, {"paragraph_vector": [-0.484155, -32.955673], "paragraph_keywords": ["stories", "instance", "data", "sentences"]}, {"paragraph_vector": [1.335544, -28.997682], "paragraph_keywords": ["insights", "visualizations", "quotes", "data"]}, {"paragraph_vector": [2.596642, -45.040992], "paragraph_keywords": ["data", "overview", "visualization", "maps"]}, {"paragraph_vector": [28.342256, -55.871212], "paragraph_keywords": ["plots", "data", "visualization", "line"]}, {"paragraph_vector": [13.644962, -42.485317], "paragraph_keywords": ["data", "visualizations", "voters", "offer"]}, {"paragraph_vector": [-0.16108, -27.746294], "paragraph_keywords": ["visualization", "links", "text", "visualizations"]}, {"paragraph_vector": [-7.314581, -24.231245], "paragraph_keywords": ["visualizations", "visualization", "collection", "explanations"]}, {"paragraph_vector": [-6.42071, -26.60988], "paragraph_keywords": ["visualization", "visualizations", "stories", "space"]}, {"paragraph_vector": [-3.748211, -31.86116], "paragraph_keywords": ["stories", "text", "visualization", "visualizations"]}, {"paragraph_vector": [-4.158664, -30.15557], "paragraph_keywords": ["stories", "examples", "sample", "text"]}, {"paragraph_vector": [-3.282103, -32.954761], "paragraph_keywords": ["entities", "data", "regions", "findings"]}, {"paragraph_vector": [-7.710947, -26.539815], "paragraph_keywords": ["visualization", "text", "data", "captions"]}, {"paragraph_vector": [-9.292084, -25.613006], "paragraph_keywords": ["visualizations", "content", "findings", "overview"]}, {"paragraph_vector": [-4.455794, -27.651731], "paragraph_keywords": ["text", "data", "approaches", "visualization"]}, {"paragraph_vector": [-2.740922, -29.880075], "paragraph_keywords": ["data", "stories", "project", "visualizations"]}], "content": {}, "doi": "empty"}, {"uri": "1", "title": "Topography of Violence: Considerations for Ethical and Collaborative Visualization Design", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["F. Ehmel", "M. D\u00f6rk"], "summary": "Based on a collaborative visualization design process involving sensitive historical data and historiographical expertise, we investigate the relevance of ethical principles in visualization design. While fundamental ethical norms like truthfulness and accuracy are already well-described and common goals in visualization design, datasets that are accompanied by specific ethical concerns need to be processed and visualized with an additional level of carefulness and thought. There has been little research on adequate visualization design incorporating such considerations. To address this gap we present insights from Topography of Violence, a visualization project with the Jewish Museum Berlin that focuses on a dataset of more than 4,500 acts of violence against Jews in Germany between 1930 and 1938. Drawing from the joint project, we develop an approach to the visualization of sensitive data, which features both conceptual and procedural considerations for visualization design. Our findings provide value for both visualization researchers and practitioners by highlighting challenges and opportunities for ethical data visualization.", "keywords": ["work", "exhibition", "group", "lead", "year", "project", "data", "consider", "result", "symbol", "time", "source", "instance", "discussed", "wall", "animation", "people", "visitor", "research", "violence", "aspiration", "information", "perspective", "representation", "set", "method", "process", "attack", "dataset", "convey", "study", "interface", "based", "find", "expert", "participant", "filter", "displayed", "museum", "use", "animated", "feedback", "form", "workshop", "figure", "color", "design", "technique", "map", "act", "user", "category", "visualization"], "document_vector": [18.096015, -85.59188], "paragraphs": [{"paragraph_vector": [26.927141, -28.182382], "paragraph_keywords": ["design", "violence", "visualization", "data"]}, {"paragraph_vector": [20.475353, -22.938205], "paragraph_keywords": ["visualization", "data", "research", "humanities"]}, {"paragraph_vector": [20.684164, -21.394472], "paragraph_keywords": ["visualizations", "data", "museum", "cartography"]}, {"paragraph_vector": [19.602363, -21.761671], "paragraph_keywords": ["visualization", "data", "visualize", "design"]}, {"paragraph_vector": [23.823122, -25.121355], "paragraph_keywords": ["visualization", "design", "visualizations", "process"]}, {"paragraph_vector": [-86.563346, -31.964021], "paragraph_keywords": ["visualization", "design", "dataset", "experts"]}, {"paragraph_vector": [19.867559, -20.299783], "paragraph_keywords": ["visualization", "museum", "research", "group"]}, {"paragraph_vector": [35.782402, -33.96408], "paragraph_keywords": ["violence", "dataset", "research", "years"]}, {"paragraph_vector": [34.333362, -32.58826], "paragraph_keywords": ["data", "sources", "workshop", "attacks"]}, {"paragraph_vector": [28.547521, -26.592086], "paragraph_keywords": ["visitors", "map", "wall", "animated"]}, {"paragraph_vector": [23.884532, -24.063085], "paragraph_keywords": ["artifacts", "forms", "participants", "selected"]}, {"paragraph_vector": [27.309492, -27.781709], "paragraph_keywords": ["forms", "participants", "data", "instance"]}, {"paragraph_vector": [40.190063, -40.683883], "paragraph_keywords": ["data", "perspectives", "location", "participants"]}, {"paragraph_vector": [27.445465, -25.475234], "paragraph_keywords": ["wall", "map", "interface", "section"]}, {"paragraph_vector": [28.777593, -28.38541], "paragraph_keywords": ["symbols", "violence", "design", "experts"]}, {"paragraph_vector": [32.353538, -32.643039], "paragraph_keywords": ["found", "categories", "star", "hexagon"]}, {"paragraph_vector": [29.702104, -33.47071], "paragraph_keywords": ["figure", "map", "violence", "grid"]}, {"paragraph_vector": [33.970619, -33.482612], "paragraph_keywords": ["interface", "symbols", "screen", "animation"]}, {"paragraph_vector": [40.243587, -36.611003], "paragraph_keywords": ["map", "attacks", "dataset", "filter"]}, {"paragraph_vector": [43.488948, -37.259166], "paragraph_keywords": ["data", "filter", "design", "violence"]}, {"paragraph_vector": [22.956987, -24.622034], "paragraph_keywords": ["visualization", "design", "process", "experts"]}, {"paragraph_vector": [29.96734, -30.182365], "paragraph_keywords": ["visualization", "dataset", "project", "limitations"]}, {"paragraph_vector": [30.028141, -31.2945], "paragraph_keywords": ["usage", "graphics", "level", "visualization"]}, {"paragraph_vector": [26.853155, -27.430727], "paragraph_keywords": ["visualization", "fates", "impact", "data"]}, {"paragraph_vector": [27.725728, -26.623744], "paragraph_keywords": ["design", "set", "interface", "process"]}, {"paragraph_vector": [24.392387, -26.047605], "paragraph_keywords": ["research", "like", "based", "feedback"]}], "content": {}, "doi": "empty"}, {"uri": "2", "title": "Parameterized Splitting of Summed Volume Tables", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Christian Reinbold", "R\u00fcdiger Westermann"], "summary": "Summed Volume Tables (SVTs) allow one to compute integrals over the data values in any cubical area of a three-dimensional orthogonal grid in constant time, and they are especially interesting for building spatial search structures for sparse volumes. However, SVTs become extremely memory consuming due to the large values they need to store; for a dataset of n values an SVT requiresO(n logn) bits. The 3D Fenwick tree allows recovering the integral values inO(log3 n) time, at a memory consumption ofO(n) bits. We propose an algorithm that generates SVT representations that can flexibly trade speed for memory: From similar characteristics as SVTs, over equal memory consumption as 3D Fenwick trees at significantly lower computational complexity, to even further reduced memory consumption at the cost of raising computational complexity. For a 641\u00d79601\u00d79601 binary dataset, the algorithm can generate an SVT representation that requires 27.0GB and 46 \u00b78 data fetch operations to retrieve an integral value, compared to 27.5GB and 1521 \u00b78 fetches by 3D Fenwick trees, a decrease in fetches of 97%. A full SVT requires 247.6GB and 8 fetches per integral value. We present a novel hierarchical approach to compute and store intermediate prefix sums of SVTs, so that any prescribed memory consumption between O(n) bits and O(n logn) bits is achieved. We evaluate the performance of the proposed algorithm in a number of examples considering large volume data, and we perform comparisons to existing alternatives. CCS Concepts \u2022 Information systems \u2192 Data structures; \u2022 Human-centered computing \u2192 Scientific visualization;", "keywords": ["consumption", "stored", "compute", "number", "value", "split", "data", "volume", "heuristic", "input", "svt", "time", "position", "approach", "structure", "size", "tree", "sum", "fetch", "representation", "computed", "subarrays", "operation", "memory", "prefix", "use", "parameter", "requires", "given", "precision", "shape", "entry", "svts", "search", "array", "subarray"], "document_vector": [45.852401, 74.578552], "paragraphs": [{"paragraph_vector": [-141.510681, 40.551723], "paragraph_keywords": ["memory", "data", "volume", "values"]}, {"paragraph_vector": [-147.588226, 44.302238], "paragraph_keywords": ["data", "volume", "representations", "memory"]}, {"paragraph_vector": [-145.559326, 44.007419], "paragraph_keywords": ["memory", "data", "consumption", "tree"]}, {"paragraph_vector": [-150.975631, 38.170471], "paragraph_keywords": ["data", "svts", "volume", "bvh"]}, {"paragraph_vector": [-150.903381, 37.423465], "paragraph_keywords": ["rounding", "memory", "computer", "sums"]}, {"paragraph_vector": [-144.212509, 42.686691], "paragraph_keywords": ["array", "entries", "sums", "precision"]}, {"paragraph_vector": [-145.321197, 42.096275], "paragraph_keywords": ["memory", "meiv", "brick", "stored"]}, {"paragraph_vector": [-143.418258, 38.641822], "paragraph_keywords": ["values", "sat", "y", "memory"]}, {"paragraph_vector": [-144.018112, 41.751144], "paragraph_keywords": ["array", "svt", "prefix", "sums"]}, {"paragraph_vector": [-143.105178, 42.770225], "paragraph_keywords": ["values", "prefix", "sum", "split"]}, {"paragraph_vector": [-146.637603, 45.604236], "paragraph_keywords": ["split", "array", "parameter", "dimension"]}, {"paragraph_vector": [-144.761062, 42.324924], "paragraph_keywords": ["distributed", "subarrays", "size", "dimension"]}, {"paragraph_vector": [-138.238388, 41.530883], "paragraph_keywords": ["split", "subarray", "size", "node"]}, {"paragraph_vector": [-142.495422, 42.898235], "paragraph_keywords": ["entry", "array", "tree", "parameter"]}, {"paragraph_vector": [-142.045791, 44.329204], "paragraph_keywords": ["fetch", "prefix", "bound", "ni"]}, {"paragraph_vector": [-144.661712, 42.842185], "paragraph_keywords": ["memory", "space", "search", "representations"]}, {"paragraph_vector": [-145.461486, 44.182163], "paragraph_keywords": ["parameter", "tree", "\u03bb", "fetch"]}, {"paragraph_vector": [-140.267456, 41.360118], "paragraph_keywords": ["\u03bba", "\u03bb", "heuristic", "estimate"]}, {"paragraph_vector": [-145.145507, 44.010082], "paragraph_keywords": ["parameter", "trees", "tree", "heuristic"]}, {"paragraph_vector": [-145.490921, 43.330436], "paragraph_keywords": ["heuristic", "memory", "results", "fetches"]}, {"paragraph_vector": [-142.814926, 43.239921], "paragraph_keywords": ["memory", "operations", "fetch", "approach"]}, {"paragraph_vector": [-145.382354, 44.186191], "paragraph_keywords": ["data", "meiv", "memory", "precision"]}, {"paragraph_vector": [-146.015441, 41.393939], "paragraph_keywords": ["memory", "svt", "encoding", "representations"]}, {"paragraph_vector": [-157.699645, 45.412651], "paragraph_keywords": ["histograms", "data", "regions", "approach"]}], "content": {}, "doi": "empty"}, {"uri": "3", "title": "Exploring Multi-dimensional Data via Subset Embedding", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Peng Xie", "Wenyuan Tao", "Jie Li", "Wentao Huang", "Siming Chen"], "summary": "Multi-dimensional data exploration is a classic research topic in visualization. Most existing approaches are designed for identifying record patterns in dimensional space or subspace. In this paper, we propose a visual analytics approach to exploring subset patterns. The core of the approach is a subset embedding network (SEN) that represents a group of subsets as uniformlyformatted embeddings. We implement the SEN as multiple subnets with separate loss functions. The design enables to handle arbitrary subsets and capture the similarity of subsets on single features, thus achieving accurate pattern exploration, which in most cases is searching for subsets having similar values on few features. Moreover, each subnet is a fully-connected neural network with one hidden layer. The simple structure brings high training efficiency. We integrate the SEN into a visualization system that achieves a 3-step workflow. Specifically, analysts (1) partition the given dataset into subsets, (2) select portions in a projected latent space created using the SEN, and (3) determine the existence of patterns within selected subsets. Generally, the system combines visualizations, interactions, automatic methods, and quantitative measures to balance the exploration flexibility and operation efficiency, and improve the interpretability and faithfulness of the identified patterns. Case studies and quantitative experiments on multiple open datasets demonstrate the general applicability and effectiveness of our approach. CCS Concepts \u2022 Human-centered computing \u2192 Visual analytics; Visualization systems and tools;", "keywords": ["subset", "propose", "selected", "group", "section", "sen", "according", "node", "learning", "exploration", "embeddings", "number", "value", "space", "data", "vector", "training", "approach", "partition", "find", "dataset", "record", "network", "system", "measure", "cluster", "figure", "technique", "analyst", "embedding", "select", "attribute", "projection", "feature", "slicing", "visualization", "pattern"], "document_vector": [-167.82106, 15.399023], "paragraphs": [{"paragraph_vector": [-166.93518, -15.950425], "paragraph_keywords": ["subset", "subsets", "data", "patterns"]}, {"paragraph_vector": [-168.503448, -11.643098], "paragraph_keywords": ["subsets", "sen", "patterns", "subset"]}, {"paragraph_vector": [-165.680358, -14.620511], "paragraph_keywords": ["subset", "section", "number", "attribute"]}, {"paragraph_vector": [-168.591033, -12.70449], "paragraph_keywords": ["features", "subsets", "subset", "existing"]}, {"paragraph_vector": [-170.0009, -12.170458], "paragraph_keywords": ["learning", "subset", "sen", "figure"]}, {"paragraph_vector": [-170.747222, -9.024115], "paragraph_keywords": ["embeddings", "subnets", "subnet", "features"]}, {"paragraph_vector": [-171.037261, -8.437503], "paragraph_keywords": ["subsets", "embeddings", "training", "sen"]}, {"paragraph_vector": [-166.833465, -20.039779], "paragraph_keywords": ["subsets", "data", "subset", "visualization"]}, {"paragraph_vector": [-167.213989, -14.084006], "paragraph_keywords": ["subsets", "subset", "figure", "attribute"]}, {"paragraph_vector": [-166.245819, -15.931157], "paragraph_keywords": ["subsets", "attribute", "slicing", "node"]}, {"paragraph_vector": [-167.648223, -12.387002], "paragraph_keywords": ["subsets", "projection", "subset", "analysts"]}, {"paragraph_vector": [94.757904, -48.219608], "paragraph_keywords": ["feature", "subsets", "clusters", "figure"]}, {"paragraph_vector": [-167.629074, -12.89325], "paragraph_keywords": ["subsets", "feature", "data", "patterns"]}, {"paragraph_vector": [63.438442, -39.086128], "paragraph_keywords": ["subsets", "figure", "find", "crimes"]}, {"paragraph_vector": [-169.499526, -10.69237], "paragraph_keywords": ["records", "accuracy", "features", "clusters"]}, {"paragraph_vector": [-172.505218, -8.920111], "paragraph_keywords": ["features", "sen", "sne", "values"]}, {"paragraph_vector": [-167.847488, -13.217035], "paragraph_keywords": ["sen", "features", "projections", "subsets"]}, {"paragraph_vector": [-172.590713, -7.04777], "paragraph_keywords": ["dr", "hyperparameters", "patterns", "network"]}, {"paragraph_vector": [-168.11856, -12.865287], "paragraph_keywords": ["data", "technique", "projections", "network"]}, {"paragraph_vector": [-169.609481, -22.259695], "paragraph_keywords": ["patterns", "subspaces", "subsets", "find"]}, {"paragraph_vector": [-167.322921, -14.963939], "paragraph_keywords": ["subset", "subsets", "approach", "data"]}, {"paragraph_vector": [-168.704254, -23.994045], "paragraph_keywords": ["subset", "techniques", "features", "integrate"]}], "content": {}, "doi": "empty"}, {"uri": "4", "title": "A novel approach for exploring annotated data with interactive lenses", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["F. Bettio"], "summary": "We introduce a novel approach for assisting users in exploring 2D data representations with an interactive lens. Focus-andcontext exploration is supported by translating user actions to the joint adjustments in camera and lens parameters that ensure a good placement and sizing of the lens within the view. This general approach, implemented using standard device mappings, overcomes the limitations of current solutions, which force users to continuously switch from lens positioning and scaling to view panning and zooming. Navigation is further assisted by exploiting data annotations. In addition to traditional visual markups and information links, we associate to each annotation a lens configuration that highlights the region of interest. During interaction, an assisting controller determines the next best lens in the database based on the current view and lens parameters and the navigation history. Then, the controller interactively guides the user\u2019s lens towards the selected target and displays its annotation markup. As only one annotation markup is displayed at a time, clutter is reduced. Moreover, in addition to guidance, the navigation can also be automated to create a tour through the data. While our methods are generally applicable to general 2D visualization, we have implemented them for the exploration of stratigraphic relightable models. The capabilities of our approach are demonstrated in cultural heritage use cases. A user study has been performed in order to validate our approach. CCS Concepts \u2022 Computing methodologies \u2192 Computer graphics; Graphics systems and interfaces;", "keywords": ["work", "view", "focus", "provide", "display", "annotation", "navigation", "context", "exploration", "sec", "distance", "explore", "thumbnail", "suggestion", "area", "space", "controller", "data", "interaction", "presented", "model", "time", "position", "approach", "layer", "fig", "control", "target", "image", "motion", "information", "lens", "annotated", "interface", "camera", "based", "scaling", "displayed", "moving", "system", "support", "use", "analysis", "parameter", "score", "technique", "order", "bar", "user", "scale", "guidance", "change", "similarity", "visualization"], "document_vector": [98.04335, -42.937625], "paragraphs": [{"paragraph_vector": [-45.823822, 37.774784], "paragraph_keywords": ["lens", "visualization", "view", "lenses"]}, {"paragraph_vector": [-43.704284, 37.943065], "paragraph_keywords": ["lens", "annotation", "parameters", "annotations"]}, {"paragraph_vector": [-47.442974, 35.088577], "paragraph_keywords": ["users", "visualization", "support", "guidance"]}, {"paragraph_vector": [-43.280303, 38.699428], "paragraph_keywords": ["lens", "lenses", "control", "viewpoints"]}, {"paragraph_vector": [-48.861316, 34.447685], "paragraph_keywords": ["annotations", "annotated", "techniques", "annotation"]}, {"paragraph_vector": [-45.187805, 37.967178], "paragraph_keywords": ["lens", "users", "data", "space"]}, {"paragraph_vector": [-49.393905, 33.306102], "paragraph_keywords": ["lens", "camera", "context", "focus"]}, {"paragraph_vector": [-48.120391, 34.761234], "paragraph_keywords": ["boundary", "lens", "context", "change"]}, {"paragraph_vector": [-50.11029, 32.329261], "paragraph_keywords": ["lens", "camera", "mouse", "control"]}, {"paragraph_vector": [-51.352973, 32.348464], "paragraph_keywords": ["lens", "navigation", "annotation", "annotations"]}, {"paragraph_vector": [-46.706245, 35.855869], "paragraph_keywords": ["lens", "annotations", "annotation", "parameters"]}, {"paragraph_vector": [-47.28923, 34.444107], "paragraph_keywords": ["lens", "annotation", "score", "similarity"]}, {"paragraph_vector": [-49.219623, 34.267341], "paragraph_keywords": ["lens", "context", "lenses", "area"]}, {"paragraph_vector": [-40.656185, 36.241786], "paragraph_keywords": ["change", "function", "similarity", "lens"]}, {"paragraph_vector": [-52.927448, 28.115371], "paragraph_keywords": ["user", "annotation", "priority", "lens"]}, {"paragraph_vector": [-52.885704, 31.289609], "paragraph_keywords": ["lens", "user", "suggestion", "suggestions"]}, {"paragraph_vector": [-42.058788, 38.670742], "paragraph_keywords": ["lens", "suggestion", "target", "direction"]}, {"paragraph_vector": [-55.610866, 61.579528], "paragraph_keywords": ["layers", "exploration", "sculptures", "user"]}, {"paragraph_vector": [-53.881782, 26.679185], "paragraph_keywords": ["model", "target", "lens", "users"]}, {"paragraph_vector": [-53.792686, 18.546173], "paragraph_keywords": ["users", "perceived", "training", "usability"]}, {"paragraph_vector": [-53.642059, 23.832054], "paragraph_keywords": ["interface", "completion", "lens", "users"]}, {"paragraph_vector": [-51.4962, 26.367906], "paragraph_keywords": ["controller", "effect", "p", "focused"]}, {"paragraph_vector": [-49.459903, 26.854749], "paragraph_keywords": ["user", "users", "annotations", "explore"]}, {"paragraph_vector": [-49.081436, 28.976085], "paragraph_keywords": ["user", "presented", "interface", "interfaces"]}, {"paragraph_vector": [-55.733409, 23.818605], "paragraph_keywords": ["annotations", "time", "thumbnail", "bar"]}, {"paragraph_vector": [-60.102283, 19.138275], "paragraph_keywords": ["bar", "sus", "thumbnail", "fix"]}, {"paragraph_vector": [-51.970649, 19.534242], "paragraph_keywords": ["use", "p", "idea", "way"]}, {"paragraph_vector": [-49.494884, 30.163896], "paragraph_keywords": ["exploration", "lens", "users", "annotations"]}, {"paragraph_vector": [-47.344318, 34.467643], "paragraph_keywords": ["lenses", "data", "patches", "extend"]}], "content": {}, "doi": "empty"}, {"uri": "5", "title": "ParSetgnostics: Quality Metrics for Parallel Sets", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Frederik L. Dennig", "Maximilian T. Fischer", "Michael Blumenschein", "Johannes Fuchs", "Daniel A. Keim", "Evanthia Dimara"], "summary": "While there are many visualization techniques for exploring numeric data, only a few work with categorical data. One prominent example is Parallel Sets, showing data frequencies instead of data points analogous to parallel coordinates for numerical data. As nominal data does not have an intrinsic order, the design of Parallel Sets is sensitive to visual clutter due to overlaps, crossings, and subdivision of ribbons hindering readability and pattern detection. In this paper, we propose a set of quality metrics, called ParSetgnostics (Parallel Sets diagnostics), which aim to improve Parallel Sets by reducing clutter. These quality metrics quantify important properties of Parallel Sets such as overlap, orthogonality, ribbon width variance, and mutual information to optimize the category and dimension ordering. By conducting a systematic correlation analysis between the individual metrics, we ensure their distinctiveness. Further, we evaluate the clutter reduction effect of ParSetgnostics by reconstructing six datasets from previous publications using Parallel Sets measuring and comparing their respective properties. Our results show that ParSetgostics facilitates multi-dimensional analysis of categorical data by automatically providing optimized Parallel Set designs with a clutter reduction of up to 81% compared to the originally proposed Parallel Sets visualizations. CCS Concepts \u2022 Human-centered computing \u2192 Visualization design and evaluation methods;", "keywords": ["angle", "readability", "slope", "metric", "number", "value", "data", "ribbon", "ax", "clutter", "property", "approach", "set", "quality", "information", "dataset", "based", "width", "crossing", "analysis", "dimension", "overlap", "figure", "order", "datasets", "ordering", "user", "category", "axis", "visualization"], "document_vector": [165.940582, -16.252756], "paragraphs": [{"paragraph_vector": [-164.08966, -38.177436], "paragraph_keywords": ["data", "sets", "solution", "analysis"]}, {"paragraph_vector": [-158.02803, -33.015968], "paragraph_keywords": ["sets", "data", "dimension", "interaction"]}, {"paragraph_vector": [-158.03627, -34.818817], "paragraph_keywords": ["sets", "ribbons", "metrics", "ordering"]}, {"paragraph_vector": [-169.845031, -34.632949], "paragraph_keywords": ["sets", "data", "visualization", "metrics"]}, {"paragraph_vector": [-156.376342, -31.225301], "paragraph_keywords": ["dimension", "quality", "visualization", "categories"]}, {"paragraph_vector": [-156.603759, -34.767211], "paragraph_keywords": ["dimensions", "sets", "ribbons", "dataset"]}, {"paragraph_vector": [-156.167968, -34.567016], "paragraph_keywords": ["ribbons", "dimension", "axes", "dimensions"]}, {"paragraph_vector": [-154.971267, -32.169933], "paragraph_keywords": ["ribbons", "data", "dimension", "number"]}, {"paragraph_vector": [-151.776382, -29.226057], "paragraph_keywords": ["ribbons", "plot", "width", "distance"]}, {"paragraph_vector": [-131.812545, -10.505967], "paragraph_keywords": ["colors", "ribbons", "dimension", "ribbon"]}, {"paragraph_vector": [-158.676498, -31.221101], "paragraph_keywords": ["sets", "overlap", "ribbons", "metrics"]}, {"paragraph_vector": [-150.460098, -37.083671], "paragraph_keywords": ["slope", "ribbons", "orthogonality", "angle"]}, {"paragraph_vector": [-156.149749, -33.989425], "paragraph_keywords": ["number", "crossings", "crossing", "ribbons"]}, {"paragraph_vector": [-155.865386, -33.396942], "paragraph_keywords": ["ribbons", "number", "dimension", "splits"]}, {"paragraph_vector": [-161.972335, -36.198619], "paragraph_keywords": ["sets", "ordering", "category", "information"]}, {"paragraph_vector": [-158.9151, -37.870735], "paragraph_keywords": ["ribbons", "ribbon", "sets", "performed"]}, {"paragraph_vector": [-147.823257, -35.739124], "paragraph_keywords": ["metrics", "sets", "visualizations", "ribbons"]}, {"paragraph_vector": [-151.928756, -37.642383], "paragraph_keywords": ["visualization", "ordering", "ribbons", "dimension"]}, {"paragraph_vector": [-154.25, -34.127922], "paragraph_keywords": ["metrics", "ribbons", "dimension", "correlation"]}, {"paragraph_vector": [-144.538589, -40.81319], "paragraph_keywords": ["metrics", "dimension", "categories", "properties"]}, {"paragraph_vector": [-155.54927, -33.829418], "paragraph_keywords": ["metrics", "sets", "number", "properties"]}, {"paragraph_vector": [-157.873641, -34.977188], "paragraph_keywords": ["sets", "quality", "metrics", "metric"]}], "content": {}, "doi": "empty"}, {"uri": "6", "title": "Visual Analysis of Spatio-temporal Phenomena with 1D Projections", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["M. Franke", "K. Kurzhals"], "summary": "It is crucial to visually extrapolate the characteristics of their evolution to understand critical spatio-temporal events such as earthquakes, fires, or the spreading of a disease. Animations embedded in the spatial context can be helpful for understanding details, but have proven to be less effective for overview and comparison tasks. We present an interactive approach for the exploration of spatio-temporal data, based on a set of neighborhood-preserving 1D projections which help identify patterns and support the comparison of numerous time steps and multivariate data. An important objective of the proposed approach is the visual description of local neighborhoods in the 1D projection to reveal patterns of similarity and propagation. As this locality cannot generally be guaranteed, we provide a selection of different projection techniques, as well as a hierarchical approach, to support the analysis of different data characteristics. In addition, we offer an interactive exploration technique to reorganize and improve the mapping locally to users\u2019 foci of interest. We demonstrate the usefulness of our approach with different real-world application scenarios and discuss the feedback we received from domain and visualization experts. CCS Concepts \u2022 Human-centered computing\u2192 Visual analytics; Geographic visualization; Information visualization; Visualization systems and tools;", "keywords": ["et", "neighborhood", "section", "synchronization", "grid", "task", "domain", "detail", "context", "wildfire", "value", "space", "glyph", "data", "region", "example", "time", "approach", "applied", "instance", "shown", "animation", "scenario", "identify", "spreading", "dataset", "based", "al", "support", "use", "analysis", "overview", "application", "figure", "country", "map", "order", "spatio", "projected", "visualization", "selection", "entity", "timeline", "change", "projection", "fire", "distance", "pattern"], "document_vector": [-81.101089, -29.152851], "paragraphs": [{"paragraph_vector": [39.884189, -58.183357], "paragraph_keywords": ["shown", "spatio", "time", "context"]}, {"paragraph_vector": [42.062221, -63.942455], "paragraph_keywords": ["data", "approach", "analysis", "patterns"]}, {"paragraph_vector": [35.349174, -60.863662], "paragraph_keywords": ["analysis", "propagation", "changes", "animation"]}, {"paragraph_vector": [50.41217, -73.202217], "paragraph_keywords": ["visualization", "data", "multivariate", "analysis"]}, {"paragraph_vector": [61.641822, -63.880821], "paragraph_keywords": ["data", "filling", "space", "curves"]}, {"paragraph_vector": [50.801933, -62.406757], "paragraph_keywords": ["objects", "context", "space", "-"]}, {"paragraph_vector": [48.281681, -63.563976], "paragraph_keywords": ["data", "based", "instance", "tasks"]}, {"paragraph_vector": [81.563796, -64.040168], "paragraph_keywords": ["based", "prototype", "distance", "data"]}, {"paragraph_vector": [54.290523, -63.525718], "paragraph_keywords": ["time", "hierarchy", "projected", "data"]}, {"paragraph_vector": [50.591243, -61.948345], "paragraph_keywords": ["data", "elements", "timeline", "nexus"]}, {"paragraph_vector": [49.310237, -62.759754], "paragraph_keywords": ["timelines", "map", "glyphs", "data"]}, {"paragraph_vector": [47.031234, -59.242427], "paragraph_keywords": ["projection", "projections", "entities", "selection"]}, {"paragraph_vector": [153.523818, -35.937438], "paragraph_keywords": ["projection", "neighborhood", "preservation", "projections"]}, {"paragraph_vector": [122.341209, -35.742645], "paragraph_keywords": ["stress", "neighborhoods", "projection", "choose"]}, {"paragraph_vector": [94.167678, -76.35717], "paragraph_keywords": ["projections", "dataset", "generated", "time"]}, {"paragraph_vector": [116.751541, -76.256309], "paragraph_keywords": ["projections", "values", "entities", "projection"]}, {"paragraph_vector": [44.604515, -68.950195], "paragraph_keywords": ["data", "spreading", "starting", "patterns"]}, {"paragraph_vector": [28.502248, -70.021263], "paragraph_keywords": ["hotspots", "data", "cases", "figure"]}, {"paragraph_vector": [57.667221, -74.939567], "paragraph_keywords": ["identify", "synchronization", "countries", "infection"]}, {"paragraph_vector": [13.543824, -73.659156], "paragraph_keywords": ["fire", "timeline", "forest", "wildfire"]}, {"paragraph_vector": [34.490806, -61.79985], "paragraph_keywords": ["timeline", "analyst", "figure", "pattern"]}, {"paragraph_vector": [34.116764, -63.462497], "paragraph_keywords": ["data", "time", "approach", "projections"]}, {"paragraph_vector": [33.962413, -64.922531], "paragraph_keywords": ["data", "approach", "projection", "metrics"]}, {"paragraph_vector": [55.035488, -66.503471], "paragraph_keywords": ["approach", "projections", "section", "spatio"]}, {"paragraph_vector": [128.196243, -47.762657], "paragraph_keywords": ["project", "time", "similarity", "projections"]}], "content": {}, "doi": "empty"}, {"uri": "7", "title": "iQUANT: Interactive Quantitative Investment Using Sparse Regression Factors", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Xuanwu Yue", "Qiao Gu", "Deyun Wang", "Huamin Qu", "Yong Wang"], "summary": "The model-based investing using financial factors is evolving as a principal method for quantitative investment. The main challenge lies in the selection of effective factors towards excess market returns. Existing approaches, either hand-picking factors or applying feature selection algorithms, do not orchestrate both human knowledge and computational power. This paper presents iQUANT, an interactive quantitative investment system that assists equity traders to quickly spot promising financial factors from initial recommendations suggested by algorithmic models, and conduct a joint refinement of factors and stocks for investment portfolio composition. We work closely with professional traders to assemble empirical characteristics of \u201cgood\u201d factors and propose effective visualization designs to illustrate the collective performance of financial factors, stock portfolios, and their interactions. We evaluate iQUANT through a formal user study, two case studies, and expert interviews, using a real stock market dataset consisting of 3000 stocks \u00d7 6000 days \u00d7 56 factors. CCS Concepts \u2022 Human-centered computing \u2192 Visual analytics; Visualization design and evaluation methods; Information visualization;", "keywords": ["selected", "view", "contribution", "return", "market", "prediction", "portfolio", "line", "task", "value", "space", "accuracy", "feature", "type", "data", "importance", "stock", "performance", "model", "time", "backtesting", "month", "cycle", "factor", "study", "based", "expert", "trading", "system", "regression", "iquant", "investing", "figure", "design", "sector", "investment", "selection", "user", "trader", "chart", "visualization"], "document_vector": [138.110961, 1.048824], "paragraphs": [{"paragraph_vector": [-4.773543, 28.447523], "paragraph_keywords": ["factors", "factor", "stock", "returns"]}, {"paragraph_vector": [0.352965, 21.485471], "paragraph_keywords": ["factor", "factors", "selection", "regression"]}, {"paragraph_vector": [1.13514, 19.081373], "paragraph_keywords": ["visualization", "charts", "designs", "based"]}, {"paragraph_vector": [-0.100787, 19.828617], "paragraph_keywords": ["feature", "users", "data", "features"]}, {"paragraph_vector": [7.642507, 19.572935], "paragraph_keywords": ["factor", "stock", "factors", "feature"]}, {"paragraph_vector": [-6.449125, 27.337657], "paragraph_keywords": ["factors", "factor", "traders", "trading"]}, {"paragraph_vector": [-3.480962, 26.600803], "paragraph_keywords": ["factor", "factors", "selection", "model"]}, {"paragraph_vector": [1.471941, 21.200523], "paragraph_keywords": ["portfolio", "factors", "stocks", "stock"]}, {"paragraph_vector": [-1.885095, 24.326833], "paragraph_keywords": ["stock", "data", "market", "system"]}, {"paragraph_vector": [-0.556711, 23.337581], "paragraph_keywords": ["trading", "model", "stock", "t"]}, {"paragraph_vector": [-6.29498, 28.314226], "paragraph_keywords": ["model", "number", "stock", "factors"]}, {"paragraph_vector": [-1.380422, 25.250308], "paragraph_keywords": ["factor", "factors", "market", "stock"]}, {"paragraph_vector": [-3.018181, 24.222036], "paragraph_keywords": ["factor", "factors", "stock", "stocks"]}, {"paragraph_vector": [10.014225, 14.923156], "paragraph_keywords": ["factor", "factors", "time", "view"]}, {"paragraph_vector": [6.178203, 14.39592], "paragraph_keywords": ["factor", "stock", "factors", "figure"]}, {"paragraph_vector": [8.013484, 11.893173], "paragraph_keywords": ["factor", "factors", "line", "importance"]}, {"paragraph_vector": [-4.444355, 26.222013], "paragraph_keywords": ["factor", "factors", "stock", "selected"]}, {"paragraph_vector": [2.060386, 19.59839], "paragraph_keywords": ["factor", "stock", "selection", "factors"]}, {"paragraph_vector": [1.95787, 20.296396], "paragraph_keywords": ["design", "data", "tasks", "accuracy"]}, {"paragraph_vector": [5.690151, 17.44724], "paragraph_keywords": ["factor", "accuracy", "iquant", "baseline"]}, {"paragraph_vector": [6.896246, 16.631238], "paragraph_keywords": ["factors", "iquant", "design", "experts"]}, {"paragraph_vector": [3.688423, 21.102304], "paragraph_keywords": ["stock", "factor", "factors", "return"]}, {"paragraph_vector": [2.358724, 21.692153], "paragraph_keywords": ["factor", "manager", "factors", "stocks"]}, {"paragraph_vector": [-1.18387, 22.475782], "paragraph_keywords": ["figure", "factor", "stocks", "sector"]}, {"paragraph_vector": [-4.055088, 25.37302], "paragraph_keywords": ["factors", "factor", "model", "regression"]}, {"paragraph_vector": [2.772832, 20.594636], "paragraph_keywords": ["stock", "iquant", "factor", "study"]}, {"paragraph_vector": [1.968557, 20.425664], "paragraph_keywords": ["iquant", "stock", "factor", "system"]}], "content": {}, "doi": "empty"}, {"uri": "8", "title": "Guided Stable Dynamic Projections", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["E. F. Vernier", "J. L. D. Comba", "A. C. Telea"], "summary": "Projections aim to convey the relationships and similarity of high-dimensional data in a low-dimensional representation. Most such techniques are designed for static data. When used for time-dependent data, they usually fail to create a stable and suitable low dimensional representation. We propose two dynamic projection methods (PCD-tSNE and LD-tSNE) that use global guides to steer projection points. This avoids unstable movement that does not encode data dynamics while keeping t-SNE\u2019s neighborhood preservation ability. PCD-tSNE scores a good balance between stability, neighborhood preservation, and distance preservation, while LD-tSNE allows creating stable and customizable projections. We compare our methods to 11 other techniques using quality metrics and datasets provided by a recent benchmark for dynamic projections. CCS Concepts \u2022 Computing methodologies \u2192 Dimensionality reduction and manifold learning;", "keywords": ["et", "neighborhood", "sample", "k", "timesteps", "metric", "sec", "sne", "p", "value", "c", "function", "data", "result", "d", "time", "cost", "dynamic", "set", "quality", "class", "t", "pca", "method", "stability", "j", "pcd", "point", "dataset", "based", "strategy", "use", "tsne", "dimension", "cluster", "given", "figure", "g", "technique", "\u03bb", "datasets", "preservation", "show", "projection", "distance", "landmark"], "document_vector": [-142.97528, 26.372619], "paragraphs": [{"paragraph_vector": [125.972892, -43.988018], "paragraph_keywords": ["projections", "techniques", "datasets", "projection"]}, {"paragraph_vector": [135.698684, -35.6972], "paragraph_keywords": ["methods", "projections", "stability", "data"]}, {"paragraph_vector": [131.155532, -39.455551], "paragraph_keywords": ["methods", "data", "projections", "t"]}, {"paragraph_vector": [136.09584, -37.881862], "paragraph_keywords": ["projections", "projection", "base", "stability"]}, {"paragraph_vector": [133.715774, -35.785812], "paragraph_keywords": ["projection", "points", "quality", "use"]}, {"paragraph_vector": [136.858291, -32.055732], "paragraph_keywords": ["methods", "projections", "strategy", "pca"]}, {"paragraph_vector": [137.869644, -37.385108], "paragraph_keywords": ["projection", "landmarks", "sne", "data"]}, {"paragraph_vector": [135.54248, -37.653995], "paragraph_keywords": ["points", "l", "rn", "j"]}, {"paragraph_vector": [138.410934, -37.124233], "paragraph_keywords": ["j", "t", "yi", "cost"]}, {"paragraph_vector": [136.923309, -37.744659], "paragraph_keywords": ["points", "cost", "j", "tsne"]}, {"paragraph_vector": [135.283035, -40.471286], "paragraph_keywords": ["tsne", "projection", "given", "methods"]}, {"paragraph_vector": [135.3927, -37.657524], "paragraph_keywords": ["tsne", "neighbors", "metrics", "data"]}, {"paragraph_vector": [138.676345, -40.719154], "paragraph_keywords": ["j", "k", "neighbors", "t"]}, {"paragraph_vector": [131.401138, -41.702621], "paragraph_keywords": ["t", "data", "statistics", "cti"]}, {"paragraph_vector": [33.330406, 21.568889], "paragraph_keywords": ["dataset", "classes", "learning", "timesteps"]}, {"paragraph_vector": [129.559509, -36.524051], "paragraph_keywords": ["dataset", "projection", "sec", "activations"]}, {"paragraph_vector": [134.8871, -34.224639], "paragraph_keywords": ["g", "methods", "tsne", "method"]}, {"paragraph_vector": [134.799011, -35.071186], "paragraph_keywords": ["methods", "based", "pca", "projections"]}, {"paragraph_vector": [137.117797, -37.357856], "paragraph_keywords": ["g", "datasets", "preservation", "tsne"]}, {"paragraph_vector": [132.703308, -39.875831], "paragraph_keywords": ["tsne", "preservation", "distance", "influence"]}, {"paragraph_vector": [136.460281, -40.676986], "paragraph_keywords": ["tsne", "metrics", "c", "values"]}, {"paragraph_vector": [134.386352, -33.665851], "paragraph_keywords": ["landmarks", "d", "states", "class"]}, {"paragraph_vector": [136.123565, -38.439006], "paragraph_keywords": ["tsne", "landmarks", "stability", "d"]}, {"paragraph_vector": [135.148101, -38.777286], "paragraph_keywords": ["tsne", "placement", "projection", "preservation"]}, {"paragraph_vector": [136.968872, -34.787124], "paragraph_keywords": ["data", "methods", "projection", "projections"]}], "content": {}, "doi": "empty"}, {"uri": "9", "title": "Automatic Improvement of Continuous Colormaps in Euclidean Colorspaces", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Pascal Nardini", "Min Chen", "Michael B\u00f6ttinger", "Gerik Scheuermann", "Roxana Bujack"], "summary": "Colormapping is one of the simplest and most widely used data visualization methods within and outside the visualization community. Uniformity, order, discriminative power, and smoothness of continuous colormaps are the most important criteria for evaluating and potentially improving colormaps. We present a local and a global automatic optimization algorithm in Euclidean color spaces for each of these design rules in this work. As a foundation for our optimization algorithms, we used the CCC-Tool colormap specification (CMS); each algorithm has been implemented in this tool. In addition to synthetic examples that demonstrate each method\u2019s effect, we show the outcome of some of the methods applied to a typhoon simulation.", "keywords": ["work", "respect", "section", "colormaps", "line", "distance", "path", "value", "c", "tool", "data", "function", "example", "time", "colormap", "cm", "control", "method", "j", "speed", "rule", "point", "based", "algorithm", "use", "optimization", "application", "figure", "given", "color", "design", "ccc", "order", "key", "uniformity", "curvature", "show", "user", "power", "difference", "interpolation", "visualization"], "document_vector": [60.395488, -2.898748], "paragraphs": [{"paragraph_vector": [-135.696441, 3.233216], "paragraph_keywords": ["colormap", "order", "visualization", "algorithms"]}, {"paragraph_vector": [-143.148056, 6.774795], "paragraph_keywords": ["design", "colormap", "rules", "power"]}, {"paragraph_vector": [-135.92369, 2.855301], "paragraph_keywords": ["colormaps", "color", "colormap", "users"]}, {"paragraph_vector": [-142.006027, 6.268302], "paragraph_keywords": ["colormap", "colormaps", "algorithms", "users"]}, {"paragraph_vector": [-145.997787, 13.078976], "paragraph_keywords": ["colormap", "algorithm", "colormaps", "data"]}, {"paragraph_vector": [-139.692245, 5.700911], "paragraph_keywords": ["colormap", "points", "j", "values"]}, {"paragraph_vector": [-141.163467, 10.424619], "paragraph_keywords": ["colormap", "optimization", "c", "order"]}, {"paragraph_vector": [-148.213729, 13.947709], "paragraph_keywords": ["colors", "colormap", "uniformity", "algorithms"]}, {"paragraph_vector": [-147.578216, 12.920407], "paragraph_keywords": ["t", "control", "c", "colors"]}, {"paragraph_vector": [-151.366409, 17.609691], "paragraph_keywords": ["order", "line", "c", "j"]}, {"paragraph_vector": [-155.347167, 13.680232], "paragraph_keywords": ["points", "order", "speed", "intersection"]}, {"paragraph_vector": [-152.307998, 16.960733], "paragraph_keywords": ["lbo", "speed", "color", "points"]}, {"paragraph_vector": [-153.657394, 16.752502], "paragraph_keywords": ["colormap", "force", "points", "dp"]}, {"paragraph_vector": [-149.991241, 17.384786], "paragraph_keywords": ["curvature", "colormap", "importance", "speed"]}, {"paragraph_vector": [-158.426757, 19.348823], "paragraph_keywords": ["point", "j", "circle", "xi"]}, {"paragraph_vector": [-155.594009, 17.228218], "paragraph_keywords": ["interpolation", "points", "spline", "curvature"]}, {"paragraph_vector": [-145.8497, 11.810998], "paragraph_keywords": ["colormap", "function", "test", "shows"]}, {"paragraph_vector": [-143.262695, -1.254358], "paragraph_keywords": ["tool", "colormap", "optimization", "ccc"]}, {"paragraph_vector": [-141.759231, 7.086833], "paragraph_keywords": ["rainbow", "order", "colormaps", "power"]}, {"paragraph_vector": [-142.383666, 5.327326], "paragraph_keywords": ["colormap", "colormaps", "shows", "right"]}, {"paragraph_vector": [-151.197174, -69.723999], "paragraph_keywords": ["colormap", "temperature", "time", "height"]}, {"paragraph_vector": [-144.01625, -3.086018], "paragraph_keywords": ["cms", "keys", "lightness", "optimization"]}, {"paragraph_vector": [-145.232574, -1.059841], "paragraph_keywords": ["cms", "range", "data", "keys"]}, {"paragraph_vector": [-140.827575, 6.140079], "paragraph_keywords": ["optimization", "based", "colormap", "criteria"]}, {"paragraph_vector": [-142.043685, 4.72894], "paragraph_keywords": ["color", "optimization", "methods", "criteria"]}], "content": {}, "doi": "empty"}, {"uri": "10", "title": "Animated Presentation of Static Infographics with InfoMotion", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Yun Wang", "Yi Gao", "Ray Huang", "Weiwei Cui", "Haidong Zhang", "Dongmei Zhang"], "summary": "By displaying visual elements logically in temporal order, animated infographics can help readers better understand layers of information expressed in an infographic. While many techniques and tools target the quick generation of static infographics, few support animation designs. We propose InfoMotion that automatically generates animated presentations of static infographics. We first conduct a survey to explore the design space of animated infographics. Based on this survey, InfoMotion extracts graphical properties of an infographic to analyze the underlying information structures; then, animation effects are applied to the visual elements in the infographic in temporal order to present the infographic. The generated animations can be used in data videos or presentations. We demonstrate the utility of InfoMotion with two example applications, including mixed-initiative animation authoring and animation recommendation. To further understand the quality of the generated animations, we conduct a user study to gather subjective feedback on the animations generated by InfoMotion. CCS Concepts \u2022 Human-centered computing \u2192 Visualization design and evaluation methods;", "keywords": ["survey", "group", "connector", "infographic", "understand", "element", "number", "tag", "tool", "data", "example", "time", "one", "shown", "template", "animation", "structure", "file", "infographics", "powerpoint", "set", "size", "information", "sequence", "based", "participant", "add", "algorithm", "designer", "authoring", "animated", "effect", "infomotion", "unit", "repeating", "figure", "cluster", "design", "order", "layout", "presentation", "visualization", "user", "shape", "generated"], "document_vector": [-10.254329, -37.27317], "paragraphs": [{"paragraph_vector": [127.117866, 15.073277], "paragraph_keywords": ["animation", "infographics", "animations", "animated"]}, {"paragraph_vector": [128.868469, 15.80572], "paragraph_keywords": ["animation", "infographics", "infomotion", "elements"]}, {"paragraph_vector": [131.836044, 16.716438], "paragraph_keywords": ["infographics", "data", "animation", "design"]}, {"paragraph_vector": [130.685501, 14.908212], "paragraph_keywords": ["data", "animated", "animations", "propose"]}, {"paragraph_vector": [126.376358, 15.300409], "paragraph_keywords": ["templates", "information", "animations", "infographics"]}, {"paragraph_vector": [126.652839, 15.014168], "paragraph_keywords": ["infographics", "elements", "title", "design"]}, {"paragraph_vector": [128.354598, 12.566828], "paragraph_keywords": ["infographic", "designs", "design", "infographics"]}, {"paragraph_vector": [121.405052, 4.4505], "paragraph_keywords": ["units", "layouts", "infographic", "layout"]}, {"paragraph_vector": [123.935325, 8.652347], "paragraph_keywords": ["units", "elements", "shown", "designers"]}, {"paragraph_vector": [126.156654, 16.1972], "paragraph_keywords": ["elements", "animation", "animations", "infographics"]}, {"paragraph_vector": [126.799362, 7.253585], "paragraph_keywords": ["elements", "animation", "designs", "units"]}, {"paragraph_vector": [120.96894, -2.602065], "paragraph_keywords": ["elements", "units", "similarity", "clusters"]}, {"paragraph_vector": [119.690048, -2.925406], "paragraph_keywords": ["units", "elements", "layout", "proximity"]}, {"paragraph_vector": [119.529685, -4.390613], "paragraph_keywords": ["units", "elements", "connectors", "components"]}, {"paragraph_vector": [125.892478, 13.262681], "paragraph_keywords": ["orders", "based", "presentation", "animation"]}, {"paragraph_vector": [125.994331, 10.180467], "paragraph_keywords": ["effects", "survey", "tools", "sequence"]}, {"paragraph_vector": [128.656814, 17.335479], "paragraph_keywords": ["animation", "effects", "effect", "element"]}, {"paragraph_vector": [124.307624, 3.849853], "paragraph_keywords": ["units", "figure", "infomotion", "elements"]}, {"paragraph_vector": [129.097656, 16.048622], "paragraph_keywords": ["infomotion", "powerpoint", "users", "design"]}, {"paragraph_vector": [129.527633, 15.568378], "paragraph_keywords": ["animation", "infomotion", "design", "users"]}, {"paragraph_vector": [128.688491, 17.047388], "paragraph_keywords": ["animations", "infographic", "study", "design"]}, {"paragraph_vector": [128.368515, 15.643462], "paragraph_keywords": ["participants", "ratings", "animations", "generated"]}, {"paragraph_vector": [127.300903, 15.433037], "paragraph_keywords": ["generated", "animations", "animation", "order"]}, {"paragraph_vector": [128.867416, 16.556495], "paragraph_keywords": ["design", "animations", "users", "animation"]}, {"paragraph_vector": [129.107772, 15.996809], "paragraph_keywords": ["animations", "model", "animation", "infographic"]}, {"paragraph_vector": [127.997352, 17.06818], "paragraph_keywords": ["infographic", "generated", "infomotion", "infographics"]}], "content": {}, "doi": "empty"}, {"uri": "11", "title": "Thin-Volume Visualization on Curved Domains", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Felix Herter", "Hans-Christian Hege", "Markus Hadwiger", "Verena Lepper3and", "Daniel Baum"], "summary": "Thin, curved structures occur in many volumetric datasets. Their analysis using classical volume rendering is difficult because parts of such structures can bend away or hide behind occluding elements. This problem cannot be fully compensated by effective navigation alone, as structure-adapted navigation in the volume is cumbersome and only parts of the structure are visible in each view. We solve this problem by rendering a spatially transformed view of the volume so that an unobstructed visualization of the entire curved structure is obtained. As a result, simple and intuitive navigation becomes possible. The domain of the spatial transform is defined by a triangle mesh that is topologically equivalent to an open disc and that approximates the structure of interest. The rendering is based on ray-casting, in which the rays traverse the original volume. In order to carve out volumes of varying thicknesses, the lengths of the rays as well as the positions of the mesh vertices can be easily modified by interactive painting under view control. We describe a prototypical implementation and demonstrate the interactive visual inspection of complex structures from digital humanities, biology, medicine, and material sciences. The visual representation of the structure as a whole allows for easy inspection of interesting substructures in their original spatial context. Overall, we show that thin, curved structures in volumetric data can be excellently visualized using ray-casting-based volume rendering of transformed views defined by guiding surface meshes, supplemented by interactive, local modifications of ray lengths and vertex positions. CCS Concepts \u2022 Human-centered computing \u2192 Scientific visualization; Visualization techniques; \u2022 Computing methodologies \u2192 Rendering;", "keywords": ["et", "rendering", "view", "vertex", "v", "mesh", "interest", "ofmcurv", "p", "space", "ray", "volume", "data", "example", "result", "region", "papyrus", "geometry", "described", "approach", "length", "structure", "fig", "image", "method", "frame", "dataset", "point", "basis", "based", "camera", "mflat", "use", "mcurv", "transformed", "direction", "given", "sampled", "user", "surface", "visualization"], "document_vector": [3.571211, 59.379154], "paragraphs": [{"paragraph_vector": [-66.513351, 82.484848], "paragraph_keywords": ["structures", "volume", "structure", "writing"]}, {"paragraph_vector": [-124.570808, 82.080085], "paragraph_keywords": ["structure", "flattening", "surface", "meshes"]}, {"paragraph_vector": [-107.708595, 78.798614], "paragraph_keywords": ["methods", "structures", "centerline", "method"]}, {"paragraph_vector": [-103.203598, 84.528259], "paragraph_keywords": ["structures", "volume", "unfolding", "surface"]}, {"paragraph_vector": [-115.630134, 79.008026], "paragraph_keywords": ["surface", "volume", "ray", "rendering"]}, {"paragraph_vector": [-128.464126, 81.076789], "paragraph_keywords": ["volume", "geometry", "rays", "ray"]}, {"paragraph_vector": [-110.877891, 78.043785], "paragraph_keywords": ["based", "approach", "rays", "space"]}, {"paragraph_vector": [-106.149871, 74.432403], "paragraph_keywords": ["basis", "j", "vertex", "p"]}, {"paragraph_vector": [-23.098991, -76.705856], "paragraph_keywords": ["frame", "vector", "compute", "vertex"]}, {"paragraph_vector": [-106.098976, 78.386581], "paragraph_keywords": ["given", "ray", "vector", "basis"]}, {"paragraph_vector": [-119.700454, 79.907768], "paragraph_keywords": ["ray", "user", "volume", "segment"]}, {"paragraph_vector": [-95.45536, 78.742706], "paragraph_keywords": ["ray", "volume", "interest", "vertices"]}, {"paragraph_vector": [-146.526626, 70.113121], "paragraph_keywords": ["vertex", "direction", "ray", "attributes"]}, {"paragraph_vector": [-55.933036, 1.668138], "paragraph_keywords": ["space", "cone", "mouse", "area"]}, {"paragraph_vector": [144.408569, 64.121841], "paragraph_keywords": ["selection", "region", "vertices", "volume"]}, {"paragraph_vector": [146.723266, 78.730003], "paragraph_keywords": ["rendering", "surface", "contours", "volume"]}, {"paragraph_vector": [152.506393, 75.270263], "paragraph_keywords": ["fig", "volume", "rendering", "contours"]}, {"paragraph_vector": [-70.604393, 81.165084], "paragraph_keywords": ["surface", "papyrus", "mesh", "ray"]}, {"paragraph_vector": [-166.270507, 81.021148], "paragraph_keywords": ["data", "rendering", "indicates", "surface"]}, {"paragraph_vector": [-160.888534, 85.319129], "paragraph_keywords": ["carapace", "surface", "ray", "fig"]}, {"paragraph_vector": [-82.784736, 81.643272], "paragraph_keywords": ["volume", "data", "rendering", "dvr"]}, {"paragraph_vector": [-81.036529, 85.830192], "paragraph_keywords": ["method", "volumes", "curvature", "rates"]}, {"paragraph_vector": [-124.962791, 79.782653], "paragraph_keywords": ["rendering", "camera", "volume", "surface"]}, {"paragraph_vector": [158.299041, -77.705139], "paragraph_keywords": ["university", "providing", "dataset", "felix"]}], "content": {}, "doi": "empty"}, {"uri": "12", "title": "Texture Browser: Feature-based Texture Exploration", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Xuejiao Luo", "Leonardo Scandolo", "Elmar Eisemann"], "summary": "Texture is a key characteristic in the definition of the physical appearance of an object and a crucial element in the creation process of 3D artists. However, retrieving a texture that matches an intended look from an image collection is difficult. Contrary to most photo collections, for which object recognition has proven quite useful, syntactic descriptions of texture characteristics is not straightforward, and even creating appropriate metadata is a very difficult task. In this paper, we propose a system to help explore large unlabeled collections of texture images. The key insight is that spatially grouping textures sharing similar features can simplify navigation. Our system uses a pre-trained convolutional neural network to extract high-level semantic image features, which are then mapped to a 2-dimensional location using an adaptation of t-SNE, a dimensionality-reduction technique. We describe an interface to visualize and explore the resulting distribution and provide a series of enhanced navigation tools, our prioritized t-SNE, scalable clustering, and multi-resolution embedding, to further facilitate exploration and retrieval tasks. Finally, we also present the results of a user evaluation that demonstrates the effectiveness of our solution. CCS Concepts \u2022 Human-centerd computing \u2192 Visualization; Visualization systems and tools; Visualization toolkits;", "keywords": ["work", "propose", "view", "recognition", "sample", "group", "grid", "task", "navigation", "liu", "exploration", "sne", "space", "feature", "database", "tool", "data", "vector", "eisemann", "time", "ieee", "prioritized", "computer", "shown", "fig", "target", "image", ".", "t", "information", "method", "texture", "based", "interface", "clustering", "al", "collection", "network", "algorithm", "system", "use", "browsing", "analysis", "conference", "overview", "cluster", "color", "embedding", "user", "scale", "retrieval", "search", "similarity", "visualization", "imagenet"], "document_vector": [158.487274, 55.614555], "paragraphs": [{"paragraph_vector": [-23.016698, 52.816947], "paragraph_keywords": ["texture", "computer", "samples", "process"]}, {"paragraph_vector": [-15.949954, 53.021377], "paragraph_keywords": ["texture", "image", "textures", "retrieval"]}, {"paragraph_vector": [-15.963928, 51.586559], "paragraph_keywords": ["retrieval", "images", "textures", "color"]}, {"paragraph_vector": [-7.267885, 49.756202], "paragraph_keywords": ["image", "images", "features", "retrieval"]}, {"paragraph_vector": [-15.207911, 53.159496], "paragraph_keywords": ["exploration", "texture", "visualization", "data"]}, {"paragraph_vector": [-13.605716, 50.942073], "paragraph_keywords": ["image", "based", "embedding", "propose"]}, {"paragraph_vector": [-7.60928, 56.320075], "paragraph_keywords": ["layers", "image", "texture", "network"]}, {"paragraph_vector": [-22.428031, 55.551322], "paragraph_keywords": ["sne", "t", "embedding", "texture"]}, {"paragraph_vector": [-32.036319, 58.690071], "paragraph_keywords": ["embedding", "textures", "j", "samples"]}, {"paragraph_vector": [-23.110136, 55.505287], "paragraph_keywords": ["images", "features", "scale", "embedding"]}, {"paragraph_vector": [-20.981672, 51.373645], "paragraph_keywords": ["embedding", "clusters", "texture", "images"]}, {"paragraph_vector": [-16.606264, 54.356719], "paragraph_keywords": ["user", "images", "image", "priority"]}, {"paragraph_vector": [-17.372234, 53.813735], "paragraph_keywords": ["user", "texture", "color", "based"]}, {"paragraph_vector": [-14.667357, 47.837779], "paragraph_keywords": ["users", "images", "texture", "evaluation"]}, {"paragraph_vector": [-13.016236, 47.355472], "paragraph_keywords": ["grid", "task", "retrieval", "time"]}, {"paragraph_vector": [-19.163696, 52.512256], "paragraph_keywords": ["texture", "view", "embedding", "scale"]}, {"paragraph_vector": [-19.273141, 50.452472], "paragraph_keywords": ["texture", "textures", "retrieval", "users"]}, {"paragraph_vector": [-19.166175, 49.225387], "paragraph_keywords": ["group", "image", "prioritized", "search"]}, {"paragraph_vector": [-18.734701, 49.897247], "paragraph_keywords": ["user", "image", "retrieval", "based"]}, {"paragraph_vector": [-12.593451, 51.08604], "paragraph_keywords": ["texture", "image", "based", "ieee"]}, {"paragraph_vector": [-7.807588, 52.900566], "paragraph_keywords": ["image", "texture", "computer", "bethge"]}, {"paragraph_vector": [-9.815764, 54.396884], "paragraph_keywords": ["texture", "computer", "image", "ieee"]}, {"paragraph_vector": [-10.344692, 55.050231], "paragraph_keywords": ["image", "texture", "ieee", "feature"]}, {"paragraph_vector": [-5.993236, 59.561878], "paragraph_keywords": ["image", "ieee", "based", "computer"]}, {"paragraph_vector": [-8.516534, 55.564559], "paragraph_keywords": ["image", "texture", "retrieval", "ieee"]}, {"paragraph_vector": [-5.982452, 56.177379], "paragraph_keywords": ["ieee", "retrieval", "texture", "transactions"]}], "content": {}, "doi": "empty"}, {"uri": "13", "title": "Accessible Visualization: Design Space, Opportunities, and Challenges", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["N. W. Kim", "S. C. Joyner", "Y. Kim"], "summary": "Visualizations are now widely used across disciplines to understand and communicate data. The benefit of visualizations lies in leveraging our natural visual perception. However, the sole dependency on vision can produce unintended discrimination against people with visual impairments. While the visualization field has seen enormous growth in recent years, supporting people with disabilities is much less explored. In this work, we examine approaches to support this marginalized user group, focusing on visual disabilities. We collected and analyzed papers published for the last 20 years on visualization accessibility. We mapped a design space for accessible visualization that includes seven dimensions: user group, literacy task, chart type, interaction, information granularity, sensory modality, assistive technology. We described the current knowledge gap in light of the latest advances in visualization and presented a preliminary accessibility model by synthesizing findings from existing research. Finally, we reflected on the dimensions and discussed opportunities and challenges for future research. CCS Concepts \u2022 Human-centered computing \u2192 Visualization; Accessibility;", "keywords": ["observed", "accessibility", "work", "provide", "task", "content", "detail", "text", "context", "vision", "element", "data", "interaction", "existing", "screen", "paper", "model", "modality", "understanding", "speech", "structure", "people", "research", "information", "creating", "technology", "based", "collection", "tactile", "reading", "support", "including", "dimension", "overview", "feedback", "graphic", "figure", "code", "design", "sonification", "perception", "impaired", "user", "impairment", "search", "chart", "visualization", "braille"], "document_vector": [84.956001, -39.53968], "paragraphs": [{"paragraph_vector": [-63.506923, -9.677846], "paragraph_keywords": ["visualization", "visualizations", "data", "research"]}, {"paragraph_vector": [-59.332313, -4.152731], "paragraph_keywords": ["visualizations", "visualization", "design", "accessibility"]}, {"paragraph_vector": [-55.718154, 1.632874], "paragraph_keywords": ["accessibility", "web", "content", "guidelines"]}, {"paragraph_vector": [-51.820384, -6.191578], "paragraph_keywords": ["data", "visualization", "tactile", "accessibility"]}, {"paragraph_vector": [-55.54951, -8.774314], "paragraph_keywords": ["search", "papers", "criteria", "researchers"]}, {"paragraph_vector": [-62.05857, -15.365377], "paragraph_keywords": ["codes", "papers", "dimensions", "set"]}, {"paragraph_vector": [-51.310684, -16.147285], "paragraph_keywords": ["s", "research", "venue", "t"]}, {"paragraph_vector": [-57.689609, -0.336045], "paragraph_keywords": ["vision", "acuity", "impairment", "reading"]}, {"paragraph_vector": [-56.889057, -0.960892], "paragraph_keywords": ["visualization", "visualizations", "needs", "tasks"]}, {"paragraph_vector": [-54.086044, -9.063177], "paragraph_keywords": ["visualizations", "charts", "information", "understanding"]}, {"paragraph_vector": [-57.271076, -3.213251], "paragraph_keywords": ["chart", "users", "interactions", "data"]}, {"paragraph_vector": [-45.320716, -9.360631], "paragraph_keywords": ["overview", "details", "perception", "research"]}, {"paragraph_vector": [-52.527194, -2.56943], "paragraph_keywords": ["data", "speech", "visualization", "graphics"]}, {"paragraph_vector": [-56.477909, 1.116313], "paragraph_keywords": ["tactile", "feedback", "graphics", "braille"]}, {"paragraph_vector": [-54.425685, 2.015938], "paragraph_keywords": ["graphics", "speech", "screen", "support"]}, {"paragraph_vector": [-56.482959, 1.275429], "paragraph_keywords": ["devices", "technologies", "model", "chart"]}, {"paragraph_vector": [-47.363224, -10.419176], "paragraph_keywords": ["text", "chart", "message", "people"]}, {"paragraph_vector": [-53.478492, 0.41785], "paragraph_keywords": ["data", "points", "provide", "graphics"]}, {"paragraph_vector": [-57.331272, -2.200661], "paragraph_keywords": ["chart", "visualization", "design", "information"]}, {"paragraph_vector": [-60.137451, -4.562747], "paragraph_keywords": ["visualization", "visualizations", "creating", "research"]}, {"paragraph_vector": [-53.612846, -2.582319], "paragraph_keywords": ["visualizations", "existing", "approaches", "modalities"]}, {"paragraph_vector": [-64.548843, -10.910027], "paragraph_keywords": ["visualization", "research", "support", "visualizations"]}], "content": {}, "doi": "empty"}, {"uri": "14", "title": "VICE: Visual Identification and Correction of Neural Circuit Errors", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Felix Gonda", "Xueying Wang", "Johanna Beyer", "Markus Hadwiger", "Jeff W. Lichtman", "Hanspeter Pfister"], "summary": "A connectivity graph of neurons at the resolution of single synapses provides scientists with a tool for understanding the nervous system in health and disease. Recent advances in automatic image segmentation and synapse prediction in electron microscopy (EM) datasets of the brain have made reconstructions of neurons possible at the nanometer scale. However, automatic segmentation sometimes struggles to segment large neurons correctly, requiring human effort to proofread its output. General proofreading involves inspecting large volumes to correct segmentation errors at the pixel level, a visually intensive and time-consuming process. This paper presents the design and implementation of an analytics framework that streamlines proofreading, focusing on connectivity-related errors. We accomplish this with automated likely-error detection and synapse clustering that drives the proofreading effort with highly interactive 3D visualizations. In particular, our strategy centers on proofreading the local circuit of a single cell to ensure a basic level of completeness. We demonstrate our framework\u2019s utility with a user study and report quantitative and subjective feedback from our users. Overall, users find the framework more efficient for proofreading, understanding evolving graphs, and sharing error correction strategies. CCS Concepts \u2022 Human-centered computing \u2192 Web-based interaction; Scientific visualization;", "keywords": ["circuit", "task", "error", "collaborator", "object", "cell", "synapse", "branch", "examine", "number", "tool", "data", "time", "approach", "shown", "provides", "structure", "enable", "reconstruction", "vice", "neurites", "neuron", "component", "segmentation", "based", "study", "expert", "participant", "system", "use", "inspection", "cluster", "figure", "design", "proofreading", "connectivity", "user", "synapsis", "brain", "level", "skeleton", "visualization", "enables"], "document_vector": [-8.461097, 45.165218], "paragraphs": [{"paragraph_vector": [-179.883514, 53.331726], "paragraph_keywords": ["brain", "connectome", "neurons", "proofreading"]}, {"paragraph_vector": [-176.100128, 53.937675], "paragraph_keywords": ["cell", "strategy", "connectivity", "proofreading"]}, {"paragraph_vector": [178.205474, 54.371433], "paragraph_keywords": ["segmentation", "data", "errors", "approach"]}, {"paragraph_vector": [178.628189, 56.197433], "paragraph_keywords": ["connectivity", "data", "provides", "visualization"]}, {"paragraph_vector": [177.590362, 54.278419], "paragraph_keywords": ["experts", "proofreading", "domain", "design"]}, {"paragraph_vector": [178.440063, 52.998237], "paragraph_keywords": ["data", "neurons", "graphs", "proofreading"]}, {"paragraph_vector": [-178.377136, 55.189815], "paragraph_keywords": ["errors", "connectivity", "synapses", "proofreading"]}, {"paragraph_vector": [-174.825302, 55.39133], "paragraph_keywords": ["components", "circuit", "user", "compartments"]}, {"paragraph_vector": [-179.76239, 53.856506], "paragraph_keywords": ["users", "object", "examine", "enables"]}, {"paragraph_vector": [-178.494369, 57.332199], "paragraph_keywords": ["errors", "skeleton", "shown", "volume"]}, {"paragraph_vector": [175.208953, 54.243736], "paragraph_keywords": ["skeleton", "object", "error", "images"]}, {"paragraph_vector": [-179.006958, 54.758365], "paragraph_keywords": ["errors", "users", "neurites", "neurite"]}, {"paragraph_vector": [-174.235855, 55.632232], "paragraph_keywords": ["synapses", "clusters", "synapse", "cluster"]}, {"paragraph_vector": [-178.659454, 55.22425], "paragraph_keywords": ["proofreading", "synapses", "cell", "shown"]}, {"paragraph_vector": [-178.146911, 54.883617], "paragraph_keywords": ["segmentation", "cells", "elements", "data"]}, {"paragraph_vector": [171.855331, 49.769233], "paragraph_keywords": ["neurites", "study", "users", "tasks"]}, {"paragraph_vector": [171.026412, 51.333637], "paragraph_keywords": ["participants", "time", "vice", "synapse"]}, {"paragraph_vector": [176.386352, 54.343471], "paragraph_keywords": ["vice", "synapse", "participants", "accuracy"]}, {"paragraph_vector": [175.160736, 52.918281], "paragraph_keywords": ["participants", "vice", "classification", "learnability"]}, {"paragraph_vector": [176.661529, 53.40126], "paragraph_keywords": ["approach", "circuit", "synapses", "tasks"]}, {"paragraph_vector": [-52.895687, -22.321693], "paragraph_keywords": ["john", "association", "wiley", "user"]}], "content": {}, "doi": "empty"}, {"uri": "15", "title": "ProBGP: Progressive Visual Analytics of Live BGP Updates", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["A. Ulmer", "D. Sessler", "J. Kohlhammer"], "summary": "The global routing network is the backbone of the Internet. However, it is quite vulnerable to attacks that cause major disruptions or routing manipulations. Prior related works have visualized routing path changes with node link diagrams, but it requires strong domain expertise to understand if a routing change between autonomous systems is suspicious. Geographic visualization has an advantage over conventional node-link diagrams by helping uncover such suspicious routes as the user can immediately see if a path is the shortest path to the target or an unreasonable detour. In this paper, we present ProBGP, a web-based progressive approach to visually analyze BGP update routes. We created a novel progressive data processing algorithm for the geographic approximation of autonomous systems and combined it with a progressively updating visualization. While the newest log data is continuously loaded, our approach also allows querying the entire log recordings since 1999. We present the usefulness of our approach with a real use case of a major route leak from June 2019. We report on multiple interviews with domain experts throughout the development. Finally, we evaluated our algorithm quantitatively against a public peering database and qualitatively against AS network maps. CCS Concepts \u2022 Human-centered computing \u2192 Visual analytics; \u2022 Networks \u2192 Data center networks; \u2022 Theory of computation \u2192 Routing and network design problems; \u00a9 2021 The Author(s) Computer Graphics Forum \u00a9 2021 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd. DOI: 10.1111/cgf.14287", "keywords": ["query", "work", "section", "provide", "geoip", "domain", "task", "center", "path", "collector", "as", "internet", "traffic", "accuracy", "data", "result", "time", "ip", "approach", "routing", "location", "connection", "research", "approximation", "information", "find", "based", "expert", "update", "world", "analytics", "isps", "network", "algorithm", "tier", "prefix", "use", "analysis", "figure", "map", "log", "bgp", "show", "user", "service", "visualization"], "document_vector": [-153.995559, -58.436294], "paragraphs": [{"paragraph_vector": [61.120204, -1.837623], "paragraph_keywords": ["routing", "ases", "data", "ip"]}, {"paragraph_vector": [63.68711, -4.186151], "paragraph_keywords": ["data", "bgp", "section", "analytics"]}, {"paragraph_vector": [63.71997, -2.799737], "paragraph_keywords": ["routing", "bgp", "network", "visualization"]}, {"paragraph_vector": [64.926666, -5.646631], "paragraph_keywords": ["data", "results", "analytics", "datasets"]}, {"paragraph_vector": [65.55957, -7.279526], "paragraph_keywords": ["data", "ip", "accuracy", "geoip"]}, {"paragraph_vector": [62.097629, -3.219651], "paragraph_keywords": ["data", "locations", "collectors", "address"]}, {"paragraph_vector": [62.74274, -3.516484], "paragraph_keywords": ["data", "tier", "bgp", "ases"]}, {"paragraph_vector": [59.725063, -2.437764], "paragraph_keywords": ["ip", "tasks", "user", "traffic"]}, {"paragraph_vector": [60.343593, -3.29354], "paragraph_keywords": ["data", "update", "bgp", "ip"]}, {"paragraph_vector": [60.87136, -3.180111], "paragraph_keywords": ["data", "centers", "approximation", "routing"]}, {"paragraph_vector": [67.204086, -6.712053], "paragraph_keywords": ["data", "k", "centers", "approximation"]}, {"paragraph_vector": [62.159435, -3.036786], "paragraph_keywords": ["data", "centers", "approximation", "step"]}, {"paragraph_vector": [63.66679, -7.703005], "paragraph_keywords": ["data", "edge", "network", "algorithm"]}, {"paragraph_vector": [63.454303, -4.629431], "paragraph_keywords": ["ases", "path", "origin", "graph"]}, {"paragraph_vector": [62.89027, -3.247573], "paragraph_keywords": ["data", "time", "prefix", "ip"]}, {"paragraph_vector": [60.190994, -1.977764], "paragraph_keywords": ["data", "log", "files", "results"]}, {"paragraph_vector": [60.811878, 1.635544], "paragraph_keywords": ["data", "visualization", "bgp", "query"]}, {"paragraph_vector": [64.393806, -5.23893], "paragraph_keywords": ["paths", "path", "user", "data"]}, {"paragraph_vector": [64.408355, -5.882676], "paragraph_keywords": ["data", "dots", "shows", "path"]}, {"paragraph_vector": [62.308906, -4.451074], "paragraph_keywords": ["data", "prefix", "user", "computation"]}, {"paragraph_vector": [61.806449, -3.284907], "paragraph_keywords": ["user", "shows", "paths", "development"]}, {"paragraph_vector": [65.957107, -7.486809], "paragraph_keywords": ["data", "domain", "accuracy", "expert"]}, {"paragraph_vector": [63.743999, -4.598538], "paragraph_keywords": ["data", "ases", "database", "centers"]}, {"paragraph_vector": [64.765724, -5.333023], "paragraph_keywords": ["network", "data", "cogent", "map"]}, {"paragraph_vector": [60.920818, -4.802453], "paragraph_keywords": ["data", "connections", "network", "time"]}, {"paragraph_vector": [65.090293, -5.767157], "paragraph_keywords": ["data", "bgp", "research", "algorithm"]}], "content": {}, "doi": "empty"}, {"uri": "16", "title": "Boundary Objects in Design Studies: Reflections on the Collaborative Creation of Isochrone Maps", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["R. Vuillemot", "P. Rivi\u00e8re", "A. Beignon", "A. Tabard"], "summary": "We propose to take an artifact-centric approach to design studies by leveraging the concept of boundary object. Design studies typically focus on processes and articulate design decisions in a project-specific context with a goal of transferability. We argue that design studies could benefit from paying attention to the material conditions in which teams collaborate to reach design outcomes. We report on a design study of isochrone maps following cartographic generalization principles. Focusing on boundary objects enables us to characterize five categories of artifacts and tools that facilitated collaboration between actors involved in the design process (structured collections, structuring artifacts, process-centric artifacts, generative artifacts, and bridging artifacts). We found that artifacts such as layered maps and map collections played a unifying role for our inter-disciplinary team. We discuss how such artifacts can be pivotal in the design process. Finally, we discuss how considering boundary objects could improve the transferability of design study results, and support reflection on inter-disciplinary collaboration in the domain of Information Visualization.", "keywords": ["work", "notebook", "simplification", "underlying", "shared", "object", "element", "project", "tool", "data", "artifact", "paper", "time", "transit", "created", "supported", "layer", "instance", "discussed", "structure", "research", "de", "information", "team", "collaboration", "process", "convey", "isochrone", "study", "based", "related", "prototype", "star", "collection", "generalization", "use", "parameter", "observablehq", "workshop", "figure", "code", "design", "map", "shape", "capture", "level"], "document_vector": [72.253379, -72.303924], "paragraphs": [{"paragraph_vector": [-52.020572, -39.252418], "paragraph_keywords": ["design", "studies", "artifacts", "work"]}, {"paragraph_vector": [-57.309543, -35.549625], "paragraph_keywords": ["design", "artifacts", "process", "studies"]}, {"paragraph_vector": [-51.957382, -40.432022], "paragraph_keywords": ["objects", "artifacts", "design", "work"]}, {"paragraph_vector": [-54.201244, -40.895004], "paragraph_keywords": ["objects", "work", "star", "scope"]}, {"paragraph_vector": [-52.831066, -42.094451], "paragraph_keywords": ["maps", "isochrone", "isochrones", "time"]}, {"paragraph_vector": [-69.470016, -60.418731], "paragraph_keywords": ["elements", "maps", "isochrone", "work"]}, {"paragraph_vector": [-60.967033, -44.034156], "paragraph_keywords": ["research", "project", "design", "layers"]}, {"paragraph_vector": [-65.406646, -51.762825], "paragraph_keywords": ["project", "travel", "location", "tools"]}, {"paragraph_vector": [-59.846458, -37.178581], "paragraph_keywords": ["maps", "team", "shared", "design"]}, {"paragraph_vector": [-64.794876, -46.29034], "paragraph_keywords": ["data", "design", "layers", "team"]}, {"paragraph_vector": [-69.033927, -48.224529], "paragraph_keywords": ["design", "map", "city", "transit"]}, {"paragraph_vector": [-66.988586, -48.325172], "paragraph_keywords": ["design", "maps", "project", "centered"]}, {"paragraph_vector": [-58.29541, -37.354194], "paragraph_keywords": ["maps", "created", "artifacts", "isochrone"]}, {"paragraph_vector": [-57.119186, -37.184532], "paragraph_keywords": ["artifacts", "team", "design", "project"]}, {"paragraph_vector": [-59.395172, -37.92229], "paragraph_keywords": ["paper", "artifacts", "notebook", "opacity"]}, {"paragraph_vector": [-58.698329, -36.966285], "paragraph_keywords": ["team", "notebook", "maps", "tool"]}, {"paragraph_vector": [-71.150314, -48.386154], "paragraph_keywords": ["figure", "isochrone", "transit", "layer"]}, {"paragraph_vector": [-62.225284, -35.267017], "paragraph_keywords": ["process", "moments", "time", "objects"]}, {"paragraph_vector": [-55.804424, -36.100543], "paragraph_keywords": ["capture", "artifacts", "supported", "design"]}, {"paragraph_vector": [-55.896057, -38.706352], "paragraph_keywords": ["design", "projects", "work", "collaboration"]}, {"paragraph_vector": [-55.344108, -39.844005], "paragraph_keywords": ["design", "artifacts", "process", "project"]}], "content": {}, "doi": "empty"}, {"uri": "17", "title": "A Progressive Approach for Uncertainty Visualization in Diffusion Tensor Imaging", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Faizan Siddiqui", "Thomas H\u00f6llt", "Anna Vilanova"], "summary": "Diffusion Tensor Imaging (DTI) is a non-invasive magnetic resonance imaging technique that, combined with fiber tracking algorithms, allows the characterization and visualization of white matter structures in the brain. The resulting fiber tracts are used, for example, in tumor surgery to evaluate the potential brain functional damage due to tumor resection. The DTI processing pipeline from image acquisition to the final visualization is rather complex generating undesirable uncertainties in the final results. Most DTI visualization techniques do not provide any information regarding the presence of uncertainty. When planning surgery, a fixed safety margin around the fiber tracts is often used; however, it cannot capture local variability and distribution of the uncertainty, thereby limiting the informed decision-making process. Stochastic techniques are a possibility to estimate uncertainty for the DTI pipeline. However, it has high computational and memory requirements that make it infeasible in a clinical setting. The delay in the visualization of the results adds hindrance to the workflow. We propose a progressive approach that relies on a combination of wild-bootstrapping and fiber tracking to be used within the progressive visual analytics paradigm. We present a local bootstrapping strategy, which reduces the computational and memory costs, and provides fibertracking results in a progressive manner. We have also implemented a progressive aggregation technique that computes the distances in the fiber ensemble during progressive bootstrap computations. We present experiments with different scenarios to highlight the benefits of using our progressive visual analytic pipeline in a clinical workflow along with a use case and analysis obtained by discussions with our collaborators. CCS Concepts \u2022 Human-centered computing \u2192 Visual analytics; Scientific visualization;", "keywords": ["work", "et", "sample", "distribution", "need", "section", "computation", "distance", "collaborator", "tracking", "number", "tract", "fiber", "data", "volume", "histogram", "result", "presented", "time", "voxels", "approach", "tensor", "method", "computed", "bootstrapping", "based", "workflow", "use", "uncertainty", "diffusion", "simulation", "figure", "aggregation", "framework", "pipeline", "brain", "iteration", "bootstrap", "visualization"], "document_vector": [-105.372459, 67.732017], "paragraphs": [{"paragraph_vector": [-96.6109, 50.665382], "paragraph_keywords": ["fiber", "pipeline", "brain", "uncertainty"]}, {"paragraph_vector": [-91.75914, 52.071475], "paragraph_keywords": ["uncertainty", "fiber", "distribution", "tracking"]}, {"paragraph_vector": [-87.77285, 52.674415], "paragraph_keywords": ["fiber", "framework", "uncertainty", "generation"]}, {"paragraph_vector": [-91.405906, 52.966026], "paragraph_keywords": ["uncertainty", "fiber", "uncertainties", "techniques"]}, {"paragraph_vector": [-91.163368, 52.198326], "paragraph_keywords": ["fiber", "tracking", "uncertainty", "fibers"]}, {"paragraph_vector": [-108.923614, 53.752712], "paragraph_keywords": ["fiber", "curves", "visualization", "compute"]}, {"paragraph_vector": [-89.158645, 51.985809], "paragraph_keywords": ["tensor", "bootstrapping", "diffusion", "signal"]}, {"paragraph_vector": [-87.70301, 52.792293], "paragraph_keywords": ["fiber", "uncertainty", "visualization", "tensor"]}, {"paragraph_vector": [-91.371276, 52.619926], "paragraph_keywords": ["fiber", "uncertainty", "approach", "bootstrap"]}, {"paragraph_vector": [-87.475769, 54.297229], "paragraph_keywords": ["tensor", "diffusion", "fiber", "volume"]}, {"paragraph_vector": [-100.658599, 55.870441], "paragraph_keywords": ["fiber", "uncertainty", "samples", "visualization"]}, {"paragraph_vector": [-91.22248, 53.356506], "paragraph_keywords": ["fiber", "distance", "sample", "score"]}, {"paragraph_vector": [-106.228553, 54.598621], "paragraph_keywords": ["fiber", "distance", "samples", "score"]}, {"paragraph_vector": [-109.596038, 54.077365], "paragraph_keywords": ["fiber", "samples", "fibers", "selection"]}, {"paragraph_vector": [-94.175399, 54.886322], "paragraph_keywords": ["histogram", "fiber", "uncertainty", "stability"]}, {"paragraph_vector": [-87.241485, 53.432964], "paragraph_keywords": ["fiber", "framework", "seen", "figures"]}, {"paragraph_vector": [-91.103324, 50.157245], "paragraph_keywords": ["simulation", "fiber", "tract", "figure"]}, {"paragraph_vector": [-88.543052, 53.398567], "paragraph_keywords": ["fiber", "samples", "uncertainty", "histogram"]}, {"paragraph_vector": [-86.348258, 50.648719], "paragraph_keywords": ["fiber", "figure", "histogram", "fibers"]}, {"paragraph_vector": [-86.15776, 53.855262], "paragraph_keywords": ["voxels", "number", "bootstrap", "interval"]}, {"paragraph_vector": [-89.981903, 53.850521], "paragraph_keywords": ["fiber", "computed", "figure", "time"]}, {"paragraph_vector": [-98.218315, 55.461601], "paragraph_keywords": ["fiber", "tracking", "threshold", "figure"]}, {"paragraph_vector": [-99.285049, 54.934036], "paragraph_keywords": ["uncertainty", "fiber", "visualization", "pipeline"]}, {"paragraph_vector": [-95.035217, 53.587818], "paragraph_keywords": ["uncertainty", "work", "diffusion", "tweesteden"]}], "content": {}, "doi": "empty"}, {"uri": "18", "title": "Line Weaver: Importance-Driven Order Enhanced Rendering of Dense Line Charts", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["T. Trautner"], "summary": "Line charts are an effective and widely used technique for visualizing series of ordered two-dimensional data points. The relationship between consecutive points is indicated by connecting line segments, revealing potential trends or clusters in the underlying data. However, when dealing with an increasing number of lines, the render order substantially influences the resulting visualization. Rendering transparent lines can help but unfortunately the blending order is currently either ignored or naively used, for example, assuming it is implicitly given by the order in which the data was saved in a file. Due to the noncommutativity of classic alpha blending, this results in contradicting visualizations of the same underlying data set, so-called \"hallucinators\". In this paper, we therefore present line weaver, a novel visualization technique for dense line charts. Using an importance function, we developed an approach that correctly considers the blending order independently of the render order and without any prior sorting of the data. We allow for importance functions which are either explicitly given or implicitly derived from the geometric properties of the data if no external data is available. The importance can then be applied globally to entire lines, or locally per pixel which simultaneously supports various types of user interaction. Finally, we discuss the potential of our contribution based on different synthetic and real-world data sets where classic or naive approaches would fail. CCS Concepts \u2022 Human-centered computing \u2192 Information visualization; Visualization techniques; Visualization theory, concepts and paradigms;", "keywords": ["et", "rendering", "contribution", "group", "section", "line", "weaver", "axis", "density", "value", "element", "number", "bundle", "function", "data", "importance", "example", "clutter", "time", "series", "weaving", "approach", "property", "operator", "set", "pixel", "occlusion", "method", "allows", "step", "point", "plot", "based", "al", "curve", "use", "blending", "cluster", "figure", "resulting", "color", "technique", "order", "chart", "visualization"], "document_vector": [131.848052, -14.100049], "paragraphs": [{"paragraph_vector": [-171.96939, 11.788978], "paragraph_keywords": ["order", "elements", "line", "lines"]}, {"paragraph_vector": [-172.640335, 17.572986], "paragraph_keywords": ["line", "importance", "data", "clutter"]}, {"paragraph_vector": [-177.137496, 6.943159], "paragraph_keywords": ["approach", "density", "data", "plots"]}, {"paragraph_vector": [-178.599884, 11.430106], "paragraph_keywords": ["line", "functions", "data", "density"]}, {"paragraph_vector": [-173.338882, 18.306795], "paragraph_keywords": ["example", "techniques", "line", "et"]}, {"paragraph_vector": [-168.732925, 28.09361], "paragraph_keywords": ["blending", "lines", "approach", "et"]}, {"paragraph_vector": [-171.672515, 17.980974], "paragraph_keywords": ["order", "lines", "rendering", "blending"]}, {"paragraph_vector": [-170.114456, 18.58078], "paragraph_keywords": ["importance", "order", "data", "points"]}, {"paragraph_vector": [-170.769775, 19.23262], "paragraph_keywords": ["importance", "operator", "techniques", "buffer"]}, {"paragraph_vector": [-163.975784, 22.690467], "paragraph_keywords": ["importance", "values", "elements", "color"]}, {"paragraph_vector": [-170.044876, 19.785156], "paragraph_keywords": ["line", "importance", "segments", "threshold"]}, {"paragraph_vector": [-175.203887, 15.63756], "paragraph_keywords": ["line", "segment", "importance", "use"]}, {"paragraph_vector": [172.322494, -27.028966], "paragraph_keywords": ["importance", "values", "time", "group"]}, {"paragraph_vector": [-167.217712, 23.383937], "paragraph_keywords": ["importance", "group", "values", "axis"]}, {"paragraph_vector": [-166.693145, 23.688529], "paragraph_keywords": ["line", "order", "shader", "g"]}, {"paragraph_vector": [-173.614639, 17.66496], "paragraph_keywords": ["based", "blending", "data", "line"]}, {"paragraph_vector": [-177.717742, 1.378101], "paragraph_keywords": ["cars", "clusters", "importance", "line"]}, {"paragraph_vector": [128.167022, -35.348915], "paragraph_keywords": ["time", "data", "series", "area"]}, {"paragraph_vector": [-175.407318, 12.482332], "paragraph_keywords": ["lines", "importance", "order", "interactions"]}, {"paragraph_vector": [134.465408, -40.25711], "paragraph_keywords": ["data", "sets", "time", "set"]}, {"paragraph_vector": [-176.322677, 14.403775], "paragraph_keywords": ["line", "data", "weaver", "lines"]}, {"paragraph_vector": [-177.355392, 12.98543], "paragraph_keywords": ["data", "blending", "clusters", "lines"]}, {"paragraph_vector": [-173.747375, 16.512529], "paragraph_keywords": ["visualizations", "lines", "data", "line"]}], "content": {}, "doi": "empty"}, {"uri": "19", "title": "Uncertainty-aware Visualization of Regional Time Series Correlation in Spatio-temporal Ensembles", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Marina Evers", "Karim Huesmann", "Lars Linsen"], "summary": "Given a time-varying scalar field, the analysis of correlations between different spatial regions, i.e., the linear dependence of time series within these regions, provides insights into the structural properties of the data. In this context, regions are connected components of the spatial domain with high time series correlations. The detection and analysis of such regions is often performed globally, which requires pairwise correlation computations that are quadratic in the number of spatial data samples. Thus, operations based on all pairwise correlations are computationally demanding, especially when dealing with ensembles that model the uncertainty in the spatio-temporal phenomena using multiple simulation runs. We propose a two-step procedure: In a first step, we map the spatial samples to a 3D embedding based on a pairwise correlation matrix computed from the ensemble of time series. The 3D embedding allows for a one-to-one mapping to a 3D color space such that the outcome can be visually investigated by rendering the colors for all samples in the spatial domain. In a second step, we generate a hierarchical image segmentation based on the color images. From then on, we can visually analyze correlations of regions at all levels in the hierarchy within an interactive setting, which includes the uncertainty-aware analysis of the region\u2019s time series correlation and respective time lags.", "keywords": ["sample", "section", "domain", "detail", "distance", "number", "value", "matrix", "data", "region", "time", "series", "approach", "lag", "tree", "image", "information", "method", "allows", "step", "climate", "point", "segmentation", "based", "clustering", "correlation", "algorithm", "use", "uncertainty", "analysis", "simulation", "hierarchy", "figure", "given", "color", "user", "heatmap", "level", "segment", "similarity", "visualization"], "document_vector": [-103.192092, 16.605318], "paragraphs": [{"paragraph_vector": [102.657592, -56.548442], "paragraph_keywords": ["correlations", "time", "regions", "analysis"]}, {"paragraph_vector": [101.327041, -53.4141], "paragraph_keywords": ["correlations", "time", "color", "data"]}, {"paragraph_vector": [104.068222, -56.901836], "paragraph_keywords": ["data", "correlations", "correlation", "use"]}, {"paragraph_vector": [89.720176, -55.877021], "paragraph_keywords": ["correlation", "approach", "based", "analysis"]}, {"paragraph_vector": [103.321754, -54.091896], "paragraph_keywords": ["analysis", "correlation", "approach", "correlations"]}, {"paragraph_vector": [105.806259, -54.087833], "paragraph_keywords": ["section", "time", "correlations", "color"]}, {"paragraph_vector": [103.21173, -54.646755], "paragraph_keywords": ["time", "series", "correlation", "compute"]}, {"paragraph_vector": [106.60675, -53.929248], "paragraph_keywords": ["time", "correlation", "matrix", "like"]}, {"paragraph_vector": [166.022003, -35.0732], "paragraph_keywords": ["color", "points", "use", "space"]}, {"paragraph_vector": [103.572525, -50.463203], "paragraph_keywords": ["color", "image", "colors", "segmentation"]}, {"paragraph_vector": [107.409416, -30.233646], "paragraph_keywords": ["image", "edges", "pixels", "color"]}, {"paragraph_vector": [104.452331, -32.850997], "paragraph_keywords": ["tree", "hierarchy", "data", "partition"]}, {"paragraph_vector": [102.031455, -54.170799], "paragraph_keywords": ["segments", "time", "correlation", "store"]}, {"paragraph_vector": [92.833236, -53.846736], "paragraph_keywords": ["correlations", "value", "values", "user"]}, {"paragraph_vector": [98.915969, -55.698448], "paragraph_keywords": ["segments", "user", "regions", "segment"]}, {"paragraph_vector": [92.786224, -55.441387], "paragraph_keywords": ["segments", "information", "regions", "analysis"]}, {"paragraph_vector": [90.941375, -52.380481], "paragraph_keywords": ["matrix", "correlations", "heatmap", "segments"]}, {"paragraph_vector": [92.684509, -55.167243], "paragraph_keywords": ["time", "linkage", "correlation", "series"]}, {"paragraph_vector": [96.043357, -53.303428], "paragraph_keywords": ["colors", "time", "regions", "series"]}, {"paragraph_vector": [100.22779, -54.331253], "paragraph_keywords": ["dataset", "region", "investigation", "detail"]}, {"paragraph_vector": [105.316032, -49.564846], "paragraph_keywords": ["figure", "climate", "segments", "regions"]}, {"paragraph_vector": [103.716209, -53.549907], "paragraph_keywords": ["correlation", "time", "segments", "lag"]}, {"paragraph_vector": [105.85202, -56.986946], "paragraph_keywords": ["figure", "temperature", "analysis", "region"]}, {"paragraph_vector": [97.42266, -55.093383], "paragraph_keywords": ["approach", "number", "correlation", "segmentation"]}], "content": {}, "doi": "empty"}, {"uri": "20", "title": "Learning Contextualized User Preferences for Co\u2010Adaptive Guidance in Mixed\u2010Initiative Topic Model Refinement", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["F. Sperrle"], "summary": "Mixed-initiative visual analytics systems support collaborative human-machine decision-making processes. However, many multiobjective optimization tasks, such as topic model refinement, are highly subjective and context-dependent. Hence, systems need to adapt their optimization suggestions throughout the interactive refinement process to provide efficient guidance. To tackle this challenge, we present a technique for learning context-dependent user preferences and demonstrate its applicability to topic model refinement. We deploy agents with distinct associated optimization strategies that compete for the user\u2019s acceptance of their suggestions. To decide when to provide guidance, each agent maintains an intelligible, rule-based classifier over context vectorizations that captures the development of quality metrics between distinct analysis states. By observing implicit and explicit user feedback, agents learn in which contexts to provide their specific guidance operation. An agent in topic model refinement might, for example, learn to react to declining model coherence by suggesting to split a topic. Our results confirm that the rules learned by agents capture contextual user preferences. Further, we show that the learned rules are transferable between similar datasets, avoiding common cold-start problems and enabling a continuous refinement of agents across corpora.", "keywords": ["work", "provide", "agent", "domain", "learning", "context", "metric", "number", "suggestion", "space", "provided", "vector", "training", "result", "interaction", "model", "time", "approach", "document", "learned", "modeling", "keywords", "quality", "information", "rule", "topic", "process", "study", "based", "avoid", "participant", "analytics", "icicle", "learn", "system", "use", "analysis", "feedback", "optimization", "preference", "debate", "evaluation", "state", "technique", "show", "user", "guidance", "refinement"], "document_vector": [103.057151, 0.067974], "paragraphs": [{"paragraph_vector": [-21.311561, 1.554081], "paragraph_keywords": ["agents", "model", "user", "tasks"]}, {"paragraph_vector": [-19.901012, -0.919262], "paragraph_keywords": ["user", "guidance", "suggestions", "technique"]}, {"paragraph_vector": [-26.393999, 3.236146], "paragraph_keywords": ["guidance", "model", "agents", "process"]}, {"paragraph_vector": [-26.395402, 4.097044], "paragraph_keywords": ["topic", "model", "modeling", "guidance"]}, {"paragraph_vector": [-21.382638, 0.935306], "paragraph_keywords": ["system", "guidance", "process", "users"]}, {"paragraph_vector": [-24.549692, 2.544664], "paragraph_keywords": ["agents", "system", "refinement", "model"]}, {"paragraph_vector": [-28.335878, 5.000467], "paragraph_keywords": ["topic", "tree", "model", "document"]}, {"paragraph_vector": [-20.372381, 0.858555], "paragraph_keywords": ["keywords", "topic", "color", "topics"]}, {"paragraph_vector": [-26.940809, 6.013747], "paragraph_keywords": ["topic", "model", "documents", "sankey"]}, {"paragraph_vector": [-29.003852, 10.680397], "paragraph_keywords": ["suggestions", "agent", "agents", "model"]}, {"paragraph_vector": [-27.430835, 6.844791], "paragraph_keywords": ["model", "suggestion", "topics", "suggestions"]}, {"paragraph_vector": [-27.572406, 6.60904], "paragraph_keywords": ["guidance", "agents", "model", "topics"]}, {"paragraph_vector": [-24.743177, 6.511914], "paragraph_keywords": ["context", "model", "analysis", "topic"]}, {"paragraph_vector": [-22.242975, -0.436606], "paragraph_keywords": ["context", "vectors", "agent", "preference"]}, {"paragraph_vector": [-23.328113, 2.046968], "paragraph_keywords": ["context", "contexts", "support", "closed"]}, {"paragraph_vector": [-25.654321, 5.411795], "paragraph_keywords": ["context", "contexts", "vectors", "model"]}, {"paragraph_vector": [-29.493431, 9.986073], "paragraph_keywords": ["agent", "suggestion", "point", "suggestions"]}, {"paragraph_vector": [-22.610095, -0.570826], "paragraph_keywords": ["provided", "feedback", "guidance", "agents"]}, {"paragraph_vector": [-24.952753, 4.620223], "paragraph_keywords": ["topic", "participants", "results", "system"]}, {"paragraph_vector": [-28.293592, 3.430206], "paragraph_keywords": ["agents", "model", "system", "participants"]}, {"paragraph_vector": [-28.205444, 6.631415], "paragraph_keywords": ["agents", "time", "analysis", "timing"]}, {"paragraph_vector": [-27.560407, 7.877346], "paragraph_keywords": ["topic", "debate", "results", "agents"]}, {"paragraph_vector": [-27.801229, 8.075838], "paragraph_keywords": ["agents", "topics", "participants", "baseline"]}, {"paragraph_vector": [-26.348047, 7.060837], "paragraph_keywords": ["participants", "topic", "combine", "agent"]}, {"paragraph_vector": [-24.070159, 4.200652], "paragraph_keywords": ["contexts", "seen", "learned", "agents"]}, {"paragraph_vector": [-27.10556, 6.192214], "paragraph_keywords": ["agents", "context", "training", "guidance"]}, {"paragraph_vector": [-23.259315, 2.471062], "paragraph_keywords": ["context", "quality", "agents", "vectorization"]}, {"paragraph_vector": [-23.991868, 2.91096], "paragraph_keywords": ["technique", "agents", "guidance", "rules"]}, {"paragraph_vector": [-27.480621, 5.506516], "paragraph_keywords": ["sperrle", "et", "al", "co"]}], "content": {}, "doi": "empty"}, {"uri": "21", "title": "Visual Analysis of Electronic Densities and Transitions in Molecules", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["T. Bin Masood", "M. Linares", "A. I. Abrikosov", "V. Natarajan"], "summary": "The study of electronic transitions within a molecule connected to the absorption or emission of light is a common task in the process of the design of new materials. The transitions are complex quantum mechanical processes and a detailed analysis requires a breakdown of these processes into components that can be interpreted via characteristic chemical properties. We approach these tasks by providing a detailed analysis of the electron density field. This entails methods to quantify and visualize electron localization and transfer from molecular subgroups combining spatial and abstract representations. The core of our method uses geometric segmentation of the electronic density field coupled with a graph-theoretic formulation of charge transfer between molecular subgroups. The design of the methods has been guided by the goal of providing a generic and objective analysis following fundamental concepts. We illustrate the proposed approach using several case studies involving the study of electronic transitions in different molecular systems. CCS Concepts \u2022 Human-centered computing \u2192 Scientific visualization; Visualization techniques; \u2022 Applied computing \u2192 Chemistry;", "keywords": ["field", "orbitals", "density", "number", "space", "constraint", "matrix", "diagram", "volume", "solution", "region", "case", "d", "molecule", "problem", "approach", "proposed", "property", "transfer", "particle", "provides", "fig", "set", "hole", "method", "j", "voronoi", "point", "segmentation", "based", "study", "atom", "al", "subgroup", "analysis", "design", "visualization", "difference", "electron", "transition", "charge"], "document_vector": [6.77917, 22.132707], "paragraphs": [{"paragraph_vector": [140.11325, 42.584415], "paragraph_keywords": ["density", "analysis", "visualization", "electron"]}, {"paragraph_vector": [141.854705, 43.524593], "paragraph_keywords": ["sec", "electrons", "problem", "visualization"]}, {"paragraph_vector": [135.485275, 39.019721], "paragraph_keywords": ["orbitals", "molecule", "energy", "electrons"]}, {"paragraph_vector": [136.386505, 45.251319], "paragraph_keywords": ["methods", "molecule", "atoms", "molecules"]}, {"paragraph_vector": [139.823364, 47.532428], "paragraph_keywords": ["charge", "density", "indexes", "ground"]}, {"paragraph_vector": [134.644149, 49.361759], "paragraph_keywords": ["visualization", "plots", "representations", "charge"]}, {"paragraph_vector": [142.970413, 48.532012], "paragraph_keywords": ["segmentation", "introduced", "methods", "sets"]}, {"paragraph_vector": [129.399597, 46.997543], "paragraph_keywords": ["charge", "flow", "visualization", "graphs"]}, {"paragraph_vector": [138.363174, 44.17686], "paragraph_keywords": ["charge", "analysis", "hole", "particle"]}, {"paragraph_vector": [142.097473, 45.817256], "paragraph_keywords": ["segmentation", "charge", "atom", "voronoi"]}, {"paragraph_vector": [137.731857, 46.250469], "paragraph_keywords": ["charge", "volume", "voronoi", "point"]}, {"paragraph_vector": [139.656295, 40.78041], "paragraph_keywords": ["charge", "transfer", "problem", "matrix"]}, {"paragraph_vector": [138.256805, 41.587741], "paragraph_keywords": ["j", "charge", "transfer", "matrix"]}, {"paragraph_vector": [137.357376, 43.276958], "paragraph_keywords": ["j", "ti", "solution", "constraints"]}, {"paragraph_vector": [143.427215, 39.513423], "paragraph_keywords": ["constraints", "problem", "optimization", "constraint"]}, {"paragraph_vector": [143.694961, 49.057731], "paragraph_keywords": ["color", "atoms", "visualization", "map"]}, {"paragraph_vector": [140.583312, 47.658771], "paragraph_keywords": ["subgroups", "visualization", "charge", "hole"]}, {"paragraph_vector": [141.900283, 39.360015], "paragraph_keywords": ["charge", "transition", "transfer", "thiophene"]}, {"paragraph_vector": [140.1958, 40.258831], "paragraph_keywords": ["molecules", "metal", "charge", "excitations"]}, {"paragraph_vector": [147.398422, 40.947463], "paragraph_keywords": ["phe", "complexes", "ligand", "differences"]}, {"paragraph_vector": [147.456024, 43.146419], "paragraph_keywords": ["visualization", "charge", "transition", "diagrams"]}, {"paragraph_vector": [139.890243, 46.064262], "paragraph_keywords": ["segmentation", "molecules", "atoms", "time"]}, {"paragraph_vector": [140.486129, 47.275707], "paragraph_keywords": ["segmentation", "decisions", "molecules", "transitions"]}, {"paragraph_vector": [137.416778, 41.048004], "paragraph_keywords": ["analysis", "densities", "transitions", "molecules"]}], "content": {}, "doi": "empty"}, {"uri": "22", "title": "Local Extraction of 3D Time-Dependent Vector Field Topology", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Lutz Hofmann", "Filip Sadlo"], "summary": "We present an approach to local extraction of 3D time-dependent vector field topology. In this concept, Lagrangian coherent structures, which represent the separating manifolds in time-dependent transport, correspond to generalized streak manifolds seeded along hyperbolic path surfaces (HPSs). Instead of expensive and numerically challenging direct computation of the HPSs by intersection of ridges in the forward and backward finite-time Lyapunov exponent (FTLE) fields, our approach employs local extraction of respective candidates in the four-dimensional space-time domain. These candidates are subsequently refined toward the hyperbolic path surfaces, which provides unsteady equivalents of saddle-type critical points, periodic orbits, and bifurcation lines from steady, traditional vector field topology. In contrast to FTLE-based methods, we obtain an explicit geometric representation of the topological skeleton of the flow, which for steady flows coincides with the hyperbolic invariant manifolds of vector field topology. We evaluate our approach on analytical flows, as well as data from computational fluid dynamics, using the FTLE as a ground truth superset, i.e., we also show that FTLE ridges exhibit several types of false positives. CCS Concepts \u2022 Human-centered computing \u2192 Visualization techniques; \u2022 Applied computing \u2192 Mathematics and statistics;", "keywords": ["obtained", "section", "line", "reference", "field", "space", "type", "vector", "topology", "time", "approach", "structure", "vft", "flow", "lcs", "t", "extraction", "integration", "frame", "point", "ftle", "seeding", "trajectory", "hts", "saddle", "figure", "ridge", "bifurcation", "streak", "surface", "candidate", "manifold"], "document_vector": [-58.881423, 46.806652], "paragraphs": [{"paragraph_vector": [-81.58673, -83.770317], "paragraph_keywords": ["separatrices", "time", "vector", "streamlines"]}, {"paragraph_vector": [124.249404, -89.10614], "paragraph_keywords": ["time", "ridges", "field", "flow"]}, {"paragraph_vector": [-126.940216, -88.412139], "paragraph_keywords": ["time", "hts", "lcs", "integration"]}, {"paragraph_vector": [148.469329, -85.445762], "paragraph_keywords": ["trajectories", "approach", "time", "et"]}, {"paragraph_vector": [-56.590003, -88.714813], "paragraph_keywords": ["time", "lines", "field", "defined"]}, {"paragraph_vector": [-22.07327, -88.841316], "paragraph_keywords": ["time", "t", "ht", "trajectory"]}, {"paragraph_vector": [88.793998, -88.47525], "paragraph_keywords": ["time", "surfaces", "trajectories", "flow"]}, {"paragraph_vector": [-50.831489, -87.777618], "paragraph_keywords": ["time", "vector", "figure", "lcs"]}, {"paragraph_vector": [-14.673917, -89.796409], "paragraph_keywords": ["time", "section", "t", "space"]}, {"paragraph_vector": [142.065765, -89.161949], "paragraph_keywords": ["time", "surface", "candidate", "edges"]}, {"paragraph_vector": [-93.837715, -86.582664], "paragraph_keywords": ["time", "repelling", "section", "candidate"]}, {"paragraph_vector": [179.723861, -85.786933], "paragraph_keywords": ["time", "t", "space", "integration"]}, {"paragraph_vector": [-81.121849, -89.519973], "paragraph_keywords": ["time", "streakline", "manifolds", "length"]}, {"paragraph_vector": [-151.713577, -88.577362], "paragraph_keywords": ["lines", "bifurcation", "vft", "vector"]}, {"paragraph_vector": [166.844177, -84.995552], "paragraph_keywords": ["prototype", "time", "topology", "refer"]}, {"paragraph_vector": [135.468261, -84.536796], "paragraph_keywords": ["figure", "bifurcation", "structures", "vft"]}, {"paragraph_vector": [73.802505, -86.563125], "paragraph_keywords": ["figure", "time", "surfaces", "bifurcation"]}, {"paragraph_vector": [-97.273941, -89.183708], "paragraph_keywords": ["resolution", "fields", "ridge", "scale"]}, {"paragraph_vector": [-124.623313, -85.078407], "paragraph_keywords": ["time", "topology", "figure", "fields"]}, {"paragraph_vector": [114.146705, -88.589797], "paragraph_keywords": ["figure", "computed", "ridge", "g"]}, {"paragraph_vector": [179.935424, -89.587959], "paragraph_keywords": ["time", "frame", "reference", "flow"]}, {"paragraph_vector": [54.085609, -88.955902], "paragraph_keywords": ["reference", "flow", "frame", "lines"]}, {"paragraph_vector": [-177.604278, -84.708244], "paragraph_keywords": ["time", "topology", "approach", "ftle"]}], "content": {}, "doi": "empty"}, {"uri": "23", "title": "Public Data Visualization: Analyzing Local Running Statistics on Situated Displays", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["J. Coenen", "A. Vande Moere"], "summary": "Popular sports tracking applications allow athletes to share and compare their personal performance data with others. Visualizing this data in relevant public settings can be beneficial in provoking novel types of opportunistic and communal sense-making. We investigated this premise by situating an analytical visualization of running performances on two touch-enabled public displays in proximity to a local community running trail. Using a rich mixed-method evaluation protocol during a three-week-long in-the-wild deployment, we captured its social and analytical impact across 235 distinct interaction sessions. Our results show how our public analytical visualization supported passers-by to create novel insights that were rather of casual nature. Several textual features that surrounded the visualization, such as titles that were framed as provocative hypotheses and predefined attention-grabbing data queries, sparked interest and social debate, while a narrative tutorial facilitated more analytical interaction patterns. Our detailed mixed-methods evaluation approach led to a set of actionable takeaways for public visualizations that allow novice audiences to engage with data analytical insights that have local relevance. CCS Concepts \u2022 Human-centered computing \u2192 Empirical studies in visualization; Visualization design and evaluation methods;", "keywords": ["profile", "group", "age", "strava", "line", "display", "interest", "context", "exploration", "explore", "shared", "type", "data", "interaction", "title", "performance", "time", "fig", "people", "stacked", "trail", "information", "session", "study", "based", "m", "filter", "insight", "run", "use", "runner", "tutorial", "analysis", "effect", "engagement", "design", "log", "running", "impact", "identified", "sport", "touch", "user", "passer", "weight", "segment", "category", "feature", "visualization", "pattern"], "document_vector": [35.597415, -39.247047], "paragraphs": [{"paragraph_vector": [25.18411, -4.906525], "paragraph_keywords": ["data", "displays", "visualization", "running"]}, {"paragraph_vector": [29.849267, 1.125206], "paragraph_keywords": ["visualization", "data", "running", "displays"]}, {"paragraph_vector": [31.087762, 7.66494], "paragraph_keywords": ["visualization", "data", "sports", "running"]}, {"paragraph_vector": [21.412618, -15.15651], "paragraph_keywords": ["data", "display", "passers", "order"]}, {"paragraph_vector": [29.442546, 0.834875], "paragraph_keywords": ["data", "running", "api", "impact"]}, {"paragraph_vector": [23.718418, 8.197224], "paragraph_keywords": ["terms", "time", "use", "attributes"]}, {"paragraph_vector": [29.684175, 6.475052], "paragraph_keywords": ["user", "running", "runner", "performance"]}, {"paragraph_vector": [30.965324, 1.869718], "paragraph_keywords": ["university", "fig", "display", "runs"]}, {"paragraph_vector": [11.371158, -4.161118], "paragraph_keywords": ["displays", "interactions", "video", "logs"]}, {"paragraph_vector": [15.585739, -3.116563], "paragraph_keywords": ["visualization", "engagement", "discovery", "users"]}, {"paragraph_vector": [9.062438, -6.64065], "paragraph_keywords": ["users", "visualization", "tutorial", "passers"]}, {"paragraph_vector": [29.321645, 8.648037], "paragraph_keywords": ["m", "run", "tracking", "visualization"]}, {"paragraph_vector": [15.606459, -0.310432], "paragraph_keywords": ["sessions", "filters", "tutorial", "visualization"]}, {"paragraph_vector": [4.860134, 0.387251], "paragraph_keywords": ["sessions", "use", "filters", "users"]}, {"paragraph_vector": [12.834469, -4.551464], "paragraph_keywords": ["sessions", "display", "group", "members"]}, {"paragraph_vector": [26.787221, 9.430771], "paragraph_keywords": ["data", "users", "m", "runs"]}, {"paragraph_vector": [22.885606, 3.349268], "paragraph_keywords": ["m", "insights", "users", "people"]}, {"paragraph_vector": [9.562735, -4.246475], "paragraph_keywords": ["data", "pd", "dv", "users"]}, {"paragraph_vector": [11.963783, -8.850204], "paragraph_keywords": ["visualization", "data", "titles", "use"]}, {"paragraph_vector": [8.97465, -3.357252], "paragraph_keywords": ["visualization", "passers", "use", "sessions"]}, {"paragraph_vector": [10.460691, -5.873776], "paragraph_keywords": ["visualization", "user", "data", "impact"]}, {"paragraph_vector": [11.777147, -3.892985], "paragraph_keywords": ["data", "displays", "display", "points"]}, {"paragraph_vector": [9.997799, -1.976159], "paragraph_keywords": ["data", "user", "display", "displays"]}, {"paragraph_vector": [17.030418, -9.105073], "paragraph_keywords": ["data", "visualization", "user", "features"]}], "content": {}, "doi": "empty"}, {"uri": "24", "title": "Leveraging Topological Events in Tracking Graphs for Understanding Particle Diffusion", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["T. McDonald", "R. Shrestha", "X. Yi", "H. Bhatia", "D. Chen", "D. Goswami", "V. Pascucci", "T. Turbyville", "P.-T. Bremer"], "summary": "Single particle tracking (SPT) of fluorescent molecules provides significant insights into the diffusion and relative motion of tagged proteins and other structures of interest in biology. However, despite the latest advances in high-resolution microscopy, individual particles are typically not distinguished from clusters of particles. This lack of resolution obscures potential evidence for how merging and splitting of particles affect their diffusion and any implications on the biological environment. The particle tracks are typically decomposed into individual segments at observed merge and split events, and analysis is performed without knowing the true count of particles in the resulting segments. Here, we address the challenges in analyzing particle tracks in the context of cancer biology. In particular, we study the tracks of KRAS protein, which is implicated in nearly 20% of all human cancers, and whose clustering and aggregation have been linked to the signaling pathway leading to uncontrolled cell growth. We present a new analysis approach for particle tracks by representing them as tracking graphs and using topological events \u2013 merging and splitting, to disambiguate the tracks. Using this analysis, we infer a lower bound on the count of particles as they cluster and create conditional distributions of diffusion speeds before and after merge and split events. Using thousands of time-steps of simulated and in-vitro SPT data, we demonstrate the efficacy of our method, as it offers the biologists a new, detailed look into the relationship between KRAS clustering and diffusion speeds. CCS Concepts \u2022 Human-centered computing \u2192 Scientific visualization; \u2022 Applied computing \u2192 Computational biology;", "keywords": ["view", "distribution", "filtering", "event", "section", "provide", "lipid", "number", "tracking", "count", "membrane", "split", "data", "time", "msd", "approach", "particle", "tvfs", "spt", "structure", "set", "method", "step", "graph", "frame", "segmentation", "labeled", "clustering", "protein", "correlation", "edge", "track", "trajectory", "use", "analysis", "diffusion", "simulation", "cluster", "figure", "technique", "visualization", "user", "kras", "threshold", "feature", "merge"], "document_vector": [-23.259277, 26.157222], "paragraphs": [{"paragraph_vector": [94.403205, 17.260503], "paragraph_keywords": ["cancer", "kras", "signaling", "hopes"]}, {"paragraph_vector": [92.498741, 15.309294], "paragraph_keywords": ["kras", "lipid", "molecules", "membrane"]}, {"paragraph_vector": [92.303619, 15.728867], "paragraph_keywords": ["diffusion", "analysis", "tracks", "kras"]}, {"paragraph_vector": [92.452133, 15.114757], "paragraph_keywords": ["kras", "membrane", "clustering", "signaling"]}, {"paragraph_vector": [92.335594, 14.925308], "paragraph_keywords": ["kras", "dynamics", "events", "image"]}, {"paragraph_vector": [101.541687, 12.032024], "paragraph_keywords": ["trajectories", "tools", "tracking", "diffusion"]}, {"paragraph_vector": [99.28746, 10.503999], "paragraph_keywords": ["time", "features", "paper", "tracking"]}, {"paragraph_vector": [99.963783, 9.944005], "paragraph_keywords": ["graph", "tracking", "time", "analysis"]}, {"paragraph_vector": [104.475502, 8.861058], "paragraph_keywords": ["tracking", "features", "correlation", "associated"]}, {"paragraph_vector": [101.325897, 11.146461], "paragraph_keywords": ["graph", "tracking", "section", "graphs"]}, {"paragraph_vector": [101.586021, 8.498703], "paragraph_keywords": ["edges", "tracking", "graph", "structure"]}, {"paragraph_vector": [101.590057, 8.678419], "paragraph_keywords": ["features", "tvfs", "time", "feature"]}, {"paragraph_vector": [99.014625, 10.681954], "paragraph_keywords": ["particles", "tracking", "events", "merge"]}, {"paragraph_vector": [98.440757, 11.925916], "paragraph_keywords": ["feature", "count", "features", "counts"]}, {"paragraph_vector": [100.616188, 11.048612], "paragraph_keywords": ["analysis", "data", "features", "visualization"]}, {"paragraph_vector": [99.141456, 12.016286], "paragraph_keywords": ["tracking", "correlation", "graph", "threshold"]}, {"paragraph_vector": [103.311203, 5.220932], "paragraph_keywords": ["graph", "time", "feature", "nodes"]}, {"paragraph_vector": [104.260147, 12.570291], "paragraph_keywords": ["feature", "time", "diffusion", "distribution"]}, {"paragraph_vector": [97.297126, 13.59842], "paragraph_keywords": ["diffusion", "number", "computation", "data"]}, {"paragraph_vector": [92.121627, 16.09832], "paragraph_keywords": ["membrane", "simulation", "kras", "lipid"]}, {"paragraph_vector": [93.232093, 14.966494], "paragraph_keywords": ["kras", "events", "tracking", "edges"]}, {"paragraph_vector": [92.276336, 16.406265], "paragraph_keywords": ["cluster", "collaborators", "diffusion", "kras"]}, {"paragraph_vector": [91.99105, 15.302731], "paragraph_keywords": ["segmentation", "model", "pris", "particles"]}, {"paragraph_vector": [93.857978, 14.677611], "paragraph_keywords": ["msd", "clusters", "distribution", "events"]}, {"paragraph_vector": [89.942314, 17.681079], "paragraph_keywords": ["tracking", "particle", "graph", "diffusion"]}, {"paragraph_vector": [92.527793, -9.813652], "paragraph_keywords": ["known", "provide", "counts", "indication"]}], "content": {}, "doi": "empty"}, {"uri": "25", "title": "Daisen: A Framework for Visualizing Detailed GPU Execution", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Yifan Sun", "Yixuan Zhang", "Ali Mosallaei", "Michael D. Shah", "Cody Dunne", "David Kaeli"], "summary": "Graphics Processing Units (GPUs) have been widely used to accelerate artificial intelligence, physics simulation, medical imaging, and information visualization applications. To improve GPU performance, GPU hardware designers need to identify performance issues by inspecting a huge amount of simulator-generated traces. Visualizing the execution traces can reduce the cognitive burden of users and facilitate making sense of behaviors of GPU hardware components. In this paper, we first formalize the process of GPU performance analysis and characterize the design requirements of visualizing execution traces based on a survey study and interviews with GPU hardware designers. We contribute data and task abstraction for GPU performance analysis. Based on our task analysis, we propose Daisen, a framework that supports data collection from GPU simulators and provides visualization of the simulator-generated GPU execution traces. Daisen features a data abstraction and trace format that can record simulator-generated GPU execution traces. Daisen also includes a web-based visualization tool that helps GPU hardware designers examine GPU execution traces, identify performance bottlenecks, and verify performance improvement. Our qualitative evaluation with GPU hardware designers demonstrates that the design of Daisen reflects the typical workflow of GPU hardware designers. Using Daisen, participants were able to effectively identify potential performance bottlenecks and opportunities for performance improvement. The open-sourced implementation of Daisen can be found at gitlab.com/akita/vis. Supplemental materials including a demo video, survey questions, evaluation study guide, and post-study evaluation survey are available at osf.io/j5ghq. CCS Concepts \u2022 Computer systems organization \u2192 Single instruction, multiple data; \u2022 Human-centered computing \u2192 Information visualization; \u00a9 2021 The Author(s) Computer Graphics Forum \u00a9 2021 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd. DOI: 10.1111/cgf.14303", "keywords": ["work", "view", "survey", "need", "provide", "task", "domain", "request", "metric", "execution", "compute", "understand", "number", "examine", "gpu", "tool", "data", "panel", "performance", "time", "computer", "issue", "help", "identify", "information", "daisen", "cpu", "component", "trace", "based", "participant", "compare", "cache", "memory", "designer", "use", "abstraction", "analysis", "overview", "unit", "simulation", "figure", "design", "visualizing", "hardware", "software", "user", "instruction", "level", "simd", "visualization"], "document_vector": [52.149829, 48.06842], "paragraphs": [{"paragraph_vector": [-110.922294, 23.266479], "paragraph_keywords": ["gpu", "execution", "performance", "hardware"]}, {"paragraph_vector": [-110.283248, 18.994335], "paragraph_keywords": ["gpu", "hardware", "data", "design"]}, {"paragraph_vector": [-110.926628, 22.317478], "paragraph_keywords": ["work", "gpu", "instructions", "units"]}, {"paragraph_vector": [-109.226264, 25.992437], "paragraph_keywords": ["gpu", "memory", "unit", "work"]}, {"paragraph_vector": [-111.463752, 20.247922], "paragraph_keywords": ["tools", "performance", "execution", "function"]}, {"paragraph_vector": [-107.196212, 18.04347], "paragraph_keywords": ["hardware", "gpu", "performance", "visualization"]}, {"paragraph_vector": [-113.59114, 20.473926], "paragraph_keywords": ["performance", "analysis", "survey", "help"]}, {"paragraph_vector": [-113.278503, 20.07563], "paragraph_keywords": ["task", "performance", "survey", "gpu"]}, {"paragraph_vector": [-111.830932, 20.193294], "paragraph_keywords": ["task", "tasks", "design", "designer"]}, {"paragraph_vector": [-110.323394, 18.500272], "paragraph_keywords": ["hardware", "task", "tasks", "formats"]}, {"paragraph_vector": [-113.502067, 22.478492], "paragraph_keywords": ["task", "request", "time", "component"]}, {"paragraph_vector": [-113.384101, 21.870441], "paragraph_keywords": ["components", "users", "task", "metrics"]}, {"paragraph_vector": [-110.414848, 21.350465], "paragraph_keywords": ["component", "tasks", "users", "task"]}, {"paragraph_vector": [-112.171478, 5.566991], "paragraph_keywords": ["height", "tasks", "task", "bar"]}, {"paragraph_vector": [-115.990486, 8.829024], "paragraph_keywords": ["tasks", "task", "view", "colors"]}, {"paragraph_vector": [-107.603553, 21.993549], "paragraph_keywords": ["task", "view", "component", "users"]}, {"paragraph_vector": [-113.169502, 20.419134], "paragraph_keywords": ["data", "mgpusim", "model", "task"]}, {"paragraph_vector": [-113.499877, 21.880058], "paragraph_keywords": ["tasks", "simd", "task", "view"]}, {"paragraph_vector": [-113.066543, 21.544832], "paragraph_keywords": ["memory", "work", "execution", "time"]}, {"paragraph_vector": [-113.979888, 22.753646], "paragraph_keywords": ["participants", "gpu", "performance", "benchmark"]}, {"paragraph_vector": [-112.192626, 20.325908], "paragraph_keywords": ["participants", "components", "gives", "performance"]}, {"paragraph_vector": [-113.022026, 21.574939], "paragraph_keywords": ["performance", "understand", "daisen", "median"]}, {"paragraph_vector": [-113.099533, 20.84624], "paragraph_keywords": ["design", "component", "gpu", "components"]}, {"paragraph_vector": [-111.785354, 21.129201], "paragraph_keywords": ["users", "visualization", "design", "components"]}, {"paragraph_vector": [-109.821525, 20.18087], "paragraph_keywords": ["hardware", "daisen", "architecture", "computer"]}], "content": {}, "doi": "empty"}, {"uri": "26", "title": "TourVis: Narrative Visualization of Multi-Stage Bicycle Races", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["J. D\u00edaz", "P. V\u00e1zquez"], "summary": "There are many multiple-stage racing competitions in various sports such as swimming, running, or cycling. The wide availability of affordable tracking devices facilitates monitoring the position along with the race of all participants, even for non-professional contests. Getting real-time information of contenders is useful but also unleashes the possibility of creating more complex visualization systems that ease the understanding of the behavior of all participants during a simple stage or throughout the whole competition. In this paper we focus on bicycle races, which are highly popular, especially in Europe, being the Tour de France its greatest exponent. Current visualizations from TV broadcasting or real-time tracking websites are useful to understand the current stage status, up to a certain extent. Unfortunately, still no current system exists that visualizes a whole multi-stage contest in such a way that users can interactively explore the relevant events of a single stage (e.g. breakaways, groups, virtual leadership. . .), as well as the full competition. In this paper, we present an interactive system that is useful both for aficionados and professionals to visually analyze the development of multi-stage cycling competitions. CCS Concepts \u2022 Human-centered computing \u2192 Visualization systems and tools; Visual analytics; \u00a9 2021 The Author(s) Computer Graphics Forum \u00a9 2021 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd. DOI: 10.1111/cgf.14327", "keywords": ["work", "view", "profile", "group", "event", "section", "provide", "detail", "race", "evolution", "number", "end", "element", "cyclist", "provided", "tool", "data", "time", "rider", "position", "mountain", "stage", "information", "team", "tour", "point", "participant", "ranking", "leader", "system", "kilometer", "use", "analysis", "finish", "application", "member", "sport", "cycling", "user", "change", "classification", "analyze", "visualization"], "document_vector": [22.696956, -22.323371], "paragraphs": [{"paragraph_vector": [39.646339, 22.020666], "paragraph_keywords": ["stage", "cycling", "tool", "provide"]}, {"paragraph_vector": [37.719657, 18.594133], "paragraph_keywords": ["section", "data", "stage", "race"]}, {"paragraph_vector": [34.914306, 12.947256], "paragraph_keywords": ["data", "information", "races", "time"]}, {"paragraph_vector": [36.266517, 17.131891], "paragraph_keywords": ["stage", "time", "data", "visualization"]}, {"paragraph_vector": [35.95362, 16.205327], "paragraph_keywords": ["teams", "ranking", "events", "provide"]}, {"paragraph_vector": [33.541942, 15.379646], "paragraph_keywords": ["elements", "cyclists", "position", "stage"]}, {"paragraph_vector": [41.747856, 21.913854], "paragraph_keywords": ["tour", "time", "stages", "events"]}, {"paragraph_vector": [38.888214, 24.907077], "paragraph_keywords": ["riders", "stage", "stages", "cyclists"]}, {"paragraph_vector": [40.058876, 25.856393], "paragraph_keywords": ["group", "points", "mountain", "ranking"]}, {"paragraph_vector": [40.017677, 22.328577], "paragraph_keywords": ["information", "line", "finish", "media"]}, {"paragraph_vector": [32.176921, 21.504144], "paragraph_keywords": ["stage", "information", "time", "details"]}, {"paragraph_vector": [36.938201, 21.626577], "paragraph_keywords": ["stage", "time", "facts", "system"]}, {"paragraph_vector": [36.896446, 17.446121], "paragraph_keywords": ["stage", "users", "race", "application"]}, {"paragraph_vector": [36.775131, 22.784193], "paragraph_keywords": ["stage", "riders", "groups", "positions"]}, {"paragraph_vector": [34.444805, 24.021141], "paragraph_keywords": ["time", "groups", "riders", "races"]}, {"paragraph_vector": [33.178081, 22.233972], "paragraph_keywords": ["riders", "stage", "stages", "view"]}, {"paragraph_vector": [38.187103, 24.036352], "paragraph_keywords": ["view", "riders", "group", "performance"]}, {"paragraph_vector": [38.494186, 24.229127], "paragraph_keywords": ["stage", "information", "team", "data"]}, {"paragraph_vector": [36.953098, 22.839189], "paragraph_keywords": ["stage", "ranking", "views", "view"]}, {"paragraph_vector": [37.520755, 23.210956], "paragraph_keywords": ["view", "stage", "riders", "group"]}, {"paragraph_vector": [37.692081, 24.511173], "paragraph_keywords": ["stage", "riders", "leadership", "differences"]}, {"paragraph_vector": [40.728218, 25.361873], "paragraph_keywords": ["stage", "kilometers", "analysis", "leader"]}, {"paragraph_vector": [38.92451, 24.165407], "paragraph_keywords": ["stage", "teams", "peloton", "sprinters"]}, {"paragraph_vector": [37.615722, 24.698539], "paragraph_keywords": ["stage", "application", "users", "view"]}, {"paragraph_vector": [37.268127, 19.269912], "paragraph_keywords": ["application", "riders", "stage", "experts"]}, {"paragraph_vector": [34.229774, 21.129188], "paragraph_keywords": ["information", "application", "cycling", "users"]}, {"paragraph_vector": [36.282188, 24.068658], "paragraph_keywords": ["information", "group", "stage", "signal"]}, {"paragraph_vector": [36.771629, 21.672277], "paragraph_keywords": ["r", "data", "stage", "f"]}, {"paragraph_vector": [33.572029, 22.499967], "paragraph_keywords": ["information", "provided", "encodes", "stage"]}], "content": {}, "doi": "empty"}, {"uri": "27", "title": "Optimal Axes for Data Value Estimation in Star Coordinates and Radial Axes Plots", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["M. Rubio-S\u00e1nchez", "D. J. Lehmann", "J. L. Rojo-\u00c1lvarez"], "summary": "Radial axes plots are projection methods that represent high-dimensional data samples as points on a two-dimensional plane. These techniques define mappings through a set of axis vectors, each associated with a data variable, which users can manipulate interactively to create different plots and analyze data from multiple points of view. However, updating the direction and length of an axis vector is far from trivial. Users must consider the data analysis task, domain knowledge, the directions in which values should increase, the relative importance of each variable, or the correlations between variables, among other factors. Another issue is the difficulty to approximate high-dimensional data values in the two-dimensional visualizations, which can hamper searching for data with particular characteristics, analyzing the most common data values in clusters, inspecting outliers, etc. In this paper we present and analyze several optimization approaches for enhancing radial axes plots regarding their ability to represent high-dimensional data values. The techniques can be used not only to approximate data values with greater accuracy, but also to guide users when updating axis vectors or extending visualizations with new variables, since they can reveal poor choices of axis vectors. The optimal axes can also be included in nonlinear plots. In particular, we show how they can be used within RadViz to assess the quality of a variable ordering. The in-depth analysis carried out is useful for visualization designers developing radial axes techniques, or planning to incorporate axes into other visualization methods. CCS Concepts \u2022 Human-centered computing \u2192 Visualization techniques; Visualization theory, concepts and paradigms; \u2022 Mathematics of computing \u2192 Exploratory data analysis;", "keywords": ["vi", "variable", "v", "pcb", "error", "estimation", "p", "material", "value", "accuracy", "matrix", "c", "applying", "data", "vector", "note", "ax", "th", "approach", "associated", "set", "method", "j", "point", "plot", "embedded", "sc", "order", "estimate", "opt", "user", "ara", "axis"], "document_vector": [172.18193, 6.214657], "paragraphs": [{"paragraph_vector": [176.772766, -44.441272], "paragraph_keywords": ["data", "axis", "axes", "points"]}, {"paragraph_vector": [175.034408, -40.795883], "paragraph_keywords": ["data", "axes", "values", "paper"]}, {"paragraph_vector": [173.402664, -46.667423], "paragraph_keywords": ["data", "axis", "vectors", "th"]}, {"paragraph_vector": [164.092391, -50.790431], "paragraph_keywords": ["vectors", "data", "sc", "axis"]}, {"paragraph_vector": [167.937149, -48.344375], "paragraph_keywords": ["matrix", "data", "axis", "decomposition"]}, {"paragraph_vector": [169.889755, -49.546012], "paragraph_keywords": ["axis", "data", "minimize", "plot"]}, {"paragraph_vector": [167.517364, -47.712509], "paragraph_keywords": ["axis", "vectors", "data", "ara"]}, {"paragraph_vector": [174.822799, -44.630386], "paragraph_keywords": ["axis", "th", "vectors", "axes"]}, {"paragraph_vector": [170.408843, -50.132122], "paragraph_keywords": ["data", "estimates", "axis", "calibration"]}, {"paragraph_vector": [160.741378, -53.454124], "paragraph_keywords": ["data", "estimation", "axes", "ara"]}, {"paragraph_vector": [167.310165, -49.520439], "paragraph_keywords": ["v", "data", "estimates", "ara"]}, {"paragraph_vector": [172.483993, -47.167636], "paragraph_keywords": ["data", "axis", "approach", "p"]}, {"paragraph_vector": [167.856506, -49.491592], "paragraph_keywords": ["applying", "opt", "sc", "ara"]}, {"paragraph_vector": [166.986007, -50.533321], "paragraph_keywords": ["differences", "axis", "angle", "opt"]}, {"paragraph_vector": [172.583007, -46.477542], "paragraph_keywords": ["algorithm", "axis", "ara", "p"]}, {"paragraph_vector": [174.712081, -52.486152], "paragraph_keywords": ["axis", "vectors", "lengths", "data"]}, {"paragraph_vector": [173.76538, -51.153144], "paragraph_keywords": ["data", "c", "variables", "correlations"]}, {"paragraph_vector": [172.084167, -51.929199], "paragraph_keywords": ["values", "axis", "correlations", "variable"]}, {"paragraph_vector": [174.163986, -45.566596], "paragraph_keywords": ["values", "points", "palmitoleic", "anchor"]}, {"paragraph_vector": [169.059158, -48.329811], "paragraph_keywords": ["axis", "data", "vector", "estimation"]}, {"paragraph_vector": [167.626785, -53.497837], "paragraph_keywords": ["vector", "j", "axis", "solution"]}, {"paragraph_vector": [168.351196, -51.656871], "paragraph_keywords": ["vector", "estimation", "variable", "use"]}, {"paragraph_vector": [168.890502, -49.111656], "paragraph_keywords": ["vectors", "axis", "methods", "users"]}, {"paragraph_vector": [175.761749, -42.629329], "paragraph_keywords": ["axis", "data", "axes", "vectors"]}], "content": {}, "doi": "empty"}, {"uri": "28", "title": "Design Space of Origin-Destination Data Visualization", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Martijn Tennekes", "Min Chen"], "summary": "Visualization is an essential tool for observing and analyzing origin-destination (OD) data, which encodes flows between geographic locations, e.g., in applications concerning commuting, migration, and transport of goods. However, depicting OD data often encounter issues of cluttering and occlusion. To address these issues, many visual designs feature data abstraction and visual abstraction, such as node aggregation and edge bundling, resulting in information loss. The recent theoretical and empirical developments in visualization have substantiated the merits of such abstraction, while confirming that viewers\u2019 knowledge can alleviate the negative impact due to information loss. It is thus desirable to map out different ways of losing and adding information in origin-destination data visualization (ODDV). We therefore formulate a new design space of ODDV based on the categorization of informative operations on OD data in data abstraction and visual abstraction. We apply this design space to existing ODDV methods, outline strategies for exploring the design space, and suggest ideas for further exploration. \u00a9 2021 The Author(s) Computer Graphics Forum \u00a9 2021 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd. DOI: 10.1111/cgf.14310", "keywords": ["core", "filtering", "group", "section", "variable", "e", "task", "node", "chen", "space", "oddv", "encoded", "destination", "function", "data", "interaction", "example", "computer", "knowledge", "shown", "people", "transformation", "set", ".", "flow", "y", "information", "method", "point", "based", "u", "edge", "add", "designer", "use", "dimension", "graphic", "encoding", "figure", "design", "map", "coordinate", "loss", "origin", "visualization"], "document_vector": [-100.347221, -67.627212], "paragraphs": [{"paragraph_vector": [-91.108787, -57.197494], "paragraph_keywords": ["data", "map", "visualization", "oddv"]}, {"paragraph_vector": [-88.948036, -53.462066], "paragraph_keywords": ["information", "edges", "oddv", "design"]}, {"paragraph_vector": [-89.742103, -62.276134], "paragraph_keywords": ["data", "flow", "movements", "flows"]}, {"paragraph_vector": [-90.923377, -58.584815], "paragraph_keywords": ["data", "edges", "design", "destinations"]}, {"paragraph_vector": [-92.872337, -53.769241], "paragraph_keywords": ["design", "people", "oddv", "figure"]}, {"paragraph_vector": [-90.631645, -37.237228], "paragraph_keywords": ["design", "information", "space", "concepts"]}, {"paragraph_vector": [-89.194282, -38.711498], "paragraph_keywords": ["data", "design", "information", "dimensions"]}, {"paragraph_vector": [-96.26963, -52.550609], "paragraph_keywords": ["u", "oddv", "functions", "data"]}, {"paragraph_vector": [-149.261627, -61.725124], "paragraph_keywords": ["nodes", "transformation", "function", "figure"]}, {"paragraph_vector": [-103.361938, -46.038837], "paragraph_keywords": ["edge", "data", "variables", "transformation"]}, {"paragraph_vector": [-105.891517, -43.84457], "paragraph_keywords": ["variables", "encoded", "line", "u"]}, {"paragraph_vector": [-104.840751, -43.956851], "paragraph_keywords": ["node", "data", "c", "variables"]}, {"paragraph_vector": [-107.067756, -40.225543], "paragraph_keywords": ["encoding", "data", "y", "node"]}, {"paragraph_vector": [-107.799392, -38.085128], "paragraph_keywords": ["node", "y", "presence", "dot"]}, {"paragraph_vector": [-108.628471, -36.392658], "paragraph_keywords": ["variables", "edge", "y", "core"]}, {"paragraph_vector": [-107.437759, -38.141082], "paragraph_keywords": ["figure", "variables", "point", "information"]}, {"paragraph_vector": [-101.97509, -39.500793], "paragraph_keywords": ["variables", "respect", "point", "action"]}, {"paragraph_vector": [-91.856742, -53.567207], "paragraph_keywords": ["oddv", "space", "design", "existing"]}, {"paragraph_vector": [-97.257064, -59.584873], "paragraph_keywords": ["edges", "transformation", "figure", "matrix"]}, {"paragraph_vector": [-92.437301, -40.713382], "paragraph_keywords": ["design", "information", "space", "data"]}, {"paragraph_vector": [-104.61087, -41.781883], "paragraph_keywords": ["design", "space", "edges", "transformation"]}, {"paragraph_vector": [-93.108657, -55.787307], "paragraph_keywords": ["design", "figure", "edge", "origin"]}, {"paragraph_vector": [-95.637931, -23.827402], "paragraph_keywords": ["node", "transformation", "design", "decisions"]}, {"paragraph_vector": [-105.022247, -41.139514], "paragraph_keywords": ["information", "transformations", "design", "dimension"]}, {"paragraph_vector": [-107.604949, -38.928428], "paragraph_keywords": ["impact", "edge", "variables", "y"]}, {"paragraph_vector": [-104.214469, -42.169773], "paragraph_keywords": ["information", "oddv", "loss", "dimension"]}, {"paragraph_vector": [-82.913429, -46.195842], "paragraph_keywords": ["design", "data", "project", "space"]}, {"paragraph_vector": [-87.652641, -69.142318], "paragraph_keywords": ["visualization", "chen", "information", "design"]}, {"paragraph_vector": [-95.651649, -67.137924], "paragraph_keywords": ["visualization", ".", "maps", "design"]}, {"paragraph_vector": [-102.8796, -71.100357], "paragraph_keywords": ["chen", "visualization", "computer", "flow"]}], "content": {}, "doi": "empty"}, {"uri": "29", "title": "Implicit Modeling of Patient-Specific Aortic Dissections with Elliptic Fourier Descriptors", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["G. Mistelbauer", "C. R\u00f6ssl", "K. B\u00e4umler", "D. Fleischmann"], "summary": "Aortic dissection is a life-threatening vascular disease characterized by abrupt formation of a new flow channel (false lumen) within the aortic wall. Survivors of the acute phase remain at high risk for late complications, such as aneurysm formation, rupture, and death. Morphologic features of aortic dissection determine not only treatment strategies in the acute phase (surgical vs. endovascular vs. medical), but also modulate the hemodynamics in the false lumen, ultimately responsible for late complications. Accurate description of the true and false lumen, any communications across the dissection membrane separating the two lumina, and blood supply from each lumen to aortic branch vessels is critical for risk prediction. Patient-specific surface representations are also a prerequisite for hemodynamic simulations, but currently require time-consuming manual segmentation of CT data. We present an aortic dissection cross-sectional model that captures the varying aortic anatomy, allowing for reliable measurements and creation of high-quality surface representations. In contrast to the traditional spline-based cross-sectional model, we employ elliptic Fourier descriptors, which allows users to control the accuracy of the cross-sectional contour of a flow channel. We demonstrate (i) how our approach can solve the requirements for generating surface and wall representations of the flow channels, (ii) how any number of communications between flow channels can be specified in a consistent manner, and (iii) how well branches connected to the respective flow channels are handled. Finally, we discuss how our approach is a step forward to an automated generation of surface models for aortic dissections from raw 3D imaging segmentation masks. CCS Concepts \u2022 Human-centered computing \u2192 Scientific visualization; \u2022 Applied computing \u2192 Health informatics; \u2022 Computing methodologies \u2192 Parametric curve and surface models;", "keywords": ["work", "et", "fcc", "section", "mpr", "centerline", "branch", "number", "space", "function", "volume", "model", "dissection", "approach", "wall", "vessel", "fig", "modeling", "reconstruction", "-", "descriptor", "representation", "point", "contour", "segmentation", "based", "al", "participant", "lumen", "cross", "blending", "chain", "code", "efds", "connected", "aorta", "harmonic", "spline", "shape", "surface", "distance"], "document_vector": [-65.30429, 72.07492], "paragraphs": [{"paragraph_vector": [25.970546, 61.080337], "paragraph_keywords": ["lumen", "dissection", "complications", "features"]}, {"paragraph_vector": [28.179771, 63.964157], "paragraph_keywords": ["model", "representation", "based", "descriptors"]}, {"paragraph_vector": [80.124633, 66.672134], "paragraph_keywords": ["code", "chain", "contour", "fcc"]}, {"paragraph_vector": [68.250556, 67.777122], "paragraph_keywords": ["shape", "shapes", "efds", "cross"]}, {"paragraph_vector": [33.337696, 59.526332], "paragraph_keywords": ["surface", "modeling", "model", "based"]}, {"paragraph_vector": [34.995204, 61.280025], "paragraph_keywords": ["blending", "splines", "-", "sections"]}, {"paragraph_vector": [28.853704, 59.441883], "paragraph_keywords": ["lumen", "branches", "lumina", "vessel"]}, {"paragraph_vector": [42.003437, 59.360687], "paragraph_keywords": ["lumen", "centerline", "mapping", "mpr"]}, {"paragraph_vector": [34.351356, 66.335533], "paragraph_keywords": ["lumen", "contours", "mpr", "branch"]}, {"paragraph_vector": [48.840431, 65.557434], "paragraph_keywords": ["fcc", "contour", "length", "connected"]}, {"paragraph_vector": [46.624809, 65.899711], "paragraph_keywords": ["shape", "harmonics", "lumina", "lumen"]}, {"paragraph_vector": [27.354196, 58.978332], "paragraph_keywords": ["lumen", "distance", "p", "wall"]}, {"paragraph_vector": [37.971538, 59.985019], "paragraph_keywords": ["mpr", "point", "distance", "j"]}, {"paragraph_vector": [28.610145, 59.023738], "paragraph_keywords": ["lumen", "communication", "volume", "fig"]}, {"paragraph_vector": [22.559165, 62.648658], "paragraph_keywords": ["lumen", "approach", "pathologies", "visualization"]}, {"paragraph_vector": [28.832279, 60.140396], "paragraph_keywords": ["aorta", "harmonics", "lumen", "fig"]}, {"paragraph_vector": [27.864906, 60.736778], "paragraph_keywords": ["ms", "distance", "arteries", "gb"]}, {"paragraph_vector": [37.845375, 67.841438], "paragraph_keywords": ["approach", "participants", "likert", "point"]}, {"paragraph_vector": [30.805997, 68.106231], "paragraph_keywords": ["rate", "importance", "likert", "point"]}, {"paragraph_vector": [34.915985, 65.646148], "paragraph_keywords": ["participants", "functions", "contour", "samples"]}, {"paragraph_vector": [39.45335, 66.354042], "paragraph_keywords": ["psr", "reconstruction", "surface", "method"]}, {"paragraph_vector": [41.698314, 66.98294], "paragraph_keywords": ["harmonics", "model", "surface", "simulations"]}, {"paragraph_vector": [26.840621, 59.93288], "paragraph_keywords": ["lumen", "representation", "surface", "ads"]}, {"paragraph_vector": [26.447319, 59.533092], "paragraph_keywords": ["john", "association", "wiley", "eurographics"]}], "content": {}, "doi": "empty"}, {"uri": "30", "title": "A Visual Designer of Layer-wise Relevance Propagation Models", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Xinyi Huang", "Ye Zhao1and", "Tsung Heng Wu", "Wei Xu"], "summary": "Layer-wise Relevance Propagation (LRP) is an emerging and widely-used method for interpreting the prediction results of convolutional neural networks (CNN). LRP developers often select and employ different relevance backpropagation rules and parameters, to compute relevance scores on input images. However, there exists no obvious solution to define a \u201cbest\u201d LRP model. A satisfied model is highly reliant on pertinent images and designers\u2019 goals. We develop a visual model designer, named as VisLRPDesigner, to overcome the challenges in the design and use of LRP models. Various LRP rules are unified into an integrated framework with an intuitive workflow of parameter setup. VisLRPDesigner thus allows users to interactively configure and compare LRP models. It also facilitates relevance-based visual analysis with two important functions: relevance-based pixel flipping and neuron ablation. Several use cases illustrate the benefits of VisLRPDesigner. The usability and limitation of the visual designer is evaluated by LRP users.", "keywords": ["flipping", "relevance", "heatmaps", "prediction", "learning", "understand", "value", "ablation", "input", "result", "model", "cnn", "layer", "shown", "fig", "barn", "image", "class", "pixel", "method", "rule", "neuron", "study", "lrp", "based", "comparison", "system", "including", "parameter", "score", "vislrpdesigner", "design", "show", "propagation", "user", "weight", "segment"], "document_vector": [115.07167, 50.219932], "paragraphs": [{"paragraph_vector": [162.638992, 20.685642], "paragraph_keywords": ["relevance", "methods", "input", "lrp"]}, {"paragraph_vector": [160.634628, 24.948879], "paragraph_keywords": ["lrp", "model", "rules", "relevance"]}, {"paragraph_vector": [163.901626, 20.628322], "paragraph_keywords": ["lrp", "input", "methods", "explanation"]}, {"paragraph_vector": [166.429412, 21.797441], "paragraph_keywords": ["lrp", "understand", "neuron", "cnn"]}, {"paragraph_vector": [160.94989, 20.973657], "paragraph_keywords": ["lrp", "layer", "\u03b2", "j"]}, {"paragraph_vector": [162.171951, 20.632455], "paragraph_keywords": ["relevance", "lrp", "cnn", "parameters"]}, {"paragraph_vector": [166.74414, 18.499195], "paragraph_keywords": ["lrp", "users", "relevance", "rules"]}, {"paragraph_vector": [160.803359, 21.119352], "paragraph_keywords": ["users", "rules", "values", "relevance"]}, {"paragraph_vector": [163.790588, 17.445636], "paragraph_keywords": ["users", "model", "lrp", "fig"]}, {"paragraph_vector": [-111.309715, -6.886558], "paragraph_keywords": ["lrp", "segments", "shown", "color"]}, {"paragraph_vector": [167.208053, 22.586519], "paragraph_keywords": ["lrp", "fig", "users", "comparison"]}, {"paragraph_vector": [161.312164, 20.549413], "paragraph_keywords": ["relevance", "image", "fig", "flipping"]}, {"paragraph_vector": [163.739151, 18.783979], "paragraph_keywords": ["neurons", "neuron", "relevance", "users"]}, {"paragraph_vector": [163.24057, 19.837749], "paragraph_keywords": ["lrp", "relevance", "users", "models"]}, {"paragraph_vector": [162.741973, 17.299757], "paragraph_keywords": ["barn", "horses", "relevance", "ox"]}, {"paragraph_vector": [162.497421, 18.26291], "paragraph_keywords": ["prediction", "shows", "class", "relevance"]}, {"paragraph_vector": [162.669601, 19.052671], "paragraph_keywords": ["neurons", "neuron", "layer", "class"]}, {"paragraph_vector": [165.598098, 22.495685], "paragraph_keywords": ["lrp", "vislrpdesigner", "design", "model"]}, {"paragraph_vector": [-60.469356, -30.979682], "paragraph_keywords": ["vislrpdesigner", "lrp", "scores", "model"]}, {"paragraph_vector": [168.655303, 23.070964], "paragraph_keywords": ["lrp", "relevance", "system", "parameter"]}, {"paragraph_vector": [161.938201, 21.681457], "paragraph_keywords": ["lrp", "relevance", "models", "tools"]}], "content": {}, "doi": "empty"}, {"uri": "31", "title": "ClusterSets: Optimizing Planar Clusters in Categorical Point Data", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["J. Geiger", "J.-H. Haunert", "P. Kindermann", "T. Mchedlidze", "A. Wolff"], "summary": "J. Geiger1 , S. Cornelsen2 , J.-H. Haunert3 , P. Kindermann1,4 , T. Mchedlidze5 , M. N\u00f6llenburg6 , Y. Okamoto7 , and A. Wolff1 1 Universit\u00e4t W\u00fcrzburg, W\u00fcrzburg, Germany 2 University of Konstanz, Konstanz, Germany 3 University of Bonn, Bonn, Germany 4 Universit\u00e4t Trier, Trier, Germany 5 Utrecht University, Utrecht, The Netherlands 6 TU Wien, Vienna, Austria 7 University of Electro-Communications, Tokyo, Japan", "keywords": ["section", "v", "e", "line", "thank", "number", "data", "region", "heuristic", "solution", "plane", "case", "department", "fig", "set", "method", "minimization", "ilp", "step", "graph", "point", "based", "m", "clustering", "edge", "crossing", "use", "spanning", "cluster", "connected", "\u03b2", "proximity", "category", "visualization"], "document_vector": [-97.985832, 20.414346], "paragraphs": [{"paragraph_vector": [99.807174, -25.031826], "paragraph_keywords": ["points", "visualization", "sets", "clustersets"]}, {"paragraph_vector": [96.847038, -19.113637], "paragraph_keywords": ["clusters", "edges", "categories", "points"]}, {"paragraph_vector": [96.289764, -15.309411], "paragraph_keywords": ["graph", "section", "cluster", "edge"]}, {"paragraph_vector": [103.421058, -24.520858], "paragraph_keywords": ["visualization", "methods", "clusters", "cluster"]}, {"paragraph_vector": [99.942535, -20.435022], "paragraph_keywords": ["cluster", "based", "points", "spanning"]}, {"paragraph_vector": [98.97525, -18.999498], "paragraph_keywords": ["cluster", "based", "shapes", "method"]}, {"paragraph_vector": [99.468116, -18.209512], "paragraph_keywords": ["point", "clustering", "category", "graph"]}, {"paragraph_vector": [92.953025, -13.726144], "paragraph_keywords": ["graph", "proximity", "step", "edges"]}, {"paragraph_vector": [101.772636, -22.641351], "paragraph_keywords": ["clusters", "\u03b2", "proximity", "cluster"]}, {"paragraph_vector": [95.214057, -15.440107], "paragraph_keywords": ["edges", "e", "heuristics", "cluster"]}, {"paragraph_vector": [93.09436, -14.941413], "paragraph_keywords": ["graphs", "edges", "plane", "crossings"]}, {"paragraph_vector": [90.891639, -14.720641], "paragraph_keywords": ["m", "v", "edges", "plane"]}, {"paragraph_vector": [94.268676, -15.684928], "paragraph_keywords": ["edges", "variables", "number", "problems"]}, {"paragraph_vector": [94.837501, -16.052604], "paragraph_keywords": ["clusters", "flow", "v", "edges"]}, {"paragraph_vector": [98.706474, -17.364036], "paragraph_keywords": ["points", "methods", "\u03b2", "department"]}, {"paragraph_vector": [100.480194, -21.060216], "paragraph_keywords": ["regions", "edges", "point", "department"]}, {"paragraph_vector": [93.633163, -15.028348], "paragraph_keywords": ["clusters", "data", "\u03b2", "pois"]}, {"paragraph_vector": [99.923309, -20.378139], "paragraph_keywords": ["points", "clusters", "crossing", "design"]}, {"paragraph_vector": [104.24121, -22.8736], "paragraph_keywords": ["clusters", "points", "data", "fig"]}, {"paragraph_vector": [96.14083, -17.266412], "paragraph_keywords": ["\u03b2", "ilp", "instances", "clusters"]}, {"paragraph_vector": [94.522575, -17.426286], "paragraph_keywords": ["edges", "number", "\u03b2", "heuristics"]}, {"paragraph_vector": [92.623931, -14.213403], "paragraph_keywords": ["thank", "graph", "case", "cluster"]}], "content": {}, "doi": "empty"}, {"uri": "32", "title": "Visualizing Carotid Blood Flow Simulations for Stroke Prevention", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["P. Eulzer", "M. Meuschke", "C. M. Klingner", "K. Lawonn"], "summary": "In this work, we investigate how concepts from medical flow visualization can be applied to enhance stroke prevention diagnostics. Our focus lies on carotid stenoses, i.e., local narrowings of the major brain-supplying arteries, which are a frequent cause of stroke. Carotid surgery can reduce the stroke risk associated with stenoses, however, the procedure entails risks itself. Therefore, a thorough assessment of each case is necessary. In routine diagnostics, the morphology and hemodynamics of an afflicted vessel are separately analyzed using angiography and sonography, respectively. Blood flow simulations based on computational fluid dynamics could enable the visual integration of hemodynamic and morphological information and provide a higher resolution on relevant parameters. We identify and abstract the tasks involved in the assessment of stenoses and investigate how clinicians could derive relevant insights from carotid blood flow simulations. We adapt and refine a combination of techniques to facilitate this purpose, integrating spatiotemporal navigation, dimensional reduction, and contextual embedding. We evaluated and discussed our approach with an interdisciplinary group of medical practitioners, fluid simulation and flow visualization researchers. Our initial findings indicate that visualization techniques could promote usage of carotid blood flow simulations in practice. CCS Concepts \u2022 Human-centered computing \u2192 Scientific visualization; \u2022 Applied computing \u2192 Life and medical sciences;", "keywords": ["view", "need", "probe", "domain", "task", "display", "context", "exploration", "depiction", "stroke", "stenosis", "type", "data", "volume", "carotid", "carotids", "found", "region", "time", "velocity", "blood", "shown", "vessel", "flow", "cta", "information", "method", "computed", "point", "based", "diameter", "participant", "lumen", "use", "analysis", "parameter", "overview", "cfd", "simulation", "hemodynamics", "figure", "map", "plaque", "physician", "simulated", "visualization"], "document_vector": [-83.888412, 52.706192], "paragraphs": [{"paragraph_vector": [54.209644, 84.014045], "paragraph_keywords": ["stroke", "flow", "plaque", "need"]}, {"paragraph_vector": [101.230667, 89.513092], "paragraph_keywords": ["flow", "methods", "stroke", "carotids"]}, {"paragraph_vector": [49.972904, 81.938316], "paragraph_keywords": ["stenosis", "blood", "carotid", "flow"]}, {"paragraph_vector": [13.733722, 87.066619], "paragraph_keywords": ["flow", "domain", "blood", "visualization"]}, {"paragraph_vector": [144.369369, 85.916702], "paragraph_keywords": ["flow", "domain", "data", "shown"]}, {"paragraph_vector": [-41.462619, 86.854843], "paragraph_keywords": ["context", "flow", "data", "methods"]}, {"paragraph_vector": [26.581617, 85.389167], "paragraph_keywords": ["flow", "data", "methods", "simulation"]}, {"paragraph_vector": [-7.840084, 87.308189], "paragraph_keywords": ["data", "use", "carotid", "flow"]}, {"paragraph_vector": [56.159904, 85.054817], "paragraph_keywords": ["stenosis", "vessel", "tasks", "flow"]}, {"paragraph_vector": [40.570507, 85.958106], "paragraph_keywords": ["flow", "carotid", "data", "visualization"]}, {"paragraph_vector": [49.827827, 82.443153], "paragraph_keywords": ["flow", "vessel", "visualization", "cycles"]}, {"paragraph_vector": [-55.874389, 87.974617], "paragraph_keywords": ["flow", "display", "rendering", "selected"]}, {"paragraph_vector": [43.940086, 78.099243], "paragraph_keywords": ["vessel", "map", "branch", "d"]}, {"paragraph_vector": [25.556797, 80.797882], "paragraph_keywords": ["scaling", "carotid", "vessel", "stenoses"]}, {"paragraph_vector": [6.81343, 87.541854], "paragraph_keywords": ["flow", "rate", "branch", "graphs"]}, {"paragraph_vector": [86.175819, 85.570114], "paragraph_keywords": ["vessel", "plane", "time", "domain"]}, {"paragraph_vector": [18.099437, 85.812614], "paragraph_keywords": ["probe", "vessel", "view", "functions"]}, {"paragraph_vector": [30.404716, 87.188201], "paragraph_keywords": ["vessel", "volume", "probe", "cta"]}, {"paragraph_vector": [-111.771545, 89.386184], "paragraph_keywords": ["data", "participants", "methods", "statements"]}, {"paragraph_vector": [-24.293498, 86.9179], "paragraph_keywords": ["probe", "data", "visualization", "diameter"]}, {"paragraph_vector": [-66.201782, 89.980285], "paragraph_keywords": ["flow", "stenoses", "expert", "participants"]}, {"paragraph_vector": [-38.286537, 88.227416], "paragraph_keywords": ["data", "cfd", "clinicians", "simulated"]}, {"paragraph_vector": [-10.08453, 88.130477], "paragraph_keywords": ["flow", "visualization", "stenoses", "explore"]}, {"paragraph_vector": [-19.290893, 89.010757], "paragraph_keywords": ["role", "flow", "domain", "methods"]}], "content": {}, "doi": "empty"}, {"uri": "33", "title": "Design Patterns and Trade-Offs in Responsive Visualization for Communication", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Hyeok Kim", "Dominik Moritz", "Jessica Hullman"], "summary": "Increased access to mobile devices motivates the need to design communicative visualizations that are responsive to varying screen sizes. However, relatively little design guidance or tooling is currently available to authors. We contribute a detailed characterization of responsive visualization strategies in communication-oriented visualizations, identifying 76 total strategies by analyzing 378 pairs of large screen (LS) and small screen (SS) visualizations from online articles and reports. Our analysis distinguishes between the Targets of responsive visualization, referring to what elements of a design are changed and Actions representing how targets are changed. We identify key trade-offs related to authors\u2019 need to maintain graphical density, referring to the amount of information per pixel, while also maintaining the \u201cmessage\u201d or intended takeaways for users of a visualization. We discuss implications of our findings for future visualization tool design to support responsive transformation of visualization designs, including requirements for automated recommenders for communication-oriented responsive visualizations. CCS Concepts \u2022 Human-centered computing \u2192 Empirical studies in visualization; Visualization design and evaluation methods;", "keywords": ["work", "view", "sample", "annotation", "action", "text", "density", "element", "space", "data", "interaction", "screen", "example", "ax", "problem", "communication", "position", "removing", "trade", "size", "message", "target", "set", "information", "fix", "refers", "based", "s", "remove", "mark", "record", "strategy", "author", "including", "use", "analysis", "encoding", "figure", "design", "offs", "layout", "device", "difference", "level", "tooltip", "change", "label", "visualization", "pattern", "alternative"], "document_vector": [120.790008, -51.783187], "paragraphs": [{"paragraph_vector": [-78.532188, -11.909497], "paragraph_keywords": ["visualization", "design", "authors", "strategies"]}, {"paragraph_vector": [-80.380554, -11.738598], "paragraph_keywords": ["design", "scalability", "visualization", "message"]}, {"paragraph_vector": [-79.793937, -11.73254], "paragraph_keywords": ["visualization", "devices", "ss", "desktop"]}, {"paragraph_vector": [-78.711547, -11.556232], "paragraph_keywords": ["visualization", "ss", "strategies", "views"]}, {"paragraph_vector": [-80.500991, -13.035502], "paragraph_keywords": ["visualizations", "visualization", "design", "data"]}, {"paragraph_vector": [-79.001731, -13.876367], "paragraph_keywords": ["visualization", "strategies", "design", "designing"]}, {"paragraph_vector": [-80.612014, -16.050802], "paragraph_keywords": ["design", "view", "information", "strategies"]}, {"paragraph_vector": [-5.383624, -44.687248], "paragraph_keywords": ["visualization", "view", "remove", "tooltips"]}, {"paragraph_vector": [-0.965522, -48.858524], "paragraph_keywords": ["visualization", "position", "encoding", "election"]}, {"paragraph_vector": [-82.146781, -9.576315], "paragraph_keywords": ["annotations", "state", "design", "target"]}, {"paragraph_vector": [-88.450233, -20.603973], "paragraph_keywords": ["encoding", "remove", "change", "changes"]}, {"paragraph_vector": [-77.246963, -11.496051], "paragraph_keywords": ["interaction", "authors", "text", "input"]}, {"paragraph_vector": [-80.368431, -10.993178], "paragraph_keywords": ["action", "target", "interactions", "remove"]}, {"paragraph_vector": [-82.300323, -8.693574], "paragraph_keywords": ["visualization", "labels", "actions", "refers"]}, {"paragraph_vector": [-84.098884, -11.187887], "paragraph_keywords": ["targets", "screen", "fix", "tooltip"]}, {"paragraph_vector": [-81.728507, -14.194176], "paragraph_keywords": ["data", "targets", "authors", "figure"]}, {"paragraph_vector": [-81.136306, -11.415106], "paragraph_keywords": ["visualization", "authors", "data", "design"]}, {"paragraph_vector": [-83.558998, -15.409691], "paragraph_keywords": ["problems", "megabank", "design", "math"]}, {"paragraph_vector": [-82.222839, -15.285908], "paragraph_keywords": ["ss", "interaction", "density", "data"]}, {"paragraph_vector": [-82.624122, -14.0462], "paragraph_keywords": ["visualization", "information", "perception", "view"]}, {"paragraph_vector": [-88.009376, -20.358003], "paragraph_keywords": ["alternatives", "change", "message", "authors"]}, {"paragraph_vector": [-79.869232, -11.916279], "paragraph_keywords": ["strategies", "design", "visualization", "information"]}, {"paragraph_vector": [-82.487556, -13.564057], "paragraph_keywords": ["visualization", "design", "message", "authors"]}, {"paragraph_vector": [-78.026466, -12.658797], "paragraph_keywords": ["design", "visualization", "messages", "based"]}, {"paragraph_vector": [-79.178932, -10.413247], "paragraph_keywords": ["visualization", "visualizations", "design", "strategies"]}], "content": {}, "doi": "empty"}, {"uri": "34", "title": "VEHICLE: Validation and Exploration of the Hierarchical Integration of Conflict Event Data", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["B. Mayer", "K. Lawonn", "K. Donnay", "B. Preim", "M. Meuschke"], "summary": "The exploration of large-scale conflicts, as well as their causes and effects, is an important aspect of socio-political analysis. Since event data related to major conflicts are usually obtained from different sources, researchers developed a semi-automatic matching algorithm to integrate event data of different origins into one comprehensive dataset using hierarchical taxonomies. The validity of the corresponding integration results is not easy to assess since the results depend on user-defined input parameters and the relationships between the original data sources. However, only rudimentary visualization techniques have been used so far to analyze the results, allowing no trustworthy validation or exploration of how the final dataset is composed. To overcome this problem, we developed VEHICLE, a web-based tool to validate and explore the results of the hierarchical integration. For the design, we collaborated with a domain expert to identify the underlying domain problems and derive a task and workflow description. The tool combines both traditional and novel visual analysis techniques, employing statistical and map-based depictions as well as advanced interaction techniques. We showed the usefulness of VEHICLE in two case studies and by conducting an evaluation together with conflict researchers, confirming domain hypotheses and generating new insights. CCS Concepts \u2022 Human-centered computing \u2192 Information visualization; Geographic visualization; Visualization toolkits;", "keywords": ["match", "view", "need", "event", "integrated", "domain", "node", "taxonomy", "value", "number", "space", "tool", "data", "case", "result", "time", "tree", "set", "information", "vehicle", "integration", "addition", "dataset", "based", "compare", "displayed", "algorithm", "arc", "use", "analysis", "parameter", "score", "conflict", "figure", "technique", "analyst", "bar", "identified", "datasets", "attribute", "scale", "matching", "corresponding", "level", "category", "analyze"], "document_vector": [-72.200775, -64.254211], "paragraphs": [{"paragraph_vector": [54.87535, -33.365608], "paragraph_keywords": ["datasets", "information", "events", "based"]}, {"paragraph_vector": [47.105381, -33.568675], "paragraph_keywords": ["data", "conflict", "event", "domain"]}, {"paragraph_vector": [52.015369, -39.806621], "paragraph_keywords": ["data", "analysis", "conflict", "event"]}, {"paragraph_vector": [53.529106, -47.327201], "paragraph_keywords": ["events", "point", "data", "information"]}, {"paragraph_vector": [43.517894, -60.472949], "paragraph_keywords": ["data", "use", "dataset", "space"]}, {"paragraph_vector": [58.826202, -49.991653], "paragraph_keywords": ["hierarchy", "self", "events", "event"]}, {"paragraph_vector": [56.110637, -32.700473], "paragraph_keywords": ["taxonomy", "datasets", "event", "levels"]}, {"paragraph_vector": [61.115779, -36.037673], "paragraph_keywords": ["events", "data", "taxonomy", "algorithm"]}, {"paragraph_vector": [62.364864, -38.543899], "paragraph_keywords": ["data", "domain", "parameters", "events"]}, {"paragraph_vector": [67.502326, -39.32011], "paragraph_keywords": ["events", "need", "analysts", "matches"]}, {"paragraph_vector": [63.439441, -37.65126], "paragraph_keywords": ["tool", "workflow", "design", "data"]}, {"paragraph_vector": [65.580192, -34.483142], "paragraph_keywords": ["analysts", "compare", "match", "patterns"]}, {"paragraph_vector": [56.549671, -32.15192], "paragraph_keywords": ["matches", "parameter", "matching", "selected"]}, {"paragraph_vector": [16.93155, 46.42707], "paragraph_keywords": ["trees", "dissimilarity", "weights", "tree"]}, {"paragraph_vector": [67.363731, -32.829265], "paragraph_keywords": ["events", "matches", "dissimilarity", "event"]}, {"paragraph_vector": [45.669826, -52.488807], "paragraph_keywords": ["events", "values", "clutter", "context"]}, {"paragraph_vector": [56.477642, -45.947334], "paragraph_keywords": ["events", "use", "figure", "event"]}, {"paragraph_vector": [66.892189, -37.713462], "paragraph_keywords": ["bar", "categories", "events", "attribute"]}, {"paragraph_vector": [62.088222, -35.270469], "paragraph_keywords": ["categories", "attribute", "category", "events"]}, {"paragraph_vector": [60.142681, -34.584072], "paragraph_keywords": ["categories", "matches", "displayed", "match"]}, {"paragraph_vector": [78.257514, -26.928262], "paragraph_keywords": ["arc", "matches", "count", "filtering"]}, {"paragraph_vector": [52.935119, -33.095405], "paragraph_keywords": ["events", "case", "matches", "findings"]}, {"paragraph_vector": [57.785194, -31.35367], "paragraph_keywords": ["events", "matches", "case", "data"]}, {"paragraph_vector": [56.151458, -33.572849], "paragraph_keywords": ["matches", "events", "match", "analyst"]}, {"paragraph_vector": [66.177024, -34.761528], "paragraph_keywords": ["information", "view", "conflict", "sessions"]}, {"paragraph_vector": [62.250774, -37.4594], "paragraph_keywords": ["data", "analyst", "stated", "feedback"]}, {"paragraph_vector": [34.914398, -2.855206], "paragraph_keywords": ["axes", "future", "bar", "attribute"]}, {"paragraph_vector": [56.677478, -33.111507], "paragraph_keywords": ["matching", "ranges", "data", "need"]}, {"paragraph_vector": [53.922653, -34.090404], "paragraph_keywords": ["analysis", "vehicle", "data", "tool"]}, {"paragraph_vector": [54.614532, -34.271945], "paragraph_keywords": ["john", "association", "wiley", "exploration"]}], "content": {}, "doi": "empty"}, {"uri": "35", "title": "CommAID: Visual Analytics for Communication Analysis through Interactive Dynamics Modeling", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["M. T. Fischer", "D. A. Keim", "M. El-Assady"], "summary": "Communication consists of both meta-information as well as content. Currently, the automated analysis of such data often focuses either on the network aspects via social network analysis or on the content, utilizing methods from text-mining. However, the first category of approaches does not leverage the rich content information, while the latter ignores the conversation environment and the temporal evolution, as evident in the meta-information. In contradiction to communication research, which stresses the importance of a holistic approach, both aspects are rarely applied simultaneously, and consequently, their combination has not yet received enough attention in automated analysis systems. In this work, we aim to address this challenge by discussing the difficulties and design decisions of such a path as well as contribute CommAID, a blueprint for a holistic strategy to communication analysis. It features an integrated visual analytics design to analyze communication networks through dynamics modeling, semantic pattern retrieval, and a user-adaptable and problem-specific machine learning-based retrieval system. An interactive multi-level matrix-based visualization facilitates a focused analysis of both network and content using inline visuals supporting cross-checks and reducing context switches. We evaluate our approach in both a case study and through formative evaluation with eight law enforcement experts using a real-world communication corpus. Results show that our solution surpasses existing techniques in terms of integration level and applicability. With this contribution, we aim to pave the path for a more holistic approach to communication analysis. CCS Concepts \u2022 Human-centered computing \u2192 Visual analytics; \u2022 Applied computing \u2192 Law, social and behavioral sciences; \u00a9 2021 The Author(s) Computer Graphics Forum \u00a9 2021 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd. DOI: 10.1111/cgf.14286", "keywords": ["query", "work", "view", "allow", "section", "domain", "task", "content", "node", "exploration", "named", "space", "matrix", "data", "lea", "example", "result", "interaction", "model", "solution", "time", "communication", "approach", "combined", "dynamic", "set", "research", "information", "method", "allows", "episode", "graph", "study", "based", "expert", "network", "system", "support", "concept", "use", "analysis", "figure", "design", "user", "level", "entity", "aspect", "search", "visualization"], "document_vector": [-132.174804, -48.997051], "paragraphs": [{"paragraph_vector": [75.924957, 34.868331], "paragraph_keywords": ["communication", "network", "content", "analysis"]}, {"paragraph_vector": [79.284545, 38.166999], "paragraph_keywords": ["communication", "system", "analysis", "content"]}, {"paragraph_vector": [70.943885, 32.932228], "paragraph_keywords": ["analysis", "communication", "network", "dynamics"]}, {"paragraph_vector": [73.573738, 33.352722], "paragraph_keywords": ["analysis", "communication", "network", "content"]}, {"paragraph_vector": [68.971992, 27.183418], "paragraph_keywords": ["matrix", "communication", "networks", "techniques"]}, {"paragraph_vector": [73.916656, 33.343982], "paragraph_keywords": ["analysis", "content", "network", "capabilities"]}, {"paragraph_vector": [73.141555, 34.273708], "paragraph_keywords": ["analysis", "communication", "methods", "visualization"]}, {"paragraph_vector": [67.362373, 28.903015], "paragraph_keywords": ["approach", "analysis", "level", "matrix"]}, {"paragraph_vector": [66.31948, 31.961769], "paragraph_keywords": ["levels", "level", "section", "information"]}, {"paragraph_vector": [62.990756, 27.317836], "paragraph_keywords": ["communication", "m", "define", "levels"]}, {"paragraph_vector": [65.467048, 30.393199], "paragraph_keywords": ["communication", "concepts", "search", "allows"]}, {"paragraph_vector": [62.647247, 27.684207], "paragraph_keywords": ["levels", "level", "x", "based"]}, {"paragraph_vector": [62.534275, 26.056833], "paragraph_keywords": ["communication", "levels", "information", "feedback"]}, {"paragraph_vector": [66.370697, 24.540515], "paragraph_keywords": ["views", "view", "cell", "size"]}, {"paragraph_vector": [64.635704, 29.562294], "paragraph_keywords": ["color", "entities", "communications", "level"]}, {"paragraph_vector": [60.599868, 25.488559], "paragraph_keywords": ["named", "query", "entities", "communication"]}, {"paragraph_vector": [66.481147, 30.463073], "paragraph_keywords": ["query", "named", "level", "concepts"]}, {"paragraph_vector": [69.719566, 33.045421], "paragraph_keywords": ["user", "classifier", "classification", "training"]}, {"paragraph_vector": [72.909248, 32.446548], "paragraph_keywords": ["results", "states", "communication", "history"]}, {"paragraph_vector": [71.071296, 32.017734], "paragraph_keywords": ["security", "experience", "based", "communication"]}, {"paragraph_vector": [67.023956, 32.695575], "paragraph_keywords": ["experts", "aspects", "visualization", "reduce"]}, {"paragraph_vector": [68.795722, 31.596065], "paragraph_keywords": ["communication", "experts", "lea", "analysis"]}, {"paragraph_vector": [70.26818, 31.411199], "paragraph_keywords": ["lea", "features", "possibilities", "communication"]}, {"paragraph_vector": [72.088821, 30.665397], "paragraph_keywords": ["persons", "study", "task", "analysis"]}, {"paragraph_vector": [-38.938499, 8.507438], "paragraph_keywords": ["system", "search", "results", "experts"]}, {"paragraph_vector": [73.097557, 32.408969], "paragraph_keywords": ["analysis", "approach", "data", "node"]}, {"paragraph_vector": [71.848228, 32.052486], "paragraph_keywords": ["communication", "study", "knowledge", "analysis"]}, {"paragraph_vector": [70.470375, 32.561241], "paragraph_keywords": ["analysis", "communication", "content", "based"]}, {"paragraph_vector": [73.002044, 31.909339], "paragraph_keywords": ["analysis", "communication", "john", "association"]}], "content": {}, "doi": "empty"}, {"uri": "36", "title": "Compressive Neural Representations of Volumetric Scalar Fields", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Y. Lu", "K. Jiang", "J. A. Levine", "M. Berger"], "summary": "We present an approach for compressing volumetric scalar fields using implicit neural representations. Our approach represents a scalar field as a learned function, wherein a neural network maps a point in the domain to an output scalar value. By setting the number of weights of the neural network to be smaller than the input size, we achieve compressed representations of scalar fields, thus framing compression as a type of function approximation. Combined with carefully quantizing network weights, we show that this approach yields highly compact representations that outperform state-of-the-art volume compression approaches. The conceptual simplicity of our approach enables a number of benefits, such as support for time-varying scalar fields, optimizing to preserve spatial gradients, and random-access field evaluation. We study the impact of network design choices on compression performance, highlighting how simple network architectures are effective for a broad range of volumes. CCS Concepts \u2022 Human-centered computing \u2192 Visualization; \u2022 Computing methodologies \u2192 Neural networks; Image compression;", "keywords": ["work", "et", "learning", "field", "tthresh", "ratio", "number", "value", "function", "volume", "data", "training", "result", "performance", "time", "approach", "layer", "size", "resolution", "obtain", "regularization", "method", "representation", "find", "based", "volumetric", "psnr", "network", "use", "simulation", "compression", "coordinate", "weight", "gradient", "feature", "visualization"], "document_vector": [176.363769, 79.726249], "paragraphs": [{"paragraph_vector": [101.470436, 55.369926], "paragraph_keywords": ["data", "methods", "based", "field"]}, {"paragraph_vector": [101.719863, 52.900962], "paragraph_keywords": ["network", "number", "activation", "weights"]}, {"paragraph_vector": [97.228462, 55.337894], "paragraph_keywords": ["compression", "data", "approach", "based"]}, {"paragraph_vector": [96.927597, 56.695598], "paragraph_keywords": ["data", "representations", "volume", "networks"]}, {"paragraph_vector": [102.388992, 54.302955], "paragraph_keywords": ["-", "fields", "resolution", "field"]}, {"paragraph_vector": [103.148811, 55.529628], "paragraph_keywords": ["field", "d", "sample", "networks"]}, {"paragraph_vector": [98.190055, 52.64207], "paragraph_keywords": ["network", "compression", "function", "number"]}, {"paragraph_vector": [98.866783, 51.316272], "paragraph_keywords": ["weight", "network", "number", "layers"]}, {"paragraph_vector": [103.670585, 51.84037], "paragraph_keywords": ["number", "layers", "block", "network"]}, {"paragraph_vector": [102.058914, 52.604816], "paragraph_keywords": ["weights", "network", "precision", "layers"]}, {"paragraph_vector": [101.928611, 51.179737], "paragraph_keywords": ["psnr", "regularization", "network", "number"]}, {"paragraph_vector": [101.234992, 52.697299], "paragraph_keywords": ["field", "gradients", "provided", "differencing"]}, {"paragraph_vector": [102.414497, 54.100864], "paragraph_keywords": ["network", "function", "field", "gradients"]}, {"paragraph_vector": [96.937263, 53.071483], "paragraph_keywords": ["field", "compression", "simulation", "method"]}, {"paragraph_vector": [100.073326, 51.800315], "paragraph_keywords": ["compression", "volume", "tthresh", "method"]}, {"paragraph_vector": [101.61367, 52.317226], "paragraph_keywords": ["method", "tthresh", "find", "time"]}, {"paragraph_vector": [98.333084, 53.100646], "paragraph_keywords": ["compression", "resolution", "volume", "network"]}, {"paragraph_vector": [104.690338, 50.745815], "paragraph_keywords": ["times", "method", "psnr", "training"]}, {"paragraph_vector": [99.260169, 56.150291], "paragraph_keywords": ["time", "work", "data", "volume"]}, {"paragraph_vector": [98.938064, 52.846549], "paragraph_keywords": ["data", "schemes", "simulation", "networks"]}], "content": {}, "doi": "empty"}, {"uri": "37", "title": "SumRe: Design and Evaluation of a Gist-based Summary Visualization for Incident Reports Triage", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["T. Kakar", "X. Qin", "T. La", "S. K. Sahoo", "S. De", "E. A. Rundensteiner", "L. Harrison"], "summary": "Incident report triage is a common endeavor in many industry sectors, often coupled with serious public safety implications. For example, at the US Food and Drug Administration (FDA), analysts triage an influx of incident reports to identify previously undiscovered drug safety problems. However, these analysts currently conduct this critical yet error-prone incident report triage using a generic table-based interface, with no formal support. Visualization design, task-characterization methodologies, and evaluation models offer several possibilities for better supporting triage workflows, including those dealing with drug safety and beyond. In this work, we aim to elevate the work of triage through a task-abstraction activity with FDA analysts. Second, we design an alternative gist-based summary of text documents used in triage (SumRe). Third, we conduct a crowdsourced evaluation of SumRe with medical experts. Results of the crowdsourced study with medical experts (n = 20) suggest that SumRe better supports accuracy in understanding the gist of a given report, and in identifying important reports for followup activities. We discuss implications of these results, including design considerations for triage workflows beyond the drug domain, as well as methodologies for comparing visualization-enabled text summaries.", "keywords": ["work", "icon", "onset", "provide", "task", "domain", "text", "data", "safety", "taken", "compared", "result", "time", "drug", "fda", "document", "instance", "summary", "help", "fig", "identify", "cue", "set", "incident", "information", "sumre", "reaction", "process", "study", "triage", "based", "ass", "participant", "expert", "insight", "investigation", "use", "patient", "report", "analysis", "design", "analyst", "layout", "following", "level", "visualization"], "document_vector": [171.456161, -22.680797], "paragraphs": [{"paragraph_vector": [-31.489683, -33.429389], "paragraph_keywords": ["reports", "incident", "report", "triage"]}, {"paragraph_vector": [-25.524066, -37.566444], "paragraph_keywords": ["sumre", "reports", "analysts", "triage"]}, {"paragraph_vector": [-26.445968, -35.742523], "paragraph_keywords": ["triage", "work", "visualization", "sumre"]}, {"paragraph_vector": [-11.868362, -23.989154], "paragraph_keywords": ["triage", "document", "based", "summary"]}, {"paragraph_vector": [-35.372367, -31.730886], "paragraph_keywords": ["reports", "drug", "report", "incident"]}, {"paragraph_vector": [-36.557239, -28.203077], "paragraph_keywords": ["analysts", "triage", "report", "process"]}, {"paragraph_vector": [-38.167095, -26.365407], "paragraph_keywords": ["report", "triage", "analysts", "cues"]}, {"paragraph_vector": [-35.291992, -27.096244], "paragraph_keywords": ["reaction", "triage", "drug", "analysts"]}, {"paragraph_vector": [-24.604516, -37.514015], "paragraph_keywords": ["triage", "cues", "report", "analysts"]}, {"paragraph_vector": [-35.052814, -30.288063], "paragraph_keywords": ["drug", "patient", "incident", "reaction"]}, {"paragraph_vector": [-32.886383, -27.812526], "paragraph_keywords": ["triage", "report", "categories", "color"]}, {"paragraph_vector": [-31.410984, -29.009313], "paragraph_keywords": ["reaction", "drug", "onset", "represent"]}, {"paragraph_vector": [-31.063919, -30.172367], "paragraph_keywords": ["drug", "shapes", "status", "fig"]}, {"paragraph_vector": [-27.157472, -32.77222], "paragraph_keywords": ["participants", "study", "participant", "expertise"]}, {"paragraph_vector": [-28.520633, -35.385047], "paragraph_keywords": ["report", "triage", "layout", "sumre"]}, {"paragraph_vector": [-36.370254, -29.220441], "paragraph_keywords": ["reports", "analysts", "report", "drugs"]}, {"paragraph_vector": [-34.453578, -30.765882], "paragraph_keywords": ["layouts", "participants", "triage", "task"]}, {"paragraph_vector": [-25.649213, -36.701381], "paragraph_keywords": ["reports", "tasks", "task", "triage"]}, {"paragraph_vector": [-40.257686, 5.517158], "paragraph_keywords": ["task", "time", "tasks", "participants"]}, {"paragraph_vector": [-28.547201, -35.308876], "paragraph_keywords": ["sumre", "reports", "participants", "triage"]}, {"paragraph_vector": [-27.243951, -34.6991], "paragraph_keywords": ["triage", "participants", "sumre", "reports"]}, {"paragraph_vector": [-27.090744, -36.229442], "paragraph_keywords": ["insights", "information", "cues", "layout"]}, {"paragraph_vector": [-34.435974, -29.194036], "paragraph_keywords": ["insights", "drug", "information", "arrest"]}, {"paragraph_vector": [-28.891424, -33.484828], "paragraph_keywords": ["triage", "layout", "sumre", "task"]}, {"paragraph_vector": [-28.269329, -35.406032], "paragraph_keywords": ["layout", "participants", "efforts", "analyses"]}, {"paragraph_vector": [-32.043342, -32.684288], "paragraph_keywords": ["design", "triage", "incident", "data"]}, {"paragraph_vector": [-28.176061, -35.796749], "paragraph_keywords": ["visualization", "triage", "analysts", "sumre"]}], "content": {}, "doi": "empty"}, {"uri": "38", "title": "Color Nameability Predicts Inference Accuracy in Spatial Visualizations", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Khairi Reda", "Amey A. Salvi", "Jack Gray", "Michael E. Papka"], "summary": "Color encoding is foundational to visualizing quantitative data. Guidelines for colormap design have traditionally emphasized perceptual principles, such as order and uniformity. However, colors also evoke cognitive and linguistic associations whose role in data interpretation remains underexplored. We study how two linguistic factors, name salience and name variation, affect people\u2019s ability to draw inferences from spatial visualizations. In two experiments, we found that participants are better at interpreting visualizations when viewing colors with more salient names (e.g., prototypical \u2018blue\u2019, \u2018yellow\u2019, and \u2018red\u2019 over \u2018teal\u2019, \u2018beige\u2019, and \u2018maroon\u2019). The effect was robust across four visualization types, but was more pronounced in continuous (e.g., smooth geographical maps) than in similar discrete representations (e.g., choropleths). Participants\u2019 accuracy also improved as the number of nameable colors increased, although the latter had a less robust effect. Our findings suggest that color nameability is an important design consideration for quantitative colormaps, and may even outweigh traditional perceptual metrics. In particular, we found that the linguistic associations of color are a better predictor of performance than the perceptual properties of those colors. We discuss the implications and outline research opportunities. The data and materials for this study are available at https://osf.io/asb7n CCS Concepts \u2022 Human-centered computing \u2192 Empirical studies in visualization;", "keywords": ["choropleth", "variety", "colormaps", "task", "distance", "metric", "nameability", "interpretation", "accuracy", "data", "experiment", "result", "performance", "model", "property", "colormap", "people", "target", "name", "discriminability", "plot", "salience", "study", "test", "participant", "association", "inference", "effect", "observer", "encoding", "given", "figure", "color", "variation", "divergence", "map", "decoy", "scale", "difference", "feature", "visualization", "pattern"], "document_vector": [81.941703, -17.887809], "paragraphs": [{"paragraph_vector": [-127.89598, -11.756814], "paragraph_keywords": ["color", "colors", "data", "guidelines"]}, {"paragraph_vector": [-128.860733, -11.479611], "paragraph_keywords": ["colors", "color", "visualizations", "inferences"]}, {"paragraph_vector": [-127.271736, -12.436173], "paragraph_keywords": ["color", "data", "tasks", "estimating"]}, {"paragraph_vector": [-128.639221, -9.730241], "paragraph_keywords": ["color", "colors", "names", "people"]}, {"paragraph_vector": [-127.271316, -11.127815], "paragraph_keywords": ["color", "nameability", "given", "model"]}, {"paragraph_vector": [-127.813224, -11.04086], "paragraph_keywords": ["color", "nameability", "visualizations", "colors"]}, {"paragraph_vector": [-125.490577, -14.86262], "paragraph_keywords": ["models", "inference", "patterns", "researcher"]}, {"paragraph_vector": [-116.533363, -7.378932], "paragraph_keywords": ["decoy", "kernels", "models", "target"]}, {"paragraph_vector": [-126.898277, -14.208711], "paragraph_keywords": ["color", "attend", "comparing", "colors"]}, {"paragraph_vector": [-129.149978, -9.848116], "paragraph_keywords": ["colors", "color", "attention", "features"]}, {"paragraph_vector": [-126.145401, -12.69598], "paragraph_keywords": ["color", "salience", "discriminability", "effects"]}, {"paragraph_vector": [-125.649665, -11.716073], "paragraph_keywords": ["entropy", "color", "distance", "colormap"]}, {"paragraph_vector": [-124.804191, -13.020243], "paragraph_keywords": ["discriminability", "variation", "salience", "color"]}, {"paragraph_vector": [-121.389533, -11.736966], "paragraph_keywords": ["target", "differences", "visualizations", "model"]}, {"paragraph_vector": [-120.303543, -13.327111], "paragraph_keywords": ["accuracy", "participants", "choropleth", "map"]}, {"paragraph_vector": [-120.504638, -12.53627], "paragraph_keywords": ["participants", "checks", "trials", "completed"]}, {"paragraph_vector": [-117.719451, -17.97553], "paragraph_keywords": ["inference", "color", "salience", "colormap"]}, {"paragraph_vector": [-120.437759, -14.718564], "paragraph_keywords": ["model", "models", "ci", "performance"]}, {"paragraph_vector": [-125.375198, -11.914947], "paragraph_keywords": ["experiment", "participants", "color", "heatmap"]}, {"paragraph_vector": [-120.350883, -13.760527], "paragraph_keywords": ["salience", "model", "effect", "experiment"]}, {"paragraph_vector": [-128.393798, -12.55592], "paragraph_keywords": ["nameability", "color", "properties", "salience"]}, {"paragraph_vector": [-122.71566, -14.659572], "paragraph_keywords": ["color", "salience", "variation", "colors"]}, {"paragraph_vector": [-131.429809, -8.783917], "paragraph_keywords": ["nameability", "color", "tasks", "data"]}, {"paragraph_vector": [-123.658439, -13.241692], "paragraph_keywords": ["color", "tools", "nameability", "encodings"]}, {"paragraph_vector": [-124.366325, -11.450569], "paragraph_keywords": ["color", "colors", "nameability", "people"]}], "content": {}, "doi": "empty"}, {"uri": "39", "title": "VisEvol: Visual Analytics to Support Hyperparameter Search through Evolutionary Optimization", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["A. Chatzimparmpas", "R. M. Martins", "K. Kucher", "A. Kerren"], "summary": "During the training phase of machine learning (ML) models, it is usually necessary to configure several hyperparameters. This process is computationally intensive and requires an extensive search to infer the best hyperparameter set for the given problem. The challenge is exacerbated by the fact that most ML models are complex internally, and training involves trial-and-error processes that could remarkably affect the predictive result. Moreover, each hyperparameter of an ML algorithm is potentially intertwined with the others, and changing it might result in unforeseeable impacts on the remaining hyperparameters. Evolutionary optimization is a promising method to try and address those issues. According to this method, performant models are stored, while the remainder are improved through crossover and mutation processes inspired by genetic algorithms. We present VisEvol, a visual analytics tool that supports interactive exploration of hyperparameters and intervention in this evolutionary procedure. In summary, our proposed tool helps the user to generate new models through evolution and eventually explore powerful hyperparameter combinations in diverse regions of the extensive hyperparameter space. The outcome is a voting ensemble (with equal rights) that boosts the final predictive performance. The utility and applicability of VisEvol are demonstrated with two use cases and interviews with ML experts who evaluated the effectiveness of the tool. CCS Concepts \u2022 Human-centered computing\u2192 Visualization; Visual analytics; \u2022Machine learning\u2192 Supervised learning; \u00a9 2021 The Author(s) Computer Graphics Forum \u00a9 2021 The Eurographics Association and John Wiley & Sons Ltd. Published by John Wiley & Sons Ltd. DOI: 10.1111/cgf.14300", "keywords": ["et", "mutation", "view", "section", "va", "learning", "metric", "ml", "ensemble", "value", "space", "number", "tool", "data", "majority", "result", "performance", "model", "compared", "crossover", "approach", "instance", "set", "hyperparameters", "voting", "method", "process", "based", "mlp", "algorithm", "use", "optimization", "cluster", "figure", "combination", "visevol", "validation", "hyperparameter", "selection", "user", "search", "visualization"], "document_vector": [106.536964, 23.194496], "paragraphs": [{"paragraph_vector": [-81.460876, 22.450078], "paragraph_keywords": ["models", "optimization", "hyperparameters", "hyperparameter"]}, {"paragraph_vector": [-84.451705, 19.984651], "paragraph_keywords": ["data", "metrics", "set", "voting"]}, {"paragraph_vector": [-82.525276, 22.17181], "paragraph_keywords": ["hyperparameter", "data", "section", "optimization"]}, {"paragraph_vector": [-81.900161, 21.414745], "paragraph_keywords": ["hyperparameter", "visevol", "section", "va"]}, {"paragraph_vector": [-83.236991, 19.449001], "paragraph_keywords": ["hyperparameter", "models", "search", "hyperparameters"]}, {"paragraph_vector": [-83.004585, 21.836263], "paragraph_keywords": ["models", "search", "algorithms", "visualization"]}, {"paragraph_vector": [-81.149612, 20.125135], "paragraph_keywords": ["models", "et", "al", "model"]}, {"paragraph_vector": [-83.537078, 20.979709], "paragraph_keywords": ["model", "crossover", "hyperparameter", "models"]}, {"paragraph_vector": [-83.447677, 19.347013], "paragraph_keywords": ["models", "model", "users", "performance"]}, {"paragraph_vector": [-81.040382, 21.04062], "paragraph_keywords": ["ensemble", "performance", "phase", "models"]}, {"paragraph_vector": [-83.104255, 21.408393], "paragraph_keywords": ["figure", "number", "projection", "views"]}, {"paragraph_vector": [-84.803428, 20.471208], "paragraph_keywords": ["data", "sets", "metrics", "ml"]}, {"paragraph_vector": [-84.549217, 19.270254], "paragraph_keywords": ["models", "figure", "space", "set"]}, {"paragraph_vector": [-177.975112, -1.271235], "paragraph_keywords": ["models", "figure", "axis", "bean"]}, {"paragraph_vector": [-86.759246, 18.539171], "paragraph_keywords": ["instances", "grid", "figure", "models"]}, {"paragraph_vector": [-82.860763, 19.900203], "paragraph_keywords": ["models", "figure", "mutation", "search"]}, {"paragraph_vector": [-85.981811, 19.067358], "paragraph_keywords": ["models", "figure", "ensemble", "crossover"]}, {"paragraph_vector": [-87.303344, 21.561628], "paragraph_keywords": ["molecules", "set", "majority", "figure"]}, {"paragraph_vector": [-86.121582, 18.629978], "paragraph_keywords": ["models", "figure", "metrics", "validation"]}, {"paragraph_vector": [-84.176155, 19.876455], "paragraph_keywords": ["models", "figure", "gradb", "mutation"]}, {"paragraph_vector": [-84.201805, 21.747171], "paragraph_keywords": ["ml", "data", "working", "accuracy"]}, {"paragraph_vector": [-82.105995, 23.111747], "paragraph_keywords": ["views", "models", "stages", "view"]}, {"paragraph_vector": [-85.160957, 19.760034], "paragraph_keywords": ["hyperparameters", "models", "visevol", "hyperparameter"]}, {"paragraph_vector": [-83.781936, 20.914691], "paragraph_keywords": ["visevol", "limitations", "ml", "john"]}], "content": {}, "doi": "empty"}, {"uri": "40", "title": "SenVis: Interactive Tensor-based Sensitivity Visualization", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Haiyan Yang", "Rafael Ballester-Ripoll", "Renato Pajarola"], "summary": "Sobol\u2019s method is one of the most powerful and widely used frameworks for global sensitivity analysis, and it maps every possible combination of input variables to an associated Sobol index. However, these indices are often challenging to analyze in depth, due in part to the lack of suitable, flexible enough, and fast-to-query data access structures as well as visualization techniques. We propose a visualization tool that leverages tensor decomposition, a compressed data format that can quickly and approximately answer sophisticated queries over exponential-sized sets of Sobol indices. This way, we are able to capture the complete global sensitivity information of high-dimensional scalar models. Our application is based on a three-stage visualization, to which variables to be analyzed can be added or removed interactively. It includes a novel hourglass-like diagram presenting the relative importance for any single variable or combination of input variables with respect to any composition of the rest of the input variables. We showcase our visualization with a range of example models, whereby we demonstrate the high expressive power and analytical capability made possible with the proposed method.", "keywords": ["view", "variable", "tuple", "task", "visualize", "bubble", "influence", "number", "sobol", "diagram", "type", "data", "interaction", "output", "input", "importance", "model", "example", "\u03b1", "index", "tensor", "fig", "set", "sensitivity", "based", "system", "use", "uncertainty", "analysis", "effect", "order", "bar", "\u03b2", "user", "visualization", "relation"], "document_vector": [158.541198, 17.259553], "paragraphs": [{"paragraph_vector": [163.456253, -9.952359], "paragraph_keywords": ["variables", "model", "input", "analysis"]}, {"paragraph_vector": [162.488464, -10.326114], "paragraph_keywords": ["sensitivity", "indices", "visualization", "subset"]}, {"paragraph_vector": [162.69728, -13.450075], "paragraph_keywords": ["indices", "variables", "decomposition", "sobol"]}, {"paragraph_vector": [162.726608, -9.726983], "paragraph_keywords": ["indices", "variables", "number", "based"]}, {"paragraph_vector": [168.665496, -18.063508], "paragraph_keywords": ["set", "visualization", "indices", "sets"]}, {"paragraph_vector": [163.564025, -9.084364], "paragraph_keywords": ["tensor", "tensors", "data", "dimensionality"]}, {"paragraph_vector": [164.763504, -9.960842], "paragraph_keywords": ["sobol", "tt", "sequence", "tensor"]}, {"paragraph_vector": [159.95729, -11.841297], "paragraph_keywords": ["indices", "index", "tuple", "variables"]}, {"paragraph_vector": [162.777252, -12.002107], "paragraph_keywords": ["model", "variables", "c\u03b1", "tasks"]}, {"paragraph_vector": [163.994812, -10.231133], "paragraph_keywords": ["variables", "sobol", "system", "indices"]}, {"paragraph_vector": [163.562652, -9.611341], "paragraph_keywords": ["view", "visualization", "variables", "indices"]}, {"paragraph_vector": [161.136322, -12.608123], "paragraph_keywords": ["indices", "sobol", "order", "variables"]}, {"paragraph_vector": [161.515884, -10.334966], "paragraph_keywords": ["sobol", "indices", "order", "model"]}, {"paragraph_vector": [-146.496246, -8.809783], "paragraph_keywords": ["indices", "sobol", "chart", "diagrams"]}, {"paragraph_vector": [161.219375, -9.686186], "paragraph_keywords": ["view", "variables", "tuple", "indices"]}, {"paragraph_vector": [162.023269, -16.115791], "paragraph_keywords": ["bubbles", "\u03b2", "variables", "importance"]}, {"paragraph_vector": [162.203872, -10.431873], "paragraph_keywords": ["model", "bubbles", "comparison", "design"]}, {"paragraph_vector": [-5.060648, -73.662765], "paragraph_keywords": ["variables", "\u03c8", "sensitivity", "model"]}, {"paragraph_vector": [162.285949, -10.700518], "paragraph_keywords": ["output", "variables", "model", "interaction"]}, {"paragraph_vector": [161.654846, -9.360789], "paragraph_keywords": ["variables", "interaction", "indices", "sobol"]}, {"paragraph_vector": [161.734985, -8.872805], "paragraph_keywords": ["variables", "indices", "sensitivity", "tensor"]}, {"paragraph_vector": [161.585983, -9.442028], "paragraph_keywords": ["variables", "models", "visualization", "system"]}], "content": {}, "doi": "empty"}, {"uri": "41", "title": "Hornero: Thunderstorms Characterization using Visual Analytics", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["Alexandra Diehl", "Rodrigo Pelorosso", "Juan Ruiz", "Renato Pajarola", "M. Eduard Gr\u00f6ller", "Stefan Bruckner"], "summary": "Analyzing the evolution of thunderstorms is critical in determining the potential for the development of severe weather events. Existing visualization systems for short-term weather forecasting (nowcasting) allow for basic analysis and prediction of storm developments. However, they lack advanced visual features for efficient decision-making. We developed a visual analytics tool for the detection of hazardous thunderstorms and their characterization, using a visual design centered on a reformulated expert task workflow that includes visual features to overview storms and quickly identify high-impact weather events, a novel storm graph visualization to inspect and analyze the storm structure, as well as a set of interactive views for efficient identification of similar storm cells (known as analogs) in historical data and their use for nowcasting. Our tool was designed with and evaluated by meteorologists and expert forecasters working in short-term operational weather forecasting of severe weather events. Results show that our solution suits the forecasters\u2019 workflow. Our visual design is expressive, easy to use, and effective for prompt analysis and quick decision-making in the context of short-range operational weather forecasting. CCS Concepts \u2022 Human-centered computing \u2192 Visual analytics; Visualization application domains;", "keywords": ["work", "forecasting", "view", "decision", "event", "provide", "domain", "task", "titan", "evolution", "cell", "reflectivity", "radar", "area", "tracking", "provided", "tool", "data", "example", "time", "weather", "interview", "property", "storm", "structure", "associated", "information", "graph", "based", "expert", "hornero", "use", "trajectory", "nowcasting", "analysis", "figure", "color", "design", "hail", "forecaster", "thunderstorm", "analyze", "visualization"], "document_vector": [-91.294242, -43.235637], "paragraphs": [{"paragraph_vector": [8.650927, -78.031478], "paragraph_keywords": ["thunderstorms", "forecasters", "storm", "time"]}, {"paragraph_vector": [-31.006944, -75.224769], "paragraph_keywords": ["visualization", "data", "storm", "weather"]}, {"paragraph_vector": [-29.094923, -75.691864], "paragraph_keywords": ["visualization", "design", "time", "data"]}, {"paragraph_vector": [84.633399, -63.487838], "paragraph_keywords": ["clustering", "storm", "structures", "regions"]}, {"paragraph_vector": [33.762771, -71.017807], "paragraph_keywords": ["visualizations", "storm", "clusters", "analysis"]}, {"paragraph_vector": [-14.200276, -75.578948], "paragraph_keywords": ["weather", "visualization", "data", "storm"]}, {"paragraph_vector": [-30.204212, -74.526977], "paragraph_keywords": ["weather", "expert", "domain", "storm"]}, {"paragraph_vector": [-4.215078, -77.191154], "paragraph_keywords": ["storm", "radar", "reflectivity", "data"]}, {"paragraph_vector": [-32.296249, -83.415626], "paragraph_keywords": ["storm", "cells", "events", "cell"]}, {"paragraph_vector": [14.762719, -77.781105], "paragraph_keywords": ["storm", "radar", "data", "visualization"]}, {"paragraph_vector": [-131.247848, -80.76963], "paragraph_keywords": ["storm", "color", "storms", "visualization"]}, {"paragraph_vector": [-10.57059, -80.229629], "paragraph_keywords": ["storm", "storms", "paths", "events"]}, {"paragraph_vector": [28.023832, -82.095695], "paragraph_keywords": ["storm", "layout", "graph", "branches"]}, {"paragraph_vector": [-14.079705, -77.819953], "paragraph_keywords": ["storm", "evolution", "view", "time"]}, {"paragraph_vector": [20.383943, -80.572509], "paragraph_keywords": ["storm", "radar", "property", "provided"]}, {"paragraph_vector": [36.68864, -77.382858], "paragraph_keywords": ["storm", "data", "figure", "trajectory"]}, {"paragraph_vector": [6.724645, -80.579551], "paragraph_keywords": ["storm", "figure", "analysis", "hail"]}, {"paragraph_vector": [27.389379, -81.435791], "paragraph_keywords": ["storm", "forecasting", "analysis", "time"]}, {"paragraph_vector": [-40.165706, -73.476219], "paragraph_keywords": ["design", "interviews", "nws", "weather"]}, {"paragraph_vector": [-30.762731, -76.329078], "paragraph_keywords": ["data", "tool", "analysis", "storm"]}, {"paragraph_vector": [-7.291685, -73.7807], "paragraph_keywords": ["storm", "visualization", "data", "experts"]}, {"paragraph_vector": [-167.84703, -51.025279], "paragraph_keywords": ["et", "al", "hornero"]}], "content": {}, "doi": "empty"}, {"uri": "42", "title": "AutoClips: An Automatic Approach to Video Generation from Data Facts", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["D. Shi", "F. Sun", "X. Xu", "X. Lan", "D. Gotz", "N. Cao"], "summary": "Data videos, a storytelling genre that visualizes data facts with motion graphics, are gaining increasing popularity among data journalists, non-profits, and marketers to communicate data to broad audiences. However, crafting a data video is often timeconsuming and asks for various domain knowledge such as data visualization, animation design, and screenwriting. Existing authoring tools usually enable users to edit and compose a set of templates manually, which still cost a lot of human effort. To further lower the barrier of creating data videos, this work introduces a new approach, AutoClips, which can automatically generate data videos given the input of a sequence of data facts. We built AutoClips through two stages. First, we constructed a fact-driven clip library where we mapped ten data facts to potential animated visualizations respectively by analyzing 230 online data videos and conducting interviews. Next, we constructed an algorithm that generates data videos from data facts through three steps: selecting and identifying the optimal clip for each of the data facts, arranging the clips into a coherent video, and optimizing the duration of the video. The results from two user studies indicated that the data videos generated by AutoClips are comprehensible, engaging, and have comparable quality with human-made videos. CCS Concepts \u2022 Human-centered computing \u2192 Information visualization; Visualization toolkits; Visualization systems and tools;", "keywords": ["work", "bubble", "value", "number", "type", "data", "tool", "example", "proposed", "animation", "structure", "set", "autoclips", "viewer", "creating", "sequence", "based", "consistency", "video", "participant", "algorithm", "designer", "transition", "including", "use", "fact", "animated", "design", "bar", "present", "clip", "user", "story", "library", "level", "change", "chart", "visualization"], "document_vector": [8.037498, -45.475872], "paragraphs": [{"paragraph_vector": [140.379592, -8.615286], "paragraph_keywords": ["data", "video", "users", "tools"]}, {"paragraph_vector": [135.253128, -9.906603], "paragraph_keywords": ["data", "videos", "algorithm", "autoclips"]}, {"paragraph_vector": [137.130981, -9.141471], "paragraph_keywords": ["data", "videos", "clips", "visualization"]}, {"paragraph_vector": [135.554672, -7.046029], "paragraph_keywords": ["data", "animation", "video", "graphics"]}, {"paragraph_vector": [137.016311, -7.992721], "paragraph_keywords": ["data", "animation", "facts", "autoclips"]}, {"paragraph_vector": [138.422378, -9.459143], "paragraph_keywords": ["data", "visualizations", "team", "videos"]}, {"paragraph_vector": [136.273696, -11.322647], "paragraph_keywords": ["data", "fact", "facts", "clip"]}, {"paragraph_vector": [134.825836, -8.024639], "paragraph_keywords": ["data", "design", "fact", "clip"]}, {"paragraph_vector": [134.672775, -7.996136], "paragraph_keywords": ["autoclips", "data", "visualization", "fact"]}, {"paragraph_vector": [139.402877, -8.736263], "paragraph_keywords": ["data", "video", "clips", "videos"]}, {"paragraph_vector": [146.707107, -21.025451], "paragraph_keywords": ["data", "clips", "design", "clip"]}, {"paragraph_vector": [-177.352416, -33.381824], "paragraph_keywords": ["charts", "value", "data", "bar"]}, {"paragraph_vector": [138.276367, -10.745502], "paragraph_keywords": ["data", "fact", "charts", "value"]}, {"paragraph_vector": [135.874313, -11.100303], "paragraph_keywords": ["clip", "data", "story", "transition"]}, {"paragraph_vector": [130.726608, -14.514506], "paragraph_keywords": ["fact", "visualizations", "sequence", "consistency"]}, {"paragraph_vector": [135.342086, -10.472116], "paragraph_keywords": ["fact", "autoclips", "clips", "data"]}, {"paragraph_vector": [133.308792, -11.399862], "paragraph_keywords": ["content", "autoclips", "viewers", "bubble"]}, {"paragraph_vector": [135.588195, -8.507506], "paragraph_keywords": ["data", "facts", "clips", "fi"]}, {"paragraph_vector": [-170.346878, -37.504993], "paragraph_keywords": ["participants", "data", "clips", "facts"]}, {"paragraph_vector": [139.00357, -6.924731], "paragraph_keywords": ["data", "library", "clips", "animation"]}, {"paragraph_vector": [136.43605, -8.599024], "paragraph_keywords": ["participants", "videos", "data", "study"]}, {"paragraph_vector": [137.488037, -8.705083], "paragraph_keywords": ["videos", "autoclips", "video", "data"]}, {"paragraph_vector": [133.85324, -6.052495], "paragraph_keywords": ["data", "videos", "clip", "autoclips"]}], "content": {}, "doi": "empty"}, {"uri": "43", "title": "What are Table Cartograms Good for Anyway? An Algebraic Analysis", "timestamp": "2021", "rating": "0.0", "annotation": "", "tags": [], "authors": ["A. McNutt"], "summary": "Unfamiliar or esoteric visual forms arise in many areas of visualization. While such forms can be intriguing, it can be unclear how to make effective use of them without long periods of practice or costly user studies. In this work we analyze the table cartogram\u2014a graphic which visualizes tabular data by bringing the areas of a grid of quadrilaterals into correspondence with the input data, like a heat map that has been \u201carea-ed\u201d rather than colored. Despite having existed for several years, little is known about its appropriate usage. We mend this gap by using Algebraic Visualization Design to show that they are best suited to relatively small tables with ordinal axes for some comparison and outlier identification tasks. In doing so we demonstrate a discount theory-based analysis that can be used to cheaply determine best practices for unknown visualizations. CCS Concepts \u2022 Human-centered computing \u2192 Visualization design and evaluation methods; Visualization theory, concepts and paradigms;", "keywords": ["work", "discussion", "way", "distribution", "usage", "provide", "focus", "task", "cell", "row", "value", "area", "space", "guideline", "cartograms", "type", "data", "avd", "column", "understanding", "property", "taco", "fig", "tree", "set", "quality", "find", "theory", "study", "based", "confuser", "assertion", "u", "hallucinator", "yield", "question", "use", "analysis", "form", "graphic", "unit", "evaluation", "design", "choice", "change", "chart", "visualization", "table"], "document_vector": [146.120773, -29.402452], "paragraphs": [{"paragraph_vector": [-102.953109, -31.383045], "paragraph_keywords": ["usage", "visualization", "chart", "analysis"]}, {"paragraph_vector": [-125.247749, -41.468223], "paragraph_keywords": ["tacos", "table", "analysis", "grid"]}, {"paragraph_vector": [-122.429039, -41.863212], "paragraph_keywords": ["data", "usage", "tacos", "based"]}, {"paragraph_vector": [-96.412078, -23.524332], "paragraph_keywords": ["based", "theories", "quality", "evaluation"]}, {"paragraph_vector": [-108.815788, -31.206848], "paragraph_keywords": ["data", "change", "changes", "visualization"]}, {"paragraph_vector": [-108.195724, -27.389034], "paragraph_keywords": ["data", "form", "analysis", "visualization"]}, {"paragraph_vector": [-99.565849, -23.354124], "paragraph_keywords": ["avd", "data", "design", "task"]}, {"paragraph_vector": [-126.079391, -43.178348], "paragraph_keywords": ["hallucinator", "reader", "taco", "designers"]}, {"paragraph_vector": [-129.49588, -45.805706], "paragraph_keywords": ["space", "types", "data", "tacos"]}, {"paragraph_vector": [-138.625396, -45.346553], "paragraph_keywords": ["data", "tables", "algorithm", "row"]}, {"paragraph_vector": [-130.079635, -46.095153], "paragraph_keywords": ["data", "interval", "value", "tacos"]}, {"paragraph_vector": [-126.124198, -43.612079], "paragraph_keywords": ["values", "data", "area", "choice"]}, {"paragraph_vector": [-130.654113, -46.128261], "paragraph_keywords": ["values", "bound", "pixel", "task"]}, {"paragraph_vector": [-124.152389, -43.047008], "paragraph_keywords": ["value", "task", "values", "typology"]}, {"paragraph_vector": [-121.36235, -41.552791], "paragraph_keywords": ["values", "comparison", "tacos", "addition"]}, {"paragraph_vector": [-129.131774, -45.372783], "paragraph_keywords": ["distribution", "u", "tacos", "comparisons"]}, {"paragraph_vector": [-136.90921, -47.732994], "paragraph_keywords": ["outliers", "tacos", "rows", "anomalies"]}, {"paragraph_vector": [88.391487, -45.020866], "paragraph_keywords": ["taco", "crossings", "distribution", "area"]}, {"paragraph_vector": [-132.442886, -45.0032], "paragraph_keywords": ["tasks", "use", "tacos", "magnitude"]}, {"paragraph_vector": [-127.558181, -45.20494], "paragraph_keywords": ["tacos", "area", "tree", "maps"]}, {"paragraph_vector": [134.103088, -7.432529], "paragraph_keywords": ["tacos", "calendars", "engagement", "tasks"]}, {"paragraph_vector": [-94.902015, -26.745965], "paragraph_keywords": ["design", "avd", "way", "evaluation"]}, {"paragraph_vector": [-119.767387, -41.035305], "paragraph_keywords": ["data", "form", "chart", "question"]}, {"paragraph_vector": [-94.508666, -27.440944], "paragraph_keywords": ["ava", "avd", "form", "context"]}, {"paragraph_vector": [-97.018051, -25.941532], "paragraph_keywords": ["theory", "analysis", "graphics", "explanation"]}, {"paragraph_vector": [-120.944038, -20.809589], "paragraph_keywords": ["race", "avd", "chart", "analysis"]}], "content": {}, "doi": "empty"}]